const text = `
HloModule SyncTensorsGraph.1561, input_output_alias={ {0}: (35, {}, must-alias), {1}: (36, {}, must-alias), {2}: (37, {}, must-alias), {3}: (38, {}, must-alias), {4}: (39, {}, must-alias), {5}: (40, {}, must-alias), {6}: (41, {}, must-alias), {7}: (42, {}, must-alias), {8}: (43, {}, must-alias), {9}: (44, {}, must-alias), {10}: (45, {}, must-alias), {11}: (46, {}, must-alias), {12}: (47, {}, must-alias), {13}: (48, {}, must-alias), {14}: (49, {}, must-alias), {15}: (50, {}, must-alias), {16}: (51, {}, must-alias), {17}: (52, {}, must-alias), {18}: (53, {}, must-alias), {19}: (54, {}, must-alias), {20}: (55, {}, must-alias), {21}: (56, {}, must-alias), {22}: (57, {}, must-alias), {23}: (58, {}, must-alias), {24}: (59, {}, must-alias), {25}: (60, {}, must-alias), {26}: (61, {}, must-alias), {27}: (62, {}, must-alias), {28}: (63, {}, must-alias), {29}: (64, {}, must-alias), {30}: (65, {}, must-alias) }

%AddComputation.18 (x.19: f32[], y.20: f32[]) -> f32[] {
  %x.19 = f32[] parameter(0)
  %y.20 = f32[] parameter(1)
  ROOT %add.21 = f32[] add(f32[] %x.19, f32[] %y.20)
}

%AddComputation.28 (x.29: f32[], y.30: f32[]) -> f32[] {
  %x.29 = f32[] parameter(0)
  %y.30 = f32[] parameter(1)
  ROOT %add.31 = f32[] add(f32[] %x.29, f32[] %y.30)
}

%AddComputation.38 (x.39: f32[], y.40: f32[]) -> f32[] {
  %x.39 = f32[] parameter(0)
  %y.40 = f32[] parameter(1)
  ROOT %add.41 = f32[] add(f32[] %x.39, f32[] %y.40)
}

%AddComputation.48 (x.49: f32[], y.50: f32[]) -> f32[] {
  %x.49 = f32[] parameter(0)
  %y.50 = f32[] parameter(1)
  ROOT %add.51 = f32[] add(f32[] %x.49, f32[] %y.50)
}

%AddComputation.58 (x.59: f32[], y.60: f32[]) -> f32[] {
  %x.59 = f32[] parameter(0)
  %y.60 = f32[] parameter(1)
  ROOT %add.61 = f32[] add(f32[] %x.59, f32[] %y.60)
}

%AddComputation.68 (x.69: f32[], y.70: f32[]) -> f32[] {
  %x.69 = f32[] parameter(0)
  %y.70 = f32[] parameter(1)
  ROOT %add.71 = f32[] add(f32[] %x.69, f32[] %y.70)
}

%AddComputation.78 (x.79: f32[], y.80: f32[]) -> f32[] {
  %x.79 = f32[] parameter(0)
  %y.80 = f32[] parameter(1)
  ROOT %add.81 = f32[] add(f32[] %x.79, f32[] %y.80)
}

%AddComputation.88 (x.89: f32[], y.90: f32[]) -> f32[] {
  %x.89 = f32[] parameter(0)
  %y.90 = f32[] parameter(1)
  ROOT %add.91 = f32[] add(f32[] %x.89, f32[] %y.90)
}

%AddComputation.98 (x.99: f32[], y.100: f32[]) -> f32[] {
  %x.99 = f32[] parameter(0)
  %y.100 = f32[] parameter(1)
  ROOT %add.101 = f32[] add(f32[] %x.99, f32[] %y.100)
}

%AddComputation.108 (x.109: f32[], y.110: f32[]) -> f32[] {
  %x.109 = f32[] parameter(0)
  %y.110 = f32[] parameter(1)
  ROOT %add.111 = f32[] add(f32[] %x.109, f32[] %y.110)
}

%AddComputation.118 (x.119: f32[], y.120: f32[]) -> f32[] {
  %x.119 = f32[] parameter(0)
  %y.120 = f32[] parameter(1)
  ROOT %add.121 = f32[] add(f32[] %x.119, f32[] %y.120)
}

%AddComputation.128 (x.129: f32[], y.130: f32[]) -> f32[] {
  %x.129 = f32[] parameter(0)
  %y.130 = f32[] parameter(1)
  ROOT %add.131 = f32[] add(f32[] %x.129, f32[] %y.130)
}

%AddComputation.138 (x.139: f32[], y.140: f32[]) -> f32[] {
  %x.139 = f32[] parameter(0)
  %y.140 = f32[] parameter(1)
  ROOT %add.141 = f32[] add(f32[] %x.139, f32[] %y.140)
}

%AddComputation.148 (x.149: f32[], y.150: f32[]) -> f32[] {
  %x.149 = f32[] parameter(0)
  %y.150 = f32[] parameter(1)
  ROOT %add.151 = f32[] add(f32[] %x.149, f32[] %y.150)
}

%AddComputation.158 (x.159: f32[], y.160: f32[]) -> f32[] {
  %x.159 = f32[] parameter(0)
  %y.160 = f32[] parameter(1)
  ROOT %add.161 = f32[] add(f32[] %x.159, f32[] %y.160)
}

%AddComputation.168 (x.169: f32[], y.170: f32[]) -> f32[] {
  %x.169 = f32[] parameter(0)
  %y.170 = f32[] parameter(1)
  ROOT %add.171 = f32[] add(f32[] %x.169, f32[] %y.170)
}

%AddComputation.178 (x.179: f32[], y.180: f32[]) -> f32[] {
  %x.179 = f32[] parameter(0)
  %y.180 = f32[] parameter(1)
  ROOT %add.181 = f32[] add(f32[] %x.179, f32[] %y.180)
}

%AddComputation.188 (x.189: f32[], y.190: f32[]) -> f32[] {
  %x.189 = f32[] parameter(0)
  %y.190 = f32[] parameter(1)
  ROOT %add.191 = f32[] add(f32[] %x.189, f32[] %y.190)
}

%AddComputation.198 (x.199: f32[], y.200: f32[]) -> f32[] {
  %x.199 = f32[] parameter(0)
  %y.200 = f32[] parameter(1)
  ROOT %add.201 = f32[] add(f32[] %x.199, f32[] %y.200)
}

%AddComputation.208 (x.209: f32[], y.210: f32[]) -> f32[] {
  %x.209 = f32[] parameter(0)
  %y.210 = f32[] parameter(1)
  ROOT %add.211 = f32[] add(f32[] %x.209, f32[] %y.210)
}

%AddComputation.218 (x.219: f32[], y.220: f32[]) -> f32[] {
  %x.219 = f32[] parameter(0)
  %y.220 = f32[] parameter(1)
  ROOT %add.221 = f32[] add(f32[] %x.219, f32[] %y.220)
}

%AddComputation.228 (x.229: f32[], y.230: f32[]) -> f32[] {
  %x.229 = f32[] parameter(0)
  %y.230 = f32[] parameter(1)
  ROOT %add.231 = f32[] add(f32[] %x.229, f32[] %y.230)
}

%AddComputation.238 (x.239: f32[], y.240: f32[]) -> f32[] {
  %x.239 = f32[] parameter(0)
  %y.240 = f32[] parameter(1)
  ROOT %add.241 = f32[] add(f32[] %x.239, f32[] %y.240)
}

%AddComputation.248 (x.249: f32[], y.250: f32[]) -> f32[] {
  %x.249 = f32[] parameter(0)
  %y.250 = f32[] parameter(1)
  ROOT %add.251 = f32[] add(f32[] %x.249, f32[] %y.250)
}

%AddComputation.258 (x.259: f32[], y.260: f32[]) -> f32[] {
  %x.259 = f32[] parameter(0)
  %y.260 = f32[] parameter(1)
  ROOT %add.261 = f32[] add(f32[] %x.259, f32[] %y.260)
}

%AddComputation.268 (x.269: f32[], y.270: f32[]) -> f32[] {
  %x.269 = f32[] parameter(0)
  %y.270 = f32[] parameter(1)
  ROOT %add.271 = f32[] add(f32[] %x.269, f32[] %y.270)
}

%AddComputation.278 (x.279: f32[], y.280: f32[]) -> f32[] {
  %x.279 = f32[] parameter(0)
  %y.280 = f32[] parameter(1)
  ROOT %add.281 = f32[] add(f32[] %x.279, f32[] %y.280)
}

%AddComputation.288 (x.289: f32[], y.290: f32[]) -> f32[] {
  %x.289 = f32[] parameter(0)
  %y.290 = f32[] parameter(1)
  ROOT %add.291 = f32[] add(f32[] %x.289, f32[] %y.290)
}

%AddComputation.298 (x.299: f32[], y.300: f32[]) -> f32[] {
  %x.299 = f32[] parameter(0)
  %y.300 = f32[] parameter(1)
  ROOT %add.301 = f32[] add(f32[] %x.299, f32[] %y.300)
}

%AddComputation.308 (x.309: f32[], y.310: f32[]) -> f32[] {
  %x.309 = f32[] parameter(0)
  %y.310 = f32[] parameter(1)
  ROOT %add.311 = f32[] add(f32[] %x.309, f32[] %y.310)
}

%AddComputation.348 (x.349: f32[], y.350: f32[]) -> f32[] {
  %x.349 = f32[] parameter(0)
  %y.350 = f32[] parameter(1)
  ROOT %add.351 = f32[] add(f32[] %x.349, f32[] %y.350)
}

ENTRY %SyncTensorsGraph.1561 (p0.8: f32[], p1.10: f32[], p2.14: f32[2], p3.24: f32[2,16], p4.34: f32[16], p5.44: f32[16], p6.54: f32[16], p7.64: f32[16,16], p8.74: f32[30522], p9.84: f32[16], p10.94: f32[16,16], p11.104: f32[16], p12.114: f32[16], p13.124: f32[16], p14.134: f32[16,4096], p15.144: f32[4096], p16.154: f32[4096,16], p17.164: f32[16], p18.174: f32[16], p19.184: f32[16], p20.194: f32[16,16], p21.204: f32[16], p22.214: f32[16,16], p23.224: f32[16], p24.234: f32[16,16], p25.244: f32[16], p26.254: f32[16,16], p27.264: f32[16], p28.274: f32[16], p29.284: f32[2,16], p30.294: f32[512,16], p31.304: f32[30522,16], p32.363: f32[], p33.378: f32[], p34.384: f32[], p35.393: f32[30522,16], p36.437: f32[512,16], p37.481: f32[2,16], p38.520: f32[16], p39.557: f32[16], p40.599: f32[16,16], p41.638: f32[16], p42.680: f32[16,16], p43.719: f32[16], p44.761: f32[16,16], p45.800: f32[16], p46.842: f32[16,16], p47.881: f32[16], p48.918: f32[16], p49.955: f32[16], p50.997: f32[4096,16], p51.1036: f32[4096], p52.1078: f32[16,4096], p53.1117: f32[16], p54.1154: f32[16], p55.1191: f32[16], p56.1233: f32[16,16], p57.1272: f32[16], p58.1314: f32[16,16], p59.1353: f32[16], p60.1390: f32[16], p61.1427: f32[16], p62.1464: f32[30522], p63.1506: f32[2,16], p64.1545: f32[2], p65.1554: f32[1]) -> (f32[30522,16], f32[512,16], f32[2,16], f32[16], f32[16], /*index=5*/f32[16,16], f32[16], f32[16,16], f32[16], f32[16,16], /*index=10*/f32[16], f32[16,16], f32[16], f32[16], f32[16], /*index=15*/f32[4096,16], f32[4096], f32[16,4096], f32[16], f32[16], /*index=20*/f32[16], f32[16,16], f32[16], f32[16,16], f32[16], /*index=25*/f32[16], f32[16], f32[30522], f32[2,16], f32[2], /*index=30*/f32[1], f32[1], f32[1], f32[30522,16], f32[30522,16], /*index=35*/f32[512,16], f32[512,16], f32[2,16], f32[2,16], f32[16,16], /*index=40*/f32[16,16], f32[16,16], f32[16,16], f32[16,16], f32[16,16], /*index=45*/f32[16,16], f32[16,16], f32[4096,16], f32[4096,16], f32[16,4096], /*index=50*/f32[16,4096], f32[16,16], f32[16,16], f32[16,16], f32[16,16], /*index=55*/f32[2,16], f32[2,16], f32[16], f32[16], f32[16], /*index=60*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=65*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=70*/f32[16], f32[16], f32[16], f32[4096], f32[4096], /*index=75*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=80*/f32[16], f32[16], f32[16], f32[30522], f32[30522], /*index=85*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=90*/f32[16], f32[2], f32[2], f32[1]) {
  %p35.393 = f32[30522,16]{1,0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant = f32[] constant(0)
  %p34.384 = f32[] parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.0 = f32[] multiply(f32[] %constant, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2 = f32[30522,16]{1,0} broadcast(f32[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %p31.304 = f32[30522,16]{1,0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.355 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=49}
  %multiply.305 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %p31.304, f32[30522,16]{1,0} %p31.304), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.306 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.312 = f32[] reduce(f32[30522,16]{1,0} %multiply.305, f32[] %constant.306), dimensions={0,1}, to_apply=%AddComputation.308, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.313 = f32[] sqrt(f32[] %reduce.312), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.314 = f32[1]{0} reshape(f32[] %sqrt.313), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p30.294 = f32[512,16]{1,0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.295 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %p30.294, f32[512,16]{1,0} %p30.294), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.296 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.302 = f32[] reduce(f32[512,16]{1,0} %multiply.295, f32[] %constant.296), dimensions={0,1}, to_apply=%AddComputation.298, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.303 = f32[] sqrt(f32[] %reduce.302), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.315 = f32[1]{0} reshape(f32[] %sqrt.303), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p29.284 = f32[2,16]{1,0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.285 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p29.284, f32[2,16]{1,0} %p29.284), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.286 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.292 = f32[] reduce(f32[2,16]{1,0} %multiply.285, f32[] %constant.286), dimensions={0,1}, to_apply=%AddComputation.288, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.293 = f32[] sqrt(f32[] %reduce.292), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.316 = f32[1]{0} reshape(f32[] %sqrt.293), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p28.274 = f32[16]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.275 = f32[16]{0} multiply(f32[16]{0} %p28.274, f32[16]{0} %p28.274), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.276 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.282 = f32[] reduce(f32[16]{0} %multiply.275, f32[] %constant.276), dimensions={0}, to_apply=%AddComputation.278, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.283 = f32[] sqrt(f32[] %reduce.282), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.317 = f32[1]{0} reshape(f32[] %sqrt.283), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p27.264 = f32[16]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.265 = f32[16]{0} multiply(f32[16]{0} %p27.264, f32[16]{0} %p27.264), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.266 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.272 = f32[] reduce(f32[16]{0} %multiply.265, f32[] %constant.266), dimensions={0}, to_apply=%AddComputation.268, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.273 = f32[] sqrt(f32[] %reduce.272), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.318 = f32[1]{0} reshape(f32[] %sqrt.273), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p26.254 = f32[16,16]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.255 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p26.254, f32[16,16]{1,0} %p26.254), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.256 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.262 = f32[] reduce(f32[16,16]{1,0} %multiply.255, f32[] %constant.256), dimensions={0,1}, to_apply=%AddComputation.258, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.263 = f32[] sqrt(f32[] %reduce.262), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.319 = f32[1]{0} reshape(f32[] %sqrt.263), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p25.244 = f32[16]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.245 = f32[16]{0} multiply(f32[16]{0} %p25.244, f32[16]{0} %p25.244), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.246 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.252 = f32[] reduce(f32[16]{0} %multiply.245, f32[] %constant.246), dimensions={0}, to_apply=%AddComputation.248, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.253 = f32[] sqrt(f32[] %reduce.252), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.320 = f32[1]{0} reshape(f32[] %sqrt.253), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p24.234 = f32[16,16]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.235 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p24.234, f32[16,16]{1,0} %p24.234), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.236 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.242 = f32[] reduce(f32[16,16]{1,0} %multiply.235, f32[] %constant.236), dimensions={0,1}, to_apply=%AddComputation.238, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.243 = f32[] sqrt(f32[] %reduce.242), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.321 = f32[1]{0} reshape(f32[] %sqrt.243), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p23.224 = f32[16]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.225 = f32[16]{0} multiply(f32[16]{0} %p23.224, f32[16]{0} %p23.224), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.226 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.232 = f32[] reduce(f32[16]{0} %multiply.225, f32[] %constant.226), dimensions={0}, to_apply=%AddComputation.228, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.233 = f32[] sqrt(f32[] %reduce.232), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.322 = f32[1]{0} reshape(f32[] %sqrt.233), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p22.214 = f32[16,16]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.215 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p22.214, f32[16,16]{1,0} %p22.214), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.216 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.222 = f32[] reduce(f32[16,16]{1,0} %multiply.215, f32[] %constant.216), dimensions={0,1}, to_apply=%AddComputation.218, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.223 = f32[] sqrt(f32[] %reduce.222), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.323 = f32[1]{0} reshape(f32[] %sqrt.223), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p21.204 = f32[16]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.205 = f32[16]{0} multiply(f32[16]{0} %p21.204, f32[16]{0} %p21.204), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.206 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.212 = f32[] reduce(f32[16]{0} %multiply.205, f32[] %constant.206), dimensions={0}, to_apply=%AddComputation.208, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.213 = f32[] sqrt(f32[] %reduce.212), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.324 = f32[1]{0} reshape(f32[] %sqrt.213), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p20.194 = f32[16,16]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.195 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p20.194, f32[16,16]{1,0} %p20.194), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.196 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.202 = f32[] reduce(f32[16,16]{1,0} %multiply.195, f32[] %constant.196), dimensions={0,1}, to_apply=%AddComputation.198, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.203 = f32[] sqrt(f32[] %reduce.202), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.325 = f32[1]{0} reshape(f32[] %sqrt.203), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p19.184 = f32[16]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.185 = f32[16]{0} multiply(f32[16]{0} %p19.184, f32[16]{0} %p19.184), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.186 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.192 = f32[] reduce(f32[16]{0} %multiply.185, f32[] %constant.186), dimensions={0}, to_apply=%AddComputation.188, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.193 = f32[] sqrt(f32[] %reduce.192), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.326 = f32[1]{0} reshape(f32[] %sqrt.193), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p18.174 = f32[16]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.175 = f32[16]{0} multiply(f32[16]{0} %p18.174, f32[16]{0} %p18.174), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.176 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.182 = f32[] reduce(f32[16]{0} %multiply.175, f32[] %constant.176), dimensions={0}, to_apply=%AddComputation.178, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.183 = f32[] sqrt(f32[] %reduce.182), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.327 = f32[1]{0} reshape(f32[] %sqrt.183), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p17.164 = f32[16]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.165 = f32[16]{0} multiply(f32[16]{0} %p17.164, f32[16]{0} %p17.164), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.166 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.172 = f32[] reduce(f32[16]{0} %multiply.165, f32[] %constant.166), dimensions={0}, to_apply=%AddComputation.168, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.173 = f32[] sqrt(f32[] %reduce.172), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.328 = f32[1]{0} reshape(f32[] %sqrt.173), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p16.154 = f32[4096,16]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.155 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %p16.154, f32[4096,16]{1,0} %p16.154), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.156 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.162 = f32[] reduce(f32[4096,16]{1,0} %multiply.155, f32[] %constant.156), dimensions={0,1}, to_apply=%AddComputation.158, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.163 = f32[] sqrt(f32[] %reduce.162), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.329 = f32[1]{0} reshape(f32[] %sqrt.163), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p15.144 = f32[4096]{0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.145 = f32[4096]{0} multiply(f32[4096]{0} %p15.144, f32[4096]{0} %p15.144), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.146 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.152 = f32[] reduce(f32[4096]{0} %multiply.145, f32[] %constant.146), dimensions={0}, to_apply=%AddComputation.148, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.153 = f32[] sqrt(f32[] %reduce.152), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.330 = f32[1]{0} reshape(f32[] %sqrt.153), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p14.134 = f32[16,4096]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.135 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %p14.134, f32[16,4096]{1,0} %p14.134), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.136 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.142 = f32[] reduce(f32[16,4096]{1,0} %multiply.135, f32[] %constant.136), dimensions={0,1}, to_apply=%AddComputation.138, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.143 = f32[] sqrt(f32[] %reduce.142), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.331 = f32[1]{0} reshape(f32[] %sqrt.143), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p13.124 = f32[16]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.125 = f32[16]{0} multiply(f32[16]{0} %p13.124, f32[16]{0} %p13.124), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.126 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.132 = f32[] reduce(f32[16]{0} %multiply.125, f32[] %constant.126), dimensions={0}, to_apply=%AddComputation.128, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.133 = f32[] sqrt(f32[] %reduce.132), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.332 = f32[1]{0} reshape(f32[] %sqrt.133), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p12.114 = f32[16]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.115 = f32[16]{0} multiply(f32[16]{0} %p12.114, f32[16]{0} %p12.114), metadata={op_type="aten__mul" op_name="aten__norm.20/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.116 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.122 = f32[] reduce(f32[16]{0} %multiply.115, f32[] %constant.116), dimensions={0}, to_apply=%AddComputation.118, metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.123 = f32[] sqrt(f32[] %reduce.122), metadata={op_type="aten__sqrt" op_name="aten__norm.20/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.333 = f32[1]{0} reshape(f32[] %sqrt.123), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p11.104 = f32[16]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.105 = f32[16]{0} multiply(f32[16]{0} %p11.104, f32[16]{0} %p11.104), metadata={op_type="aten__mul" op_name="aten__norm.21/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.106 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.112 = f32[] reduce(f32[16]{0} %multiply.105, f32[] %constant.106), dimensions={0}, to_apply=%AddComputation.108, metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.113 = f32[] sqrt(f32[] %reduce.112), metadata={op_type="aten__sqrt" op_name="aten__norm.21/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.334 = f32[1]{0} reshape(f32[] %sqrt.113), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p10.94 = f32[16,16]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.95 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p10.94, f32[16,16]{1,0} %p10.94), metadata={op_type="aten__mul" op_name="aten__norm.22/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.96 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.102 = f32[] reduce(f32[16,16]{1,0} %multiply.95, f32[] %constant.96), dimensions={0,1}, to_apply=%AddComputation.98, metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.103 = f32[] sqrt(f32[] %reduce.102), metadata={op_type="aten__sqrt" op_name="aten__norm.22/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.335 = f32[1]{0} reshape(f32[] %sqrt.103), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p9.84 = f32[16]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.85 = f32[16]{0} multiply(f32[16]{0} %p9.84, f32[16]{0} %p9.84), metadata={op_type="aten__mul" op_name="aten__norm.23/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.86 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.92 = f32[] reduce(f32[16]{0} %multiply.85, f32[] %constant.86), dimensions={0}, to_apply=%AddComputation.88, metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.93 = f32[] sqrt(f32[] %reduce.92), metadata={op_type="aten__sqrt" op_name="aten__norm.23/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.336 = f32[1]{0} reshape(f32[] %sqrt.93), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p8.74 = f32[30522]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.75 = f32[30522]{0} multiply(f32[30522]{0} %p8.74, f32[30522]{0} %p8.74), metadata={op_type="aten__mul" op_name="aten__norm.24/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.76 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.82 = f32[] reduce(f32[30522]{0} %multiply.75, f32[] %constant.76), dimensions={0}, to_apply=%AddComputation.78, metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.83 = f32[] sqrt(f32[] %reduce.82), metadata={op_type="aten__sqrt" op_name="aten__norm.24/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.337 = f32[1]{0} reshape(f32[] %sqrt.83), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p7.64 = f32[16,16]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.65 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p7.64, f32[16,16]{1,0} %p7.64), metadata={op_type="aten__mul" op_name="aten__norm.25/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.66 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.72 = f32[] reduce(f32[16,16]{1,0} %multiply.65, f32[] %constant.66), dimensions={0,1}, to_apply=%AddComputation.68, metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.73 = f32[] sqrt(f32[] %reduce.72), metadata={op_type="aten__sqrt" op_name="aten__norm.25/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.338 = f32[1]{0} reshape(f32[] %sqrt.73), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p6.54 = f32[16]{0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.55 = f32[16]{0} multiply(f32[16]{0} %p6.54, f32[16]{0} %p6.54), metadata={op_type="aten__mul" op_name="aten__norm.26/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.56 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.62 = f32[] reduce(f32[16]{0} %multiply.55, f32[] %constant.56), dimensions={0}, to_apply=%AddComputation.58, metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.63 = f32[] sqrt(f32[] %reduce.62), metadata={op_type="aten__sqrt" op_name="aten__norm.26/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.339 = f32[1]{0} reshape(f32[] %sqrt.63), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p5.44 = f32[16]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.45 = f32[16]{0} multiply(f32[16]{0} %p5.44, f32[16]{0} %p5.44), metadata={op_type="aten__mul" op_name="aten__norm.27/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.46 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.52 = f32[] reduce(f32[16]{0} %multiply.45, f32[] %constant.46), dimensions={0}, to_apply=%AddComputation.48, metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.53 = f32[] sqrt(f32[] %reduce.52), metadata={op_type="aten__sqrt" op_name="aten__norm.27/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.340 = f32[1]{0} reshape(f32[] %sqrt.53), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p4.34 = f32[16]{0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.35 = f32[16]{0} multiply(f32[16]{0} %p4.34, f32[16]{0} %p4.34), metadata={op_type="aten__mul" op_name="aten__norm.28/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.36 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.42 = f32[] reduce(f32[16]{0} %multiply.35, f32[] %constant.36), dimensions={0}, to_apply=%AddComputation.38, metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.43 = f32[] sqrt(f32[] %reduce.42), metadata={op_type="aten__sqrt" op_name="aten__norm.28/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.341 = f32[1]{0} reshape(f32[] %sqrt.43), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p3.24 = f32[2,16]{1,0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.25 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p3.24, f32[2,16]{1,0} %p3.24), metadata={op_type="aten__mul" op_name="aten__norm.29/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.26 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.32 = f32[] reduce(f32[2,16]{1,0} %multiply.25, f32[] %constant.26), dimensions={0,1}, to_apply=%AddComputation.28, metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.33 = f32[] sqrt(f32[] %reduce.32), metadata={op_type="aten__sqrt" op_name="aten__norm.29/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.342 = f32[1]{0} reshape(f32[] %sqrt.33), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %p2.14 = f32[2]{0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.15 = f32[2]{0} multiply(f32[2]{0} %p2.14, f32[2]{0} %p2.14), metadata={op_type="aten__mul" op_name="aten__norm.30/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.16 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.22 = f32[] reduce(f32[2]{0} %multiply.15, f32[] %constant.16), dimensions={0}, to_apply=%AddComputation.18, metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.23 = f32[] sqrt(f32[] %reduce.22), metadata={op_type="aten__sqrt" op_name="aten__norm.30/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reshape.343 = f32[1]{0} reshape(f32[] %sqrt.23), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %concatenate.344 = f32[30]{0} concatenate(f32[1]{0} %reshape.314, f32[1]{0} %reshape.315, f32[1]{0} %reshape.316, f32[1]{0} %reshape.317, f32[1]{0} %reshape.318, /*index=5*/f32[1]{0} %reshape.319, f32[1]{0} %reshape.320, f32[1]{0} %reshape.321, f32[1]{0} %reshape.322, f32[1]{0} %reshape.323, /*index=10*/f32[1]{0} %reshape.324, f32[1]{0} %reshape.325, f32[1]{0} %reshape.326, f32[1]{0} %reshape.327, f32[1]{0} %reshape.328, /*index=15*/f32[1]{0} %reshape.329, f32[1]{0} %reshape.330, f32[1]{0} %reshape.331, f32[1]{0} %reshape.332, f32[1]{0} %reshape.333, /*index=20*/f32[1]{0} %reshape.334, f32[1]{0} %reshape.335, f32[1]{0} %reshape.336, f32[1]{0} %reshape.337, f32[1]{0} %reshape.338, /*index=25*/f32[1]{0} %reshape.339, f32[1]{0} %reshape.340, f32[1]{0} %reshape.341, f32[1]{0} %reshape.342, f32[1]{0} %reshape.343), dimensions={0}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=41}
  %multiply.345 = f32[30]{0} multiply(f32[30]{0} %concatenate.344, f32[30]{0} %concatenate.344), metadata={op_type="aten__mul" op_name="aten__norm.31/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.346 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.31/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.352 = f32[] reduce(f32[30]{0} %multiply.345, f32[] %constant.346), dimensions={0}, to_apply=%AddComputation.348, metadata={op_type="aten__sum" op_name="aten__norm.31/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.353 = f32[] sqrt(f32[] %reduce.352), metadata={op_type="aten__sqrt" op_name="aten__norm.31/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %p0.8 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.354 = f32[] add(f32[] %sqrt.353, f32[] %p0.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=49}
  %divide.356 = f32[] divide(f32[] %constant.355, f32[] %add.354), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=49}
  %constant.2 = f32[] constant(1)
  %compare.359 = pred[] compare(f32[] %divide.356, f32[] %constant.2), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=50}
  %constant.11 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=51}
  %select.360 = f32[] select(pred[] %compare.359, f32[] %divide.356, f32[] %constant.11), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=50}
  %broadcast.361 = f32[30522,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.362 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %p31.304, f32[30522,16]{1,0} %broadcast.361), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %p33.378 = f32[] parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.382 = f32[30522,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.383 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.362, f32[30522,16]{1,0} %broadcast.382), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.392 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.2, f32[30522,16]{1,0} %multiply.383), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.3 = f32[] constant(0)
  %p32.363 = f32[] parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1 = f32[] multiply(f32[] %constant.3, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.7 = f32[30522,16]{1,0} broadcast(f32[] %multiply.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.371 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.362, f32[30522,16]{1,0} %multiply.362), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %p1.10 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.372 = f32[30522,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.373 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.371, f32[30522,16]{1,0} %broadcast.372), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.374 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.7, f32[30522,16]{1,0} %multiply.373), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.375 = f32[30522,16]{1,0} sqrt(f32[30522,16]{1,0} %add.374), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.376 = f32[30522,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.377 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %sqrt.375, f32[30522,16]{1,0} %broadcast.376), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.394 = f32[30522,16]{1,0} divide(f32[30522,16]{1,0} %add.392, f32[30522,16]{1,0} %add.377), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.6 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.395 = f32[30522,16]{1,0} broadcast(f32[] %constant.6), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.396 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %divide.394, f32[30522,16]{1,0} %broadcast.395), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.397 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %p35.393, f32[30522,16]{1,0} %multiply.396), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.5 = f32[30522,16]{1,0} broadcast(f32[] %constant.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.398 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %add.397, f32[30522,16]{1,0} %broadcast.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.399 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %add.397, f32[30522,16]{1,0} %multiply.398), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p36.437 = f32[512,16]{1,0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.4 = f32[] constant(0)
  %multiply.2 = f32[] multiply(f32[] %constant.4, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.10 = f32[512,16]{1,0} broadcast(f32[] %multiply.2), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.408 = f32[512,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.409 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %p30.294, f32[512,16]{1,0} %broadcast.408), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.427 = f32[512,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.428 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.409, f32[512,16]{1,0} %broadcast.427), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.436 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.10, f32[512,16]{1,0} %multiply.428), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.5 = f32[] constant(0)
  %multiply.3 = f32[] multiply(f32[] %constant.5, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.13 = f32[512,16]{1,0} broadcast(f32[] %multiply.3), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.417 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.409, f32[512,16]{1,0} %multiply.409), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.418 = f32[512,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.419 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.417, f32[512,16]{1,0} %broadcast.418), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.420 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.13, f32[512,16]{1,0} %multiply.419), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.421 = f32[512,16]{1,0} sqrt(f32[512,16]{1,0} %add.420), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.422 = f32[512,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.423 = f32[512,16]{1,0} add(f32[512,16]{1,0} %sqrt.421, f32[512,16]{1,0} %broadcast.422), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.438 = f32[512,16]{1,0} divide(f32[512,16]{1,0} %add.436, f32[512,16]{1,0} %add.423), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.405 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.439 = f32[512,16]{1,0} broadcast(f32[] %constant.405), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.440 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %divide.438, f32[512,16]{1,0} %broadcast.439), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.441 = f32[512,16]{1,0} add(f32[512,16]{1,0} %p36.437, f32[512,16]{1,0} %multiply.440), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.400 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.404 = f32[512,16]{1,0} broadcast(f32[] %constant.400), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.442 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %add.441, f32[512,16]{1,0} %broadcast.404), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.443 = f32[512,16]{1,0} add(f32[512,16]{1,0} %add.441, f32[512,16]{1,0} %multiply.442), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p37.481 = f32[2,16]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.8 = f32[] constant(0)
  %multiply.4 = f32[] multiply(f32[] %constant.8, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.16 = f32[2,16]{1,0} broadcast(f32[] %multiply.4), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.452 = f32[2,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.453 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p29.284, f32[2,16]{1,0} %broadcast.452), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.471 = f32[2,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.472 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.453, f32[2,16]{1,0} %broadcast.471), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.480 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.16, f32[2,16]{1,0} %multiply.472), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.9 = f32[] constant(0)
  %multiply.5 = f32[] multiply(f32[] %constant.9, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.19 = f32[2,16]{1,0} broadcast(f32[] %multiply.5), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.461 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.453, f32[2,16]{1,0} %multiply.453), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.462 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.463 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.461, f32[2,16]{1,0} %broadcast.462), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.464 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.19, f32[2,16]{1,0} %multiply.463), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.465 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.464), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.466 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.467 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.465, f32[2,16]{1,0} %broadcast.466), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.482 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.480, f32[2,16]{1,0} %add.467), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.449 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.483 = f32[2,16]{1,0} broadcast(f32[] %constant.449), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.484 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.482, f32[2,16]{1,0} %broadcast.483), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.485 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p37.481, f32[2,16]{1,0} %multiply.484), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.444 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.448 = f32[2,16]{1,0} broadcast(f32[] %constant.444), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.486 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.485, f32[2,16]{1,0} %broadcast.448), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.487 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.485, f32[2,16]{1,0} %multiply.486), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p38.520 = f32[16]{0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.10 = f32[] constant(0)
  %multiply.6 = f32[] multiply(f32[] %constant.10, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.22 = f32[16]{0} broadcast(f32[] %multiply.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.491 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.492 = f32[16]{0} multiply(f32[16]{0} %p28.274, f32[16]{0} %broadcast.491), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.510 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.511 = f32[16]{0} multiply(f32[16]{0} %multiply.492, f32[16]{0} %broadcast.510), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.519 = f32[16]{0} add(f32[16]{0} %broadcast.22, f32[16]{0} %multiply.511), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.13 = f32[] constant(0)
  %multiply.7 = f32[] multiply(f32[] %constant.13, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.25 = f32[16]{0} broadcast(f32[] %multiply.7), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.500 = f32[16]{0} multiply(f32[16]{0} %multiply.492, f32[16]{0} %multiply.492), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.501 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.502 = f32[16]{0} multiply(f32[16]{0} %multiply.500, f32[16]{0} %broadcast.501), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.503 = f32[16]{0} add(f32[16]{0} %broadcast.25, f32[16]{0} %multiply.502), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.504 = f32[16]{0} sqrt(f32[16]{0} %add.503), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.505 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.506 = f32[16]{0} add(f32[16]{0} %sqrt.504, f32[16]{0} %broadcast.505), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.521 = f32[16]{0} divide(f32[16]{0} %add.519, f32[16]{0} %add.506), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.488 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.522 = f32[16]{0} broadcast(f32[] %constant.488), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.523 = f32[16]{0} multiply(f32[16]{0} %divide.521, f32[16]{0} %broadcast.522), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.524 = f32[16]{0} add(f32[16]{0} %p38.520, f32[16]{0} %multiply.523), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p39.557 = f32[16]{0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.14 = f32[] constant(0)
  %multiply.8 = f32[] multiply(f32[] %constant.14, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.28 = f32[16]{0} broadcast(f32[] %multiply.8), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.528 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.529 = f32[16]{0} multiply(f32[16]{0} %p27.264, f32[16]{0} %broadcast.528), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.547 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.548 = f32[16]{0} multiply(f32[16]{0} %multiply.529, f32[16]{0} %broadcast.547), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.556 = f32[16]{0} add(f32[16]{0} %broadcast.28, f32[16]{0} %multiply.548), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.15 = f32[] constant(0)
  %multiply.10 = f32[] multiply(f32[] %constant.15, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.31 = f32[16]{0} broadcast(f32[] %multiply.10), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.537 = f32[16]{0} multiply(f32[16]{0} %multiply.529, f32[16]{0} %multiply.529), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.538 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.539 = f32[16]{0} multiply(f32[16]{0} %multiply.537, f32[16]{0} %broadcast.538), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.540 = f32[16]{0} add(f32[16]{0} %broadcast.31, f32[16]{0} %multiply.539), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.541 = f32[16]{0} sqrt(f32[16]{0} %add.540), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.542 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.543 = f32[16]{0} add(f32[16]{0} %sqrt.541, f32[16]{0} %broadcast.542), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.558 = f32[16]{0} divide(f32[16]{0} %add.556, f32[16]{0} %add.543), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.525 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.559 = f32[16]{0} broadcast(f32[] %constant.525), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.560 = f32[16]{0} multiply(f32[16]{0} %divide.558, f32[16]{0} %broadcast.559), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.561 = f32[16]{0} add(f32[16]{0} %p39.557, f32[16]{0} %multiply.560), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p40.599 = f32[16,16]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.18 = f32[] constant(0)
  %multiply.11 = f32[] multiply(f32[] %constant.18, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.34 = f32[16,16]{1,0} broadcast(f32[] %multiply.11), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.570 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.571 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p26.254, f32[16,16]{1,0} %broadcast.570), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.589 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.590 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.571, f32[16,16]{1,0} %broadcast.589), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.598 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.34, f32[16,16]{1,0} %multiply.590), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.19 = f32[] constant(0)
  %multiply.12 = f32[] multiply(f32[] %constant.19, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.37 = f32[16,16]{1,0} broadcast(f32[] %multiply.12), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.579 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.571, f32[16,16]{1,0} %multiply.571), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.580 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.581 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.579, f32[16,16]{1,0} %broadcast.580), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.582 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.37, f32[16,16]{1,0} %multiply.581), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.583 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.582), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.584 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.585 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.583, f32[16,16]{1,0} %broadcast.584), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.600 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.598, f32[16,16]{1,0} %add.585), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.567 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.601 = f32[16,16]{1,0} broadcast(f32[] %constant.567), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.602 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.600, f32[16,16]{1,0} %broadcast.601), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.603 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p40.599, f32[16,16]{1,0} %multiply.602), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.562 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.566 = f32[16,16]{1,0} broadcast(f32[] %constant.562), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.604 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.603, f32[16,16]{1,0} %broadcast.566), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.605 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.603, f32[16,16]{1,0} %multiply.604), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p41.638 = f32[16]{0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.20 = f32[] constant(0)
  %multiply.14 = f32[] multiply(f32[] %constant.20, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.40 = f32[16]{0} broadcast(f32[] %multiply.14), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.609 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.610 = f32[16]{0} multiply(f32[16]{0} %p25.244, f32[16]{0} %broadcast.609), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.628 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.629 = f32[16]{0} multiply(f32[16]{0} %multiply.610, f32[16]{0} %broadcast.628), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.637 = f32[16]{0} add(f32[16]{0} %broadcast.40, f32[16]{0} %multiply.629), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.21 = f32[] constant(0)
  %multiply.16 = f32[] multiply(f32[] %constant.21, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.43 = f32[16]{0} broadcast(f32[] %multiply.16), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.618 = f32[16]{0} multiply(f32[16]{0} %multiply.610, f32[16]{0} %multiply.610), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.619 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.620 = f32[16]{0} multiply(f32[16]{0} %multiply.618, f32[16]{0} %broadcast.619), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.621 = f32[16]{0} add(f32[16]{0} %broadcast.43, f32[16]{0} %multiply.620), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.622 = f32[16]{0} sqrt(f32[16]{0} %add.621), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.623 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.624 = f32[16]{0} add(f32[16]{0} %sqrt.622, f32[16]{0} %broadcast.623), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.639 = f32[16]{0} divide(f32[16]{0} %add.637, f32[16]{0} %add.624), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.606 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.640 = f32[16]{0} broadcast(f32[] %constant.606), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.641 = f32[16]{0} multiply(f32[16]{0} %divide.639, f32[16]{0} %broadcast.640), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.642 = f32[16]{0} add(f32[16]{0} %p41.638, f32[16]{0} %multiply.641), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p42.680 = f32[16,16]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.22 = f32[] constant(0)
  %multiply.17 = f32[] multiply(f32[] %constant.22, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.46 = f32[16,16]{1,0} broadcast(f32[] %multiply.17), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.651 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.652 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p24.234, f32[16,16]{1,0} %broadcast.651), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.670 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.671 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.652, f32[16,16]{1,0} %broadcast.670), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.679 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.46, f32[16,16]{1,0} %multiply.671), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.23 = f32[] constant(0)
  %multiply.18 = f32[] multiply(f32[] %constant.23, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.49 = f32[16,16]{1,0} broadcast(f32[] %multiply.18), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.660 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.652, f32[16,16]{1,0} %multiply.652), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.661 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.662 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.660, f32[16,16]{1,0} %broadcast.661), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.663 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.49, f32[16,16]{1,0} %multiply.662), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.664 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.663), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.665 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.666 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.664, f32[16,16]{1,0} %broadcast.665), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.681 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.679, f32[16,16]{1,0} %add.666), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.648 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.682 = f32[16,16]{1,0} broadcast(f32[] %constant.648), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.683 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.681, f32[16,16]{1,0} %broadcast.682), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.684 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p42.680, f32[16,16]{1,0} %multiply.683), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.643 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.647 = f32[16,16]{1,0} broadcast(f32[] %constant.643), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.685 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.684, f32[16,16]{1,0} %broadcast.647), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.686 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.684, f32[16,16]{1,0} %multiply.685), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p43.719 = f32[16]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.24 = f32[] constant(0)
  %multiply.19 = f32[] multiply(f32[] %constant.24, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.52 = f32[16]{0} broadcast(f32[] %multiply.19), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.690 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.691 = f32[16]{0} multiply(f32[16]{0} %p23.224, f32[16]{0} %broadcast.690), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.709 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.710 = f32[16]{0} multiply(f32[16]{0} %multiply.691, f32[16]{0} %broadcast.709), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.718 = f32[16]{0} add(f32[16]{0} %broadcast.52, f32[16]{0} %multiply.710), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.25 = f32[] constant(0)
  %multiply.20 = f32[] multiply(f32[] %constant.25, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.55 = f32[16]{0} broadcast(f32[] %multiply.20), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.699 = f32[16]{0} multiply(f32[16]{0} %multiply.691, f32[16]{0} %multiply.691), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.700 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.701 = f32[16]{0} multiply(f32[16]{0} %multiply.699, f32[16]{0} %broadcast.700), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.702 = f32[16]{0} add(f32[16]{0} %broadcast.55, f32[16]{0} %multiply.701), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.703 = f32[16]{0} sqrt(f32[16]{0} %add.702), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.704 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.705 = f32[16]{0} add(f32[16]{0} %sqrt.703, f32[16]{0} %broadcast.704), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.720 = f32[16]{0} divide(f32[16]{0} %add.718, f32[16]{0} %add.705), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.687 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.721 = f32[16]{0} broadcast(f32[] %constant.687), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.722 = f32[16]{0} multiply(f32[16]{0} %divide.720, f32[16]{0} %broadcast.721), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.723 = f32[16]{0} add(f32[16]{0} %p43.719, f32[16]{0} %multiply.722), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p44.761 = f32[16,16]{1,0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.28 = f32[] constant(0)
  %multiply.21 = f32[] multiply(f32[] %constant.28, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.58 = f32[16,16]{1,0} broadcast(f32[] %multiply.21), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.732 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.733 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p22.214, f32[16,16]{1,0} %broadcast.732), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.751 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.752 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.733, f32[16,16]{1,0} %broadcast.751), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.760 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.58, f32[16,16]{1,0} %multiply.752), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.29 = f32[] constant(0)
  %multiply.22 = f32[] multiply(f32[] %constant.29, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.61 = f32[16,16]{1,0} broadcast(f32[] %multiply.22), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.741 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.733, f32[16,16]{1,0} %multiply.733), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.742 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.743 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.741, f32[16,16]{1,0} %broadcast.742), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.744 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.61, f32[16,16]{1,0} %multiply.743), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.745 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.744), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.746 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.747 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.745, f32[16,16]{1,0} %broadcast.746), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.762 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.760, f32[16,16]{1,0} %add.747), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.729 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.763 = f32[16,16]{1,0} broadcast(f32[] %constant.729), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.764 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.762, f32[16,16]{1,0} %broadcast.763), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.765 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p44.761, f32[16,16]{1,0} %multiply.764), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.724 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.728 = f32[16,16]{1,0} broadcast(f32[] %constant.724), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.766 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.765, f32[16,16]{1,0} %broadcast.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.767 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.765, f32[16,16]{1,0} %multiply.766), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p45.800 = f32[16]{0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.30 = f32[] constant(0)
  %multiply.23 = f32[] multiply(f32[] %constant.30, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.64 = f32[16]{0} broadcast(f32[] %multiply.23), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.771 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.772 = f32[16]{0} multiply(f32[16]{0} %p21.204, f32[16]{0} %broadcast.771), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.790 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.791 = f32[16]{0} multiply(f32[16]{0} %multiply.772, f32[16]{0} %broadcast.790), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.799 = f32[16]{0} add(f32[16]{0} %broadcast.64, f32[16]{0} %multiply.791), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.31 = f32[] constant(0)
  %multiply.24 = f32[] multiply(f32[] %constant.31, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.67 = f32[16]{0} broadcast(f32[] %multiply.24), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.780 = f32[16]{0} multiply(f32[16]{0} %multiply.772, f32[16]{0} %multiply.772), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.781 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.782 = f32[16]{0} multiply(f32[16]{0} %multiply.780, f32[16]{0} %broadcast.781), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.783 = f32[16]{0} add(f32[16]{0} %broadcast.67, f32[16]{0} %multiply.782), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.784 = f32[16]{0} sqrt(f32[16]{0} %add.783), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.785 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.786 = f32[16]{0} add(f32[16]{0} %sqrt.784, f32[16]{0} %broadcast.785), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.801 = f32[16]{0} divide(f32[16]{0} %add.799, f32[16]{0} %add.786), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.768 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.802 = f32[16]{0} broadcast(f32[] %constant.768), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.803 = f32[16]{0} multiply(f32[16]{0} %divide.801, f32[16]{0} %broadcast.802), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.804 = f32[16]{0} add(f32[16]{0} %p45.800, f32[16]{0} %multiply.803), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p46.842 = f32[16,16]{1,0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.32 = f32[] constant(0)
  %multiply.26 = f32[] multiply(f32[] %constant.32, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.70 = f32[16,16]{1,0} broadcast(f32[] %multiply.26), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.813 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.814 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p20.194, f32[16,16]{1,0} %broadcast.813), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.832 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.833 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.814, f32[16,16]{1,0} %broadcast.832), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.841 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.70, f32[16,16]{1,0} %multiply.833), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.33 = f32[] constant(0)
  %multiply.27 = f32[] multiply(f32[] %constant.33, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.73 = f32[16,16]{1,0} broadcast(f32[] %multiply.27), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.822 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.814, f32[16,16]{1,0} %multiply.814), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.823 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.824 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.822, f32[16,16]{1,0} %broadcast.823), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.825 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.73, f32[16,16]{1,0} %multiply.824), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.826 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.825), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.827 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.828 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.826, f32[16,16]{1,0} %broadcast.827), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.843 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.841, f32[16,16]{1,0} %add.828), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.810 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.844 = f32[16,16]{1,0} broadcast(f32[] %constant.810), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.845 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.843, f32[16,16]{1,0} %broadcast.844), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.846 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p46.842, f32[16,16]{1,0} %multiply.845), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.805 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.809 = f32[16,16]{1,0} broadcast(f32[] %constant.805), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.847 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.846, f32[16,16]{1,0} %broadcast.809), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.848 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.846, f32[16,16]{1,0} %multiply.847), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p47.881 = f32[16]{0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.34 = f32[] constant(0)
  %multiply.28 = f32[] multiply(f32[] %constant.34, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.76 = f32[16]{0} broadcast(f32[] %multiply.28), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.852 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.853 = f32[16]{0} multiply(f32[16]{0} %p19.184, f32[16]{0} %broadcast.852), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.871 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.872 = f32[16]{0} multiply(f32[16]{0} %multiply.853, f32[16]{0} %broadcast.871), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.880 = f32[16]{0} add(f32[16]{0} %broadcast.76, f32[16]{0} %multiply.872), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.35 = f32[] constant(0)
  %multiply.29 = f32[] multiply(f32[] %constant.35, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.79 = f32[16]{0} broadcast(f32[] %multiply.29), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.861 = f32[16]{0} multiply(f32[16]{0} %multiply.853, f32[16]{0} %multiply.853), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.862 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.863 = f32[16]{0} multiply(f32[16]{0} %multiply.861, f32[16]{0} %broadcast.862), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.864 = f32[16]{0} add(f32[16]{0} %broadcast.79, f32[16]{0} %multiply.863), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.865 = f32[16]{0} sqrt(f32[16]{0} %add.864), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.866 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.867 = f32[16]{0} add(f32[16]{0} %sqrt.865, f32[16]{0} %broadcast.866), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.882 = f32[16]{0} divide(f32[16]{0} %add.880, f32[16]{0} %add.867), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.849 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.883 = f32[16]{0} broadcast(f32[] %constant.849), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.884 = f32[16]{0} multiply(f32[16]{0} %divide.882, f32[16]{0} %broadcast.883), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.885 = f32[16]{0} add(f32[16]{0} %p47.881, f32[16]{0} %multiply.884), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p48.918 = f32[16]{0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.38 = f32[] constant(0)
  %multiply.30 = f32[] multiply(f32[] %constant.38, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.82 = f32[16]{0} broadcast(f32[] %multiply.30), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.889 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.890 = f32[16]{0} multiply(f32[16]{0} %p18.174, f32[16]{0} %broadcast.889), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.908 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.909 = f32[16]{0} multiply(f32[16]{0} %multiply.890, f32[16]{0} %broadcast.908), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.917 = f32[16]{0} add(f32[16]{0} %broadcast.82, f32[16]{0} %multiply.909), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.39 = f32[] constant(0)
  %multiply.31 = f32[] multiply(f32[] %constant.39, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.85 = f32[16]{0} broadcast(f32[] %multiply.31), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.898 = f32[16]{0} multiply(f32[16]{0} %multiply.890, f32[16]{0} %multiply.890), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.899 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.900 = f32[16]{0} multiply(f32[16]{0} %multiply.898, f32[16]{0} %broadcast.899), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.901 = f32[16]{0} add(f32[16]{0} %broadcast.85, f32[16]{0} %multiply.900), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.902 = f32[16]{0} sqrt(f32[16]{0} %add.901), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.903 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.904 = f32[16]{0} add(f32[16]{0} %sqrt.902, f32[16]{0} %broadcast.903), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.919 = f32[16]{0} divide(f32[16]{0} %add.917, f32[16]{0} %add.904), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.886 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.920 = f32[16]{0} broadcast(f32[] %constant.886), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.921 = f32[16]{0} multiply(f32[16]{0} %divide.919, f32[16]{0} %broadcast.920), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.922 = f32[16]{0} add(f32[16]{0} %p48.918, f32[16]{0} %multiply.921), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p49.955 = f32[16]{0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.40 = f32[] constant(0)
  %multiply.32 = f32[] multiply(f32[] %constant.40, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.88 = f32[16]{0} broadcast(f32[] %multiply.32), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.926 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.927 = f32[16]{0} multiply(f32[16]{0} %p17.164, f32[16]{0} %broadcast.926), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.945 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.946 = f32[16]{0} multiply(f32[16]{0} %multiply.927, f32[16]{0} %broadcast.945), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.954 = f32[16]{0} add(f32[16]{0} %broadcast.88, f32[16]{0} %multiply.946), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.41 = f32[] constant(0)
  %multiply.33 = f32[] multiply(f32[] %constant.41, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.91 = f32[16]{0} broadcast(f32[] %multiply.33), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.935 = f32[16]{0} multiply(f32[16]{0} %multiply.927, f32[16]{0} %multiply.927), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.936 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.937 = f32[16]{0} multiply(f32[16]{0} %multiply.935, f32[16]{0} %broadcast.936), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.938 = f32[16]{0} add(f32[16]{0} %broadcast.91, f32[16]{0} %multiply.937), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.939 = f32[16]{0} sqrt(f32[16]{0} %add.938), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.940 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.941 = f32[16]{0} add(f32[16]{0} %sqrt.939, f32[16]{0} %broadcast.940), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.956 = f32[16]{0} divide(f32[16]{0} %add.954, f32[16]{0} %add.941), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.923 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.957 = f32[16]{0} broadcast(f32[] %constant.923), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.958 = f32[16]{0} multiply(f32[16]{0} %divide.956, f32[16]{0} %broadcast.957), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.959 = f32[16]{0} add(f32[16]{0} %p49.955, f32[16]{0} %multiply.958), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p50.997 = f32[4096,16]{1,0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.42 = f32[] constant(0)
  %multiply.34 = f32[] multiply(f32[] %constant.42, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.94 = f32[4096,16]{1,0} broadcast(f32[] %multiply.34), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.968 = f32[4096,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.969 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %p16.154, f32[4096,16]{1,0} %broadcast.968), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.987 = f32[4096,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.988 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.969, f32[4096,16]{1,0} %broadcast.987), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.996 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.94, f32[4096,16]{1,0} %multiply.988), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.43 = f32[] constant(0)
  %multiply.36 = f32[] multiply(f32[] %constant.43, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.97 = f32[4096,16]{1,0} broadcast(f32[] %multiply.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.977 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.969, f32[4096,16]{1,0} %multiply.969), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.978 = f32[4096,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.979 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.977, f32[4096,16]{1,0} %broadcast.978), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.980 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.97, f32[4096,16]{1,0} %multiply.979), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.981 = f32[4096,16]{1,0} sqrt(f32[4096,16]{1,0} %add.980), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.982 = f32[4096,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.983 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %sqrt.981, f32[4096,16]{1,0} %broadcast.982), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.998 = f32[4096,16]{1,0} divide(f32[4096,16]{1,0} %add.996, f32[4096,16]{1,0} %add.983), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.965 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.999 = f32[4096,16]{1,0} broadcast(f32[] %constant.965), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1000 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %divide.998, f32[4096,16]{1,0} %broadcast.999), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1001 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %p50.997, f32[4096,16]{1,0} %multiply.1000), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.960 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.964 = f32[4096,16]{1,0} broadcast(f32[] %constant.960), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1002 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %add.1001, f32[4096,16]{1,0} %broadcast.964), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1003 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %add.1001, f32[4096,16]{1,0} %multiply.1002), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p51.1036 = f32[4096]{0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.44 = f32[] constant(0)
  %multiply.37 = f32[] multiply(f32[] %constant.44, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.100 = f32[4096]{0} broadcast(f32[] %multiply.37), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1007 = f32[4096]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1008 = f32[4096]{0} multiply(f32[4096]{0} %p15.144, f32[4096]{0} %broadcast.1007), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1026 = f32[4096]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1027 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1008, f32[4096]{0} %broadcast.1026), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1035 = f32[4096]{0} add(f32[4096]{0} %broadcast.100, f32[4096]{0} %multiply.1027), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.45 = f32[] constant(0)
  %multiply.38 = f32[] multiply(f32[] %constant.45, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.103 = f32[4096]{0} broadcast(f32[] %multiply.38), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1016 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1008, f32[4096]{0} %multiply.1008), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1017 = f32[4096]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1018 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1016, f32[4096]{0} %broadcast.1017), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1019 = f32[4096]{0} add(f32[4096]{0} %broadcast.103, f32[4096]{0} %multiply.1018), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1020 = f32[4096]{0} sqrt(f32[4096]{0} %add.1019), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1021 = f32[4096]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1022 = f32[4096]{0} add(f32[4096]{0} %sqrt.1020, f32[4096]{0} %broadcast.1021), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1037 = f32[4096]{0} divide(f32[4096]{0} %add.1035, f32[4096]{0} %add.1022), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1004 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1038 = f32[4096]{0} broadcast(f32[] %constant.1004), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1039 = f32[4096]{0} multiply(f32[4096]{0} %divide.1037, f32[4096]{0} %broadcast.1038), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1040 = f32[4096]{0} add(f32[4096]{0} %p51.1036, f32[4096]{0} %multiply.1039), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p52.1078 = f32[16,4096]{1,0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.48 = f32[] constant(0)
  %multiply.39 = f32[] multiply(f32[] %constant.48, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.106 = f32[16,4096]{1,0} broadcast(f32[] %multiply.39), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1049 = f32[16,4096]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1050 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %p14.134, f32[16,4096]{1,0} %broadcast.1049), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1068 = f32[16,4096]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1069 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1050, f32[16,4096]{1,0} %broadcast.1068), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1077 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.106, f32[16,4096]{1,0} %multiply.1069), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.49 = f32[] constant(0)
  %multiply.40 = f32[] multiply(f32[] %constant.49, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.109 = f32[16,4096]{1,0} broadcast(f32[] %multiply.40), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1058 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1050, f32[16,4096]{1,0} %multiply.1050), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1059 = f32[16,4096]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1060 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1058, f32[16,4096]{1,0} %broadcast.1059), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1061 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.109, f32[16,4096]{1,0} %multiply.1060), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1062 = f32[16,4096]{1,0} sqrt(f32[16,4096]{1,0} %add.1061), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1063 = f32[16,4096]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1064 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %sqrt.1062, f32[16,4096]{1,0} %broadcast.1063), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1079 = f32[16,4096]{1,0} divide(f32[16,4096]{1,0} %add.1077, f32[16,4096]{1,0} %add.1064), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1046 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1080 = f32[16,4096]{1,0} broadcast(f32[] %constant.1046), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1081 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %divide.1079, f32[16,4096]{1,0} %broadcast.1080), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1082 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %p52.1078, f32[16,4096]{1,0} %multiply.1081), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1041 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1045 = f32[16,4096]{1,0} broadcast(f32[] %constant.1041), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1083 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %add.1082, f32[16,4096]{1,0} %broadcast.1045), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1084 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1082, f32[16,4096]{1,0} %multiply.1083), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p53.1117 = f32[16]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.50 = f32[] constant(0)
  %multiply.41 = f32[] multiply(f32[] %constant.50, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.112 = f32[16]{0} broadcast(f32[] %multiply.41), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1088 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1089 = f32[16]{0} multiply(f32[16]{0} %p13.124, f32[16]{0} %broadcast.1088), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1107 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1108 = f32[16]{0} multiply(f32[16]{0} %multiply.1089, f32[16]{0} %broadcast.1107), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1116 = f32[16]{0} add(f32[16]{0} %broadcast.112, f32[16]{0} %multiply.1108), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.51 = f32[] constant(0)
  %multiply.42 = f32[] multiply(f32[] %constant.51, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.115 = f32[16]{0} broadcast(f32[] %multiply.42), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1097 = f32[16]{0} multiply(f32[16]{0} %multiply.1089, f32[16]{0} %multiply.1089), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1098 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1099 = f32[16]{0} multiply(f32[16]{0} %multiply.1097, f32[16]{0} %broadcast.1098), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1100 = f32[16]{0} add(f32[16]{0} %broadcast.115, f32[16]{0} %multiply.1099), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1101 = f32[16]{0} sqrt(f32[16]{0} %add.1100), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1102 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1103 = f32[16]{0} add(f32[16]{0} %sqrt.1101, f32[16]{0} %broadcast.1102), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1118 = f32[16]{0} divide(f32[16]{0} %add.1116, f32[16]{0} %add.1103), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1085 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1119 = f32[16]{0} broadcast(f32[] %constant.1085), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1120 = f32[16]{0} multiply(f32[16]{0} %divide.1118, f32[16]{0} %broadcast.1119), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1121 = f32[16]{0} add(f32[16]{0} %p53.1117, f32[16]{0} %multiply.1120), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p54.1154 = f32[16]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.52 = f32[] constant(0)
  %multiply.43 = f32[] multiply(f32[] %constant.52, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.118 = f32[16]{0} broadcast(f32[] %multiply.43), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1125 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1126 = f32[16]{0} multiply(f32[16]{0} %p12.114, f32[16]{0} %broadcast.1125), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1144 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1145 = f32[16]{0} multiply(f32[16]{0} %multiply.1126, f32[16]{0} %broadcast.1144), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1153 = f32[16]{0} add(f32[16]{0} %broadcast.118, f32[16]{0} %multiply.1145), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.53 = f32[] constant(0)
  %multiply.44 = f32[] multiply(f32[] %constant.53, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.121 = f32[16]{0} broadcast(f32[] %multiply.44), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1134 = f32[16]{0} multiply(f32[16]{0} %multiply.1126, f32[16]{0} %multiply.1126), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1135 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1136 = f32[16]{0} multiply(f32[16]{0} %multiply.1134, f32[16]{0} %broadcast.1135), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1137 = f32[16]{0} add(f32[16]{0} %broadcast.121, f32[16]{0} %multiply.1136), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1138 = f32[16]{0} sqrt(f32[16]{0} %add.1137), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1139 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1140 = f32[16]{0} add(f32[16]{0} %sqrt.1138, f32[16]{0} %broadcast.1139), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1155 = f32[16]{0} divide(f32[16]{0} %add.1153, f32[16]{0} %add.1140), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1122 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1156 = f32[16]{0} broadcast(f32[] %constant.1122), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1157 = f32[16]{0} multiply(f32[16]{0} %divide.1155, f32[16]{0} %broadcast.1156), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1158 = f32[16]{0} add(f32[16]{0} %p54.1154, f32[16]{0} %multiply.1157), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p55.1191 = f32[16]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.54 = f32[] constant(0)
  %multiply.46 = f32[] multiply(f32[] %constant.54, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.124 = f32[16]{0} broadcast(f32[] %multiply.46), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1162 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1163 = f32[16]{0} multiply(f32[16]{0} %p11.104, f32[16]{0} %broadcast.1162), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1181 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1182 = f32[16]{0} multiply(f32[16]{0} %multiply.1163, f32[16]{0} %broadcast.1181), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1190 = f32[16]{0} add(f32[16]{0} %broadcast.124, f32[16]{0} %multiply.1182), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.55 = f32[] constant(0)
  %multiply.47 = f32[] multiply(f32[] %constant.55, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.127 = f32[16]{0} broadcast(f32[] %multiply.47), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1171 = f32[16]{0} multiply(f32[16]{0} %multiply.1163, f32[16]{0} %multiply.1163), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1172 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1173 = f32[16]{0} multiply(f32[16]{0} %multiply.1171, f32[16]{0} %broadcast.1172), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1174 = f32[16]{0} add(f32[16]{0} %broadcast.127, f32[16]{0} %multiply.1173), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1175 = f32[16]{0} sqrt(f32[16]{0} %add.1174), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1176 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1177 = f32[16]{0} add(f32[16]{0} %sqrt.1175, f32[16]{0} %broadcast.1176), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1192 = f32[16]{0} divide(f32[16]{0} %add.1190, f32[16]{0} %add.1177), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1159 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1193 = f32[16]{0} broadcast(f32[] %constant.1159), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1194 = f32[16]{0} multiply(f32[16]{0} %divide.1192, f32[16]{0} %broadcast.1193), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1195 = f32[16]{0} add(f32[16]{0} %p55.1191, f32[16]{0} %multiply.1194), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p56.1233 = f32[16,16]{1,0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.58 = f32[] constant(0)
  %multiply.48 = f32[] multiply(f32[] %constant.58, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.130 = f32[16,16]{1,0} broadcast(f32[] %multiply.48), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1204 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1205 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p10.94, f32[16,16]{1,0} %broadcast.1204), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1223 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1224 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1205, f32[16,16]{1,0} %broadcast.1223), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1232 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.130, f32[16,16]{1,0} %multiply.1224), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.59 = f32[] constant(0)
  %multiply.49 = f32[] multiply(f32[] %constant.59, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.133 = f32[16,16]{1,0} broadcast(f32[] %multiply.49), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1213 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1205, f32[16,16]{1,0} %multiply.1205), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1214 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1215 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1213, f32[16,16]{1,0} %broadcast.1214), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1216 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.133, f32[16,16]{1,0} %multiply.1215), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1217 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1216), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1218 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1219 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1217, f32[16,16]{1,0} %broadcast.1218), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1234 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1232, f32[16,16]{1,0} %add.1219), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1201 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1235 = f32[16,16]{1,0} broadcast(f32[] %constant.1201), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1236 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1234, f32[16,16]{1,0} %broadcast.1235), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1237 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p56.1233, f32[16,16]{1,0} %multiply.1236), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1196 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1200 = f32[16,16]{1,0} broadcast(f32[] %constant.1196), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1238 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1237, f32[16,16]{1,0} %broadcast.1200), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1239 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1237, f32[16,16]{1,0} %multiply.1238), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p57.1272 = f32[16]{0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.60 = f32[] constant(0)
  %multiply.50 = f32[] multiply(f32[] %constant.60, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.136 = f32[16]{0} broadcast(f32[] %multiply.50), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1243 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1244 = f32[16]{0} multiply(f32[16]{0} %p9.84, f32[16]{0} %broadcast.1243), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1262 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1263 = f32[16]{0} multiply(f32[16]{0} %multiply.1244, f32[16]{0} %broadcast.1262), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1271 = f32[16]{0} add(f32[16]{0} %broadcast.136, f32[16]{0} %multiply.1263), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.61 = f32[] constant(0)
  %multiply.51 = f32[] multiply(f32[] %constant.61, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.139 = f32[16]{0} broadcast(f32[] %multiply.51), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1252 = f32[16]{0} multiply(f32[16]{0} %multiply.1244, f32[16]{0} %multiply.1244), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1253 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1254 = f32[16]{0} multiply(f32[16]{0} %multiply.1252, f32[16]{0} %broadcast.1253), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1255 = f32[16]{0} add(f32[16]{0} %broadcast.139, f32[16]{0} %multiply.1254), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1256 = f32[16]{0} sqrt(f32[16]{0} %add.1255), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1257 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1258 = f32[16]{0} add(f32[16]{0} %sqrt.1256, f32[16]{0} %broadcast.1257), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1273 = f32[16]{0} divide(f32[16]{0} %add.1271, f32[16]{0} %add.1258), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1240 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1274 = f32[16]{0} broadcast(f32[] %constant.1240), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1275 = f32[16]{0} multiply(f32[16]{0} %divide.1273, f32[16]{0} %broadcast.1274), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1276 = f32[16]{0} add(f32[16]{0} %p57.1272, f32[16]{0} %multiply.1275), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p58.1314 = f32[16,16]{1,0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.62 = f32[] constant(0)
  %multiply.52 = f32[] multiply(f32[] %constant.62, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.142 = f32[16,16]{1,0} broadcast(f32[] %multiply.52), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1285 = f32[16,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1286 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p7.64, f32[16,16]{1,0} %broadcast.1285), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1304 = f32[16,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1305 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1286, f32[16,16]{1,0} %broadcast.1304), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1313 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.142, f32[16,16]{1,0} %multiply.1305), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.63 = f32[] constant(0)
  %multiply.53 = f32[] multiply(f32[] %constant.63, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.145 = f32[16,16]{1,0} broadcast(f32[] %multiply.53), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1294 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1286, f32[16,16]{1,0} %multiply.1286), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1295 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1296 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1294, f32[16,16]{1,0} %broadcast.1295), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1297 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.145, f32[16,16]{1,0} %multiply.1296), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1298 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1297), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1299 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1300 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1298, f32[16,16]{1,0} %broadcast.1299), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1315 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1313, f32[16,16]{1,0} %add.1300), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1282 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1316 = f32[16,16]{1,0} broadcast(f32[] %constant.1282), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1317 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1315, f32[16,16]{1,0} %broadcast.1316), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1318 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p58.1314, f32[16,16]{1,0} %multiply.1317), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1277 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1281 = f32[16,16]{1,0} broadcast(f32[] %constant.1277), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1319 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1318, f32[16,16]{1,0} %broadcast.1281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1320 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1318, f32[16,16]{1,0} %multiply.1319), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p59.1353 = f32[16]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.64 = f32[] constant(0)
  %multiply.54 = f32[] multiply(f32[] %constant.64, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.148 = f32[16]{0} broadcast(f32[] %multiply.54), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1324 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1325 = f32[16]{0} multiply(f32[16]{0} %p6.54, f32[16]{0} %broadcast.1324), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1343 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1344 = f32[16]{0} multiply(f32[16]{0} %multiply.1325, f32[16]{0} %broadcast.1343), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1352 = f32[16]{0} add(f32[16]{0} %broadcast.148, f32[16]{0} %multiply.1344), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.65 = f32[] constant(0)
  %multiply.56 = f32[] multiply(f32[] %constant.65, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.151 = f32[16]{0} broadcast(f32[] %multiply.56), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1333 = f32[16]{0} multiply(f32[16]{0} %multiply.1325, f32[16]{0} %multiply.1325), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1334 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1335 = f32[16]{0} multiply(f32[16]{0} %multiply.1333, f32[16]{0} %broadcast.1334), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1336 = f32[16]{0} add(f32[16]{0} %broadcast.151, f32[16]{0} %multiply.1335), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1337 = f32[16]{0} sqrt(f32[16]{0} %add.1336), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1338 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1339 = f32[16]{0} add(f32[16]{0} %sqrt.1337, f32[16]{0} %broadcast.1338), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1354 = f32[16]{0} divide(f32[16]{0} %add.1352, f32[16]{0} %add.1339), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1321 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1355 = f32[16]{0} broadcast(f32[] %constant.1321), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1356 = f32[16]{0} multiply(f32[16]{0} %divide.1354, f32[16]{0} %broadcast.1355), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1357 = f32[16]{0} add(f32[16]{0} %p59.1353, f32[16]{0} %multiply.1356), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p60.1390 = f32[16]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.68 = f32[] constant(0)
  %multiply.57 = f32[] multiply(f32[] %constant.68, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.154 = f32[16]{0} broadcast(f32[] %multiply.57), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1361 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1362 = f32[16]{0} multiply(f32[16]{0} %p5.44, f32[16]{0} %broadcast.1361), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1380 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1381 = f32[16]{0} multiply(f32[16]{0} %multiply.1362, f32[16]{0} %broadcast.1380), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1389 = f32[16]{0} add(f32[16]{0} %broadcast.154, f32[16]{0} %multiply.1381), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.69 = f32[] constant(0)
  %multiply.58 = f32[] multiply(f32[] %constant.69, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.157 = f32[16]{0} broadcast(f32[] %multiply.58), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1370 = f32[16]{0} multiply(f32[16]{0} %multiply.1362, f32[16]{0} %multiply.1362), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1371 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1372 = f32[16]{0} multiply(f32[16]{0} %multiply.1370, f32[16]{0} %broadcast.1371), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1373 = f32[16]{0} add(f32[16]{0} %broadcast.157, f32[16]{0} %multiply.1372), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1374 = f32[16]{0} sqrt(f32[16]{0} %add.1373), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1375 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1376 = f32[16]{0} add(f32[16]{0} %sqrt.1374, f32[16]{0} %broadcast.1375), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1391 = f32[16]{0} divide(f32[16]{0} %add.1389, f32[16]{0} %add.1376), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1358 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1392 = f32[16]{0} broadcast(f32[] %constant.1358), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1393 = f32[16]{0} multiply(f32[16]{0} %divide.1391, f32[16]{0} %broadcast.1392), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1394 = f32[16]{0} add(f32[16]{0} %p60.1390, f32[16]{0} %multiply.1393), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p61.1427 = f32[16]{0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.70 = f32[] constant(0)
  %multiply.59 = f32[] multiply(f32[] %constant.70, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.160 = f32[16]{0} broadcast(f32[] %multiply.59), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1398 = f32[16]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1399 = f32[16]{0} multiply(f32[16]{0} %p4.34, f32[16]{0} %broadcast.1398), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1417 = f32[16]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1418 = f32[16]{0} multiply(f32[16]{0} %multiply.1399, f32[16]{0} %broadcast.1417), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1426 = f32[16]{0} add(f32[16]{0} %broadcast.160, f32[16]{0} %multiply.1418), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.71 = f32[] constant(0)
  %multiply.60 = f32[] multiply(f32[] %constant.71, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.163 = f32[16]{0} broadcast(f32[] %multiply.60), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1407 = f32[16]{0} multiply(f32[16]{0} %multiply.1399, f32[16]{0} %multiply.1399), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1408 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1409 = f32[16]{0} multiply(f32[16]{0} %multiply.1407, f32[16]{0} %broadcast.1408), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1410 = f32[16]{0} add(f32[16]{0} %broadcast.163, f32[16]{0} %multiply.1409), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1411 = f32[16]{0} sqrt(f32[16]{0} %add.1410), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1412 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1413 = f32[16]{0} add(f32[16]{0} %sqrt.1411, f32[16]{0} %broadcast.1412), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1428 = f32[16]{0} divide(f32[16]{0} %add.1426, f32[16]{0} %add.1413), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1395 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1429 = f32[16]{0} broadcast(f32[] %constant.1395), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1430 = f32[16]{0} multiply(f32[16]{0} %divide.1428, f32[16]{0} %broadcast.1429), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1431 = f32[16]{0} add(f32[16]{0} %p61.1427, f32[16]{0} %multiply.1430), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p62.1464 = f32[30522]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.72 = f32[] constant(0)
  %multiply.61 = f32[] multiply(f32[] %constant.72, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.166 = f32[30522]{0} broadcast(f32[] %multiply.61), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1435 = f32[30522]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1436 = f32[30522]{0} multiply(f32[30522]{0} %p8.74, f32[30522]{0} %broadcast.1435), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1454 = f32[30522]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1455 = f32[30522]{0} multiply(f32[30522]{0} %multiply.1436, f32[30522]{0} %broadcast.1454), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1463 = f32[30522]{0} add(f32[30522]{0} %broadcast.166, f32[30522]{0} %multiply.1455), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.73 = f32[] constant(0)
  %multiply.62 = f32[] multiply(f32[] %constant.73, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.169 = f32[30522]{0} broadcast(f32[] %multiply.62), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1444 = f32[30522]{0} multiply(f32[30522]{0} %multiply.1436, f32[30522]{0} %multiply.1436), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1445 = f32[30522]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1446 = f32[30522]{0} multiply(f32[30522]{0} %multiply.1444, f32[30522]{0} %broadcast.1445), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1447 = f32[30522]{0} add(f32[30522]{0} %broadcast.169, f32[30522]{0} %multiply.1446), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1448 = f32[30522]{0} sqrt(f32[30522]{0} %add.1447), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1449 = f32[30522]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1450 = f32[30522]{0} add(f32[30522]{0} %sqrt.1448, f32[30522]{0} %broadcast.1449), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1465 = f32[30522]{0} divide(f32[30522]{0} %add.1463, f32[30522]{0} %add.1450), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1432 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1466 = f32[30522]{0} broadcast(f32[] %constant.1432), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1467 = f32[30522]{0} multiply(f32[30522]{0} %divide.1465, f32[30522]{0} %broadcast.1466), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1468 = f32[30522]{0} add(f32[30522]{0} %p62.1464, f32[30522]{0} %multiply.1467), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p63.1506 = f32[2,16]{1,0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.74 = f32[] constant(0)
  %multiply.63 = f32[] multiply(f32[] %constant.74, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.172 = f32[2,16]{1,0} broadcast(f32[] %multiply.63), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1477 = f32[2,16]{1,0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1478 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p3.24, f32[2,16]{1,0} %broadcast.1477), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1496 = f32[2,16]{1,0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1497 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.1478, f32[2,16]{1,0} %broadcast.1496), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1505 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.172, f32[2,16]{1,0} %multiply.1497), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.75 = f32[] constant(0)
  %multiply.64 = f32[] multiply(f32[] %constant.75, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.175 = f32[2,16]{1,0} broadcast(f32[] %multiply.64), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1486 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.1478, f32[2,16]{1,0} %multiply.1478), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1487 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1488 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.1486, f32[2,16]{1,0} %broadcast.1487), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1489 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.175, f32[2,16]{1,0} %multiply.1488), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1490 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.1489), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1491 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1492 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.1490, f32[2,16]{1,0} %broadcast.1491), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1507 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.1505, f32[2,16]{1,0} %add.1492), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1474 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1508 = f32[2,16]{1,0} broadcast(f32[] %constant.1474), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1509 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.1507, f32[2,16]{1,0} %broadcast.1508), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1510 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p63.1506, f32[2,16]{1,0} %multiply.1509), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1469 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1473 = f32[2,16]{1,0} broadcast(f32[] %constant.1469), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1511 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.1510, f32[2,16]{1,0} %broadcast.1473), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1512 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.1510, f32[2,16]{1,0} %multiply.1511), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %p64.1545 = f32[2]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.78 = f32[] constant(0)
  %multiply.66 = f32[] multiply(f32[] %constant.78, f32[] %p34.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.178 = f32[2]{0} broadcast(f32[] %multiply.66), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=113}
  %broadcast.1516 = f32[2]{0} broadcast(f32[] %select.360), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %multiply.1517 = f32[2]{0} multiply(f32[2]{0} %p2.14, f32[2]{0} %broadcast.1516), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/_patched_functions.py" source_line=53}
  %broadcast.1535 = f32[2]{0} broadcast(f32[] %p33.378), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1536 = f32[2]{0} multiply(f32[2]{0} %multiply.1517, f32[2]{0} %broadcast.1535), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1544 = f32[2]{0} add(f32[2]{0} %broadcast.178, f32[2]{0} %multiply.1536), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.79 = f32[] constant(0)
  %multiply.67 = f32[] multiply(f32[] %constant.79, f32[] %p32.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.181 = f32[2]{0} broadcast(f32[] %multiply.67), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=115}
  %multiply.1525 = f32[2]{0} multiply(f32[2]{0} %multiply.1517, f32[2]{0} %multiply.1517), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1526 = f32[2]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1527 = f32[2]{0} multiply(f32[2]{0} %multiply.1525, f32[2]{0} %broadcast.1526), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1528 = f32[2]{0} add(f32[2]{0} %broadcast.181, f32[2]{0} %multiply.1527), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1529 = f32[2]{0} sqrt(f32[2]{0} %add.1528), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1530 = f32[2]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1531 = f32[2]{0} add(f32[2]{0} %sqrt.1529, f32[2]{0} %broadcast.1530), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1546 = f32[2]{0} divide(f32[2]{0} %add.1544, f32[2]{0} %add.1531), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1513 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1547 = f32[2]{0} broadcast(f32[] %constant.1513), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1548 = f32[2]{0} multiply(f32[2]{0} %divide.1546, f32[2]{0} %broadcast.1547), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1549 = f32[2]{0} add(f32[2]{0} %p64.1545, f32[2]{0} %multiply.1548), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.80 = f32[1]{0} constant({0})
  %p65.1554 = f32[1]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="dp_bert_large_hf_pretrain_hdf5.py" source_line=356}
  %constant.82 = f32[1]{0} constant({0})
  ROOT %tuple.1560 = (f32[30522,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, /*index=5*/f32[16,16]{1,0}, f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, f32[16,16]{1,0}, /*index=10*/f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=15*/f32[4096,16]{1,0}, f32[4096]{0}, f32[16,4096]{1,0}, f32[16]{0}, f32[16]{0}, /*index=20*/f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, /*index=25*/f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[2,16]{1,0}, f32[2]{0}, /*index=30*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[30522,16]{1,0}, f32[30522,16]{1,0}, /*index=35*/f32[512,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=40*/f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=45*/f32[16,16]{1,0}, f32[16,16]{1,0}, f32[4096,16]{1,0}, f32[4096,16]{1,0}, f32[16,4096]{1,0}, /*index=50*/f32[16,4096]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=55*/f32[2,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=60*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=65*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=70*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, f32[4096]{0}, /*index=75*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=80*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[30522]{0}, /*index=85*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=90*/f32[16]{0}, f32[2]{0}, f32[2]{0}, f32[1]{0}) tuple(f32[30522,16]{1,0} %add.399, f32[512,16]{1,0} %add.443, f32[2,16]{1,0} %add.487, f32[16]{0} %add.524, f32[16]{0} %add.561, /*index=5*/f32[16,16]{1,0} %add.605, f32[16]{0} %add.642, f32[16,16]{1,0} %add.686, f32[16]{0} %add.723, f32[16,16]{1,0} %add.767, /*index=10*/f32[16]{0} %add.804, f32[16,16]{1,0} %add.848, f32[16]{0} %add.885, f32[16]{0} %add.922, f32[16]{0} %add.959, /*index=15*/f32[4096,16]{1,0} %add.1003, f32[4096]{0} %add.1040, f32[16,4096]{1,0} %add.1084, f32[16]{0} %add.1121, f32[16]{0} %add.1158, /*index=20*/f32[16]{0} %add.1195, f32[16,16]{1,0} %add.1239, f32[16]{0} %add.1276, f32[16,16]{1,0} %add.1320, f32[16]{0} %add.1357, /*index=25*/f32[16]{0} %add.1394, f32[16]{0} %add.1431, f32[30522]{0} %add.1468, f32[2,16]{1,0} %add.1512, f32[2]{0} %add.1549, /*index=30*/f32[1]{0} %constant.80, f32[1]{0} %p65.1554, f32[1]{0} %p65.1554, f32[30522,16]{1,0} %add.392, f32[30522,16]{1,0} %add.374, /*index=35*/f32[512,16]{1,0} %add.436, f32[512,16]{1,0} %add.420, f32[2,16]{1,0} %add.480, f32[2,16]{1,0} %add.464, f32[16,16]{1,0} %add.598, /*index=40*/f32[16,16]{1,0} %add.582, f32[16,16]{1,0} %add.679, f32[16,16]{1,0} %add.663, f32[16,16]{1,0} %add.760, f32[16,16]{1,0} %add.744, /*index=45*/f32[16,16]{1,0} %add.841, f32[16,16]{1,0} %add.825, f32[4096,16]{1,0} %add.996, f32[4096,16]{1,0} %add.980, f32[16,4096]{1,0} %add.1077, /*index=50*/f32[16,4096]{1,0} %add.1061, f32[16,16]{1,0} %add.1232, f32[16,16]{1,0} %add.1216, f32[16,16]{1,0} %add.1313, f32[16,16]{1,0} %add.1297, /*index=55*/f32[2,16]{1,0} %add.1505, f32[2,16]{1,0} %add.1489, f32[16]{0} %add.519, f32[16]{0} %add.503, f32[16]{0} %add.556, /*index=60*/f32[16]{0} %add.540, f32[16]{0} %add.637, f32[16]{0} %add.621, f32[16]{0} %add.718, f32[16]{0} %add.702, /*index=65*/f32[16]{0} %add.799, f32[16]{0} %add.783, f32[16]{0} %add.880, f32[16]{0} %add.864, f32[16]{0} %add.917, /*index=70*/f32[16]{0} %add.901, f32[16]{0} %add.954, f32[16]{0} %add.938, f32[4096]{0} %add.1035, f32[4096]{0} %add.1019, /*index=75*/f32[16]{0} %add.1116, f32[16]{0} %add.1100, f32[16]{0} %add.1153, f32[16]{0} %add.1137, f32[16]{0} %add.1190, /*index=80*/f32[16]{0} %add.1174, f32[16]{0} %add.1271, f32[16]{0} %add.1255, f32[30522]{0} %add.1463, f32[30522]{0} %add.1447, /*index=85*/f32[16]{0} %add.1352, f32[16]{0} %add.1336, f32[16]{0} %add.1389, f32[16]{0} %add.1373, f32[16]{0} %add.1426, /*index=90*/f32[16]{0} %add.1410, f32[2]{0} %add.1544, f32[2]{0} %add.1528, f32[1]{0} %constant.82), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93"}
}

`

export default text;
