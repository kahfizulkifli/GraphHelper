const text = `
HloModule SyncTensorsGraph.2840, input_output_alias={ {0}: (7, {}, must-alias), {1}: (3, {}, must-alias), {2}: (5, {}, must-alias), {3}: (8, {}, must-alias), {4}: (14, {}, must-alias), {5}: (2, {}, must-alias), {6}: (11, {}, must-alias), {7}: (18, {}, must-alias), {8}: (13, {}, must-alias), {9}: (12, {}, must-alias), {10}: (20, {}, must-alias), {11}: (19, {}, must-alias), {12}: (21, {}, must-alias), {13}: (22, {}, must-alias), {14}: (23, {}, must-alias), {15}: (26, {}, must-alias), {16}: (24, {}, must-alias), {17}: (25, {}, must-alias), {18}: (27, {}, must-alias), {19}: (28, {}, must-alias), {20}: (29, {}, must-alias), {21}: (32, {}, must-alias), {22}: (30, {}, must-alias), {23}: (31, {}, must-alias), {24}: (37, {}, must-alias), {25}: (38, {}, must-alias), {26}: (39, {}, must-alias), {27}: (42, {}, must-alias), {28}: (41, {}, must-alias), {29}: (33, {}, must-alias), {30}: (35, {}, must-alias), {31}: (108, {}, must-alias), {32}: (48, {}, must-alias), {33}: (45, {}, must-alias), {34}: (50, {}, must-alias), {35}: (49, {}, must-alias), {36}: (52, {}, must-alias), {37}: (51, {}, must-alias), {38}: (58, {}, must-alias), {39}: (57, {}, must-alias), {40}: (62, {}, must-alias), {41}: (61, {}, must-alias), {42}: (66, {}, must-alias), {43}: (65, {}, must-alias), {44}: (70, {}, must-alias), {45}: (69, {}, must-alias), {46}: (78, {}, must-alias), {47}: (77, {}, must-alias), {48}: (82, {}, must-alias), {49}: (81, {}, must-alias), {50}: (90, {}, must-alias), {51}: (89, {}, must-alias), {52}: (94, {}, must-alias), {53}: (93, {}, must-alias), {54}: (104, {}, must-alias), {55}: (103, {}, must-alias), {56}: (54, {}, must-alias), {57}: (53, {}, must-alias), {58}: (56, {}, must-alias), {59}: (55, {}, must-alias), {60}: (60, {}, must-alias), {61}: (59, {}, must-alias), {62}: (64, {}, must-alias), {63}: (63, {}, must-alias), {64}: (68, {}, must-alias), {65}: (67, {}, must-alias), {66}: (72, {}, must-alias), {67}: (71, {}, must-alias), {68}: (74, {}, must-alias), {69}: (73, {}, must-alias), {70}: (76, {}, must-alias), {71}: (75, {}, must-alias), {72}: (80, {}, must-alias), {73}: (79, {}, must-alias), {74}: (84, {}, must-alias), {75}: (83, {}, must-alias), {76}: (86, {}, must-alias), {77}: (85, {}, must-alias), {78}: (88, {}, must-alias), {79}: (87, {}, must-alias), {80}: (92, {}, must-alias), {81}: (91, {}, must-alias), {82}: (102, {}, must-alias), {83}: (101, {}, must-alias), {84}: (96, {}, must-alias), {85}: (95, {}, must-alias), {86}: (98, {}, must-alias), {87}: (97, {}, must-alias), {88}: (100, {}, must-alias), {89}: (99, {}, must-alias), {90}: (106, {}, must-alias), {91}: (105, {}, must-alias), {93}: (6, {}, must-alias), {94}: (4, {}, must-alias), {95}: (17, {}, must-alias), {96}: (40, {}, must-alias), {97}: (34, {}, must-alias) }

%MaxComputation.299 (x.300: bf16[], y.301: bf16[]) -> bf16[] {
  %x.300 = bf16[] parameter(0)
  %y.301 = bf16[] parameter(1)
  ROOT %maximum.302 = bf16[] maximum(bf16[] %x.300, bf16[] %y.301)
}

%AddComputation.308 (x.309: bf16[], y.310: bf16[]) -> bf16[] {
  %x.309 = bf16[] parameter(0)
  %y.310 = bf16[] parameter(1)
  ROOT %add.311 = bf16[] add(bf16[] %x.309, bf16[] %y.310)
}

%AddComputation.1248 (x.1249: bf16[], y.1250: bf16[]) -> bf16[] {
  %x.1249 = bf16[] parameter(0)
  %y.1250 = bf16[] parameter(1)
  ROOT %add.1251 = bf16[] add(bf16[] %x.1249, bf16[] %y.1250)
}

%ScatterCombiner.1350 (p0.1351: bf16[], p1.1352: bf16[]) -> bf16[] {
  %p0.1351 = bf16[] parameter(0)
  %p1.1352 = bf16[] parameter(1)
  ROOT %add.1353 = bf16[] add(bf16[] %p0.1351, bf16[] %p1.1352)
}

%AddComputation.1420 (x.1421: bf16[], y.1422: bf16[]) -> bf16[] {
  %x.1421 = bf16[] parameter(0)
  %y.1422 = bf16[] parameter(1)
  ROOT %add.1423 = bf16[] add(bf16[] %x.1421, bf16[] %y.1422)
}

%AddComputation.1560 (x.1561: bf16[], y.1562: bf16[]) -> bf16[] {
  %x.1561 = bf16[] parameter(0)
  %y.1562 = bf16[] parameter(1)
  ROOT %add.1563 = bf16[] add(bf16[] %x.1561, bf16[] %y.1562)
}

%AddComputation.1605 (x.1606: bf16[], y.1607: bf16[]) -> bf16[] {
  %x.1606 = bf16[] parameter(0)
  %y.1607 = bf16[] parameter(1)
  ROOT %add.1608 = bf16[] add(bf16[] %x.1606, bf16[] %y.1607)
}

%AddComputation.1986 (x.1987: bf16[], y.1988: bf16[]) -> bf16[] {
  %x.1987 = bf16[] parameter(0)
  %y.1988 = bf16[] parameter(1)
  ROOT %add.1989 = bf16[] add(bf16[] %x.1987, bf16[] %y.1988)
}

%AddComputation.2038 (x.2039: bf16[], y.2040: bf16[]) -> bf16[] {
  %x.2039 = bf16[] parameter(0)
  %y.2040 = bf16[] parameter(1)
  ROOT %add.2041 = bf16[] add(bf16[] %x.2039, bf16[] %y.2040)
}

%AddComputation.2083 (x.2084: bf16[], y.2085: bf16[]) -> bf16[] {
  %x.2084 = bf16[] parameter(0)
  %y.2085 = bf16[] parameter(1)
  ROOT %add.2086 = bf16[] add(bf16[] %x.2084, bf16[] %y.2085)
}

%AddComputation.2175 (x.2176: bf16[], y.2177: bf16[]) -> bf16[] {
  %x.2176 = bf16[] parameter(0)
  %y.2177 = bf16[] parameter(1)
  ROOT %add.2178 = bf16[] add(bf16[] %x.2176, bf16[] %y.2177)
}

%AddComputation.2267 (x.2268: bf16[], y.2269: bf16[]) -> bf16[] {
  %x.2268 = bf16[] parameter(0)
  %y.2269 = bf16[] parameter(1)
  ROOT %add.2270 = bf16[] add(bf16[] %x.2268, bf16[] %y.2269)
}

%AddComputation.2319 (x.2320: bf16[], y.2321: bf16[]) -> bf16[] {
  %x.2320 = bf16[] parameter(0)
  %y.2321 = bf16[] parameter(1)
  ROOT %add.2322 = bf16[] add(bf16[] %x.2320, bf16[] %y.2321)
}

%AddComputation.2364 (x.2365: bf16[], y.2366: bf16[]) -> bf16[] {
  %x.2365 = bf16[] parameter(0)
  %y.2366 = bf16[] parameter(1)
  ROOT %add.2367 = bf16[] add(bf16[] %x.2365, bf16[] %y.2366)
}

%AddComputation.2458 (x.2459: bf16[], y.2460: bf16[]) -> bf16[] {
  %x.2459 = bf16[] parameter(0)
  %y.2460 = bf16[] parameter(1)
  ROOT %add.2461 = bf16[] add(bf16[] %x.2459, bf16[] %y.2460)
}

%AddComputation.2550 (x.2551: bf16[], y.2552: bf16[]) -> bf16[] {
  %x.2551 = bf16[] parameter(0)
  %y.2552 = bf16[] parameter(1)
  ROOT %add.2553 = bf16[] add(bf16[] %x.2551, bf16[] %y.2552)
}

%AddComputation.2602 (x.2603: bf16[], y.2604: bf16[]) -> bf16[] {
  %x.2603 = bf16[] parameter(0)
  %y.2604 = bf16[] parameter(1)
  ROOT %add.2605 = bf16[] add(bf16[] %x.2603, bf16[] %y.2604)
}

%AddComputation.2784 (x.2785: bf16[], y.2786: bf16[]) -> bf16[] {
  %x.2785 = bf16[] parameter(0)
  %y.2786 = bf16[] parameter(1)
  ROOT %add.2787 = bf16[] add(bf16[] %x.2785, bf16[] %y.2786)
}

%SimpleCrossEntropyLossForwardMax.1058 (p0.1059: bf16[], p1.1060: bf16[]) -> bf16[] {
  %p0.1059 = bf16[] parameter(0)
  %p1.1060 = bf16[] parameter(1)
  ROOT %maximum.1061 = bf16[] maximum(bf16[] %p0.1059, bf16[] %p1.1060)
}

%SimpleCrossEntropyLossForwardAdd.1062 (p0.1063: bf16[], p1.1064: bf16[]) -> bf16[] {
  %p0.1063 = bf16[] parameter(0)
  %p1.1064 = bf16[] parameter(1)
  ROOT %add.1065 = bf16[] add(bf16[] %p0.1063, bf16[] %p1.1064)
}

%SimpleCrossEntropyLossForwardAdd.1066 (p0.1067: bf16[], p1.1068: bf16[]) -> bf16[] {
  %p0.1067 = bf16[] parameter(0)
  %p1.1068 = bf16[] parameter(1)
  ROOT %add.1069 = bf16[] add(bf16[] %p0.1067, bf16[] %p1.1068)
}

%SimpleCrossEntropyLossForwardAdd.1070 (p0.1071: bf16[], p1.1072: bf16[]) -> bf16[] {
  %p0.1071 = bf16[] parameter(0)
  %p1.1072 = bf16[] parameter(1)
  ROOT %add.1073 = bf16[] add(bf16[] %p0.1071, bf16[] %p1.1072)
}

%SimpleCrossEntropyLossForwardAdd.1074 (p0.1075: bf16[], p1.1076: bf16[]) -> bf16[] {
  %p0.1075 = bf16[] parameter(0)
  %p1.1076 = bf16[] parameter(1)
  ROOT %add.1077 = bf16[] add(bf16[] %p0.1075, bf16[] %p1.1076)
}

%SimpleCrossEntropyLossBackwardAdd.1121 (p0.1122: bf16[], p1.1123: bf16[]) -> bf16[] {
  %p0.1122 = bf16[] parameter(0)
  %p1.1123 = bf16[] parameter(1)
  ROOT %add.1124 = bf16[] add(bf16[] %p0.1122, bf16[] %p1.1123)
}

%SimpleCrossEntropyLossForwardMax.801 (p0.802: bf16[], p1.803: bf16[]) -> bf16[] {
  %p0.802 = bf16[] parameter(0)
  %p1.803 = bf16[] parameter(1)
  ROOT %maximum.804 = bf16[] maximum(bf16[] %p0.802, bf16[] %p1.803)
}

%SimpleCrossEntropyLossForwardAdd.805 (p0.806: bf16[], p1.807: bf16[]) -> bf16[] {
  %p0.806 = bf16[] parameter(0)
  %p1.807 = bf16[] parameter(1)
  ROOT %add.808 = bf16[] add(bf16[] %p0.806, bf16[] %p1.807)
}

%SimpleCrossEntropyLossForwardAdd.809 (p0.810: bf16[], p1.811: bf16[]) -> bf16[] {
  %p0.810 = bf16[] parameter(0)
  %p1.811 = bf16[] parameter(1)
  ROOT %add.812 = bf16[] add(bf16[] %p0.810, bf16[] %p1.811)
}

%SimpleCrossEntropyLossForwardAdd.813 (p0.814: bf16[], p1.815: bf16[]) -> bf16[] {
  %p0.814 = bf16[] parameter(0)
  %p1.815 = bf16[] parameter(1)
  ROOT %add.816 = bf16[] add(bf16[] %p0.814, bf16[] %p1.815)
}

%SimpleCrossEntropyLossForwardAdd.817 (p0.818: bf16[], p1.819: bf16[]) -> bf16[] {
  %p0.818 = bf16[] parameter(0)
  %p1.819 = bf16[] parameter(1)
  ROOT %add.820 = bf16[] add(bf16[] %p0.818, bf16[] %p1.819)
}

%SimpleCrossEntropyLossBackwardAdd.868 (p0.869: bf16[], p1.870: bf16[]) -> bf16[] {
  %p0.869 = bf16[] parameter(0)
  %p1.870 = bf16[] parameter(1)
  ROOT %add.871 = bf16[] add(bf16[] %p0.869, bf16[] %p1.870)
}

%Int32PermissiveEmbeddingScatterCombiner.1426 (p0.1427: bf16[], p1.1428: bf16[]) -> bf16[] {
  %p0.1427 = bf16[] parameter(0)
  %p1.1428 = bf16[] parameter(1)
  ROOT %add.1429 = bf16[] add(bf16[] %p0.1427, bf16[] %p1.1428)
}

%Int32PermissiveEmbeddingScatterCombiner.1491 (p0.1492: bf16[], p1.1493: bf16[]) -> bf16[] {
  %p0.1492 = bf16[] parameter(0)
  %p1.1493 = bf16[] parameter(1)
  ROOT %add.1494 = bf16[] add(bf16[] %p0.1492, bf16[] %p1.1493)
}

%AddComputation.2647 (x.2648: bf16[], y.2649: bf16[]) -> bf16[] {
  %x.2648 = bf16[] parameter(0)
  %y.2649 = bf16[] parameter(1)
  ROOT %add.2650 = bf16[] add(bf16[] %x.2648, bf16[] %y.2649)
}

%AddComputation.2693 (x.2694: bf16[], y.2695: bf16[]) -> bf16[] {
  %x.2694 = bf16[] parameter(0)
  %y.2695 = bf16[] parameter(1)
  ROOT %add.2696 = bf16[] add(bf16[] %x.2694, bf16[] %y.2695)
}

%AddComputation.1700 (x.1701: bf16[], y.1702: bf16[]) -> bf16[] {
  %x.1701 = bf16[] parameter(0)
  %y.1702 = bf16[] parameter(1)
  ROOT %add.1703 = bf16[] add(bf16[] %x.1701, bf16[] %y.1702)
}

%AddComputation.1796 (x.1797: bf16[], y.1798: bf16[]) -> bf16[] {
  %x.1797 = bf16[] parameter(0)
  %y.1798 = bf16[] parameter(1)
  ROOT %add.1799 = bf16[] add(bf16[] %x.1797, bf16[] %y.1798)
}

%AddComputation.1891 (x.1892: bf16[], y.1893: bf16[]) -> bf16[] {
  %x.1892 = bf16[] parameter(0)
  %y.1893 = bf16[] parameter(1)
  ROOT %add.1894 = bf16[] add(bf16[] %x.1892, bf16[] %y.1893)
}

ENTRY %SyncTensorsGraph.2840 (p0.8: f32[], p1.10: f32[], p2.46: s64[1,512], p3.50: bf16[512,16], p4.67: s64[16,128], p5.69: bf16[2,16], p6.81: s64[16,128], p7.83: bf16[30522,16], p8.118: bf16[16], p9.127: bf16[], p10.128: s64[], p11.171: bf16[16,16], p12.186: bf16[16], p13.195: bf16[16,16], p14.206: bf16[16], p15.235: bf16[], p16.241: bf16[], p17.242: s64[16,128], p18.269: bf16[16], p19.357: bf16[16], p20.366: bf16[16,16], p21.387: bf16[16,16], p22.465: bf16[16], p23.511: bf16[16], p24.525: bf16[4096,16], p25.540: bf16[4096], p26.552: bf16[16], p27.574: bf16[16,4096], p28.652: bf16[16], p29.697: bf16[16], p30.711: bf16[16,16], p31.726: bf16[16], p32.737: bf16[16], p33.775: bf16[2,16], p34.785: s64[16], p35.786: bf16[2], p36.864: bf16[], p37.920: bf16[16,16], p38.935: bf16[16], p39.998: bf16[16], p40.1016: s64[16,128], p41.1023: bf16[30522], p42.1035: bf16[16], p43.1332: s64[], p44.1377: f32[], p45.1378: f32[30522,16], p46.1388: f32[], p47.1394: f32[], p48.1395: f32[30522,16], p49.1456: f32[512,16], p50.1471: f32[512,16], p51.1521: f32[2,16], p52.1536: f32[2,16], p53.1575: f32[16], p54.1590: f32[16], p55.1620: f32[16], p56.1635: f32[16], p57.1665: f32[16,16], p58.1680: f32[16,16], p59.1715: f32[16], p60.1730: f32[16], p61.1760: f32[16,16], p62.1775: f32[16,16], p63.1811: f32[16], p64.1826: f32[16], p65.1856: f32[16,16], p66.1871: f32[16,16], p67.1906: f32[16], p68.1921: f32[16], p69.1954: f32[16,16], p70.1969: f32[16,16], p71.2001: f32[16], p72.2016: f32[16], p73.2053: f32[16], p74.2068: f32[16], p75.2098: f32[16], p76.2113: f32[16], p77.2143: f32[4096,16], p78.2158: f32[4096,16], p79.2190: f32[4096], p80.2205: f32[4096], p81.2235: f32[16,4096], p82.2250: f32[16,4096], p83.2282: f32[16], p84.2297: f32[16], p85.2334: f32[16], p86.2349: f32[16], p87.2379: f32[16], p88.2394: f32[16], p89.2426: f32[16,16], p90.2441: f32[16,16], p91.2473: f32[16], p92.2488: f32[16], p93.2518: f32[16,16], p94.2533: f32[16,16], p95.2565: f32[16], p96.2580: f32[16], p97.2617: f32[16], p98.2632: f32[16], p99.2662: f32[16], p100.2677: f32[16], p101.2708: f32[30522], p102.2723: f32[30522], p103.2752: f32[2,16], p104.2767: f32[2,16], p105.2799: f32[2], p106.2814: f32[2], p107.2825: bf16[], p108.2828: f32[1]) -> (bf16[30522,16], bf16[512,16], bf16[2,16], bf16[16], bf16[16], /*index=5*/s64[1,512], bf16[16,16], bf16[16], bf16[16,16], bf16[16], /*index=10*/bf16[16,16], bf16[16], bf16[16,16], bf16[16], bf16[16], /*index=15*/bf16[16], bf16[4096,16], bf16[4096], bf16[16,4096], bf16[16], /*index=20*/bf16[16], bf16[16], bf16[16,16], bf16[16], bf16[16,16], /*index=25*/bf16[16], bf16[16], bf16[16], bf16[30522], bf16[2,16], /*index=30*/bf16[2], f32[1], f32[30522,16], f32[30522,16], f32[512,16], /*index=35*/f32[512,16], f32[2,16], f32[2,16], f32[16,16], f32[16,16], /*index=40*/f32[16,16], f32[16,16], f32[16,16], f32[16,16], f32[16,16], /*index=45*/f32[16,16], f32[4096,16], f32[4096,16], f32[16,4096], f32[16,4096], /*index=50*/f32[16,16], f32[16,16], f32[16,16], f32[16,16], f32[2,16], /*index=55*/f32[2,16], f32[16], f32[16], f32[16], f32[16], /*index=60*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=65*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=70*/f32[16], f32[16], f32[4096], f32[4096], f32[16], /*index=75*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=80*/f32[16], f32[16], f32[30522], f32[30522], f32[16], /*index=85*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=90*/f32[2], f32[2], bf16[1], s64[16,128], s64[16,128], /*index=95*/s64[16,128], s64[16,128], s64[16], bf16[16,128,30522], bf16[16,2], /*index=100*/bf16[], bf16[], bf16[2], bf16[2,16], bf16[30522], /*index=105*/bf16[30522,16], bf16[16], bf16[16], bf16[16], bf16[16,16], /*index=110*/bf16[16], bf16[16,16], bf16[16], bf16[16], bf16[16], /*index=115*/bf16[16,4096], bf16[4096], bf16[4096,16], bf16[16], bf16[16], /*index=120*/bf16[16], bf16[16,16], bf16[16], bf16[16,16], bf16[16], /*index=125*/bf16[16,16], bf16[16], bf16[16,16], bf16[16], bf16[16], /*index=130*/bf16[512,16], bf16[2,16]) {
  %p7.83 = bf16[30522,16]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1402 = f32[30522,16]{1,0} convert(bf16[30522,16]{1,0} %p7.83), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p48.1395 = f32[30522,16]{1,0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p47.1394 = f32[] parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1396 = f32[30522,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1397 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %p48.1395, f32[30522,16]{1,0} %broadcast.1396), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p42.1035 = bf16[16]{0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.94 = bf16[16]{0} custom-call(bf16[16]{0} %p42.1035), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1048 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.94), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p32.737 = bf16[16]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.67 = bf16[16]{0} custom-call(bf16[16]{0} %p32.737), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.750 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.67), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p26.552 = bf16[16]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.68 = bf16[16]{0} custom-call(bf16[16]{0} %p26.552), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.565 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.68), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p14.206 = bf16[16]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.69 = bf16[16]{0} custom-call(bf16[16]{0} %p14.206), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.219 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.69), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %custom-call.70 = bf16[30522,16]{1,0} custom-call(bf16[30522,16]{1,0} %p7.83), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p6.81 = s64[16,128]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=344}
  %convert.7 = u32[16,128]{1,0} convert(s64[16,128]{1,0} %p6.81)
  %reshape.372 = u32[2048]{0} reshape(u32[16,128]{1,0} %convert.7), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2233}
  %gather.92 = bf16[2048,16]{1,0} gather(bf16[30522,16]{1,0} %custom-call.70, u32[2048]{0} %reshape.372), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,16}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2233}
  %p5.69 = bf16[2,16]{1,0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.71 = bf16[2,16]{1,0} custom-call(bf16[2,16]{1,0} %p5.69), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p4.67 = s64[16,128]{1,0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=345}
  %convert.6 = u32[16,128]{1,0} convert(s64[16,128]{1,0} %p4.67)
  %reshape.371 = u32[2048]{0} reshape(u32[16,128]{1,0} %convert.6), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1026}
  %gather.78 = bf16[2048,16]{1,0} gather(bf16[2,16]{1,0} %custom-call.71, u32[2048]{0} %reshape.371), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,16}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1026}
  %add.12 = bf16[2048,16]{1,0} add(bf16[2048,16]{1,0} %gather.92, bf16[2048,16]{1,0} %gather.78), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=233}
  %reshape.516 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %add.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=233}
  %p3.50 = bf16[512,16]{1,0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.73 = bf16[512,16]{1,0} custom-call(bf16[512,16]{1,0} %p3.50), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p2.46 = s64[1,512]{1,0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %convert.5 = u32[1,512]{1,0} convert(s64[1,512]{1,0} %p2.46)
  %slice.0 = u32[1,128]{1,0} slice(u32[1,512]{1,0} %convert.5), slice={[0:1], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1026}
  %reshape.370 = u32[128]{0} reshape(u32[1,128]{1,0} %slice.0), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1026}
  %gather.59 = bf16[128,16]{1,0} gather(bf16[512,16]{1,0} %custom-call.73, u32[128]{0} %reshape.370), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,16}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1026}
  %broadcast.97 = bf16[16,128,16]{2,1,0} broadcast(bf16[128,16]{1,0} %gather.59), dimensions={1,2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=236}
  %add.98 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.516, bf16[16,128,16]{2,1,0} %broadcast.97), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=236}
  %reshape.99 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.98), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.36 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.40 = bf16[2048]{0} broadcast(bf16[] %constant.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.31 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.35 = bf16[2048]{0} broadcast(bf16[] %constant.31), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.100 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-training(bf16[1,2048,16]{2,1,0} %reshape.99, bf16[2048]{0} %broadcast.40, bf16[2048]{0} %broadcast.35), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.101 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.100), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.205 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.101), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p8.118 = bf16[16]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.74 = bf16[16]{0} custom-call(bf16[16]{0} %p8.118), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.215 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.74), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.218 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.205, bf16[16,128,16]{2,1,0} %broadcast.215), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.220 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %broadcast.219, bf16[16,128,16]{2,1,0} %multiply.218), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.129 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %p10.128 = s64[] parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.130 = s64[] multiply(s64[] %constant.129, s64[] %p10.128), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.131 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.132 = s64[] add(s64[] %multiply.130, s64[] %constant.131), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.139 = u64[] convert(s64[] %add.132), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.143 = u64[1]{0} reshape(u64[] %convert.139), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.43 = u64[1]{0} constant({0})
  %concatenate.145 = u64[2]{0} concatenate(u64[1]{0} %reshape.143, u64[1]{0} %constant.43), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.146 = (u64[2]{0}, u32[16,128,16]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.145), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.147 = u32[16,128,16]{2,1,0} get-tuple-element((u64[2]{0}, u32[16,128,16]{2,1,0}) %rng-bit-generator.146), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.149 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.150 = u32[16,128,16]{2,1,0} broadcast(u32[] %constant.149), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.151 = u32[16,128,16]{2,1,0} shift-right-logical(u32[16,128,16]{2,1,0} %get-tuple-element.147, u32[16,128,16]{2,1,0} %broadcast.150), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.152 = f32[16,128,16]{2,1,0} convert(u32[16,128,16]{2,1,0} %shift-right-logical.151), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.47 = f32[] constant(1.1920929e-07)
  %broadcast.57 = f32[16,128,16]{2,1,0} broadcast(f32[] %constant.47), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.158 = f32[16,128,16]{2,1,0} multiply(f32[16,128,16]{2,1,0} %convert.152, f32[16,128,16]{2,1,0} %broadcast.57), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.161 = bf16[16,128,16]{2,1,0} convert(f32[16,128,16]{2,1,0} %multiply.158), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %p9.127 = bf16[] parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.136 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %p9.127), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %compare.162 = pred[16,128,16]{2,1,0} compare(bf16[16,128,16]{2,1,0} %convert.161, bf16[16,128,16]{2,1,0} %broadcast.136), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.27 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %divide.4 = bf16[] divide(bf16[] %constant.27, bf16[] %p9.127)
  %broadcast.58 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %divide.4), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.40 = bf16[] constant(0)
  %broadcast.81 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %constant.40), dimensions={}
  %select.13 = bf16[16,128,16]{2,1,0} select(pred[16,128,16]{2,1,0} %compare.162, bf16[16,128,16]{2,1,0} %broadcast.58, bf16[16,128,16]{2,1,0} %broadcast.81), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.459 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.220, bf16[16,128,16]{2,1,0} %select.13), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.279 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p11.171 = bf16[16,16]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.75 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p11.171), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.278 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.75), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.280 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.279, bf16[16,16]{0,1} %transpose.278), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.281 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.280), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p18.269 = bf16[16]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.76 = bf16[16]{0} custom-call(bf16[16]{0} %p18.269), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.282 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.76), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.283 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.281, bf16[16,128,16]{2,1,0} %broadcast.282), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.286 = bf16[16,128,2,8]{3,2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.283), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.287 = bf16[16,2,128,8]{3,1,2,0} transpose(bf16[16,128,2,8]{3,2,1,0} %reshape.286), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.289 = bf16[32,128,8]{2,1,0} reshape(bf16[16,2,128,8]{3,1,2,0} %transpose.287), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.222 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p13.195 = bf16[16,16]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.77 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p13.195), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.203 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.77), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.223 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.222, bf16[16,16]{0,1} %transpose.203), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.224 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.223), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p12.186 = bf16[16]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.78 = bf16[16]{0} custom-call(bf16[16]{0} %p12.186), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.225 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.78), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.226 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.224, bf16[16,128,16]{2,1,0} %broadcast.225), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.229 = bf16[16,128,2,8]{3,2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.226), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.231 = bf16[16,2,8,128]{2,1,3,0} transpose(bf16[16,128,2,8]{3,2,1,0} %reshape.229), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.263 = bf16[32,8,128]{2,1,0} reshape(bf16[16,2,8,128]{2,1,3,0} %transpose.231), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.290 = bf16[32,128,128]{2,1,0} dot(bf16[32,128,8]{2,1,0} %reshape.289, bf16[32,8,128]{2,1,0} %reshape.263), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %p15.235 = bf16[] parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %broadcast.199 = bf16[32,128,128]{2,1,0} broadcast(bf16[] %p15.235), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.10 = bf16[32,128,128]{2,1,0} divide(bf16[32,128,128]{2,1,0} %dot.290, bf16[32,128,128]{2,1,0} %broadcast.199), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.524 = bf16[16,2,128,128]{3,2,1,0} reshape(bf16[32,128,128]{2,1,0} %divide.10), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %constant.254 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=909}
  %broadcast.201 = bf16[16,128]{1,0} broadcast(bf16[] %constant.254), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=909}
  %p17.242 = s64[16,128]{1,0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=346}
  %convert.3 = bf16[16,128]{1,0} convert(s64[16,128]{1,0} %p17.242), metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=837}
  %subtract.4 = bf16[16,128]{1,0} subtract(bf16[16,128]{1,0} %broadcast.201, bf16[16,128]{1,0} %convert.3), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=909}
  %p16.241 = bf16[] parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=838}
  %broadcast.205 = bf16[16,128]{1,0} broadcast(bf16[] %p16.241), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=838}
  %multiply.32 = bf16[16,128]{1,0} multiply(bf16[16,128]{1,0} %subtract.4, bf16[16,128]{1,0} %broadcast.205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=838}
  %broadcast.296 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[16,128]{1,0} %multiply.32), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.297 = bf16[16,2,128,128]{3,2,1,0} add(bf16[16,2,128,128]{3,2,1,0} %reshape.524, bf16[16,2,128,128]{3,2,1,0} %broadcast.296), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.298 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %reduce.303 = bf16[16,2,128]{2,1,0} reduce(bf16[16,2,128,128]{3,2,1,0} %add.297, bf16[] %constant.298), dimensions={3}, to_apply=%MaxComputation.299, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %broadcast.304 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[16,2,128]{2,1,0} %reduce.303), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %subtract.305 = bf16[16,2,128,128]{3,2,1,0} subtract(bf16[16,2,128,128]{3,2,1,0} %add.297, bf16[16,2,128,128]{3,2,1,0} %broadcast.304), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %exponential.306 = bf16[16,2,128,128]{3,2,1,0} exponential(bf16[16,2,128,128]{3,2,1,0} %subtract.305), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %constant.307 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %reduce.312 = bf16[16,2,128]{2,1,0} reduce(bf16[16,2,128,128]{3,2,1,0} %exponential.306, bf16[] %constant.307), dimensions={3}, to_apply=%AddComputation.308, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %broadcast.313 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[16,2,128]{2,1,0} %reduce.312), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %divide.314 = bf16[16,2,128,128]{3,2,1,0} divide(bf16[16,2,128,128]{3,2,1,0} %exponential.306, bf16[16,2,128,128]{3,2,1,0} %broadcast.313), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1856}
  %constant.315 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.316 = s64[] multiply(s64[] %constant.315, s64[] %add.132), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.317 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.318 = s64[] add(s64[] %multiply.316, s64[] %constant.317), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.325 = u64[] convert(s64[] %add.318), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.329 = u64[1]{0} reshape(u64[] %convert.325), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.48 = u64[1]{0} constant({0})
  %concatenate.331 = u64[2]{0} concatenate(u64[1]{0} %reshape.329, u64[1]{0} %constant.48), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.332 = (u64[2]{0}, u32[16,2,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.331), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.333 = u32[16,2,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[16,2,128,128]{3,2,1,0}) %rng-bit-generator.332), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.335 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.336 = u32[16,2,128,128]{3,2,1,0} broadcast(u32[] %constant.335), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.337 = u32[16,2,128,128]{3,2,1,0} shift-right-logical(u32[16,2,128,128]{3,2,1,0} %get-tuple-element.333, u32[16,2,128,128]{3,2,1,0} %broadcast.336), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.338 = f32[16,2,128,128]{3,2,1,0} convert(u32[16,2,128,128]{3,2,1,0} %shift-right-logical.337), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.52 = f32[] constant(1.1920929e-07)
  %broadcast.62 = f32[16,2,128,128]{3,2,1,0} broadcast(f32[] %constant.52), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.344 = f32[16,2,128,128]{3,2,1,0} multiply(f32[16,2,128,128]{3,2,1,0} %convert.338, f32[16,2,128,128]{3,2,1,0} %broadcast.62), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.347 = bf16[16,2,128,128]{3,2,1,0} convert(f32[16,2,128,128]{3,2,1,0} %multiply.344), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.322 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[] %p9.127), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %compare.348 = pred[16,2,128,128]{3,2,1,0} compare(bf16[16,2,128,128]{3,2,1,0} %convert.347, bf16[16,2,128,128]{3,2,1,0} %broadcast.322), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.28 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %divide.5 = bf16[] divide(bf16[] %constant.28, bf16[] %p9.127)
  %broadcast.63 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[] %divide.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.39 = bf16[] constant(0)
  %broadcast.80 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[] %constant.39), dimensions={}
  %select.12 = bf16[16,2,128,128]{3,2,1,0} select(pred[16,2,128,128]{3,2,1,0} %compare.348, bf16[16,2,128,128]{3,2,1,0} %broadcast.63, bf16[16,2,128,128]{3,2,1,0} %broadcast.80), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.476 = bf16[16,2,128,128]{3,2,1,0} multiply(bf16[16,2,128,128]{3,2,1,0} %divide.314, bf16[16,2,128,128]{3,2,1,0} %select.12), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.478 = bf16[32,128,128]{2,1,0} reshape(bf16[16,2,128,128]{3,2,1,0} %multiply.476), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.375 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p20.366 = bf16[16,16]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.79 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p20.366), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.374 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.79), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.376 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.375, bf16[16,16]{0,1} %transpose.374), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.377 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.376), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p19.357 = bf16[16]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.80 = bf16[16]{0} custom-call(bf16[16]{0} %p19.357), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.378 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.80), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.379 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.377, bf16[16,128,16]{2,1,0} %broadcast.378), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.382 = bf16[16,128,2,8]{3,2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.379), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.383 = bf16[16,2,128,8]{3,1,2,0} transpose(bf16[16,128,2,8]{3,2,1,0} %reshape.382), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.475 = bf16[32,128,8]{2,1,0} reshape(bf16[16,2,128,8]{3,1,2,0} %transpose.383), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.479 = bf16[32,128,8]{2,1,0} dot(bf16[32,128,128]{2,1,0} %reshape.478, bf16[32,128,8]{2,1,0} %reshape.475), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.480 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.479), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.481 = bf16[16,128,2,8]{3,1,2,0} transpose(bf16[16,2,128,8]{3,2,1,0} %reshape.480), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.483 = bf16[2048,16]{1,0} reshape(bf16[16,128,2,8]{3,1,2,0} %transpose.481), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p21.387 = bf16[16,16]{1,0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.81 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p21.387), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.474 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.81), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.484 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.483, bf16[16,16]{0,1} %transpose.474), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.485 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.484), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p22.465 = bf16[16]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.82 = bf16[16]{0} custom-call(bf16[16]{0} %p22.465), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.486 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.82), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.487 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.485, bf16[16,128,16]{2,1,0} %broadcast.486), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %constant.397 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.398 = s64[] multiply(s64[] %constant.397, s64[] %add.318), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.399 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.400 = s64[] add(s64[] %multiply.398, s64[] %constant.399), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.407 = u64[] convert(s64[] %add.400), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.411 = u64[1]{0} reshape(u64[] %convert.407), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.53 = u64[1]{0} constant({0})
  %concatenate.413 = u64[2]{0} concatenate(u64[1]{0} %reshape.411, u64[1]{0} %constant.53), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.414 = (u64[2]{0}, u32[16,128,16]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.413), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.415 = u32[16,128,16]{2,1,0} get-tuple-element((u64[2]{0}, u32[16,128,16]{2,1,0}) %rng-bit-generator.414), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.417 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.418 = u32[16,128,16]{2,1,0} broadcast(u32[] %constant.417), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.419 = u32[16,128,16]{2,1,0} shift-right-logical(u32[16,128,16]{2,1,0} %get-tuple-element.415, u32[16,128,16]{2,1,0} %broadcast.418), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.420 = f32[16,128,16]{2,1,0} convert(u32[16,128,16]{2,1,0} %shift-right-logical.419), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.57 = f32[] constant(1.1920929e-07)
  %broadcast.65 = f32[16,128,16]{2,1,0} broadcast(f32[] %constant.57), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.426 = f32[16,128,16]{2,1,0} multiply(f32[16,128,16]{2,1,0} %convert.420, f32[16,128,16]{2,1,0} %broadcast.65), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.429 = bf16[16,128,16]{2,1,0} convert(f32[16,128,16]{2,1,0} %multiply.426), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.404 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %p9.127), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %compare.430 = pred[16,128,16]{2,1,0} compare(bf16[16,128,16]{2,1,0} %convert.429, bf16[16,128,16]{2,1,0} %broadcast.404), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.29 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %divide.6 = bf16[] divide(bf16[] %constant.29, bf16[] %p9.127)
  %broadcast.67 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %divide.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.38 = bf16[] constant(0)
  %broadcast.79 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %constant.38), dimensions={}
  %select.11 = bf16[16,128,16]{2,1,0} select(pred[16,128,16]{2,1,0} %compare.430, bf16[16,128,16]{2,1,0} %broadcast.67, bf16[16,128,16]{2,1,0} %broadcast.79), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.490 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.487, bf16[16,128,16]{2,1,0} %select.11), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.491 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %multiply.490, bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.492 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.491), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.449 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.453 = bf16[2048]{0} broadcast(bf16[] %constant.449), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.444 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.448 = bf16[2048]{0} broadcast(bf16[] %constant.444), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.493 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-training(bf16[1,2048,16]{2,1,0} %reshape.492, bf16[2048]{0} %broadcast.453, bf16[2048]{0} %broadcast.448), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.494 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.493), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.551 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.494), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p23.511 = bf16[16]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.83 = bf16[16]{0} custom-call(bf16[16]{0} %p23.511), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.561 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.83), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.564 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.551, bf16[16,128,16]{2,1,0} %broadcast.561), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.566 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %broadcast.565, bf16[16,128,16]{2,1,0} %multiply.564), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.567 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.566), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p24.525 = bf16[4096,16]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.84 = bf16[4096,16]{1,0} custom-call(bf16[4096,16]{1,0} %p24.525), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.549 = bf16[16,4096]{0,1} transpose(bf16[4096,16]{1,0} %custom-call.84), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.568 = bf16[2048,4096]{1,0} dot(bf16[2048,16]{1,0} %reshape.567, bf16[16,4096]{0,1} %transpose.549), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.569 = bf16[16,128,4096]{2,1,0} reshape(bf16[2048,4096]{1,0} %dot.568), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p25.540 = bf16[4096]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.85 = bf16[4096]{0} custom-call(bf16[4096]{0} %p25.540), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.570 = bf16[16,128,4096]{2,1,0} broadcast(bf16[4096]{0} %custom-call.85), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.571 = bf16[16,128,4096]{2,1,0} add(bf16[16,128,4096]{2,1,0} %reshape.569, bf16[16,128,4096]{2,1,0} %broadcast.570), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %custom-call.87 = bf16[16,128,4096]{2,1,0} custom-call(bf16[16,128,4096]{2,1,0} %add.571), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.669 = bf16[2048,4096]{1,0} reshape(bf16[16,128,4096]{2,1,0} %custom-call.87), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p27.574 = bf16[16,4096]{1,0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.88 = bf16[16,4096]{1,0} custom-call(bf16[16,4096]{1,0} %p27.574), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.661 = bf16[4096,16]{0,1} transpose(bf16[16,4096]{1,0} %custom-call.88), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.670 = bf16[2048,16]{1,0} dot(bf16[2048,4096]{1,0} %reshape.669, bf16[4096,16]{0,1} %transpose.661), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.671 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.670), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p28.652 = bf16[16]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.89 = bf16[16]{0} custom-call(bf16[16]{0} %p28.652), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.672 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.89), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.673 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.671, bf16[16,128,16]{2,1,0} %broadcast.672), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %constant.584 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.585 = s64[] multiply(s64[] %constant.584, s64[] %add.400), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.586 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.587 = s64[] add(s64[] %multiply.585, s64[] %constant.586), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.594 = u64[] convert(s64[] %add.587), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %reshape.598 = u64[1]{0} reshape(u64[] %convert.594), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.59 = u64[1]{0} constant({0})
  %concatenate.600 = u64[2]{0} concatenate(u64[1]{0} %reshape.598, u64[1]{0} %constant.59), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.601 = (u64[2]{0}, u32[16,128,16]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.600), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.602 = u32[16,128,16]{2,1,0} get-tuple-element((u64[2]{0}, u32[16,128,16]{2,1,0}) %rng-bit-generator.601), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.604 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.605 = u32[16,128,16]{2,1,0} broadcast(u32[] %constant.604), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.606 = u32[16,128,16]{2,1,0} shift-right-logical(u32[16,128,16]{2,1,0} %get-tuple-element.602, u32[16,128,16]{2,1,0} %broadcast.605), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.607 = f32[16,128,16]{2,1,0} convert(u32[16,128,16]{2,1,0} %shift-right-logical.606), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.64 = f32[] constant(1.1920929e-07)
  %broadcast.68 = f32[16,128,16]{2,1,0} broadcast(f32[] %constant.64), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.613 = f32[16,128,16]{2,1,0} multiply(f32[16,128,16]{2,1,0} %convert.607, f32[16,128,16]{2,1,0} %broadcast.68), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %convert.616 = bf16[16,128,16]{2,1,0} convert(f32[16,128,16]{2,1,0} %multiply.613), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %broadcast.591 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %p9.127), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %compare.617 = pred[16,128,16]{2,1,0} compare(bf16[16,128,16]{2,1,0} %convert.616, bf16[16,128,16]{2,1,0} %broadcast.591), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.30 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %divide.7 = bf16[] divide(bf16[] %constant.30, bf16[] %p9.127)
  %broadcast.69 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %divide.7), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %constant.37 = bf16[] constant(0)
  %broadcast.78 = bf16[16,128,16]{2,1,0} broadcast(bf16[] %constant.37), dimensions={}
  %select.10 = bf16[16,128,16]{2,1,0} select(pred[16,128,16]{2,1,0} %compare.617, bf16[16,128,16]{2,1,0} %broadcast.69, bf16[16,128,16]{2,1,0} %broadcast.78), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %multiply.676 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.673, bf16[16,128,16]{2,1,0} %select.10), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=1266}
  %add.677 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %multiply.676, bf16[16,128,16]{2,1,0} %add.566), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.678 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %add.677), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.636 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.640 = bf16[2048]{0} broadcast(bf16[] %constant.636), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.631 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.635 = bf16[2048]{0} broadcast(bf16[] %constant.631), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.679 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-training(bf16[1,2048,16]{2,1,0} %reshape.678, bf16[2048]{0} %broadcast.640, bf16[2048]{0} %broadcast.635), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.680 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.679), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.736 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.680), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p29.697 = bf16[16]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.90 = bf16[16]{0} custom-call(bf16[16]{0} %p29.697), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.746 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.90), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.749 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.736, bf16[16,128,16]{2,1,0} %broadcast.746), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.751 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %broadcast.750, bf16[16,128,16]{2,1,0} %multiply.749), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.945 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.751), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p37.920 = bf16[16,16]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.91 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p37.920), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.944 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.91), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.946 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.945, bf16[16,16]{0,1} %transpose.944), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.947 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.946), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p38.935 = bf16[16]{0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.92 = bf16[16]{0} custom-call(bf16[16]{0} %p38.935), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.948 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.92), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.949 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.947, bf16[16,128,16]{2,1,0} %broadcast.948), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %custom-call.93 = bf16[16,128,16]{2,1,0} custom-call(bf16[16,128,16]{2,1,0} %add.949), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.979 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %custom-call.93), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.967 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.971 = bf16[2048]{0} broadcast(bf16[] %constant.967), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.962 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.966 = bf16[2048]{0} broadcast(bf16[] %constant.962), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.980 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-training(bf16[1,2048,16]{2,1,0} %reshape.979, bf16[2048]{0} %broadcast.971, bf16[2048]{0} %broadcast.966), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.981 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.980), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.1034 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.981), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %p39.998 = bf16[16]{0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.95 = bf16[16]{0} custom-call(bf16[16]{0} %p39.998), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1044 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.95), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.1047 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1034, bf16[16,128,16]{2,1,0} %broadcast.1044), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.1049 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %broadcast.1048, bf16[16,128,16]{2,1,0} %multiply.1047), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %reshape.1050 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.1049), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %custom-call.96 = bf16[30522,16]{1,0} custom-call(bf16[30522,16]{1,0} %p7.83), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.1032 = bf16[16,30522]{0,1} transpose(bf16[30522,16]{1,0} %custom-call.96), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.1051 = bf16[2048,30522]{1,0} dot(bf16[2048,16]{1,0} %reshape.1050, bf16[16,30522]{0,1} %transpose.1032), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.1052 = bf16[16,128,30522]{2,1,0} reshape(bf16[2048,30522]{1,0} %dot.1051), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p41.1023 = bf16[30522]{0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.97 = bf16[30522]{0} custom-call(bf16[30522]{0} %p41.1023), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1053 = bf16[16,128,30522]{2,1,0} broadcast(bf16[30522]{0} %custom-call.97), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.1054 = bf16[16,128,30522]{2,1,0} add(bf16[16,128,30522]{2,1,0} %reshape.1052, bf16[16,128,30522]{2,1,0} %broadcast.1053), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.1057 = bf16[2048,30522]{1,0} reshape(bf16[16,128,30522]{2,1,0} %add.1054), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.0 = bf16[] constant(-inf)
  %reduce.0 = bf16[2048]{0} reduce(bf16[2048,30522]{1,0} %reshape.1057, bf16[] %constant.0), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardMax.1058
  %broadcast.0 = bf16[2048,30522]{1,0} broadcast(bf16[2048]{0} %reduce.0), dimensions={0}
  %subtract.0 = bf16[2048,30522]{1,0} subtract(bf16[2048,30522]{1,0} %reshape.1057, bf16[2048,30522]{1,0} %broadcast.0)
  %exponential.0 = bf16[2048,30522]{1,0} exponential(bf16[2048,30522]{1,0} %subtract.0)
  %constant.2 = bf16[] constant(0)
  %reduce.1 = bf16[2048]{0} reduce(bf16[2048,30522]{1,0} %exponential.0, bf16[] %constant.2), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.1062
  %log.0 = bf16[2048]{0} log(bf16[2048]{0} %reduce.1)
  %broadcast.1 = bf16[2048,30522]{1,0} broadcast(bf16[2048]{0} %log.0), dimensions={0}
  %subtract.1 = bf16[2048,30522]{1,0} subtract(bf16[2048,30522]{1,0} %subtract.0, bf16[2048,30522]{1,0} %broadcast.1), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %exponential.1 = bf16[2048,30522]{1,0} exponential(bf16[2048,30522]{1,0} %subtract.1)
  %p40.1016 = s64[16,128]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=347}
  %constant.5 = s64[] constant(-100)
  %broadcast.203 = s64[16,128]{1,0} broadcast(s64[] %constant.5), dimensions={}
  %compare.8 = pred[16,128]{1,0} compare(s64[16,128]{1,0} %p40.1016, s64[16,128]{1,0} %broadcast.203), direction=NE
  %reshape.527 = pred[2048]{0} reshape(pred[16,128]{1,0} %compare.8)
  %constant.865 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/autograd/__init__.py" source_line=127}
  %p36.864 = bf16[] parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %convert.0 = bf16[2048]{0} convert(pred[2048]{0} %reshape.527), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.8 = bf16[] constant(0)
  %reduce.5 = bf16[] reduce(bf16[2048]{0} %convert.0, bf16[] %constant.8), dimensions={0}, to_apply=%SimpleCrossEntropyLossBackwardAdd.1121
  %multiply.25 = bf16[] multiply(bf16[] %p36.864, bf16[] %reduce.5)
  %divide.1 = bf16[] divide(bf16[] %constant.865, bf16[] %multiply.25)
  %broadcast.11 = bf16[2048]{0} broadcast(bf16[] %divide.1), dimensions={}
  %constant.33 = bf16[] constant(0)
  %broadcast.71 = bf16[2048]{0} broadcast(bf16[] %constant.33), dimensions={}
  %select.7 = bf16[2048]{0} select(pred[2048]{0} %reshape.527, bf16[2048]{0} %broadcast.11, bf16[2048]{0} %broadcast.71)
  %broadcast.12 = bf16[2048,30522]{1,0} broadcast(bf16[2048]{0} %select.7), dimensions={0}
  %multiply.5 = bf16[2048,30522]{1,0} multiply(bf16[2048,30522]{1,0} %exponential.1, bf16[2048,30522]{1,0} %broadcast.12)
  %reshape.6 = s64[2048]{0} reshape(s64[16,128]{1,0} %p40.1016)
  %broadcast.16 = s64[2048,30522]{1,0} broadcast(s64[2048]{0} %reshape.6), dimensions={0}
  %iota.5 = s64[2048,30522]{1,0} iota(), iota_dimension=1
  %compare.2 = pred[2048,30522]{1,0} compare(s64[2048,30522]{1,0} %broadcast.16, s64[2048,30522]{1,0} %iota.5), direction=EQ
  %negate.1 = bf16[] negate(bf16[] %divide.1)
  %broadcast.21 = bf16[2048,30522]{1,0} broadcast(bf16[] %negate.1), dimensions={}
  %constant.9 = bf16[] constant(0)
  %broadcast.22 = bf16[2048,30522]{1,0} broadcast(bf16[] %constant.9), dimensions={}
  %select.1 = bf16[2048,30522]{1,0} select(pred[2048,30522]{1,0} %compare.2, bf16[2048,30522]{1,0} %broadcast.21, bf16[2048,30522]{1,0} %broadcast.22)
  %add.0 = bf16[2048,30522]{1,0} add(bf16[2048,30522]{1,0} %multiply.5, bf16[2048,30522]{1,0} %select.1), metadata={op_type="xla___op_SimpleCrossEntropyLossBackwardImpl" op_name="xla___op_SimpleCrossEntropyLossBackwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1364 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.1049), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1365 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.1364), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot = bf16[30522,16]{0,1} dot(bf16[2048,30522]{1,0} %add.0, bf16[16,2048]{0,1} %transpose.1365), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.104 = bf16[30522,16]{1,0} custom-call(bf16[30522,16]{0,1} %dot), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.1344 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.1348 = bf16[30522,16]{1,0} broadcast(bf16[] %constant.1344), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %reshape.1323 = s64[2048]{0} reshape(s64[16,128]{1,0} %p6.81), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.1338 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.1339 = s64[2048]{0} broadcast(s64[] %constant.1338), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt"}
  %compare.1340 = pred[2048]{0} compare(s64[2048]{0} %reshape.1323, s64[2048]{0} %broadcast.1339), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt"}
  %p43.1332 = s64[] parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %broadcast.1336 = s64[2048]{0} broadcast(s64[] %p43.1332), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %add.1337 = s64[2048]{0} add(s64[2048]{0} %reshape.1323, s64[2048]{0} %broadcast.1336), metadata={op_type="aten__add" op_name="aten__add"}
  %select.1341 = s64[2048]{0} select(pred[2048]{0} %compare.1340, s64[2048]{0} %add.1337, s64[2048]{0} %reshape.1323), metadata={op_type="aten__where" op_name="aten__where"}
  %reshape.1342 = s64[2048,1]{1,0} reshape(s64[2048]{0} %select.1341), metadata={op_type="aten__stack" op_name="aten__stack"}
  %convert.1324 = f32[2048]{0} convert(s64[2048]{0} %reshape.1323), metadata={op_type="aten__ne" op_name="aten__ne"}
  %constant.1322 = f32[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.1325 = f32[2048]{0} broadcast(f32[] %constant.1322), dimensions={}, metadata={op_type="aten__ne" op_name="aten__ne"}
  %compare.1326 = pred[2048]{0} compare(f32[2048]{0} %convert.1324, f32[2048]{0} %broadcast.1325), direction=NE, metadata={op_type="aten__ne" op_name="aten__ne"}
  %broadcast.1330 = pred[2048,16]{1,0} broadcast(pred[2048]{0} %compare.1326), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.108 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.112 = bf16[2048]{0} broadcast(bf16[] %constant.108), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %get-tuple-element.102 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.100), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.103 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.100), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.104 = bf16[] constant(1.002e-12), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.105 = bf16[2048]{0} broadcast(bf16[] %constant.104), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.106 = bf16[2048]{0} add(bf16[2048]{0} %get-tuple-element.103, bf16[2048]{0} %broadcast.105), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %sqrt = bf16[2048]{0} sqrt(bf16[2048]{0} %add.106), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.1313 = bf16[2048]{0} multiply(bf16[2048]{0} %sqrt, bf16[2048]{0} %sqrt), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.67 = bf16[] constant(-1.002e-12)
  %broadcast.72 = bf16[2048]{0} broadcast(bf16[] %constant.67), dimensions={}, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %add.8 = bf16[2048]{0} add(bf16[2048]{0} %multiply.1313, bf16[2048]{0} %broadcast.72), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.501 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.505 = bf16[2048]{0} broadcast(bf16[] %constant.501), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %get-tuple-element.495 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.493), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.496 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.493), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.497 = bf16[] constant(1.002e-12), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.498 = bf16[2048]{0} broadcast(bf16[] %constant.497), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.499 = bf16[2048]{0} add(bf16[2048]{0} %get-tuple-element.496, bf16[2048]{0} %broadcast.498), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %sqrt.1 = bf16[2048]{0} sqrt(bf16[2048]{0} %add.499), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.1228 = bf16[2048]{0} multiply(bf16[2048]{0} %sqrt.1, bf16[2048]{0} %sqrt.1), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.68 = bf16[] constant(-1.002e-12)
  %broadcast.73 = bf16[2048]{0} broadcast(bf16[] %constant.68), dimensions={}, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %add.9 = bf16[2048]{0} add(bf16[2048]{0} %multiply.1228, bf16[2048]{0} %broadcast.73), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.687 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.691 = bf16[2048]{0} broadcast(bf16[] %constant.687), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %get-tuple-element.681 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.679), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.682 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.679), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.683 = bf16[] constant(1.002e-12), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.684 = bf16[2048]{0} broadcast(bf16[] %constant.683), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.685 = bf16[2048]{0} add(bf16[2048]{0} %get-tuple-element.682, bf16[2048]{0} %broadcast.684), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %sqrt.2 = bf16[2048]{0} sqrt(bf16[2048]{0} %add.685), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.1194 = bf16[2048]{0} multiply(bf16[2048]{0} %sqrt.2, bf16[2048]{0} %sqrt.2), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.69 = bf16[] constant(-1.002e-12)
  %broadcast.74 = bf16[2048]{0} broadcast(bf16[] %constant.69), dimensions={}, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %add.10 = bf16[2048]{0} add(bf16[2048]{0} %multiply.1194, bf16[2048]{0} %broadcast.74), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.988 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.992 = bf16[2048]{0} broadcast(bf16[] %constant.988), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %get-tuple-element.982 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.980), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.983 = bf16[2048]{0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-training.980), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %constant.984 = bf16[] constant(1.002e-12), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %broadcast.985 = bf16[2048]{0} broadcast(bf16[] %constant.984), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %add.986 = bf16[2048]{0} add(bf16[2048]{0} %get-tuple-element.983, bf16[2048]{0} %broadcast.985), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %sqrt.3 = bf16[2048]{0} sqrt(bf16[2048]{0} %add.986), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/functional.py" source_line=2543}
  %multiply.1165 = bf16[2048]{0} multiply(bf16[2048]{0} %sqrt.3, bf16[2048]{0} %sqrt.3), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %constant.70 = bf16[] constant(-1.002e-12)
  %broadcast.75 = bf16[2048]{0} broadcast(bf16[] %constant.70), dimensions={}, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %add.11 = bf16[2048]{0} add(bf16[2048]{0} %multiply.1165, bf16[2048]{0} %broadcast.75), metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %dot.1156 = bf16[2048,16]{1,0} dot(bf16[2048,30522]{1,0} %add.0, bf16[30522,16]{1,0} %custom-call.96), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1157 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1156), metadata={op_type="aten__view" op_name="aten__view"}
  %broadcast.1158 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.95), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul"}
  %multiply.1159 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1157, bf16[16,128,16]{2,1,0} %broadcast.1158), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1160 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1159), metadata={op_type="aten__view" op_name="aten__view"}
  %batch-norm-grad.1168 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-grad(bf16[1,2048,16]{2,1,0} %reshape.979, bf16[2048]{0} %broadcast.992, bf16[2048]{0} %get-tuple-element.982, bf16[2048]{0} %add.11, bf16[1,2048,16]{2,1,0} %reshape.1160), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %get-tuple-element.1169 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-grad.1168), index=0, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %reshape.1172 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1169), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.98 = bf16[16,128,16]{2,1,0} custom-call(bf16[16,128,16]{2,1,0} %add.949), custom_call_target="AwsNeuronGeluBackward", api_version=API_VERSION_UNSPECIFIED
  %multiply.6 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1172, bf16[16,128,16]{2,1,0} %custom-call.98), metadata={op_type="xla___op_GeluBackwardImpl" op_name="xla___op_GeluBackwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1183 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.6), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1184 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.1183, bf16[16,16]{1,0} %custom-call.91), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1185 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1184), metadata={op_type="aten__view" op_name="aten__view"}
  %slice.753 = bf16[16,1,16]{2,1,0} slice(bf16[16,128,16]{2,1,0} %add.751), slice={[0:16], [0:1], [0:16]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %reshape.754 = bf16[16,16]{1,0} reshape(bf16[16,1,16]{2,1,0} %slice.753), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p30.711 = bf16[16,16]{1,0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.99 = bf16[16,16]{1,0} custom-call(bf16[16,16]{1,0} %p30.711), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.734 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %custom-call.99), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.755 = bf16[16,16]{1,0} dot(bf16[16,16]{1,0} %reshape.754, bf16[16,16]{0,1} %transpose.734), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p31.726 = bf16[16]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.100 = bf16[16]{0} custom-call(bf16[16]{0} %p31.726), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.759 = bf16[16,16]{1,0} broadcast(bf16[16]{0} %custom-call.100), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.760 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %dot.755, bf16[16,16]{1,0} %broadcast.759), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %tanh.761 = bf16[16,16]{1,0} tanh(bf16[16,16]{1,0} %add.760), metadata={op_type="aten__tanh" op_name="aten__tanh" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/activation.py" source_line=356}
  %p33.775 = bf16[2,16]{1,0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.101 = bf16[2,16]{1,0} custom-call(bf16[2,16]{1,0} %p33.775), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.794 = bf16[16,2]{0,1} transpose(bf16[2,16]{1,0} %custom-call.101), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.795 = bf16[16,2]{1,0} dot(bf16[16,16]{1,0} %tanh.761, bf16[16,2]{0,1} %transpose.794), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p35.786 = bf16[2]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.102 = bf16[2]{0} custom-call(bf16[2]{0} %p35.786), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.799 = bf16[16,2]{1,0} broadcast(bf16[2]{0} %custom-call.102), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.800 = bf16[16,2]{1,0} add(bf16[16,2]{1,0} %dot.795, bf16[16,2]{1,0} %broadcast.799), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %constant.10 = bf16[] constant(-inf)
  %reduce.6 = bf16[16]{0} reduce(bf16[16,2]{1,0} %add.800, bf16[] %constant.10), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardMax.801
  %broadcast.24 = bf16[16,2]{1,0} broadcast(bf16[16]{0} %reduce.6), dimensions={0}
  %subtract.2 = bf16[16,2]{1,0} subtract(bf16[16,2]{1,0} %add.800, bf16[16,2]{1,0} %broadcast.24)
  %exponential.2 = bf16[16,2]{1,0} exponential(bf16[16,2]{1,0} %subtract.2)
  %constant.12 = bf16[] constant(0)
  %reduce.7 = bf16[16]{0} reduce(bf16[16,2]{1,0} %exponential.2, bf16[] %constant.12), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.805
  %log.1 = bf16[16]{0} log(bf16[16]{0} %reduce.7)
  %broadcast.26 = bf16[16,2]{1,0} broadcast(bf16[16]{0} %log.1), dimensions={0}
  %subtract.3 = bf16[16,2]{1,0} subtract(bf16[16,2]{1,0} %subtract.2, bf16[16,2]{1,0} %broadcast.26), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %exponential.3 = bf16[16,2]{1,0} exponential(bf16[16,2]{1,0} %subtract.3)
  %p34.785 = s64[16]{0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=348}
  %constant.15 = s64[] constant(-100)
  %broadcast.37 = s64[16]{0} broadcast(s64[] %constant.15), dimensions={}
  %compare.4 = pred[16]{0} compare(s64[16]{0} %p34.785, s64[16]{0} %broadcast.37), direction=NE
  %convert.1 = bf16[16]{0} convert(pred[16]{0} %compare.4), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.17 = bf16[] constant(0)
  %reduce.11 = bf16[] reduce(bf16[16]{0} %convert.1, bf16[] %constant.17), dimensions={0}, to_apply=%SimpleCrossEntropyLossBackwardAdd.868
  %multiply.30 = bf16[] multiply(bf16[] %p36.864, bf16[] %reduce.11)
  %divide.3 = bf16[] divide(bf16[] %constant.865, bf16[] %multiply.30)
  %broadcast.39 = bf16[16]{0} broadcast(bf16[] %divide.3), dimensions={}
  %constant.35 = bf16[] constant(0)
  %broadcast.77 = bf16[16]{0} broadcast(bf16[] %constant.35), dimensions={}
  %select.9 = bf16[16]{0} select(pred[16]{0} %compare.4, bf16[16]{0} %broadcast.39, bf16[16]{0} %broadcast.77)
  %broadcast.41 = bf16[16,2]{1,0} broadcast(bf16[16]{0} %select.9), dimensions={0}
  %multiply.11 = bf16[16,2]{1,0} multiply(bf16[16,2]{1,0} %exponential.3, bf16[16,2]{1,0} %broadcast.41)
  %broadcast.44 = s64[16,2]{1,0} broadcast(s64[16]{0} %p34.785), dimensions={0}
  %iota.7 = s64[16,2]{1,0} iota(), iota_dimension=1
  %compare.5 = pred[16,2]{1,0} compare(s64[16,2]{1,0} %broadcast.44, s64[16,2]{1,0} %iota.7), direction=EQ
  %negate.3 = bf16[] negate(bf16[] %divide.3)
  %broadcast.48 = bf16[16,2]{1,0} broadcast(bf16[] %negate.3), dimensions={}
  %constant.18 = bf16[] constant(0)
  %broadcast.49 = bf16[16,2]{1,0} broadcast(bf16[] %constant.18), dimensions={}
  %select.3 = bf16[16,2]{1,0} select(pred[16,2]{1,0} %compare.5, bf16[16,2]{1,0} %broadcast.48, bf16[16,2]{1,0} %broadcast.49)
  %add.1 = bf16[16,2]{1,0} add(bf16[16,2]{1,0} %multiply.11, bf16[16,2]{1,0} %select.3), metadata={op_type="xla___op_SimpleCrossEntropyLossBackwardImpl" op_name="xla___op_SimpleCrossEntropyLossBackwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.901 = bf16[16,16]{1,0} dot(bf16[16,2]{1,0} %add.1, bf16[2,16]{1,0} %custom-call.101), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %constant.769 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.773 = bf16[16,16]{1,0} broadcast(bf16[] %constant.769), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %multiply.768 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %tanh.761, bf16[16,16]{1,0} %tanh.761), metadata={op_type="aten__pow" op_name="aten__pow"}
  %subtract.774 = bf16[16,16]{1,0} subtract(bf16[16,16]{1,0} %broadcast.773, bf16[16,16]{1,0} %multiply.768), metadata={op_type="aten__sub" op_name="aten__sub"}
  %multiply.902 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %dot.901, bf16[16,16]{1,0} %subtract.774), metadata={op_type="aten__mul" op_name="aten__mul"}
  %dot.903 = bf16[16,16]{1,0} dot(bf16[16,16]{1,0} %multiply.902, bf16[16,16]{1,0} %custom-call.99), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.904 = bf16[16,1,16]{2,1,0} reshape(bf16[16,16]{1,0} %dot.903), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.71 = bf16[] constant(0)
  %pad = bf16[16,128,16]{2,1,0} pad(bf16[16,1,16]{2,1,0} %reshape.904, bf16[] %constant.71), padding=0_0x0_127x0_0, metadata={op_type="xla__update_slice" op_name="xla__update_slice"}
  %add.1186 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.1185, bf16[16,128,16]{2,1,0} %pad), metadata={op_type="aten__add" op_name="aten__add"}
  %broadcast.1187 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.90), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul"}
  %multiply.1188 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.1186, bf16[16,128,16]{2,1,0} %broadcast.1187), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1189 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1188), metadata={op_type="aten__view" op_name="aten__view"}
  %batch-norm-grad.1197 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-grad(bf16[1,2048,16]{2,1,0} %reshape.678, bf16[2048]{0} %broadcast.691, bf16[2048]{0} %get-tuple-element.681, bf16[2048]{0} %add.10, bf16[1,2048,16]{2,1,0} %reshape.1189), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %get-tuple-element.1198 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-grad.1197), index=0, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %reshape.1201 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1198), metadata={op_type="aten__view" op_name="aten__view"}
  %multiply.1202 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1201, bf16[16,128,16]{2,1,0} %select.10), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1203 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1202), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1204 = bf16[2048,4096]{1,0} dot(bf16[2048,16]{1,0} %reshape.1203, bf16[16,4096]{1,0} %custom-call.88), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1205 = bf16[16,128,4096]{2,1,0} reshape(bf16[2048,4096]{1,0} %dot.1204), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.103 = bf16[16,128,4096]{2,1,0} custom-call(bf16[16,128,4096]{2,1,0} %add.571), custom_call_target="AwsNeuronGeluBackward", api_version=API_VERSION_UNSPECIFIED
  %multiply.12 = bf16[16,128,4096]{2,1,0} multiply(bf16[16,128,4096]{2,1,0} %reshape.1205, bf16[16,128,4096]{2,1,0} %custom-call.103), metadata={op_type="xla___op_GeluBackwardImpl" op_name="xla___op_GeluBackwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1216 = bf16[2048,4096]{1,0} reshape(bf16[16,128,4096]{2,1,0} %multiply.12), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1217 = bf16[2048,16]{1,0} dot(bf16[2048,4096]{1,0} %reshape.1216, bf16[4096,16]{1,0} %custom-call.84), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1218 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1217), metadata={op_type="aten__view" op_name="aten__view"}
  %add.1220 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.1201, bf16[16,128,16]{2,1,0} %reshape.1218), metadata={op_type="aten__add" op_name="aten__add"}
  %broadcast.1221 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.83), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul"}
  %multiply.1222 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.1220, bf16[16,128,16]{2,1,0} %broadcast.1221), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1223 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1222), metadata={op_type="aten__view" op_name="aten__view"}
  %batch-norm-grad.1231 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-grad(bf16[1,2048,16]{2,1,0} %reshape.492, bf16[2048]{0} %broadcast.505, bf16[2048]{0} %get-tuple-element.495, bf16[2048]{0} %add.9, bf16[1,2048,16]{2,1,0} %reshape.1223), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %get-tuple-element.1232 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-grad.1231), index=0, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %reshape.1235 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1232), metadata={op_type="aten__view" op_name="aten__view"}
  %reshape.1292 = bf16[32,128,128]{2,1,0} reshape(bf16[16,2,128,128]{3,2,1,0} %multiply.476), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1293 = bf16[32,128,128]{1,2,0} transpose(bf16[32,128,128]{2,1,0} %reshape.1292), dimensions={0,2,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided"}
  %multiply.1236 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1235, bf16[16,128,16]{2,1,0} %select.11), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1237 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1236), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1238 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.1237, bf16[16,16]{1,0} %custom-call.81), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1240 = bf16[16,128,2,8]{3,2,1,0} reshape(bf16[2048,16]{1,0} %dot.1238), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1241 = bf16[16,2,128,8]{3,1,2,0} transpose(bf16[16,128,2,8]{3,2,1,0} %reshape.1240), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %reshape.1242 = bf16[32,128,8]{2,1,0} reshape(bf16[16,2,128,8]{3,1,2,0} %transpose.1241), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1294 = bf16[32,128,8]{2,1,0} dot(bf16[32,128,128]{1,2,0} %transpose.1293, bf16[32,128,8]{2,1,0} %reshape.1242), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul"}
  %reshape.1295 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.1294), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1296 = bf16[16,128,2,8]{3,1,2,0} transpose(bf16[16,2,128,8]{3,2,1,0} %reshape.1295), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %reshape.1298 = bf16[2048,16]{1,0} reshape(bf16[16,128,2,8]{3,1,2,0} %transpose.1296), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1299 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.1298, bf16[16,16]{1,0} %custom-call.79), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1300 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1299), metadata={op_type="aten__view" op_name="aten__view"}
  %add.1302 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %reshape.1235, bf16[16,128,16]{2,1,0} %reshape.1300), metadata={op_type="aten__add" op_name="aten__add"}
  %reshape.1274 = bf16[32,128,8]{2,1,0} reshape(bf16[16,2,128,8]{3,1,2,0} %transpose.287), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1275 = bf16[32,8,128]{1,2,0} transpose(bf16[32,128,8]{2,1,0} %reshape.1274), dimensions={0,2,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided"}
  %reshape.385 = bf16[32,128,8]{2,1,0} reshape(bf16[16,2,128,8]{3,1,2,0} %transpose.383), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.386 = bf16[32,8,128]{1,2,0} transpose(bf16[32,128,8]{2,1,0} %reshape.385), dimensions={0,2,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided"}
  %dot.1243 = bf16[32,128,128]{2,1,0} dot(bf16[32,128,8]{2,1,0} %reshape.1242, bf16[32,8,128]{1,2,0} %transpose.386), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul"}
  %reshape.1244 = bf16[16,2,128,128]{3,2,1,0} reshape(bf16[32,128,128]{2,1,0} %dot.1243), metadata={op_type="aten__view" op_name="aten__view"}
  %multiply.1245 = bf16[16,2,128,128]{3,2,1,0} multiply(bf16[16,2,128,128]{3,2,1,0} %reshape.1244, bf16[16,2,128,128]{3,2,1,0} %select.12), metadata={op_type="aten__mul" op_name="aten__mul"}
  %multiply.1246 = bf16[16,2,128,128]{3,2,1,0} multiply(bf16[16,2,128,128]{3,2,1,0} %multiply.1245, bf16[16,2,128,128]{3,2,1,0} %divide.314), metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %constant.1247 = bf16[] constant(0), metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %reduce.1252 = bf16[16,2,128]{2,1,0} reduce(bf16[16,2,128,128]{3,2,1,0} %multiply.1246, bf16[] %constant.1247), dimensions={3}, to_apply=%AddComputation.1248, metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %broadcast.1253 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[16,2,128]{2,1,0} %reduce.1252), dimensions={0,1,2}, metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %subtract.1254 = bf16[16,2,128,128]{3,2,1,0} subtract(bf16[16,2,128,128]{3,2,1,0} %multiply.1245, bf16[16,2,128,128]{3,2,1,0} %broadcast.1253), metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %multiply.1255 = bf16[16,2,128,128]{3,2,1,0} multiply(bf16[16,2,128,128]{3,2,1,0} %divide.314, bf16[16,2,128,128]{3,2,1,0} %subtract.1254), metadata={op_type="aten___softmax_backward_data" op_name="aten___softmax_backward_data"}
  %broadcast.1256 = bf16[16,2,128,128]{3,2,1,0} broadcast(bf16[] %p15.235), dimensions={}, metadata={op_type="aten__div" op_name="aten__div"}
  %divide.1257 = bf16[16,2,128,128]{3,2,1,0} divide(bf16[16,2,128,128]{3,2,1,0} %multiply.1255, bf16[16,2,128,128]{3,2,1,0} %broadcast.1256), metadata={op_type="aten__div" op_name="aten__div"}
  %reshape.1258 = bf16[32,128,128]{2,1,0} reshape(bf16[16,2,128,128]{3,2,1,0} %divide.1257), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1276 = bf16[32,8,128]{2,1,0} dot(bf16[32,8,128]{1,2,0} %transpose.1275, bf16[32,128,128]{2,1,0} %reshape.1258), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul"}
  %reshape.1277 = bf16[16,2,8,128]{3,2,1,0} reshape(bf16[32,8,128]{2,1,0} %dot.1276), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1279 = bf16[16,128,2,8]{1,3,2,0} transpose(bf16[16,2,8,128]{3,2,1,0} %reshape.1277), dimensions={0,3,1,2}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %reshape.1281 = bf16[2048,16]{1,0} reshape(bf16[16,128,2,8]{1,3,2,0} %transpose.1279), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1282 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.1281, bf16[16,16]{1,0} %custom-call.77), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1283 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1282), metadata={op_type="aten__view" op_name="aten__view"}
  %add.1303 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %add.1302, bf16[16,128,16]{2,1,0} %reshape.1283), metadata={op_type="aten__add" op_name="aten__add"}
  %reshape.233 = bf16[32,8,128]{2,1,0} reshape(bf16[16,2,8,128]{2,1,3,0} %transpose.231), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.234 = bf16[32,128,8]{1,2,0} transpose(bf16[32,8,128]{2,1,0} %reshape.233), dimensions={0,2,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided"}
  %dot.1259 = bf16[32,128,8]{2,1,0} dot(bf16[32,128,128]{2,1,0} %reshape.1258, bf16[32,128,8]{1,2,0} %transpose.234), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul"}
  %reshape.1260 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.1259), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1261 = bf16[16,128,2,8]{3,1,2,0} transpose(bf16[16,2,128,8]{3,2,1,0} %reshape.1260), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %reshape.1263 = bf16[2048,16]{1,0} reshape(bf16[16,128,2,8]{3,1,2,0} %transpose.1261), metadata={op_type="aten__view" op_name="aten__view"}
  %dot.1264 = bf16[2048,16]{1,0} dot(bf16[2048,16]{1,0} %reshape.1263, bf16[16,16]{1,0} %custom-call.75), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.1265 = bf16[16,128,16]{2,1,0} reshape(bf16[2048,16]{1,0} %dot.1264), metadata={op_type="aten__view" op_name="aten__view"}
  %add.1304 = bf16[16,128,16]{2,1,0} add(bf16[16,128,16]{2,1,0} %add.1303, bf16[16,128,16]{2,1,0} %reshape.1265), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1305 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.1304, bf16[16,128,16]{2,1,0} %select.13), metadata={op_type="aten__mul" op_name="aten__mul"}
  %broadcast.1306 = bf16[16,128,16]{2,1,0} broadcast(bf16[16]{0} %custom-call.74), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul"}
  %multiply.1307 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %multiply.1305, bf16[16,128,16]{2,1,0} %broadcast.1306), metadata={op_type="aten__mul" op_name="aten__mul"}
  %reshape.1308 = bf16[1,2048,16]{2,1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.1307), metadata={op_type="aten__view" op_name="aten__view"}
  %batch-norm-grad.1316 = (bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) batch-norm-grad(bf16[1,2048,16]{2,1,0} %reshape.99, bf16[2048]{0} %broadcast.112, bf16[2048]{0} %get-tuple-element.102, bf16[2048]{0} %add.8, bf16[1,2048,16]{2,1,0} %reshape.1308), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %get-tuple-element.1317 = bf16[1,2048,16]{2,1,0} get-tuple-element((bf16[1,2048,16]{2,1,0}, bf16[2048]{0}, bf16[2048]{0}) %batch-norm-grad.1316), index=0, metadata={op_type="aten__native_batch_norm_backward" op_name="aten__native_batch_norm_backward"}
  %reshape.1321 = bf16[2048,16]{1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1317), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.16 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant"}
  %broadcast.20 = bf16[2048,16]{1,0} broadcast(bf16[] %constant.16), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %select.1331 = bf16[2048,16]{1,0} select(pred[2048,16]{1,0} %broadcast.1330, bf16[2048,16]{1,0} %reshape.1321, bf16[2048,16]{1,0} %broadcast.20), metadata={op_type="aten__where" op_name="aten__where"}
  %scatter.1354 = bf16[30522,16]{1,0} scatter(bf16[30522,16]{1,0} %broadcast.1348, s64[2048,1]{1,0} %reshape.1342, bf16[2048,16]{1,0} %select.1331), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%ScatterCombiner.1350, metadata={op_type="aten__index_put" op_name="aten__index_put"}
  %custom-call.105 = bf16[30522,16]{1,0} custom-call(bf16[30522,16]{1,0} %scatter.1354), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1375 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %custom-call.104, bf16[30522,16]{1,0} %custom-call.105), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.1376 = f32[30522,16]{1,0} convert(bf16[30522,16]{1,0} %add.1375), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %p46.1388 = f32[] parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1392 = f32[30522,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1393 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %convert.1376, f32[30522,16]{1,0} %broadcast.1392), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1398 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %multiply.1397, f32[30522,16]{1,0} %multiply.1393), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p45.1378 = f32[30522,16]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %p44.1377 = f32[] parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1379 = f32[30522,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1380 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %p45.1378, f32[30522,16]{1,0} %broadcast.1379), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1381 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %convert.1376, f32[30522,16]{1,0} %convert.1376), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %p1.10 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1382 = f32[30522,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1383 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.1381, f32[30522,16]{1,0} %broadcast.1382), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1384 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %multiply.1380, f32[30522,16]{1,0} %multiply.1383), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1385 = f32[30522,16]{1,0} sqrt(f32[30522,16]{1,0} %add.1384), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %p0.8 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1386 = f32[30522,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1387 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %sqrt.1385, f32[30522,16]{1,0} %broadcast.1386), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1399 = f32[30522,16]{1,0} divide(f32[30522,16]{1,0} %add.1398, f32[30522,16]{1,0} %add.1387), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.6 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1400 = f32[30522,16]{1,0} broadcast(f32[] %constant.6), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1401 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %divide.1399, f32[30522,16]{1,0} %broadcast.1400), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1403 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %convert.1402, f32[30522,16]{1,0} %multiply.1401), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1404 = bf16[30522,16]{1,0} convert(f32[30522,16]{1,0} %add.1403), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.5 = bf16[30522,16]{1,0} broadcast(bf16[] %constant.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1405 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %convert.1404, bf16[30522,16]{1,0} %broadcast.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1406 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %convert.1404, bf16[30522,16]{1,0} %multiply.1405), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1478 = f32[512,16]{1,0} convert(bf16[512,16]{1,0} %p3.50), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p50.1471 = f32[512,16]{1,0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1472 = f32[512,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1473 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %p50.1471, f32[512,16]{1,0} %broadcast.1472), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.19 = bf16[] constant(0)
  %broadcast.50 = bf16[512,16]{1,0} broadcast(bf16[] %constant.19), dimensions={}
  %slice.1416 = s64[1,128]{1,0} slice(s64[1,512]{1,0} %p2.46), slice={[0:1], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.16 = s64[128]{0} reshape(s64[1,128]{1,0} %slice.1416)
  %constant.20 = s64[] constant(0)
  %broadcast.51 = s64[128]{0} broadcast(s64[] %constant.20), dimensions={}
  %compare.6 = pred[128]{0} compare(s64[128]{0} %reshape.16, s64[128]{0} %broadcast.51), direction=GE
  %constant.22 = s64[] constant(512)
  %broadcast.52 = s64[128]{0} broadcast(s64[] %constant.22), dimensions={}
  %add.2 = s64[128]{0} add(s64[128]{0} %reshape.16, s64[128]{0} %broadcast.52)
  %select.4 = s64[128]{0} select(pred[128]{0} %compare.6, s64[128]{0} %reshape.16, s64[128]{0} %add.2)
  %reshape.18 = s64[128,1]{1,0} reshape(s64[128]{0} %select.4)
  %reshape.1417 = bf16[16,128,16]{2,1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1317), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.1418 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.1424 = bf16[128,16]{1,0} reduce(bf16[16,128,16]{2,1,0} %reshape.1417, bf16[] %constant.1418), dimensions={0}, to_apply=%AddComputation.1420, metadata={op_type="aten__sum" op_name="aten__sum"}
  %scatter.0 = bf16[512,16]{1,0} scatter(bf16[512,16]{1,0} %broadcast.50, s64[128,1]{1,0} %reshape.18, bf16[128,16]{1,0} %reduce.1424), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%Int32PermissiveEmbeddingScatterCombiner.1426, metadata={op_type="xla___op_Int32PermissiveEmbeddingGradWeight" op_name="xla___op_Int32PermissiveEmbeddingGradWeight" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.106 = bf16[512,16]{1,0} custom-call(bf16[512,16]{1,0} %scatter.0), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1455 = f32[512,16]{1,0} convert(bf16[512,16]{1,0} %custom-call.106), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1469 = f32[512,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1470 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %convert.1455, f32[512,16]{1,0} %broadcast.1469), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1474 = f32[512,16]{1,0} add(f32[512,16]{1,0} %multiply.1473, f32[512,16]{1,0} %multiply.1470), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p49.1456 = f32[512,16]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1457 = f32[512,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1458 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %p49.1456, f32[512,16]{1,0} %broadcast.1457), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1459 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %convert.1455, f32[512,16]{1,0} %convert.1455), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1460 = f32[512,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1461 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.1459, f32[512,16]{1,0} %broadcast.1460), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1462 = f32[512,16]{1,0} add(f32[512,16]{1,0} %multiply.1458, f32[512,16]{1,0} %multiply.1461), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1463 = f32[512,16]{1,0} sqrt(f32[512,16]{1,0} %add.1462), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1464 = f32[512,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1465 = f32[512,16]{1,0} add(f32[512,16]{1,0} %sqrt.1463, f32[512,16]{1,0} %broadcast.1464), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1475 = f32[512,16]{1,0} divide(f32[512,16]{1,0} %add.1474, f32[512,16]{1,0} %add.1465), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1412 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1476 = f32[512,16]{1,0} broadcast(f32[] %constant.1412), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1477 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %divide.1475, f32[512,16]{1,0} %broadcast.1476), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1479 = f32[512,16]{1,0} add(f32[512,16]{1,0} %convert.1478, f32[512,16]{1,0} %multiply.1477), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1480 = bf16[512,16]{1,0} convert(f32[512,16]{1,0} %add.1479), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1407 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1411 = bf16[512,16]{1,0} broadcast(bf16[] %constant.1407), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1481 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %convert.1480, bf16[512,16]{1,0} %broadcast.1411), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1482 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %convert.1480, bf16[512,16]{1,0} %multiply.1481), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1543 = f32[2,16]{1,0} convert(bf16[2,16]{1,0} %p5.69), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p52.1536 = f32[2,16]{1,0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1537 = f32[2,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1538 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p52.1536, f32[2,16]{1,0} %broadcast.1537), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.23 = bf16[] constant(0)
  %broadcast.53 = bf16[2,16]{1,0} broadcast(bf16[] %constant.23), dimensions={}
  %reshape.21 = s64[2048]{0} reshape(s64[16,128]{1,0} %p4.67)
  %constant.24 = s64[] constant(0)
  %broadcast.54 = s64[2048]{0} broadcast(s64[] %constant.24), dimensions={}
  %compare.7 = pred[2048]{0} compare(s64[2048]{0} %reshape.21, s64[2048]{0} %broadcast.54), direction=GE
  %constant.25 = s64[] constant(2)
  %broadcast.55 = s64[2048]{0} broadcast(s64[] %constant.25), dimensions={}
  %add.3 = s64[2048]{0} add(s64[2048]{0} %reshape.21, s64[2048]{0} %broadcast.55)
  %select.5 = s64[2048]{0} select(pred[2048]{0} %compare.7, s64[2048]{0} %reshape.21, s64[2048]{0} %add.3)
  %reshape.23 = s64[2048,1]{1,0} reshape(s64[2048]{0} %select.5)
  %reshape.25 = bf16[2048,16]{1,0} reshape(bf16[1,2048,16]{2,1,0} %get-tuple-element.1317)
  %scatter.1 = bf16[2,16]{1,0} scatter(bf16[2,16]{1,0} %broadcast.53, s64[2048,1]{1,0} %reshape.23, bf16[2048,16]{1,0} %reshape.25), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%Int32PermissiveEmbeddingScatterCombiner.1491, metadata={op_type="xla___op_Int32PermissiveEmbeddingGradWeight" op_name="xla___op_Int32PermissiveEmbeddingGradWeight" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.107 = bf16[2,16]{1,0} custom-call(bf16[2,16]{1,0} %scatter.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1520 = f32[2,16]{1,0} convert(bf16[2,16]{1,0} %custom-call.107), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1534 = f32[2,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1535 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %convert.1520, f32[2,16]{1,0} %broadcast.1534), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1539 = f32[2,16]{1,0} add(f32[2,16]{1,0} %multiply.1538, f32[2,16]{1,0} %multiply.1535), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p51.1521 = f32[2,16]{1,0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1522 = f32[2,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1523 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p51.1521, f32[2,16]{1,0} %broadcast.1522), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1524 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %convert.1520, f32[2,16]{1,0} %convert.1520), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1525 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1526 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.1524, f32[2,16]{1,0} %broadcast.1525), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1527 = f32[2,16]{1,0} add(f32[2,16]{1,0} %multiply.1523, f32[2,16]{1,0} %multiply.1526), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1528 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.1527), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1529 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1530 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.1528, f32[2,16]{1,0} %broadcast.1529), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1540 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.1539, f32[2,16]{1,0} %add.1530), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1488 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1541 = f32[2,16]{1,0} broadcast(f32[] %constant.1488), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1542 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.1540, f32[2,16]{1,0} %broadcast.1541), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1544 = f32[2,16]{1,0} add(f32[2,16]{1,0} %convert.1543, f32[2,16]{1,0} %multiply.1542), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1545 = bf16[2,16]{1,0} convert(f32[2,16]{1,0} %add.1544), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1483 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1487 = bf16[2,16]{1,0} broadcast(bf16[] %constant.1483), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1546 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %convert.1545, bf16[2,16]{1,0} %broadcast.1487), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1547 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %convert.1545, bf16[2,16]{1,0} %multiply.1546), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1597 = f32[16]{0} convert(bf16[16]{0} %p8.118), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p54.1590 = f32[16]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1591 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1592 = f32[16]{0} multiply(f32[16]{0} %p54.1590, f32[16]{0} %broadcast.1591), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1557 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %multiply.1305, bf16[16,128,16]{2,1,0} %reshape.205), metadata={op_type="aten__mul" op_name="aten__mul"}
  %constant.1558 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.1564 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.1557, bf16[] %constant.1558), dimensions={0,1}, to_apply=%AddComputation.1560, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.108 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.1564), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1574 = f32[16]{0} convert(bf16[16]{0} %custom-call.108), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1588 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1589 = f32[16]{0} multiply(f32[16]{0} %convert.1574, f32[16]{0} %broadcast.1588), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1593 = f32[16]{0} add(f32[16]{0} %multiply.1592, f32[16]{0} %multiply.1589), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p53.1575 = f32[16]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1576 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1577 = f32[16]{0} multiply(f32[16]{0} %p53.1575, f32[16]{0} %broadcast.1576), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1578 = f32[16]{0} multiply(f32[16]{0} %convert.1574, f32[16]{0} %convert.1574), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1579 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1580 = f32[16]{0} multiply(f32[16]{0} %multiply.1578, f32[16]{0} %broadcast.1579), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1581 = f32[16]{0} add(f32[16]{0} %multiply.1577, f32[16]{0} %multiply.1580), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1582 = f32[16]{0} sqrt(f32[16]{0} %add.1581), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1583 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1584 = f32[16]{0} add(f32[16]{0} %sqrt.1582, f32[16]{0} %broadcast.1583), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1594 = f32[16]{0} divide(f32[16]{0} %add.1593, f32[16]{0} %add.1584), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1548 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1595 = f32[16]{0} broadcast(f32[] %constant.1548), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1596 = f32[16]{0} multiply(f32[16]{0} %divide.1594, f32[16]{0} %broadcast.1595), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1598 = f32[16]{0} add(f32[16]{0} %convert.1597, f32[16]{0} %multiply.1596), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1599 = bf16[16]{0} convert(f32[16]{0} %add.1598), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1642 = f32[16]{0} convert(bf16[16]{0} %p14.206), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p56.1635 = f32[16]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1636 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1637 = f32[16]{0} multiply(f32[16]{0} %p56.1635, f32[16]{0} %broadcast.1636), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.1603 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.1609 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.1305, bf16[] %constant.1603), dimensions={0,1}, to_apply=%AddComputation.1605, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.109 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.1609), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1619 = f32[16]{0} convert(bf16[16]{0} %custom-call.109), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1633 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1634 = f32[16]{0} multiply(f32[16]{0} %convert.1619, f32[16]{0} %broadcast.1633), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1638 = f32[16]{0} add(f32[16]{0} %multiply.1637, f32[16]{0} %multiply.1634), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p55.1620 = f32[16]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1621 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1622 = f32[16]{0} multiply(f32[16]{0} %p55.1620, f32[16]{0} %broadcast.1621), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1623 = f32[16]{0} multiply(f32[16]{0} %convert.1619, f32[16]{0} %convert.1619), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1624 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1625 = f32[16]{0} multiply(f32[16]{0} %multiply.1623, f32[16]{0} %broadcast.1624), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1626 = f32[16]{0} add(f32[16]{0} %multiply.1622, f32[16]{0} %multiply.1625), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1627 = f32[16]{0} sqrt(f32[16]{0} %add.1626), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1628 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1629 = f32[16]{0} add(f32[16]{0} %sqrt.1627, f32[16]{0} %broadcast.1628), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1639 = f32[16]{0} divide(f32[16]{0} %add.1638, f32[16]{0} %add.1629), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1600 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1640 = f32[16]{0} broadcast(f32[] %constant.1600), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1641 = f32[16]{0} multiply(f32[16]{0} %divide.1639, f32[16]{0} %broadcast.1640), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1643 = f32[16]{0} add(f32[16]{0} %convert.1642, f32[16]{0} %multiply.1641), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1644 = bf16[16]{0} convert(f32[16]{0} %add.1643), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1687 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p11.171), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p58.1680 = f32[16,16]{1,0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1681 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1682 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p58.1680, f32[16,16]{1,0} %broadcast.1681), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1653 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1654 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.1653), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.1 = bf16[16,16]{0,1} dot(bf16[2048,16]{1,0} %reshape.1263, bf16[16,2048]{0,1} %transpose.1654), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.110 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1664 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.110), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1678 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1679 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1664, f32[16,16]{1,0} %broadcast.1678), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1683 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1682, f32[16,16]{1,0} %multiply.1679), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p57.1665 = f32[16,16]{1,0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1666 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1667 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p57.1665, f32[16,16]{1,0} %broadcast.1666), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1668 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1664, f32[16,16]{1,0} %convert.1664), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1669 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1670 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1668, f32[16,16]{1,0} %broadcast.1669), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1671 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1667, f32[16,16]{1,0} %multiply.1670), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1672 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1671), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1673 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1674 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1672, f32[16,16]{1,0} %broadcast.1673), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1684 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1683, f32[16,16]{1,0} %add.1674), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1650 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1685 = f32[16,16]{1,0} broadcast(f32[] %constant.1650), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1686 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1684, f32[16,16]{1,0} %broadcast.1685), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1688 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.1687, f32[16,16]{1,0} %multiply.1686), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1689 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.1688), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1645 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1649 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1645), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1690 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.1689, bf16[16,16]{1,0} %broadcast.1649), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1691 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.1689, bf16[16,16]{1,0} %multiply.1690), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1737 = f32[16]{0} convert(bf16[16]{0} %p18.269), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p60.1730 = f32[16]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1731 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1732 = f32[16]{0} multiply(f32[16]{0} %p60.1730, f32[16]{0} %broadcast.1731), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1695 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.1259), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.1698 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.12 = bf16[2,8]{1,0} reduce(bf16[16,2,128,8]{3,2,1,0} %reshape.1695, bf16[] %constant.1698), dimensions={0,2}, to_apply=%AddComputation.1700, metadata={op_type="aten__sum" op_name="aten__sum"}
  %reshape.1706 = bf16[16]{0} reshape(bf16[2,8]{1,0} %reduce.12), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.111 = bf16[16]{0} custom-call(bf16[16]{0} %reshape.1706), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1714 = f32[16]{0} convert(bf16[16]{0} %custom-call.111), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1728 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1729 = f32[16]{0} multiply(f32[16]{0} %convert.1714, f32[16]{0} %broadcast.1728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1733 = f32[16]{0} add(f32[16]{0} %multiply.1732, f32[16]{0} %multiply.1729), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p59.1715 = f32[16]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1716 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1717 = f32[16]{0} multiply(f32[16]{0} %p59.1715, f32[16]{0} %broadcast.1716), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1718 = f32[16]{0} multiply(f32[16]{0} %convert.1714, f32[16]{0} %convert.1714), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1719 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1720 = f32[16]{0} multiply(f32[16]{0} %multiply.1718, f32[16]{0} %broadcast.1719), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1721 = f32[16]{0} add(f32[16]{0} %multiply.1717, f32[16]{0} %multiply.1720), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1722 = f32[16]{0} sqrt(f32[16]{0} %add.1721), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1723 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1724 = f32[16]{0} add(f32[16]{0} %sqrt.1722, f32[16]{0} %broadcast.1723), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1734 = f32[16]{0} divide(f32[16]{0} %add.1733, f32[16]{0} %add.1724), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1692 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1735 = f32[16]{0} broadcast(f32[] %constant.1692), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1736 = f32[16]{0} multiply(f32[16]{0} %divide.1734, f32[16]{0} %broadcast.1735), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1738 = f32[16]{0} add(f32[16]{0} %convert.1737, f32[16]{0} %multiply.1736), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1739 = bf16[16]{0} convert(f32[16]{0} %add.1738), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1782 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p13.195), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p62.1775 = f32[16,16]{1,0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1776 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1777 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p62.1775, f32[16,16]{1,0} %broadcast.1776), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1748 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1749 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.1748), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.2 = bf16[16,16]{0,1} dot(bf16[2048,16]{1,0} %reshape.1281, bf16[16,2048]{0,1} %transpose.1749), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.112 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.2), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1759 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.112), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1773 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1774 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1759, f32[16,16]{1,0} %broadcast.1773), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1778 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1777, f32[16,16]{1,0} %multiply.1774), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p61.1760 = f32[16,16]{1,0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1761 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1762 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p61.1760, f32[16,16]{1,0} %broadcast.1761), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1763 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1759, f32[16,16]{1,0} %convert.1759), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1764 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1765 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1763, f32[16,16]{1,0} %broadcast.1764), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1766 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1762, f32[16,16]{1,0} %multiply.1765), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1767 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1766), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1768 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1769 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1767, f32[16,16]{1,0} %broadcast.1768), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1779 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1778, f32[16,16]{1,0} %add.1769), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1745 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1780 = f32[16,16]{1,0} broadcast(f32[] %constant.1745), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1781 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1779, f32[16,16]{1,0} %broadcast.1780), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1783 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.1782, f32[16,16]{1,0} %multiply.1781), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1784 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.1783), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1740 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1744 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1740), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1785 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.1784, bf16[16,16]{1,0} %broadcast.1744), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1786 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.1784, bf16[16,16]{1,0} %multiply.1785), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1833 = f32[16]{0} convert(bf16[16]{0} %p12.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p64.1826 = f32[16]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1827 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1828 = f32[16]{0} multiply(f32[16]{0} %p64.1826, f32[16]{0} %broadcast.1827), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1790 = bf16[16,2,8,128]{3,2,1,0} reshape(bf16[32,8,128]{2,1,0} %dot.1276), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.1794 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.13 = bf16[2,8]{1,0} reduce(bf16[16,2,8,128]{3,2,1,0} %reshape.1790, bf16[] %constant.1794), dimensions={0,3}, to_apply=%AddComputation.1796, metadata={op_type="aten__sum" op_name="aten__sum"}
  %reshape.1802 = bf16[16]{0} reshape(bf16[2,8]{1,0} %reduce.13), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.113 = bf16[16]{0} custom-call(bf16[16]{0} %reshape.1802), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1810 = f32[16]{0} convert(bf16[16]{0} %custom-call.113), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1824 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1825 = f32[16]{0} multiply(f32[16]{0} %convert.1810, f32[16]{0} %broadcast.1824), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1829 = f32[16]{0} add(f32[16]{0} %multiply.1828, f32[16]{0} %multiply.1825), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p63.1811 = f32[16]{0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1812 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1813 = f32[16]{0} multiply(f32[16]{0} %p63.1811, f32[16]{0} %broadcast.1812), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1814 = f32[16]{0} multiply(f32[16]{0} %convert.1810, f32[16]{0} %convert.1810), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1815 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1816 = f32[16]{0} multiply(f32[16]{0} %multiply.1814, f32[16]{0} %broadcast.1815), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1817 = f32[16]{0} add(f32[16]{0} %multiply.1813, f32[16]{0} %multiply.1816), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1818 = f32[16]{0} sqrt(f32[16]{0} %add.1817), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1819 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1820 = f32[16]{0} add(f32[16]{0} %sqrt.1818, f32[16]{0} %broadcast.1819), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1830 = f32[16]{0} divide(f32[16]{0} %add.1829, f32[16]{0} %add.1820), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1787 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1831 = f32[16]{0} broadcast(f32[] %constant.1787), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1832 = f32[16]{0} multiply(f32[16]{0} %divide.1830, f32[16]{0} %broadcast.1831), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1834 = f32[16]{0} add(f32[16]{0} %convert.1833, f32[16]{0} %multiply.1832), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1835 = bf16[16]{0} convert(f32[16]{0} %add.1834), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1878 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p20.366), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p66.1871 = f32[16,16]{1,0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1872 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1873 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p66.1871, f32[16,16]{1,0} %broadcast.1872), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1844 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %multiply.459), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1845 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.1844), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.3 = bf16[16,16]{0,1} dot(bf16[2048,16]{1,0} %reshape.1298, bf16[16,2048]{0,1} %transpose.1845), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.114 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.3), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1855 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.114), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1869 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1870 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1855, f32[16,16]{1,0} %broadcast.1869), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1874 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1873, f32[16,16]{1,0} %multiply.1870), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p65.1856 = f32[16,16]{1,0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1857 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1858 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p65.1856, f32[16,16]{1,0} %broadcast.1857), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1859 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1855, f32[16,16]{1,0} %convert.1855), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1860 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1861 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1859, f32[16,16]{1,0} %broadcast.1860), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1862 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1858, f32[16,16]{1,0} %multiply.1861), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1863 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1862), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1864 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1865 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1863, f32[16,16]{1,0} %broadcast.1864), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1875 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1874, f32[16,16]{1,0} %add.1865), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1841 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1876 = f32[16,16]{1,0} broadcast(f32[] %constant.1841), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1877 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1875, f32[16,16]{1,0} %broadcast.1876), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1879 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.1878, f32[16,16]{1,0} %multiply.1877), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1880 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.1879), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1836 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1840 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1836), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1881 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.1880, bf16[16,16]{1,0} %broadcast.1840), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1882 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.1880, bf16[16,16]{1,0} %multiply.1881), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.1928 = f32[16]{0} convert(bf16[16]{0} %p19.357), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p68.1921 = f32[16]{0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1922 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1923 = f32[16]{0} multiply(f32[16]{0} %p68.1921, f32[16]{0} %broadcast.1922), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1886 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.1294), metadata={op_type="aten__view" op_name="aten__view"}
  %constant.1889 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.14 = bf16[2,8]{1,0} reduce(bf16[16,2,128,8]{3,2,1,0} %reshape.1886, bf16[] %constant.1889), dimensions={0,2}, to_apply=%AddComputation.1891, metadata={op_type="aten__sum" op_name="aten__sum"}
  %reshape.1897 = bf16[16]{0} reshape(bf16[2,8]{1,0} %reduce.14), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.115 = bf16[16]{0} custom-call(bf16[16]{0} %reshape.1897), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1905 = f32[16]{0} convert(bf16[16]{0} %custom-call.115), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1919 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1920 = f32[16]{0} multiply(f32[16]{0} %convert.1905, f32[16]{0} %broadcast.1919), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1924 = f32[16]{0} add(f32[16]{0} %multiply.1923, f32[16]{0} %multiply.1920), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p67.1906 = f32[16]{0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1907 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1908 = f32[16]{0} multiply(f32[16]{0} %p67.1906, f32[16]{0} %broadcast.1907), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1909 = f32[16]{0} multiply(f32[16]{0} %convert.1905, f32[16]{0} %convert.1905), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1910 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1911 = f32[16]{0} multiply(f32[16]{0} %multiply.1909, f32[16]{0} %broadcast.1910), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1912 = f32[16]{0} add(f32[16]{0} %multiply.1908, f32[16]{0} %multiply.1911), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1913 = f32[16]{0} sqrt(f32[16]{0} %add.1912), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1914 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1915 = f32[16]{0} add(f32[16]{0} %sqrt.1913, f32[16]{0} %broadcast.1914), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1925 = f32[16]{0} divide(f32[16]{0} %add.1924, f32[16]{0} %add.1915), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1883 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1926 = f32[16]{0} broadcast(f32[] %constant.1883), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1927 = f32[16]{0} multiply(f32[16]{0} %divide.1925, f32[16]{0} %broadcast.1926), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1929 = f32[16]{0} add(f32[16]{0} %convert.1928, f32[16]{0} %multiply.1927), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1930 = bf16[16]{0} convert(f32[16]{0} %add.1929), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1976 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p21.387), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p70.1969 = f32[16,16]{1,0} parameter(70), frontend_attributes={neff_input_names="input70"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.1970 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1971 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p70.1969, f32[16,16]{1,0} %broadcast.1970), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.1939 = bf16[16,2,128,8]{3,2,1,0} reshape(bf16[32,128,8]{2,1,0} %dot.479), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1940 = bf16[16,128,2,8]{3,1,2,0} transpose(bf16[16,2,128,8]{3,2,1,0} %reshape.1939), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %reshape.1942 = bf16[2048,16]{1,0} reshape(bf16[16,128,2,8]{3,1,2,0} %transpose.1940), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.1943 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.1942), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.4 = bf16[16,16]{0,1} dot(bf16[2048,16]{1,0} %reshape.1237, bf16[16,2048]{0,1} %transpose.1943), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.116 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.4), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.1953 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.116), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.1967 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.1968 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1953, f32[16,16]{1,0} %broadcast.1967), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.1972 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1971, f32[16,16]{1,0} %multiply.1968), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p69.1954 = f32[16,16]{1,0} parameter(69), frontend_attributes={neff_input_names="input69"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1955 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1956 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p69.1954, f32[16,16]{1,0} %broadcast.1955), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1957 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.1953, f32[16,16]{1,0} %convert.1953), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.1958 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.1959 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1957, f32[16,16]{1,0} %broadcast.1958), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.1960 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.1956, f32[16,16]{1,0} %multiply.1959), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.1961 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1960), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.1962 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.1963 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1961, f32[16,16]{1,0} %broadcast.1962), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.1973 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1972, f32[16,16]{1,0} %add.1963), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1936 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.1974 = f32[16,16]{1,0} broadcast(f32[] %constant.1936), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.1975 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1973, f32[16,16]{1,0} %broadcast.1974), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.1977 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.1976, f32[16,16]{1,0} %multiply.1975), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.1978 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.1977), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1931 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.1935 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1931), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.1979 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.1978, bf16[16,16]{1,0} %broadcast.1935), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.1980 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.1978, bf16[16,16]{1,0} %multiply.1979), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2023 = f32[16]{0} convert(bf16[16]{0} %p22.465), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p72.2016 = f32[16]{0} parameter(72), frontend_attributes={neff_input_names="input72"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2017 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2018 = f32[16]{0} multiply(f32[16]{0} %p72.2016, f32[16]{0} %broadcast.2017), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.1984 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.1990 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.1236, bf16[] %constant.1984), dimensions={0,1}, to_apply=%AddComputation.1986, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.117 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.1990), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2000 = f32[16]{0} convert(bf16[16]{0} %custom-call.117), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2014 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2015 = f32[16]{0} multiply(f32[16]{0} %convert.2000, f32[16]{0} %broadcast.2014), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2019 = f32[16]{0} add(f32[16]{0} %multiply.2018, f32[16]{0} %multiply.2015), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p71.2001 = f32[16]{0} parameter(71), frontend_attributes={neff_input_names="input71"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2002 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2003 = f32[16]{0} multiply(f32[16]{0} %p71.2001, f32[16]{0} %broadcast.2002), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2004 = f32[16]{0} multiply(f32[16]{0} %convert.2000, f32[16]{0} %convert.2000), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2005 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2006 = f32[16]{0} multiply(f32[16]{0} %multiply.2004, f32[16]{0} %broadcast.2005), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2007 = f32[16]{0} add(f32[16]{0} %multiply.2003, f32[16]{0} %multiply.2006), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2008 = f32[16]{0} sqrt(f32[16]{0} %add.2007), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2009 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2010 = f32[16]{0} add(f32[16]{0} %sqrt.2008, f32[16]{0} %broadcast.2009), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2020 = f32[16]{0} divide(f32[16]{0} %add.2019, f32[16]{0} %add.2010), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.1981 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2021 = f32[16]{0} broadcast(f32[] %constant.1981), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2022 = f32[16]{0} multiply(f32[16]{0} %divide.2020, f32[16]{0} %broadcast.2021), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2024 = f32[16]{0} add(f32[16]{0} %convert.2023, f32[16]{0} %multiply.2022), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2025 = bf16[16]{0} convert(f32[16]{0} %add.2024), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2075 = f32[16]{0} convert(bf16[16]{0} %p23.511), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p74.2068 = f32[16]{0} parameter(74), frontend_attributes={neff_input_names="input74"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2069 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2070 = f32[16]{0} multiply(f32[16]{0} %p74.2068, f32[16]{0} %broadcast.2069), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2035 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.1220, bf16[16,128,16]{2,1,0} %reshape.551), metadata={op_type="aten__mul" op_name="aten__mul"}
  %constant.2036 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2042 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.2035, bf16[] %constant.2036), dimensions={0,1}, to_apply=%AddComputation.2038, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.118 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2042), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2052 = f32[16]{0} convert(bf16[16]{0} %custom-call.118), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2066 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2067 = f32[16]{0} multiply(f32[16]{0} %convert.2052, f32[16]{0} %broadcast.2066), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2071 = f32[16]{0} add(f32[16]{0} %multiply.2070, f32[16]{0} %multiply.2067), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p73.2053 = f32[16]{0} parameter(73), frontend_attributes={neff_input_names="input73"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2054 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2055 = f32[16]{0} multiply(f32[16]{0} %p73.2053, f32[16]{0} %broadcast.2054), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2056 = f32[16]{0} multiply(f32[16]{0} %convert.2052, f32[16]{0} %convert.2052), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2057 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2058 = f32[16]{0} multiply(f32[16]{0} %multiply.2056, f32[16]{0} %broadcast.2057), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2059 = f32[16]{0} add(f32[16]{0} %multiply.2055, f32[16]{0} %multiply.2058), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2060 = f32[16]{0} sqrt(f32[16]{0} %add.2059), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2061 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2062 = f32[16]{0} add(f32[16]{0} %sqrt.2060, f32[16]{0} %broadcast.2061), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2072 = f32[16]{0} divide(f32[16]{0} %add.2071, f32[16]{0} %add.2062), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2026 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2073 = f32[16]{0} broadcast(f32[] %constant.2026), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2074 = f32[16]{0} multiply(f32[16]{0} %divide.2072, f32[16]{0} %broadcast.2073), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2076 = f32[16]{0} add(f32[16]{0} %convert.2075, f32[16]{0} %multiply.2074), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2077 = bf16[16]{0} convert(f32[16]{0} %add.2076), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2120 = f32[16]{0} convert(bf16[16]{0} %p26.552), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p76.2113 = f32[16]{0} parameter(76), frontend_attributes={neff_input_names="input76"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2114 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2115 = f32[16]{0} multiply(f32[16]{0} %p76.2113, f32[16]{0} %broadcast.2114), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2081 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2087 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %add.1220, bf16[] %constant.2081), dimensions={0,1}, to_apply=%AddComputation.2083, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.119 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2087), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2097 = f32[16]{0} convert(bf16[16]{0} %custom-call.119), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2111 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2112 = f32[16]{0} multiply(f32[16]{0} %convert.2097, f32[16]{0} %broadcast.2111), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2116 = f32[16]{0} add(f32[16]{0} %multiply.2115, f32[16]{0} %multiply.2112), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p75.2098 = f32[16]{0} parameter(75), frontend_attributes={neff_input_names="input75"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2099 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2100 = f32[16]{0} multiply(f32[16]{0} %p75.2098, f32[16]{0} %broadcast.2099), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2101 = f32[16]{0} multiply(f32[16]{0} %convert.2097, f32[16]{0} %convert.2097), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2102 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2103 = f32[16]{0} multiply(f32[16]{0} %multiply.2101, f32[16]{0} %broadcast.2102), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2104 = f32[16]{0} add(f32[16]{0} %multiply.2100, f32[16]{0} %multiply.2103), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2105 = f32[16]{0} sqrt(f32[16]{0} %add.2104), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2106 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2107 = f32[16]{0} add(f32[16]{0} %sqrt.2105, f32[16]{0} %broadcast.2106), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2117 = f32[16]{0} divide(f32[16]{0} %add.2116, f32[16]{0} %add.2107), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2078 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2118 = f32[16]{0} broadcast(f32[] %constant.2078), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2119 = f32[16]{0} multiply(f32[16]{0} %divide.2117, f32[16]{0} %broadcast.2118), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2121 = f32[16]{0} add(f32[16]{0} %convert.2120, f32[16]{0} %multiply.2119), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2122 = bf16[16]{0} convert(f32[16]{0} %add.2121), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2165 = f32[4096,16]{1,0} convert(bf16[4096,16]{1,0} %p24.525), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p78.2158 = f32[4096,16]{1,0} parameter(78), frontend_attributes={neff_input_names="input78"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2159 = f32[4096,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2160 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %p78.2158, f32[4096,16]{1,0} %broadcast.2159), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.2131 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.566), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.2132 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.2131), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.5 = bf16[4096,16]{0,1} dot(bf16[2048,4096]{1,0} %reshape.1216, bf16[16,2048]{0,1} %transpose.2132), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.120 = bf16[4096,16]{1,0} custom-call(bf16[4096,16]{0,1} %dot.5), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2142 = f32[4096,16]{1,0} convert(bf16[4096,16]{1,0} %custom-call.120), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2156 = f32[4096,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2157 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %convert.2142, f32[4096,16]{1,0} %broadcast.2156), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2161 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %multiply.2160, f32[4096,16]{1,0} %multiply.2157), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p77.2143 = f32[4096,16]{1,0} parameter(77), frontend_attributes={neff_input_names="input77"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2144 = f32[4096,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2145 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %p77.2143, f32[4096,16]{1,0} %broadcast.2144), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2146 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %convert.2142, f32[4096,16]{1,0} %convert.2142), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2147 = f32[4096,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2148 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.2146, f32[4096,16]{1,0} %broadcast.2147), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2149 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %multiply.2145, f32[4096,16]{1,0} %multiply.2148), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2150 = f32[4096,16]{1,0} sqrt(f32[4096,16]{1,0} %add.2149), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2151 = f32[4096,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2152 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %sqrt.2150, f32[4096,16]{1,0} %broadcast.2151), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2162 = f32[4096,16]{1,0} divide(f32[4096,16]{1,0} %add.2161, f32[4096,16]{1,0} %add.2152), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2128 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2163 = f32[4096,16]{1,0} broadcast(f32[] %constant.2128), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2164 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %divide.2162, f32[4096,16]{1,0} %broadcast.2163), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2166 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %convert.2165, f32[4096,16]{1,0} %multiply.2164), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2167 = bf16[4096,16]{1,0} convert(f32[4096,16]{1,0} %add.2166), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2123 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.2127 = bf16[4096,16]{1,0} broadcast(bf16[] %constant.2123), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.2168 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %convert.2167, bf16[4096,16]{1,0} %broadcast.2127), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.2169 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %convert.2167, bf16[4096,16]{1,0} %multiply.2168), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2212 = f32[4096]{0} convert(bf16[4096]{0} %p25.540), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p80.2205 = f32[4096]{0} parameter(80), frontend_attributes={neff_input_names="input80"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2206 = f32[4096]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2207 = f32[4096]{0} multiply(f32[4096]{0} %p80.2205, f32[4096]{0} %broadcast.2206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2173 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2179 = bf16[4096]{0} reduce(bf16[16,128,4096]{2,1,0} %multiply.12, bf16[] %constant.2173), dimensions={0,1}, to_apply=%AddComputation.2175, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.122 = bf16[4096]{0} custom-call(bf16[4096]{0} %reduce.2179), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2189 = f32[4096]{0} convert(bf16[4096]{0} %custom-call.122), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2203 = f32[4096]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2204 = f32[4096]{0} multiply(f32[4096]{0} %convert.2189, f32[4096]{0} %broadcast.2203), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2208 = f32[4096]{0} add(f32[4096]{0} %multiply.2207, f32[4096]{0} %multiply.2204), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p79.2190 = f32[4096]{0} parameter(79), frontend_attributes={neff_input_names="input79"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2191 = f32[4096]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2192 = f32[4096]{0} multiply(f32[4096]{0} %p79.2190, f32[4096]{0} %broadcast.2191), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2193 = f32[4096]{0} multiply(f32[4096]{0} %convert.2189, f32[4096]{0} %convert.2189), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2194 = f32[4096]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2195 = f32[4096]{0} multiply(f32[4096]{0} %multiply.2193, f32[4096]{0} %broadcast.2194), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2196 = f32[4096]{0} add(f32[4096]{0} %multiply.2192, f32[4096]{0} %multiply.2195), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2197 = f32[4096]{0} sqrt(f32[4096]{0} %add.2196), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2198 = f32[4096]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2199 = f32[4096]{0} add(f32[4096]{0} %sqrt.2197, f32[4096]{0} %broadcast.2198), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2209 = f32[4096]{0} divide(f32[4096]{0} %add.2208, f32[4096]{0} %add.2199), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2170 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2210 = f32[4096]{0} broadcast(f32[] %constant.2170), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2211 = f32[4096]{0} multiply(f32[4096]{0} %divide.2209, f32[4096]{0} %broadcast.2210), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2213 = f32[4096]{0} add(f32[4096]{0} %convert.2212, f32[4096]{0} %multiply.2211), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2214 = bf16[4096]{0} convert(f32[4096]{0} %add.2213), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2257 = f32[16,4096]{1,0} convert(bf16[16,4096]{1,0} %p27.574), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p82.2250 = f32[16,4096]{1,0} parameter(82), frontend_attributes={neff_input_names="input82"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2251 = f32[16,4096]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2252 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %p82.2250, f32[16,4096]{1,0} %broadcast.2251), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.2223 = bf16[2048,4096]{1,0} reshape(bf16[16,128,4096]{2,1,0} %custom-call.87), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.2224 = bf16[4096,2048]{0,1} transpose(bf16[2048,4096]{1,0} %reshape.2223), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.6 = bf16[16,4096]{0,1} dot(bf16[2048,16]{1,0} %reshape.1203, bf16[4096,2048]{0,1} %transpose.2224), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.123 = bf16[16,4096]{1,0} custom-call(bf16[16,4096]{0,1} %dot.6), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2234 = f32[16,4096]{1,0} convert(bf16[16,4096]{1,0} %custom-call.123), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2248 = f32[16,4096]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2249 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %convert.2234, f32[16,4096]{1,0} %broadcast.2248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2253 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %multiply.2252, f32[16,4096]{1,0} %multiply.2249), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p81.2235 = f32[16,4096]{1,0} parameter(81), frontend_attributes={neff_input_names="input81"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2236 = f32[16,4096]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2237 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %p81.2235, f32[16,4096]{1,0} %broadcast.2236), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2238 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %convert.2234, f32[16,4096]{1,0} %convert.2234), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2239 = f32[16,4096]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2240 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.2238, f32[16,4096]{1,0} %broadcast.2239), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2241 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %multiply.2237, f32[16,4096]{1,0} %multiply.2240), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2242 = f32[16,4096]{1,0} sqrt(f32[16,4096]{1,0} %add.2241), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2243 = f32[16,4096]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2244 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %sqrt.2242, f32[16,4096]{1,0} %broadcast.2243), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2254 = f32[16,4096]{1,0} divide(f32[16,4096]{1,0} %add.2253, f32[16,4096]{1,0} %add.2244), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2220 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2255 = f32[16,4096]{1,0} broadcast(f32[] %constant.2220), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2256 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %divide.2254, f32[16,4096]{1,0} %broadcast.2255), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2258 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %convert.2257, f32[16,4096]{1,0} %multiply.2256), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2259 = bf16[16,4096]{1,0} convert(f32[16,4096]{1,0} %add.2258), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2215 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.2219 = bf16[16,4096]{1,0} broadcast(bf16[] %constant.2215), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.2260 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %convert.2259, bf16[16,4096]{1,0} %broadcast.2219), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.2261 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %convert.2259, bf16[16,4096]{1,0} %multiply.2260), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2304 = f32[16]{0} convert(bf16[16]{0} %p28.652), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p84.2297 = f32[16]{0} parameter(84), frontend_attributes={neff_input_names="input84"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2298 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2299 = f32[16]{0} multiply(f32[16]{0} %p84.2297, f32[16]{0} %broadcast.2298), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2265 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2271 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.1202, bf16[] %constant.2265), dimensions={0,1}, to_apply=%AddComputation.2267, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.124 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2271), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2281 = f32[16]{0} convert(bf16[16]{0} %custom-call.124), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2295 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2296 = f32[16]{0} multiply(f32[16]{0} %convert.2281, f32[16]{0} %broadcast.2295), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2300 = f32[16]{0} add(f32[16]{0} %multiply.2299, f32[16]{0} %multiply.2296), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p83.2282 = f32[16]{0} parameter(83), frontend_attributes={neff_input_names="input83"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2283 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2284 = f32[16]{0} multiply(f32[16]{0} %p83.2282, f32[16]{0} %broadcast.2283), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2285 = f32[16]{0} multiply(f32[16]{0} %convert.2281, f32[16]{0} %convert.2281), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2286 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2287 = f32[16]{0} multiply(f32[16]{0} %multiply.2285, f32[16]{0} %broadcast.2286), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2288 = f32[16]{0} add(f32[16]{0} %multiply.2284, f32[16]{0} %multiply.2287), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2289 = f32[16]{0} sqrt(f32[16]{0} %add.2288), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2290 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2291 = f32[16]{0} add(f32[16]{0} %sqrt.2289, f32[16]{0} %broadcast.2290), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2301 = f32[16]{0} divide(f32[16]{0} %add.2300, f32[16]{0} %add.2291), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2262 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2302 = f32[16]{0} broadcast(f32[] %constant.2262), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2303 = f32[16]{0} multiply(f32[16]{0} %divide.2301, f32[16]{0} %broadcast.2302), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2305 = f32[16]{0} add(f32[16]{0} %convert.2304, f32[16]{0} %multiply.2303), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2306 = bf16[16]{0} convert(f32[16]{0} %add.2305), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2356 = f32[16]{0} convert(bf16[16]{0} %p29.697), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p86.2349 = f32[16]{0} parameter(86), frontend_attributes={neff_input_names="input86"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2350 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2351 = f32[16]{0} multiply(f32[16]{0} %p86.2349, f32[16]{0} %broadcast.2350), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2316 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %add.1186, bf16[16,128,16]{2,1,0} %reshape.736), metadata={op_type="aten__mul" op_name="aten__mul"}
  %constant.2317 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2323 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.2316, bf16[] %constant.2317), dimensions={0,1}, to_apply=%AddComputation.2319, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.125 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2323), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2333 = f32[16]{0} convert(bf16[16]{0} %custom-call.125), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2347 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2348 = f32[16]{0} multiply(f32[16]{0} %convert.2333, f32[16]{0} %broadcast.2347), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2352 = f32[16]{0} add(f32[16]{0} %multiply.2351, f32[16]{0} %multiply.2348), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p85.2334 = f32[16]{0} parameter(85), frontend_attributes={neff_input_names="input85"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2335 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2336 = f32[16]{0} multiply(f32[16]{0} %p85.2334, f32[16]{0} %broadcast.2335), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2337 = f32[16]{0} multiply(f32[16]{0} %convert.2333, f32[16]{0} %convert.2333), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2338 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2339 = f32[16]{0} multiply(f32[16]{0} %multiply.2337, f32[16]{0} %broadcast.2338), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2340 = f32[16]{0} add(f32[16]{0} %multiply.2336, f32[16]{0} %multiply.2339), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2341 = f32[16]{0} sqrt(f32[16]{0} %add.2340), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2342 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2343 = f32[16]{0} add(f32[16]{0} %sqrt.2341, f32[16]{0} %broadcast.2342), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2353 = f32[16]{0} divide(f32[16]{0} %add.2352, f32[16]{0} %add.2343), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2307 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2354 = f32[16]{0} broadcast(f32[] %constant.2307), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2355 = f32[16]{0} multiply(f32[16]{0} %divide.2353, f32[16]{0} %broadcast.2354), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2357 = f32[16]{0} add(f32[16]{0} %convert.2356, f32[16]{0} %multiply.2355), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2358 = bf16[16]{0} convert(f32[16]{0} %add.2357), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2401 = f32[16]{0} convert(bf16[16]{0} %p32.737), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p88.2394 = f32[16]{0} parameter(88), frontend_attributes={neff_input_names="input88"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2395 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2396 = f32[16]{0} multiply(f32[16]{0} %p88.2394, f32[16]{0} %broadcast.2395), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2362 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2368 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %add.1186, bf16[] %constant.2362), dimensions={0,1}, to_apply=%AddComputation.2364, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.126 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2368), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2378 = f32[16]{0} convert(bf16[16]{0} %custom-call.126), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2392 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2393 = f32[16]{0} multiply(f32[16]{0} %convert.2378, f32[16]{0} %broadcast.2392), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2397 = f32[16]{0} add(f32[16]{0} %multiply.2396, f32[16]{0} %multiply.2393), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p87.2379 = f32[16]{0} parameter(87), frontend_attributes={neff_input_names="input87"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2380 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2381 = f32[16]{0} multiply(f32[16]{0} %p87.2379, f32[16]{0} %broadcast.2380), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2382 = f32[16]{0} multiply(f32[16]{0} %convert.2378, f32[16]{0} %convert.2378), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2383 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2384 = f32[16]{0} multiply(f32[16]{0} %multiply.2382, f32[16]{0} %broadcast.2383), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2385 = f32[16]{0} add(f32[16]{0} %multiply.2381, f32[16]{0} %multiply.2384), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2386 = f32[16]{0} sqrt(f32[16]{0} %add.2385), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2387 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2388 = f32[16]{0} add(f32[16]{0} %sqrt.2386, f32[16]{0} %broadcast.2387), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2398 = f32[16]{0} divide(f32[16]{0} %add.2397, f32[16]{0} %add.2388), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2359 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2399 = f32[16]{0} broadcast(f32[] %constant.2359), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2400 = f32[16]{0} multiply(f32[16]{0} %divide.2398, f32[16]{0} %broadcast.2399), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2402 = f32[16]{0} add(f32[16]{0} %convert.2401, f32[16]{0} %multiply.2400), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2403 = bf16[16]{0} convert(f32[16]{0} %add.2402), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2448 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p30.711), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p90.2441 = f32[16,16]{1,0} parameter(90), frontend_attributes={neff_input_names="input90"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2442 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2443 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p90.2441, f32[16,16]{1,0} %broadcast.2442), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %slice.2413 = bf16[16,1,16]{2,1,0} slice(bf16[16,128,16]{2,1,0} %add.751), slice={[0:16], [0:1], [0:16]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice"}
  %reshape.2414 = bf16[16,16]{1,0} reshape(bf16[16,1,16]{2,1,0} %slice.2413), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.2415 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %reshape.2414), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.7 = bf16[16,16]{0,1} dot(bf16[16,16]{1,0} %multiply.902, bf16[16,16]{0,1} %transpose.2415), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.127 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.7), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2425 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.127), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2439 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2440 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.2425, f32[16,16]{1,0} %broadcast.2439), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2444 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.2443, f32[16,16]{1,0} %multiply.2440), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p89.2426 = f32[16,16]{1,0} parameter(89), frontend_attributes={neff_input_names="input89"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2427 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2428 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p89.2426, f32[16,16]{1,0} %broadcast.2427), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2429 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.2425, f32[16,16]{1,0} %convert.2425), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2430 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2431 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.2429, f32[16,16]{1,0} %broadcast.2430), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2432 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.2428, f32[16,16]{1,0} %multiply.2431), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2433 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.2432), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2434 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2435 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.2433, f32[16,16]{1,0} %broadcast.2434), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2445 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.2444, f32[16,16]{1,0} %add.2435), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2409 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2446 = f32[16,16]{1,0} broadcast(f32[] %constant.2409), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2447 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.2445, f32[16,16]{1,0} %broadcast.2446), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2449 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.2448, f32[16,16]{1,0} %multiply.2447), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2450 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.2449), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2404 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.2408 = bf16[16,16]{1,0} broadcast(bf16[] %constant.2404), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.2451 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.2450, bf16[16,16]{1,0} %broadcast.2408), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.2452 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.2450, bf16[16,16]{1,0} %multiply.2451), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2495 = f32[16]{0} convert(bf16[16]{0} %p31.726), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p92.2488 = f32[16]{0} parameter(92), frontend_attributes={neff_input_names="input92"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2489 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2490 = f32[16]{0} multiply(f32[16]{0} %p92.2488, f32[16]{0} %broadcast.2489), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2456 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2462 = bf16[16]{0} reduce(bf16[16,16]{1,0} %multiply.902, bf16[] %constant.2456), dimensions={0}, to_apply=%AddComputation.2458, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.128 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2462), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2472 = f32[16]{0} convert(bf16[16]{0} %custom-call.128), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2486 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2487 = f32[16]{0} multiply(f32[16]{0} %convert.2472, f32[16]{0} %broadcast.2486), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2491 = f32[16]{0} add(f32[16]{0} %multiply.2490, f32[16]{0} %multiply.2487), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p91.2473 = f32[16]{0} parameter(91), frontend_attributes={neff_input_names="input91"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2474 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2475 = f32[16]{0} multiply(f32[16]{0} %p91.2473, f32[16]{0} %broadcast.2474), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2476 = f32[16]{0} multiply(f32[16]{0} %convert.2472, f32[16]{0} %convert.2472), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2477 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2478 = f32[16]{0} multiply(f32[16]{0} %multiply.2476, f32[16]{0} %broadcast.2477), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2479 = f32[16]{0} add(f32[16]{0} %multiply.2475, f32[16]{0} %multiply.2478), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2480 = f32[16]{0} sqrt(f32[16]{0} %add.2479), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2481 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2482 = f32[16]{0} add(f32[16]{0} %sqrt.2480, f32[16]{0} %broadcast.2481), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2492 = f32[16]{0} divide(f32[16]{0} %add.2491, f32[16]{0} %add.2482), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2453 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2493 = f32[16]{0} broadcast(f32[] %constant.2453), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2494 = f32[16]{0} multiply(f32[16]{0} %divide.2492, f32[16]{0} %broadcast.2493), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2496 = f32[16]{0} add(f32[16]{0} %convert.2495, f32[16]{0} %multiply.2494), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2497 = bf16[16]{0} convert(f32[16]{0} %add.2496), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2540 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %p37.920), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p94.2533 = f32[16,16]{1,0} parameter(94), frontend_attributes={neff_input_names="input94"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2534 = f32[16,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2535 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p94.2533, f32[16,16]{1,0} %broadcast.2534), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %reshape.2506 = bf16[2048,16]{1,0} reshape(bf16[16,128,16]{2,1,0} %add.751), metadata={op_type="aten__view" op_name="aten__view"}
  %transpose.2507 = bf16[16,2048]{0,1} transpose(bf16[2048,16]{1,0} %reshape.2506), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.8 = bf16[16,16]{0,1} dot(bf16[2048,16]{1,0} %reshape.1183, bf16[16,2048]{0,1} %transpose.2507), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.129 = bf16[16,16]{1,0} custom-call(bf16[16,16]{0,1} %dot.8), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2517 = f32[16,16]{1,0} convert(bf16[16,16]{1,0} %custom-call.129), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2531 = f32[16,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2532 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.2517, f32[16,16]{1,0} %broadcast.2531), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2536 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.2535, f32[16,16]{1,0} %multiply.2532), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p93.2518 = f32[16,16]{1,0} parameter(93), frontend_attributes={neff_input_names="input93"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2519 = f32[16,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2520 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %p93.2518, f32[16,16]{1,0} %broadcast.2519), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2521 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %convert.2517, f32[16,16]{1,0} %convert.2517), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2522 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2523 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.2521, f32[16,16]{1,0} %broadcast.2522), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2524 = f32[16,16]{1,0} add(f32[16,16]{1,0} %multiply.2520, f32[16,16]{1,0} %multiply.2523), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2525 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.2524), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2526 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2527 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.2525, f32[16,16]{1,0} %broadcast.2526), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2537 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.2536, f32[16,16]{1,0} %add.2527), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2503 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2538 = f32[16,16]{1,0} broadcast(f32[] %constant.2503), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2539 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.2537, f32[16,16]{1,0} %broadcast.2538), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2541 = f32[16,16]{1,0} add(f32[16,16]{1,0} %convert.2540, f32[16,16]{1,0} %multiply.2539), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2542 = bf16[16,16]{1,0} convert(f32[16,16]{1,0} %add.2541), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2498 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.2502 = bf16[16,16]{1,0} broadcast(bf16[] %constant.2498), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.2543 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %convert.2542, bf16[16,16]{1,0} %broadcast.2502), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.2544 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %convert.2542, bf16[16,16]{1,0} %multiply.2543), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2587 = f32[16]{0} convert(bf16[16]{0} %p38.935), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p96.2580 = f32[16]{0} parameter(96), frontend_attributes={neff_input_names="input96"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2581 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2582 = f32[16]{0} multiply(f32[16]{0} %p96.2580, f32[16]{0} %broadcast.2581), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2548 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2554 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.6, bf16[] %constant.2548), dimensions={0,1}, to_apply=%AddComputation.2550, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.130 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2554), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2564 = f32[16]{0} convert(bf16[16]{0} %custom-call.130), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2578 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2579 = f32[16]{0} multiply(f32[16]{0} %convert.2564, f32[16]{0} %broadcast.2578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2583 = f32[16]{0} add(f32[16]{0} %multiply.2582, f32[16]{0} %multiply.2579), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p95.2565 = f32[16]{0} parameter(95), frontend_attributes={neff_input_names="input95"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2566 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2567 = f32[16]{0} multiply(f32[16]{0} %p95.2565, f32[16]{0} %broadcast.2566), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2568 = f32[16]{0} multiply(f32[16]{0} %convert.2564, f32[16]{0} %convert.2564), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2569 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2570 = f32[16]{0} multiply(f32[16]{0} %multiply.2568, f32[16]{0} %broadcast.2569), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2571 = f32[16]{0} add(f32[16]{0} %multiply.2567, f32[16]{0} %multiply.2570), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2572 = f32[16]{0} sqrt(f32[16]{0} %add.2571), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2573 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2574 = f32[16]{0} add(f32[16]{0} %sqrt.2572, f32[16]{0} %broadcast.2573), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2584 = f32[16]{0} divide(f32[16]{0} %add.2583, f32[16]{0} %add.2574), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2545 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2585 = f32[16]{0} broadcast(f32[] %constant.2545), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2586 = f32[16]{0} multiply(f32[16]{0} %divide.2584, f32[16]{0} %broadcast.2585), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2588 = f32[16]{0} add(f32[16]{0} %convert.2587, f32[16]{0} %multiply.2586), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2589 = bf16[16]{0} convert(f32[16]{0} %add.2588), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2639 = f32[16]{0} convert(bf16[16]{0} %p39.998), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p98.2632 = f32[16]{0} parameter(98), frontend_attributes={neff_input_names="input98"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2633 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2634 = f32[16]{0} multiply(f32[16]{0} %p98.2632, f32[16]{0} %broadcast.2633), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2599 = bf16[16,128,16]{2,1,0} multiply(bf16[16,128,16]{2,1,0} %reshape.1157, bf16[16,128,16]{2,1,0} %reshape.1034), metadata={op_type="aten__mul" op_name="aten__mul"}
  %constant.2600 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2606 = bf16[16]{0} reduce(bf16[16,128,16]{2,1,0} %multiply.2599, bf16[] %constant.2600), dimensions={0,1}, to_apply=%AddComputation.2602, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.131 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2606), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2616 = f32[16]{0} convert(bf16[16]{0} %custom-call.131), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2630 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2631 = f32[16]{0} multiply(f32[16]{0} %convert.2616, f32[16]{0} %broadcast.2630), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2635 = f32[16]{0} add(f32[16]{0} %multiply.2634, f32[16]{0} %multiply.2631), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p97.2617 = f32[16]{0} parameter(97), frontend_attributes={neff_input_names="input97"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2618 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2619 = f32[16]{0} multiply(f32[16]{0} %p97.2617, f32[16]{0} %broadcast.2618), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2620 = f32[16]{0} multiply(f32[16]{0} %convert.2616, f32[16]{0} %convert.2616), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2621 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2622 = f32[16]{0} multiply(f32[16]{0} %multiply.2620, f32[16]{0} %broadcast.2621), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2623 = f32[16]{0} add(f32[16]{0} %multiply.2619, f32[16]{0} %multiply.2622), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2624 = f32[16]{0} sqrt(f32[16]{0} %add.2623), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2625 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2626 = f32[16]{0} add(f32[16]{0} %sqrt.2624, f32[16]{0} %broadcast.2625), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2636 = f32[16]{0} divide(f32[16]{0} %add.2635, f32[16]{0} %add.2626), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2590 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2637 = f32[16]{0} broadcast(f32[] %constant.2590), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2638 = f32[16]{0} multiply(f32[16]{0} %divide.2636, f32[16]{0} %broadcast.2637), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2640 = f32[16]{0} add(f32[16]{0} %convert.2639, f32[16]{0} %multiply.2638), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2641 = bf16[16]{0} convert(f32[16]{0} %add.2640), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2684 = f32[16]{0} convert(bf16[16]{0} %p42.1035), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p100.2677 = f32[16]{0} parameter(100), frontend_attributes={neff_input_names="input100"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2678 = f32[16]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2679 = f32[16]{0} multiply(f32[16]{0} %p100.2677, f32[16]{0} %broadcast.2678), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2645 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2651 = bf16[16]{0} reduce(bf16[2048,16]{1,0} %dot.1156, bf16[] %constant.2645), dimensions={0}, to_apply=%AddComputation.2647, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.132 = bf16[16]{0} custom-call(bf16[16]{0} %reduce.2651), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2661 = f32[16]{0} convert(bf16[16]{0} %custom-call.132), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2675 = f32[16]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2676 = f32[16]{0} multiply(f32[16]{0} %convert.2661, f32[16]{0} %broadcast.2675), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2680 = f32[16]{0} add(f32[16]{0} %multiply.2679, f32[16]{0} %multiply.2676), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p99.2662 = f32[16]{0} parameter(99), frontend_attributes={neff_input_names="input99"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2663 = f32[16]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2664 = f32[16]{0} multiply(f32[16]{0} %p99.2662, f32[16]{0} %broadcast.2663), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2665 = f32[16]{0} multiply(f32[16]{0} %convert.2661, f32[16]{0} %convert.2661), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2666 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2667 = f32[16]{0} multiply(f32[16]{0} %multiply.2665, f32[16]{0} %broadcast.2666), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2668 = f32[16]{0} add(f32[16]{0} %multiply.2664, f32[16]{0} %multiply.2667), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2669 = f32[16]{0} sqrt(f32[16]{0} %add.2668), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2670 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2671 = f32[16]{0} add(f32[16]{0} %sqrt.2669, f32[16]{0} %broadcast.2670), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2681 = f32[16]{0} divide(f32[16]{0} %add.2680, f32[16]{0} %add.2671), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2642 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2682 = f32[16]{0} broadcast(f32[] %constant.2642), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2683 = f32[16]{0} multiply(f32[16]{0} %divide.2681, f32[16]{0} %broadcast.2682), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2685 = f32[16]{0} add(f32[16]{0} %convert.2684, f32[16]{0} %multiply.2683), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2686 = bf16[16]{0} convert(f32[16]{0} %add.2685), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2730 = f32[30522]{0} convert(bf16[30522]{0} %p41.1023), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p102.2723 = f32[30522]{0} parameter(102), frontend_attributes={neff_input_names="input102"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2724 = f32[30522]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2725 = f32[30522]{0} multiply(f32[30522]{0} %p102.2723, f32[30522]{0} %broadcast.2724), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2691 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2697 = bf16[30522]{0} reduce(bf16[2048,30522]{1,0} %add.0, bf16[] %constant.2691), dimensions={0}, to_apply=%AddComputation.2693, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.133 = bf16[30522]{0} custom-call(bf16[30522]{0} %reduce.2697), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2707 = f32[30522]{0} convert(bf16[30522]{0} %custom-call.133), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2721 = f32[30522]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2722 = f32[30522]{0} multiply(f32[30522]{0} %convert.2707, f32[30522]{0} %broadcast.2721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2726 = f32[30522]{0} add(f32[30522]{0} %multiply.2725, f32[30522]{0} %multiply.2722), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p101.2708 = f32[30522]{0} parameter(101), frontend_attributes={neff_input_names="input101"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2709 = f32[30522]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2710 = f32[30522]{0} multiply(f32[30522]{0} %p101.2708, f32[30522]{0} %broadcast.2709), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2711 = f32[30522]{0} multiply(f32[30522]{0} %convert.2707, f32[30522]{0} %convert.2707), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2712 = f32[30522]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2713 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2711, f32[30522]{0} %broadcast.2712), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2714 = f32[30522]{0} add(f32[30522]{0} %multiply.2710, f32[30522]{0} %multiply.2713), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2715 = f32[30522]{0} sqrt(f32[30522]{0} %add.2714), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2716 = f32[30522]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2717 = f32[30522]{0} add(f32[30522]{0} %sqrt.2715, f32[30522]{0} %broadcast.2716), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2727 = f32[30522]{0} divide(f32[30522]{0} %add.2726, f32[30522]{0} %add.2717), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2687 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2728 = f32[30522]{0} broadcast(f32[] %constant.2687), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2729 = f32[30522]{0} multiply(f32[30522]{0} %divide.2727, f32[30522]{0} %broadcast.2728), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2731 = f32[30522]{0} add(f32[30522]{0} %convert.2730, f32[30522]{0} %multiply.2729), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2732 = bf16[30522]{0} convert(f32[30522]{0} %add.2731), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2774 = f32[2,16]{1,0} convert(bf16[2,16]{1,0} %p33.775), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p104.2767 = f32[2,16]{1,0} parameter(104), frontend_attributes={neff_input_names="input104"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2768 = f32[2,16]{1,0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2769 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p104.2767, f32[2,16]{1,0} %broadcast.2768), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %transpose.2741 = bf16[16,16]{0,1} transpose(bf16[16,16]{1,0} %tanh.761), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.9 = bf16[2,16]{0,1} dot(bf16[16,2]{1,0} %add.1, bf16[16,16]{0,1} %transpose.2741), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.134 = bf16[2,16]{1,0} custom-call(bf16[2,16]{0,1} %dot.9), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2751 = f32[2,16]{1,0} convert(bf16[2,16]{1,0} %custom-call.134), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2765 = f32[2,16]{1,0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2766 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %convert.2751, f32[2,16]{1,0} %broadcast.2765), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2770 = f32[2,16]{1,0} add(f32[2,16]{1,0} %multiply.2769, f32[2,16]{1,0} %multiply.2766), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p103.2752 = f32[2,16]{1,0} parameter(103), frontend_attributes={neff_input_names="input103"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2753 = f32[2,16]{1,0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2754 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %p103.2752, f32[2,16]{1,0} %broadcast.2753), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2755 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %convert.2751, f32[2,16]{1,0} %convert.2751), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2756 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2757 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2755, f32[2,16]{1,0} %broadcast.2756), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2758 = f32[2,16]{1,0} add(f32[2,16]{1,0} %multiply.2754, f32[2,16]{1,0} %multiply.2757), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2759 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.2758), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2760 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2761 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.2759, f32[2,16]{1,0} %broadcast.2760), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2771 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.2770, f32[2,16]{1,0} %add.2761), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2738 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2772 = f32[2,16]{1,0} broadcast(f32[] %constant.2738), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2773 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.2771, f32[2,16]{1,0} %broadcast.2772), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2775 = f32[2,16]{1,0} add(f32[2,16]{1,0} %convert.2774, f32[2,16]{1,0} %multiply.2773), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2776 = bf16[2,16]{1,0} convert(f32[2,16]{1,0} %add.2775), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2733 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %broadcast.2737 = bf16[2,16]{1,0} broadcast(bf16[] %constant.2733), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %multiply.2777 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %convert.2776, bf16[2,16]{1,0} %broadcast.2737), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %add.2778 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %convert.2776, bf16[2,16]{1,0} %multiply.2777), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=145}
  %convert.2821 = f32[2]{0} convert(bf16[2]{0} %p35.786), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p106.2814 = f32[2]{0} parameter(106), frontend_attributes={neff_input_names="input106"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %broadcast.2815 = f32[2]{0} broadcast(f32[] %p47.1394), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2816 = f32[2]{0} multiply(f32[2]{0} %p106.2814, f32[2]{0} %broadcast.2815), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %constant.2782 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.2788 = bf16[2]{0} reduce(bf16[16,2]{1,0} %add.1, bf16[] %constant.2782), dimensions={0}, to_apply=%AddComputation.2784, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.135 = bf16[2]{0} custom-call(bf16[2]{0} %reduce.2788), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %convert.2798 = f32[2]{0} convert(bf16[2]{0} %custom-call.135), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=99}
  %broadcast.2812 = f32[2]{0} broadcast(f32[] %p46.1388), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %multiply.2813 = f32[2]{0} multiply(f32[2]{0} %convert.2798, f32[2]{0} %broadcast.2812), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %add.2817 = f32[2]{0} add(f32[2]{0} %multiply.2816, f32[2]{0} %multiply.2813), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=124}
  %p105.2799 = f32[2]{0} parameter(105), frontend_attributes={neff_input_names="input105"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2800 = f32[2]{0} broadcast(f32[] %p44.1377), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2801 = f32[2]{0} multiply(f32[2]{0} %p105.2799, f32[2]{0} %broadcast.2800), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2802 = f32[2]{0} multiply(f32[2]{0} %convert.2798, f32[2]{0} %convert.2798), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %broadcast.2803 = f32[2]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %multiply.2804 = f32[2]{0} multiply(f32[2]{0} %multiply.2802, f32[2]{0} %broadcast.2803), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %add.2805 = f32[2]{0} add(f32[2]{0} %multiply.2801, f32[2]{0} %multiply.2804), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=125}
  %sqrt.2806 = f32[2]{0} sqrt(f32[2]{0} %add.2805), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %broadcast.2807 = f32[2]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %add.2808 = f32[2]{0} add(f32[2]{0} %sqrt.2806, f32[2]{0} %broadcast.2807), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=126}
  %divide.2818 = f32[2]{0} divide(f32[2]{0} %add.2817, f32[2]{0} %add.2808), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %constant.2779 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %broadcast.2819 = f32[2]{0} broadcast(f32[] %constant.2779), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %multiply.2820 = f32[2]{0} multiply(f32[2]{0} %divide.2818, f32[2]{0} %broadcast.2819), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %add.2822 = f32[2]{0} add(f32[2]{0} %convert.2821, f32[2]{0} %multiply.2820), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %convert.2823 = bf16[2]{0} convert(f32[2]{0} %add.2822), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/ubuntu/kahfi/dp_bert_hf_pretrain/adamw_fp32_optim_params.py" source_line=134}
  %p108.2828 = f32[1]{0} parameter(108), frontend_attributes={neff_input_names="input108"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=359}
  %p107.2825 = bf16[] parameter(107), frontend_attributes={neff_input_names="input107"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=359}
  %convert.56 = f32[] convert(bf16[] %p107.2825), metadata={op_type="aten__add" op_name="aten__add" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=359}
  %reshape.658 = f32[1]{0} reshape(f32[] %convert.56), metadata={op_type="aten__add" op_name="aten__add" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=359}
  %add.2830 = f32[1]{0} add(f32[1]{0} %p108.2828, f32[1]{0} %reshape.658), metadata={op_type="aten__add" op_name="aten__add" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=359}
  %constant.72 = bf16[1]{0} constant({0})
  %reshape.1 = s64[2048]{0} reshape(s64[16,128]{1,0} %p40.1016)
  %broadcast.4 = s64[2048,30522]{1,0} broadcast(s64[2048]{0} %reshape.1), dimensions={0}
  %iota.9 = s64[2048,30522]{1,0} iota(), iota_dimension=1
  %compare.0 = pred[2048,30522]{1,0} compare(s64[2048,30522]{1,0} %broadcast.4, s64[2048,30522]{1,0} %iota.9), direction=EQ
  %constant.3 = bf16[] constant(1)
  %broadcast.8 = bf16[2048,30522]{1,0} broadcast(bf16[] %constant.3), dimensions={}
  %constant.4 = bf16[] constant(0)
  %broadcast.9 = bf16[2048,30522]{1,0} broadcast(bf16[] %constant.4), dimensions={}
  %select.0 = bf16[2048,30522]{1,0} select(pred[2048,30522]{1,0} %compare.0, bf16[2048,30522]{1,0} %broadcast.8, bf16[2048,30522]{1,0} %broadcast.9)
  %multiply.2 = bf16[2048,30522]{1,0} multiply(bf16[2048,30522]{1,0} %subtract.1, bf16[2048,30522]{1,0} %select.0)
  %reduce.2 = bf16[2048]{0} reduce(bf16[2048,30522]{1,0} %multiply.2, bf16[] %constant.2), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.1066
  %constant.32 = bf16[] constant(0)
  %broadcast.70 = bf16[2048]{0} broadcast(bf16[] %constant.32), dimensions={}
  %select.6 = bf16[2048]{0} select(pred[2048]{0} %reshape.527, bf16[2048]{0} %reduce.2, bf16[2048]{0} %broadcast.70)
  %reduce.3 = bf16[] reduce(bf16[2048]{0} %select.6, bf16[] %constant.2), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.1070
  %reduce.4 = bf16[] reduce(bf16[2048]{0} %convert.0, bf16[] %constant.2), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.1074
  %divide.0 = bf16[] divide(bf16[] %reduce.3, bf16[] %reduce.4)
  %negate.0 = bf16[] negate(bf16[] %divide.0), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.29 = s64[16,2]{1,0} broadcast(s64[16]{0} %p34.785), dimensions={0}
  %iota.11 = s64[16,2]{1,0} iota(), iota_dimension=1
  %compare.3 = pred[16,2]{1,0} compare(s64[16,2]{1,0} %broadcast.29, s64[16,2]{1,0} %iota.11), direction=EQ
  %constant.13 = bf16[] constant(1)
  %broadcast.34 = bf16[16,2]{1,0} broadcast(bf16[] %constant.13), dimensions={}
  %constant.14 = bf16[] constant(0)
  %broadcast.36 = bf16[16,2]{1,0} broadcast(bf16[] %constant.14), dimensions={}
  %select.2 = bf16[16,2]{1,0} select(pred[16,2]{1,0} %compare.3, bf16[16,2]{1,0} %broadcast.34, bf16[16,2]{1,0} %broadcast.36)
  %multiply.7 = bf16[16,2]{1,0} multiply(bf16[16,2]{1,0} %subtract.3, bf16[16,2]{1,0} %select.2)
  %reduce.8 = bf16[16]{0} reduce(bf16[16,2]{1,0} %multiply.7, bf16[] %constant.12), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.809
  %constant.34 = bf16[] constant(0)
  %broadcast.76 = bf16[16]{0} broadcast(bf16[] %constant.34), dimensions={}
  %select.8 = bf16[16]{0} select(pred[16]{0} %compare.4, bf16[16]{0} %reduce.8, bf16[16]{0} %broadcast.76)
  %reduce.9 = bf16[] reduce(bf16[16]{0} %select.8, bf16[] %constant.12), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.813
  %reduce.10 = bf16[] reduce(bf16[16]{0} %convert.1, bf16[] %constant.12), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.817
  %divide.2 = bf16[] divide(bf16[] %reduce.9, bf16[] %reduce.10)
  %negate.2 = bf16[] negate(bf16[] %divide.2), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.2837 = bf16[] add(bf16[] %negate.0, bf16[] %negate.2), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=1142}
  %divide.2838 = bf16[] divide(bf16[] %add.2837, bf16[] %p36.864), metadata={op_type="aten__div" op_name="aten__div" source_file="bert_large_hf_pretrain_hdf5_v4.py" source_line=355}
  ROOT %tuple.2839 = (bf16[30522,16]{1,0}, bf16[512,16]{1,0}, bf16[2,16]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=5*/s64[1,512]{1,0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, /*index=10*/bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[4096,16]{1,0}, bf16[4096]{0}, bf16[16,4096]{1,0}, bf16[16]{0}, /*index=20*/bf16[16]{0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, /*index=25*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, bf16[2,16]{1,0}, /*index=30*/bf16[2]{0}, f32[1]{0}, f32[30522,16]{1,0}, f32[30522,16]{1,0}, f32[512,16]{1,0}, /*index=35*/f32[512,16]{1,0}, f32[2,16]{1,0}, f32[2,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=40*/f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=45*/f32[16,16]{1,0}, f32[4096,16]{1,0}, f32[4096,16]{1,0}, f32[16,4096]{1,0}, f32[16,4096]{1,0}, /*index=50*/f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[2,16]{1,0}, /*index=55*/f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=60*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=65*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=70*/f32[16]{0}, f32[16]{0}, f32[4096]{0}, f32[4096]{0}, f32[16]{0}, /*index=75*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=80*/f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[30522]{0}, f32[16]{0}, /*index=85*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=90*/f32[2]{0}, f32[2]{0}, bf16[1]{0}, s64[16,128]{1,0}, s64[16,128]{1,0}, /*index=95*/s64[16,128]{1,0}, s64[16,128]{1,0}, s64[16]{0}, bf16[16,128,30522]{2,1,0}, bf16[16,2]{1,0}, /*index=100*/bf16[], bf16[], bf16[2]{0}, bf16[2,16]{1,0}, bf16[30522]{0}, /*index=105*/bf16[30522,16]{1,0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16,16]{1,0}, /*index=110*/bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=115*/bf16[16,4096]{1,0}, bf16[4096]{0}, bf16[4096,16]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=120*/bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, /*index=125*/bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=130*/bf16[512,16]{1,0}, bf16[2,16]{1,0}) tuple(bf16[30522,16]{1,0} %add.1406, bf16[512,16]{1,0} %add.1482, bf16[2,16]{1,0} %add.1547, bf16[16]{0} %convert.1599, bf16[16]{0} %convert.1644, /*index=5*/s64[1,512]{1,0} %p2.46, bf16[16,16]{1,0} %add.1691, bf16[16]{0} %convert.1739, bf16[16,16]{1,0} %add.1786, bf16[16]{0} %convert.1835, /*index=10*/bf16[16,16]{1,0} %add.1882, bf16[16]{0} %convert.1930, bf16[16,16]{1,0} %add.1980, bf16[16]{0} %convert.2025, bf16[16]{0} %convert.2077, /*index=15*/bf16[16]{0} %convert.2122, bf16[4096,16]{1,0} %add.2169, bf16[4096]{0} %convert.2214, bf16[16,4096]{1,0} %add.2261, bf16[16]{0} %convert.2306, /*index=20*/bf16[16]{0} %convert.2358, bf16[16]{0} %convert.2403, bf16[16,16]{1,0} %add.2452, bf16[16]{0} %convert.2497, bf16[16,16]{1,0} %add.2544, /*index=25*/bf16[16]{0} %convert.2589, bf16[16]{0} %convert.2641, bf16[16]{0} %convert.2686, bf16[30522]{0} %convert.2732, bf16[2,16]{1,0} %add.2778, /*index=30*/bf16[2]{0} %convert.2823, f32[1]{0} %add.2830, f32[30522,16]{1,0} %add.1398, f32[30522,16]{1,0} %add.1384, f32[512,16]{1,0} %add.1474, /*index=35*/f32[512,16]{1,0} %add.1462, f32[2,16]{1,0} %add.1539, f32[2,16]{1,0} %add.1527, f32[16,16]{1,0} %add.1683, f32[16,16]{1,0} %add.1671, /*index=40*/f32[16,16]{1,0} %add.1778, f32[16,16]{1,0} %add.1766, f32[16,16]{1,0} %add.1874, f32[16,16]{1,0} %add.1862, f32[16,16]{1,0} %add.1972, /*index=45*/f32[16,16]{1,0} %add.1960, f32[4096,16]{1,0} %add.2161, f32[4096,16]{1,0} %add.2149, f32[16,4096]{1,0} %add.2253, f32[16,4096]{1,0} %add.2241, /*index=50*/f32[16,16]{1,0} %add.2444, f32[16,16]{1,0} %add.2432, f32[16,16]{1,0} %add.2536, f32[16,16]{1,0} %add.2524, f32[2,16]{1,0} %add.2770, /*index=55*/f32[2,16]{1,0} %add.2758, f32[16]{0} %add.1593, f32[16]{0} %add.1581, f32[16]{0} %add.1638, f32[16]{0} %add.1626, /*index=60*/f32[16]{0} %add.1733, f32[16]{0} %add.1721, f32[16]{0} %add.1829, f32[16]{0} %add.1817, f32[16]{0} %add.1924, /*index=65*/f32[16]{0} %add.1912, f32[16]{0} %add.2019, f32[16]{0} %add.2007, f32[16]{0} %add.2071, f32[16]{0} %add.2059, /*index=70*/f32[16]{0} %add.2116, f32[16]{0} %add.2104, f32[4096]{0} %add.2208, f32[4096]{0} %add.2196, f32[16]{0} %add.2300, /*index=75*/f32[16]{0} %add.2288, f32[16]{0} %add.2352, f32[16]{0} %add.2340, f32[16]{0} %add.2397, f32[16]{0} %add.2385, /*index=80*/f32[16]{0} %add.2491, f32[16]{0} %add.2479, f32[30522]{0} %add.2726, f32[30522]{0} %add.2714, f32[16]{0} %add.2583, /*index=85*/f32[16]{0} %add.2571, f32[16]{0} %add.2635, f32[16]{0} %add.2623, f32[16]{0} %add.2680, f32[16]{0} %add.2668, /*index=90*/f32[2]{0} %add.2817, f32[2]{0} %add.2805, bf16[1]{0} %constant.72, s64[16,128]{1,0} %p6.81, s64[16,128]{1,0} %p4.67, /*index=95*/s64[16,128]{1,0} %p17.242, s64[16,128]{1,0} %p40.1016, s64[16]{0} %p34.785, bf16[16,128,30522]{2,1,0} %add.1054, bf16[16,2]{1,0} %add.800, /*index=100*/bf16[] %add.2837, bf16[] %divide.2838, bf16[2]{0} %custom-call.135, bf16[2,16]{1,0} %custom-call.134, bf16[30522]{0} %custom-call.133, /*index=105*/bf16[30522,16]{1,0} %add.1375, bf16[16]{0} %custom-call.132, bf16[16]{0} %custom-call.131, bf16[16]{0} %custom-call.130, bf16[16,16]{1,0} %custom-call.129, /*index=110*/bf16[16]{0} %custom-call.128, bf16[16,16]{1,0} %custom-call.127, bf16[16]{0} %custom-call.126, bf16[16]{0} %custom-call.125, bf16[16]{0} %custom-call.124, /*index=115*/bf16[16,4096]{1,0} %custom-call.123, bf16[4096]{0} %custom-call.122, bf16[4096,16]{1,0} %custom-call.120, bf16[16]{0} %custom-call.119, bf16[16]{0} %custom-call.118, /*index=120*/bf16[16]{0} %custom-call.117, bf16[16,16]{1,0} %custom-call.116, bf16[16]{0} %custom-call.115, bf16[16,16]{1,0} %custom-call.114, bf16[16]{0} %custom-call.113, /*index=125*/bf16[16,16]{1,0} %custom-call.112, bf16[16]{0} %custom-call.111, bf16[16,16]{1,0} %custom-call.110, bf16[16]{0} %custom-call.109, bf16[16]{0} %custom-call.108, /*index=130*/bf16[512,16]{1,0} %custom-call.106, bf16[2,16]{1,0} %custom-call.107), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93,output94,output95,output96,output97,output98,output99,output100,output101,output102,output103,output104,output105,output106,output107,output108,output109,output110,output111,output112,output113,output114,output115,output116,output117,output118,output119,output120,output121,output122,output123,output124,output125,output126,output127,output128,output129,output130,output131"}
}


`

export default text;
