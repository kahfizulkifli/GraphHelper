const text = `
HloModule SyncTensorsGraph.508, input_output_alias={ {0}: (20, {}, must-alias), {1}: (23, {}, must-alias), {2}: (26, {}, must-alias), {3}: (29, {}, must-alias), {4}: (32, {}, must-alias), {5}: (35, {}, must-alias), {6}: (11, {}, must-alias), {7}: (8, {}, must-alias), {8}: (10, {}, must-alias), {9}: (7, {}, must-alias), {10}: (9, {}, must-alias), {11}: (6, {}, must-alias), {12}: (17, {}, must-alias), {13}: (14, {}, must-alias), {14}: (25, {}, must-alias), {15}: (24, {}, must-alias), {16}: (31, {}, must-alias), {17}: (30, {}, must-alias), {18}: (22, {}, must-alias), {19}: (21, {}, must-alias), {20}: (28, {}, must-alias), {21}: (27, {}, must-alias), {22}: (34, {}, must-alias), {23}: (33, {}, must-alias) }

%AddComputation.51 (x.52: bf16[], y.53: bf16[]) -> bf16[] {
  %x.52 = bf16[] parameter(0)
  %y.53 = bf16[] parameter(1)
  ROOT %add.54 = bf16[] add(bf16[] %x.52, bf16[] %y.53)
}

%AddComputation.83 (x.84: bf16[], y.85: bf16[]) -> bf16[] {
  %x.84 = bf16[] parameter(0)
  %y.85 = bf16[] parameter(1)
  ROOT %add.86 = bf16[] add(bf16[] %x.84, bf16[] %y.85)
}

%AddComputation.96 (x.97: bf16[], y.98: bf16[]) -> bf16[] {
  %x.97 = bf16[] parameter(0)
  %y.98 = bf16[] parameter(1)
  ROOT %add.99 = bf16[] add(bf16[] %x.97, bf16[] %y.98)
}

%AddComputation.109 (x.110: bf16[], y.111: bf16[]) -> bf16[] {
  %x.110 = bf16[] parameter(0)
  %y.111 = bf16[] parameter(1)
  ROOT %add.112 = bf16[] add(bf16[] %x.110, bf16[] %y.111)
}

%AddComputation.122 (x.123: bf16[], y.124: bf16[]) -> bf16[] {
  %x.123 = bf16[] parameter(0)
  %y.124 = bf16[] parameter(1)
  ROOT %add.125 = bf16[] add(bf16[] %x.123, bf16[] %y.124)
}

%AddComputation.135 (x.136: bf16[], y.137: bf16[]) -> bf16[] {
  %x.136 = bf16[] parameter(0)
  %y.137 = bf16[] parameter(1)
  ROOT %add.138 = bf16[] add(bf16[] %x.136, bf16[] %y.137)
}

%AddComputation.162 (x.163: bf16[], y.164: bf16[]) -> bf16[] {
  %x.163 = bf16[] parameter(0)
  %y.164 = bf16[] parameter(1)
  ROOT %add.165 = bf16[] add(bf16[] %x.163, bf16[] %y.164)
}

ENTRY %SyncTensorsGraph.508 (p0.1: f32[], p1.3: bf16[], p2.5: bf16[], p3.6: f32[], p4.12: bf16[], p5.17: f32[], p6.19: bf16[4,4], p7.23: bf16[4,4], p8.27: bf16[1,4], p9.31: bf16[4], p10.35: bf16[4], p11.39: bf16[1], p12.143: bf16[1], p13.190: bf16[], p14.191: bf16[4,4], p15.204: bf16[], p16.210: bf16[], p17.211: bf16[4,4], p18.220: bf16[], p19.221: bf16[], p20.222: bf16[4,4], p21.250: bf16[4], p22.268: bf16[4], p23.278: bf16[4], p24.307: bf16[4,4], p25.325: bf16[4,4], p26.334: bf16[4,4], p27.362: bf16[4], p28.380: bf16[4], p29.390: bf16[4], p30.419: bf16[1,4], p31.437: bf16[1,4], p32.446: bf16[1,4], p33.471: bf16[1], p34.487: bf16[1], p35.495: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[1,4], /*index=5*/bf16[1], bf16[1], bf16[1,4], bf16[4], bf16[4,4], /*index=10*/bf16[4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=15*/bf16[4,4], bf16[1,4], bf16[1,4], bf16[4], bf16[4], /*index=20*/bf16[4], bf16[4], bf16[1], bf16[1], bf16[1]) {
  %p20.222 = bf16[4,4]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p19.221 = bf16[] parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.223 = bf16[4,4]{1,0} broadcast(bf16[] %p19.221), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.224 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p20.222, bf16[4,4]{1,0} %broadcast.223), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p18.220 = bf16[] parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.225 = bf16[4,4]{1,0} broadcast(bf16[] %p18.220), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.227 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.224, bf16[4,4]{1,0} %broadcast.225), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.228 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p20.222, bf16[4,4]{1,0} %multiply.227), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p17.211 = bf16[4,4]{1,0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p16.210 = bf16[] parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.212 = bf16[4,4]{1,0} broadcast(bf16[] %p16.210), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.213 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p17.211, bf16[4,4]{1,0} %broadcast.212), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p11.39 = bf16[1]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p10.35 = bf16[4]{0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p9.31 = bf16[4]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p8.27 = bf16[1,4]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p7.23 = bf16[4,4]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p6.19 = bf16[4,4]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p5.17 = f32[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %convert.42 = bf16[] convert(f32[] %p5.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.55 = (bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) all-reduce(bf16[1]{0} %p11.39, bf16[4]{0} %p10.35, bf16[4]{0} %p9.31, bf16[1,4]{1,0} %p8.27, bf16[4,4]{1,0} %p7.23, /*index=5*/bf16[4,4]{1,0} %p6.19, bf16[] %convert.42), replica_groups={{0},{1}}, constrain_layout=true, to_apply=%AddComputation.51, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.61 = bf16[4,4]{1,0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=5, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.3 = bf16[1]{0} constant({1})
  %p12.143 = bf16[1]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.132 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.61, bf16[4,4]{1,0} %get-tuple-element.61), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.133 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.139 = bf16[] reduce(bf16[4,4]{1,0} %multiply.132, bf16[] %constant.133), dimensions={0,1}, to_apply=%AddComputation.135, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.140 = bf16[] sqrt(bf16[] %reduce.139), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.142 = bf16[] multiply(bf16[] %sqrt.140, bf16[] %sqrt.140), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.1 = bf16[1]{0} reshape(bf16[] %multiply.142), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.145 = bf16[1]{0} add(bf16[1]{0} %p12.143, bf16[1]{0} %reshape.1), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.60 = bf16[4,4]{1,0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=4, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.119 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.60, bf16[4,4]{1,0} %get-tuple-element.60), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.120 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.126 = bf16[] reduce(bf16[4,4]{1,0} %multiply.119, bf16[] %constant.120), dimensions={0,1}, to_apply=%AddComputation.122, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.127 = bf16[] sqrt(bf16[] %reduce.126), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.129 = bf16[] multiply(bf16[] %sqrt.127, bf16[] %sqrt.127), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.2 = bf16[1]{0} reshape(bf16[] %multiply.129), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.147 = bf16[1]{0} add(bf16[1]{0} %add.145, bf16[1]{0} %reshape.2), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.59 = bf16[1,4]{1,0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=3, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.106 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.59, bf16[1,4]{1,0} %get-tuple-element.59), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.107 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.113 = bf16[] reduce(bf16[1,4]{1,0} %multiply.106, bf16[] %constant.107), dimensions={0,1}, to_apply=%AddComputation.109, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.114 = bf16[] sqrt(bf16[] %reduce.113), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.116 = bf16[] multiply(bf16[] %sqrt.114, bf16[] %sqrt.114), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.3 = bf16[1]{0} reshape(bf16[] %multiply.116), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.149 = bf16[1]{0} add(bf16[1]{0} %add.147, bf16[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.58 = bf16[4]{0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.93 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.58, bf16[4]{0} %get-tuple-element.58), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.94 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.100 = bf16[] reduce(bf16[4]{0} %multiply.93, bf16[] %constant.94), dimensions={0}, to_apply=%AddComputation.96, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.101 = bf16[] sqrt(bf16[] %reduce.100), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.103 = bf16[] multiply(bf16[] %sqrt.101, bf16[] %sqrt.101), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.4 = bf16[1]{0} reshape(bf16[] %multiply.103), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.151 = bf16[1]{0} add(bf16[1]{0} %add.149, bf16[1]{0} %reshape.4), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.57 = bf16[4]{0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.80 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.57, bf16[4]{0} %get-tuple-element.57), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.81 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.87 = bf16[] reduce(bf16[4]{0} %multiply.80, bf16[] %constant.81), dimensions={0}, to_apply=%AddComputation.83, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.88 = bf16[] sqrt(bf16[] %reduce.87), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.90 = bf16[] multiply(bf16[] %sqrt.88, bf16[] %sqrt.88), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.5 = bf16[1]{0} reshape(bf16[] %multiply.90), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.153 = bf16[1]{0} add(bf16[1]{0} %add.151, bf16[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.56 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.11 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.56, bf16[1]{0} %get-tuple-element.56), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.155 = bf16[1]{0} add(bf16[1]{0} %add.153, bf16[1]{0} %multiply.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.161 = bf16[] get-tuple-element((bf16[1]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[4,4]{1,0}, /*index=5*/bf16[4,4]{1,0}, bf16[]) %all-reduce.55), index=6, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.166 = (bf16[1]{0}, bf16[]) all-reduce(bf16[1]{0} %add.155, bf16[] %get-tuple-element.161), replica_groups={{0,1}}, to_apply=%AddComputation.162, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.167 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.166), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.4 = bf16[1]{0} constant({0.5})
  %power.170 = bf16[1]{0} power(bf16[1]{0} %get-tuple-element.167, bf16[1]{0} %constant.4), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p4.12 = bf16[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.172 = bf16[1]{0} add(bf16[1]{0} %power.170, bf16[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.175 = bf16[1]{0} divide(bf16[1]{0} %constant.3, bf16[1]{0} %add.172), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.8 = bf16[1]{0} constant({1})
  %compare.182 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.8), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.9 = bf16[1]{0} constant({1})
  %select.184 = bf16[1]{0} select(pred[1]{0} %compare.182, bf16[1]{0} %divide.175, bf16[1]{0} %constant.9), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.186 = bf16[] reshape(bf16[1]{0} %select.184), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.188 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.186), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.189 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.61, bf16[4,4]{1,0} %broadcast.188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p15.204 = bf16[] parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.208 = bf16[4,4]{1,0} broadcast(bf16[] %p15.204), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.209 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.189, bf16[4,4]{1,0} %broadcast.208), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.214 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.213, bf16[4,4]{1,0} %multiply.209), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p14.191 = bf16[4,4]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p13.190 = bf16[] parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.192 = bf16[4,4]{1,0} broadcast(bf16[] %p13.190), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.193 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p14.191, bf16[4,4]{1,0} %broadcast.192), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.195 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.189, bf16[4,4]{1,0} %multiply.189), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.194 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.196 = bf16[4,4]{1,0} broadcast(bf16[] %convert.194), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.197 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.195, bf16[4,4]{1,0} %broadcast.196), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.198 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.193, bf16[4,4]{1,0} %multiply.197), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.199 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.198), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.200 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.201 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.199, bf16[4,4]{1,0} %broadcast.200), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = bf16[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.202 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.203 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.201, bf16[4,4]{1,0} %broadcast.202), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.230 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.214, bf16[4,4]{1,0} %add.203), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.229 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.231 = bf16[4,4]{1,0} broadcast(bf16[] %convert.229), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.232 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.230, bf16[4,4]{1,0} %broadcast.231), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.233 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.228, bf16[4,4]{1,0} %multiply.232), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p23.278 = bf16[4]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.279 = bf16[4]{0} broadcast(bf16[] %p19.221), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.280 = bf16[4]{0} multiply(bf16[4]{0} %p23.278, bf16[4]{0} %broadcast.279), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.13 = bf16[] constant(0)
  %broadcast.1 = bf16[4]{0} broadcast(bf16[] %constant.13), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.283 = bf16[4]{0} multiply(bf16[4]{0} %multiply.280, bf16[4]{0} %broadcast.1), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.284 = bf16[4]{0} subtract(bf16[4]{0} %p23.278, bf16[4]{0} %multiply.283), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p22.268 = bf16[4]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.269 = bf16[4]{0} broadcast(bf16[] %p16.210), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.270 = bf16[4]{0} multiply(bf16[4]{0} %p22.268, bf16[4]{0} %broadcast.269), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.16 = bf16[1]{0} constant({1})
  %compare.243 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.16), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.17 = bf16[1]{0} constant({1})
  %select.245 = bf16[1]{0} select(pred[1]{0} %compare.243, bf16[1]{0} %divide.175, bf16[1]{0} %constant.17), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.247 = bf16[] reshape(bf16[1]{0} %select.245), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.248 = bf16[4]{0} broadcast(bf16[] %reshape.247), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.249 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.58, bf16[4]{0} %broadcast.248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.266 = bf16[4]{0} broadcast(bf16[] %p15.204), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.267 = bf16[4]{0} multiply(bf16[4]{0} %multiply.249, bf16[4]{0} %broadcast.266), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.271 = bf16[4]{0} add(bf16[4]{0} %multiply.270, bf16[4]{0} %multiply.267), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p21.250 = bf16[4]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.251 = bf16[4]{0} broadcast(bf16[] %p13.190), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.252 = bf16[4]{0} multiply(bf16[4]{0} %p21.250, bf16[4]{0} %broadcast.251), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.254 = bf16[4]{0} multiply(bf16[4]{0} %multiply.249, bf16[4]{0} %multiply.249), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.253 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.255 = bf16[4]{0} broadcast(bf16[] %convert.253), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.256 = bf16[4]{0} multiply(bf16[4]{0} %multiply.254, bf16[4]{0} %broadcast.255), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.257 = bf16[4]{0} add(bf16[4]{0} %multiply.252, bf16[4]{0} %multiply.256), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.258 = bf16[4]{0} sqrt(bf16[4]{0} %add.257), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.259 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.260 = bf16[4]{0} divide(bf16[4]{0} %sqrt.258, bf16[4]{0} %broadcast.259), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.261 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.262 = bf16[4]{0} add(bf16[4]{0} %divide.260, bf16[4]{0} %broadcast.261), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.286 = bf16[4]{0} divide(bf16[4]{0} %add.271, bf16[4]{0} %add.262), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.285 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.287 = bf16[4]{0} broadcast(bf16[] %convert.285), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.288 = bf16[4]{0} multiply(bf16[4]{0} %divide.286, bf16[4]{0} %broadcast.287), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.289 = bf16[4]{0} add(bf16[4]{0} %subtract.284, bf16[4]{0} %multiply.288), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p26.334 = bf16[4,4]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.335 = bf16[4,4]{1,0} broadcast(bf16[] %p19.221), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.336 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p26.334, bf16[4,4]{1,0} %broadcast.335), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.337 = bf16[4,4]{1,0} broadcast(bf16[] %p18.220), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.339 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.336, bf16[4,4]{1,0} %broadcast.337), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.340 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p26.334, bf16[4,4]{1,0} %multiply.339), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p25.325 = bf16[4,4]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.326 = bf16[4,4]{1,0} broadcast(bf16[] %p16.210), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.327 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p25.325, bf16[4,4]{1,0} %broadcast.326), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.20 = bf16[1]{0} constant({1})
  %compare.299 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.20), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.21 = bf16[1]{0} constant({1})
  %select.301 = bf16[1]{0} select(pred[1]{0} %compare.299, bf16[1]{0} %divide.175, bf16[1]{0} %constant.21), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.303 = bf16[] reshape(bf16[1]{0} %select.301), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.305 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.303), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.306 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.60, bf16[4,4]{1,0} %broadcast.305), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.323 = bf16[4,4]{1,0} broadcast(bf16[] %p15.204), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.324 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.306, bf16[4,4]{1,0} %broadcast.323), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.328 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.327, bf16[4,4]{1,0} %multiply.324), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p24.307 = bf16[4,4]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.308 = bf16[4,4]{1,0} broadcast(bf16[] %p13.190), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.309 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p24.307, bf16[4,4]{1,0} %broadcast.308), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.311 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.306, bf16[4,4]{1,0} %multiply.306), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.310 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.312 = bf16[4,4]{1,0} broadcast(bf16[] %convert.310), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.313 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.311, bf16[4,4]{1,0} %broadcast.312), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.314 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.309, bf16[4,4]{1,0} %multiply.313), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.315 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.314), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.316 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.317 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.315, bf16[4,4]{1,0} %broadcast.316), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.318 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.319 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.317, bf16[4,4]{1,0} %broadcast.318), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.342 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.328, bf16[4,4]{1,0} %add.319), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.341 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.343 = bf16[4,4]{1,0} broadcast(bf16[] %convert.341), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.344 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.342, bf16[4,4]{1,0} %broadcast.343), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.345 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.340, bf16[4,4]{1,0} %multiply.344), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p29.390 = bf16[4]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.391 = bf16[4]{0} broadcast(bf16[] %p19.221), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.392 = bf16[4]{0} multiply(bf16[4]{0} %p29.390, bf16[4]{0} %broadcast.391), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.24 = bf16[] constant(0)
  %broadcast.3 = bf16[4]{0} broadcast(bf16[] %constant.24), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.395 = bf16[4]{0} multiply(bf16[4]{0} %multiply.392, bf16[4]{0} %broadcast.3), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.396 = bf16[4]{0} subtract(bf16[4]{0} %p29.390, bf16[4]{0} %multiply.395), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p28.380 = bf16[4]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.381 = bf16[4]{0} broadcast(bf16[] %p16.210), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.382 = bf16[4]{0} multiply(bf16[4]{0} %p28.380, bf16[4]{0} %broadcast.381), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.27 = bf16[1]{0} constant({1})
  %compare.355 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.27), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.28 = bf16[1]{0} constant({1})
  %select.357 = bf16[1]{0} select(pred[1]{0} %compare.355, bf16[1]{0} %divide.175, bf16[1]{0} %constant.28), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.359 = bf16[] reshape(bf16[1]{0} %select.357), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.360 = bf16[4]{0} broadcast(bf16[] %reshape.359), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.361 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.57, bf16[4]{0} %broadcast.360), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.378 = bf16[4]{0} broadcast(bf16[] %p15.204), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.379 = bf16[4]{0} multiply(bf16[4]{0} %multiply.361, bf16[4]{0} %broadcast.378), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.383 = bf16[4]{0} add(bf16[4]{0} %multiply.382, bf16[4]{0} %multiply.379), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p27.362 = bf16[4]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.363 = bf16[4]{0} broadcast(bf16[] %p13.190), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.364 = bf16[4]{0} multiply(bf16[4]{0} %p27.362, bf16[4]{0} %broadcast.363), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.366 = bf16[4]{0} multiply(bf16[4]{0} %multiply.361, bf16[4]{0} %multiply.361), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.365 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.367 = bf16[4]{0} broadcast(bf16[] %convert.365), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.368 = bf16[4]{0} multiply(bf16[4]{0} %multiply.366, bf16[4]{0} %broadcast.367), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.369 = bf16[4]{0} add(bf16[4]{0} %multiply.364, bf16[4]{0} %multiply.368), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.370 = bf16[4]{0} sqrt(bf16[4]{0} %add.369), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.371 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.372 = bf16[4]{0} divide(bf16[4]{0} %sqrt.370, bf16[4]{0} %broadcast.371), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.373 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.374 = bf16[4]{0} add(bf16[4]{0} %divide.372, bf16[4]{0} %broadcast.373), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.398 = bf16[4]{0} divide(bf16[4]{0} %add.383, bf16[4]{0} %add.374), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.397 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.399 = bf16[4]{0} broadcast(bf16[] %convert.397), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.400 = bf16[4]{0} multiply(bf16[4]{0} %divide.398, bf16[4]{0} %broadcast.399), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.401 = bf16[4]{0} add(bf16[4]{0} %subtract.396, bf16[4]{0} %multiply.400), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p32.446 = bf16[1,4]{1,0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.447 = bf16[1,4]{1,0} broadcast(bf16[] %p19.221), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.448 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p32.446, bf16[1,4]{1,0} %broadcast.447), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.449 = bf16[1,4]{1,0} broadcast(bf16[] %p18.220), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.451 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.448, bf16[1,4]{1,0} %broadcast.449), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.452 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p32.446, bf16[1,4]{1,0} %multiply.451), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p31.437 = bf16[1,4]{1,0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.438 = bf16[1,4]{1,0} broadcast(bf16[] %p16.210), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.439 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p31.437, bf16[1,4]{1,0} %broadcast.438), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.31 = bf16[1]{0} constant({1})
  %compare.411 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.31), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.32 = bf16[1]{0} constant({1})
  %select.413 = bf16[1]{0} select(pred[1]{0} %compare.411, bf16[1]{0} %divide.175, bf16[1]{0} %constant.32), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.415 = bf16[] reshape(bf16[1]{0} %select.413), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.14 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.415), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.418 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.59, bf16[1,4]{1,0} %broadcast.14), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.435 = bf16[1,4]{1,0} broadcast(bf16[] %p15.204), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.436 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.418, bf16[1,4]{1,0} %broadcast.435), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.440 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.439, bf16[1,4]{1,0} %multiply.436), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p30.419 = bf16[1,4]{1,0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.420 = bf16[1,4]{1,0} broadcast(bf16[] %p13.190), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.421 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p30.419, bf16[1,4]{1,0} %broadcast.420), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.423 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.418, bf16[1,4]{1,0} %multiply.418), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.422 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.424 = bf16[1,4]{1,0} broadcast(bf16[] %convert.422), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.425 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.423, bf16[1,4]{1,0} %broadcast.424), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.426 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.421, bf16[1,4]{1,0} %multiply.425), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.427 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.426), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.428 = bf16[1,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.429 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.427, bf16[1,4]{1,0} %broadcast.428), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.430 = bf16[1,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.431 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.429, bf16[1,4]{1,0} %broadcast.430), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.454 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.440, bf16[1,4]{1,0} %add.431), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.453 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.455 = bf16[1,4]{1,0} broadcast(bf16[] %convert.453), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.456 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.454, bf16[1,4]{1,0} %broadcast.455), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.457 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.452, bf16[1,4]{1,0} %multiply.456), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p35.495 = bf16[1]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.68 = bf16[1]{0} reshape(bf16[] %p19.221), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.497 = bf16[1]{0} multiply(bf16[1]{0} %p35.495, bf16[1]{0} %reshape.68), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.33 = bf16[1]{0} constant({0})
  %multiply.500 = bf16[1]{0} multiply(bf16[1]{0} %multiply.497, bf16[1]{0} %constant.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.501 = bf16[1]{0} subtract(bf16[1]{0} %p35.495, bf16[1]{0} %multiply.500), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p34.487 = bf16[1]{0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.71 = bf16[1]{0} reshape(bf16[] %p16.210), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.489 = bf16[1]{0} multiply(bf16[1]{0} %p34.487, bf16[1]{0} %reshape.71), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.37 = bf16[1]{0} constant({1})
  %compare.467 = pred[1]{0} compare(bf16[1]{0} %divide.175, bf16[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.39 = bf16[1]{0} constant({1})
  %select.469 = bf16[1]{0} select(pred[1]{0} %compare.467, bf16[1]{0} %divide.175, bf16[1]{0} %constant.39), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.470 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.56, bf16[1]{0} %select.469), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.76 = bf16[1]{0} reshape(bf16[] %p15.204), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.486 = bf16[1]{0} multiply(bf16[1]{0} %multiply.470, bf16[1]{0} %reshape.76), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.490 = bf16[1]{0} add(bf16[1]{0} %multiply.489, bf16[1]{0} %multiply.486), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p33.471 = bf16[1]{0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.77 = bf16[1]{0} reshape(bf16[] %p13.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.473 = bf16[1]{0} multiply(bf16[1]{0} %p33.471, bf16[1]{0} %reshape.77), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.475 = bf16[1]{0} multiply(bf16[1]{0} %multiply.470, bf16[1]{0} %multiply.470), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.474 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.78 = bf16[1]{0} reshape(bf16[] %convert.474), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.477 = bf16[1]{0} multiply(bf16[1]{0} %multiply.475, bf16[1]{0} %reshape.78), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.478 = bf16[1]{0} add(bf16[1]{0} %multiply.473, bf16[1]{0} %multiply.477), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.479 = bf16[1]{0} sqrt(bf16[1]{0} %add.478), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.79 = bf16[1]{0} reshape(bf16[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.481 = bf16[1]{0} divide(bf16[1]{0} %sqrt.479, bf16[1]{0} %reshape.79), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.80 = bf16[1]{0} reshape(bf16[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.483 = bf16[1]{0} add(bf16[1]{0} %divide.481, bf16[1]{0} %reshape.80), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.503 = bf16[1]{0} divide(bf16[1]{0} %add.490, bf16[1]{0} %add.483), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.502 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.81 = bf16[1]{0} reshape(bf16[] %convert.502), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.505 = bf16[1]{0} multiply(bf16[1]{0} %divide.503, bf16[1]{0} %reshape.81), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.506 = bf16[1]{0} add(bf16[1]{0} %subtract.501, bf16[1]{0} %multiply.505), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.507 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[1,4]{1,0}, /*index=5*/bf16[1]{0}, bf16[1]{0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=10*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=15*/bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4]{0}, /*index=20*/bf16[4]{0}, bf16[4]{0}, bf16[1]{0}, bf16[1]{0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %add.233, bf16[4]{0} %add.289, bf16[4,4]{1,0} %add.345, bf16[4]{0} %add.401, bf16[1,4]{1,0} %add.457, /*index=5*/bf16[1]{0} %add.506, bf16[1]{0} %multiply.470, bf16[1,4]{1,0} %multiply.418, bf16[4]{0} %multiply.361, bf16[4,4]{1,0} %multiply.306, /*index=10*/bf16[4]{0} %multiply.249, bf16[4,4]{1,0} %multiply.189, bf16[4,4]{1,0} %add.214, bf16[4,4]{1,0} %add.198, bf16[4,4]{1,0} %add.328, /*index=15*/bf16[4,4]{1,0} %add.314, bf16[1,4]{1,0} %add.440, bf16[1,4]{1,0} %add.426, bf16[4]{0} %add.271, bf16[4]{0} %add.257, /*index=20*/bf16[4]{0} %add.383, bf16[4]{0} %add.369, bf16[1]{0} %add.490, bf16[1]{0} %add.478, bf16[1]{0} %power.170), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24"}
}

`

export default text;
