const text = `
HloModule SyncTensorsGraph.1276, input_output_alias={ {0}: (21, {}, must-alias), {1}: (20, {}, must-alias), {2}: (15, {}, must-alias), {3}: (19, {}, must-alias), {4}: (13, {}, must-alias), {5}: (18, {}, must-alias), {6}: (11, {}, must-alias), {7}: (17, {}, must-alias), {8}: (9, {}, must-alias), {10}: (36, {}, must-alias), {11}: (39, {}, must-alias), {12}: (42, {}, must-alias), {13}: (45, {}, must-alias), {14}: (48, {}, must-alias), {15}: (51, {}, must-alias), {16}: (54, {}, must-alias), {17}: (57, {}, must-alias), {18}: (60, {}, must-alias), {19}: (63, {}, must-alias), {20}: (8, {}, must-alias), {21}: (23, {}, must-alias), {22}: (10, {}, must-alias), {23}: (24, {}, must-alias), {24}: (12, {}, must-alias), {25}: (25, {}, must-alias), {26}: (14, {}, must-alias), {27}: (26, {}, must-alias), {28}: (16, {}, must-alias), {29}: (27, {}, must-alias), {30}: (33, {}, must-alias), {31}: (30, {}, must-alias), {32}: (38, {}, must-alias), {33}: (37, {}, must-alias), {34}: (41, {}, must-alias), {35}: (40, {}, must-alias), {36}: (44, {}, must-alias), {37}: (43, {}, must-alias), {38}: (47, {}, must-alias), {39}: (46, {}, must-alias), {40}: (50, {}, must-alias), {41}: (49, {}, must-alias), {42}: (53, {}, must-alias), {43}: (52, {}, must-alias), {44}: (56, {}, must-alias), {45}: (55, {}, must-alias), {46}: (59, {}, must-alias), {47}: (58, {}, must-alias), {48}: (62, {}, must-alias), {49}: (61, {}, must-alias), {50}: (22, {}, must-alias) }

%AddComputation.37 (x.38: bf16[], y.39: bf16[]) -> bf16[] {
  %x.38 = bf16[] parameter(0)
  %y.39 = bf16[] parameter(1)
  ROOT %add.40 = bf16[] add(bf16[] %x.38, bf16[] %y.39)
}

%AddComputation.58 (x.59: bf16[], y.60: bf16[]) -> bf16[] {
  %x.59 = bf16[] parameter(0)
  %y.60 = bf16[] parameter(1)
  ROOT %add.61 = bf16[] add(bf16[] %x.59, bf16[] %y.60)
}

%AddComputation.97 (x.98: bf16[], y.99: bf16[]) -> bf16[] {
  %x.98 = bf16[] parameter(0)
  %y.99 = bf16[] parameter(1)
  ROOT %add.100 = bf16[] add(bf16[] %x.98, bf16[] %y.99)
}

%AddComputation.118 (x.119: bf16[], y.120: bf16[]) -> bf16[] {
  %x.119 = bf16[] parameter(0)
  %y.120 = bf16[] parameter(1)
  ROOT %add.121 = bf16[] add(bf16[] %x.119, bf16[] %y.120)
}

%AddComputation.129 (x.130: bf16[], y.131: bf16[]) -> bf16[] {
  %x.130 = bf16[] parameter(0)
  %y.131 = bf16[] parameter(1)
  ROOT %add.132 = bf16[] add(bf16[] %x.130, bf16[] %y.131)
}

%AddComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %add.160 = bf16[] add(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.178 (x.179: bf16[], y.180: bf16[]) -> bf16[] {
  %x.179 = bf16[] parameter(0)
  %y.180 = bf16[] parameter(1)
  ROOT %add.181 = bf16[] add(bf16[] %x.179, bf16[] %y.180)
}

%AddComputation.189 (x.190: bf16[], y.191: bf16[]) -> bf16[] {
  %x.190 = bf16[] parameter(0)
  %y.191 = bf16[] parameter(1)
  ROOT %add.192 = bf16[] add(bf16[] %x.190, bf16[] %y.191)
}

%AddComputation.217 (x.218: bf16[], y.219: bf16[]) -> bf16[] {
  %x.218 = bf16[] parameter(0)
  %y.219 = bf16[] parameter(1)
  ROOT %add.220 = bf16[] add(bf16[] %x.218, bf16[] %y.219)
}

%AddComputation.238 (x.239: bf16[], y.240: bf16[]) -> bf16[] {
  %x.239 = bf16[] parameter(0)
  %y.240 = bf16[] parameter(1)
  ROOT %add.241 = bf16[] add(bf16[] %x.239, bf16[] %y.240)
}

%AddComputation.249 (x.250: bf16[], y.251: bf16[]) -> bf16[] {
  %x.250 = bf16[] parameter(0)
  %y.251 = bf16[] parameter(1)
  ROOT %add.252 = bf16[] add(bf16[] %x.250, bf16[] %y.251)
}

%AddComputation.277 (x.278: bf16[], y.279: bf16[]) -> bf16[] {
  %x.278 = bf16[] parameter(0)
  %y.279 = bf16[] parameter(1)
  ROOT %add.280 = bf16[] add(bf16[] %x.278, bf16[] %y.279)
}

%AddComputation.298 (x.299: bf16[], y.300: bf16[]) -> bf16[] {
  %x.299 = bf16[] parameter(0)
  %y.300 = bf16[] parameter(1)
  ROOT %add.301 = bf16[] add(bf16[] %x.299, bf16[] %y.300)
}

%AddComputation.309 (x.310: bf16[], y.311: bf16[]) -> bf16[] {
  %x.310 = bf16[] parameter(0)
  %y.311 = bf16[] parameter(1)
  ROOT %add.312 = bf16[] add(bf16[] %x.310, bf16[] %y.311)
}

%AddComputation.410 (x.411: bf16[], y.412: bf16[]) -> bf16[] {
  %x.411 = bf16[] parameter(0)
  %y.412 = bf16[] parameter(1)
  ROOT %add.413 = bf16[] add(bf16[] %x.411, bf16[] %y.412)
}

%AddComputation.421 (x.422: bf16[], y.423: bf16[]) -> bf16[] {
  %x.422 = bf16[] parameter(0)
  %y.423 = bf16[] parameter(1)
  ROOT %add.424 = bf16[] add(bf16[] %x.422, bf16[] %y.423)
}

%AddComputation.453 (x.454: bf16[], y.455: bf16[]) -> bf16[] {
  %x.454 = bf16[] parameter(0)
  %y.455 = bf16[] parameter(1)
  ROOT %add.456 = bf16[] add(bf16[] %x.454, bf16[] %y.455)
}

%AddComputation.464 (x.465: bf16[], y.466: bf16[]) -> bf16[] {
  %x.465 = bf16[] parameter(0)
  %y.466 = bf16[] parameter(1)
  ROOT %add.467 = bf16[] add(bf16[] %x.465, bf16[] %y.466)
}

%AddComputation.496 (x.497: bf16[], y.498: bf16[]) -> bf16[] {
  %x.497 = bf16[] parameter(0)
  %y.498 = bf16[] parameter(1)
  ROOT %add.499 = bf16[] add(bf16[] %x.497, bf16[] %y.498)
}

%AddComputation.507 (x.508: bf16[], y.509: bf16[]) -> bf16[] {
  %x.508 = bf16[] parameter(0)
  %y.509 = bf16[] parameter(1)
  ROOT %add.510 = bf16[] add(bf16[] %x.508, bf16[] %y.509)
}

%AddComputation.539 (x.540: bf16[], y.541: bf16[]) -> bf16[] {
  %x.540 = bf16[] parameter(0)
  %y.541 = bf16[] parameter(1)
  ROOT %add.542 = bf16[] add(bf16[] %x.540, bf16[] %y.541)
}

%AddComputation.550 (x.551: bf16[], y.552: bf16[]) -> bf16[] {
  %x.551 = bf16[] parameter(0)
  %y.552 = bf16[] parameter(1)
  ROOT %add.553 = bf16[] add(bf16[] %x.551, bf16[] %y.552)
}

%AddComputation.582 (x.583: bf16[], y.584: bf16[]) -> bf16[] {
  %x.583 = bf16[] parameter(0)
  %y.584 = bf16[] parameter(1)
  ROOT %add.585 = bf16[] add(bf16[] %x.583, bf16[] %y.584)
}

%AddComputation.593 (x.594: bf16[], y.595: bf16[]) -> bf16[] {
  %x.594 = bf16[] parameter(0)
  %y.595 = bf16[] parameter(1)
  ROOT %add.596 = bf16[] add(bf16[] %x.594, bf16[] %y.595)
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.1276 (p0.1: f32[], p1.2: f32[], p2.4: bf16[], p3.6: bf16[], p4.7: f32[], p5.13: bf16[], p6.24: bf16[], p7.25: bf16[], p8.52: bf16[1], p9.84: bf16[1,4], p10.112: bf16[4], p11.144: bf16[4,4], p12.172: bf16[4], p13.204: bf16[4,4], p14.232: bf16[4], p15.264: bf16[4,4], p16.292: bf16[4], p17.324: bf16[4], p18.333: bf16[4], p19.342: bf16[4], p20.351: bf16[4], p21.359: bf16[4,4], p22.368: bf16[4,4], p23.404: bf16[1,4], p24.447: bf16[4,4], p25.490: bf16[4,4], p26.533: bf16[4,4], p27.576: bf16[4,4], p28.601: bf16[1], p29.644: bf16[], p30.645: bf16[4,4], p31.658: bf16[], p32.664: bf16[], p33.665: bf16[4,4], p34.674: bf16[], p35.675: bf16[], p36.676: bf16[4,4], p37.714: bf16[4,4], p38.732: bf16[4,4], p39.741: bf16[4,4], p40.778: bf16[4,4], p41.796: bf16[4,4], p42.805: bf16[4,4], p43.842: bf16[4,4], p44.860: bf16[4,4], p45.869: bf16[4,4], p46.906: bf16[1,4], p47.924: bf16[1,4], p48.933: bf16[1,4], p49.969: bf16[4], p50.987: bf16[4], p51.997: bf16[4], p52.1035: bf16[4], p53.1053: bf16[4], p54.1063: bf16[4], p55.1101: bf16[4], p56.1119: bf16[4], p57.1129: bf16[4], p58.1167: bf16[4], p59.1185: bf16[4], p60.1195: bf16[4], p61.1230: bf16[1], p62.1246: bf16[1], p63.1254: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=5*/bf16[4], bf16[4,4], bf16[4], bf16[1,4], bf16[1], /*index=10*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[1,4], /*index=15*/bf16[4], bf16[4], bf16[4], bf16[4], bf16[1], /*index=20*/bf16[1], bf16[1,4], bf16[4], bf16[4,4], bf16[4], /*index=25*/bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=30*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=35*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[1,4], bf16[1,4], /*index=40*/bf16[4], bf16[4], bf16[4], bf16[4], bf16[4], /*index=45*/bf16[4], bf16[4], bf16[4], bf16[1], bf16[1], /*index=50*/bf16[4,4], bf16[1]) {
  %p36.676 = bf16[4,4]{1,0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p35.675 = bf16[] parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.677 = bf16[4,4]{1,0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.678 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p36.676, bf16[4,4]{1,0} %broadcast.677), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p34.674 = bf16[] parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.679 = bf16[4,4]{1,0} broadcast(bf16[] %p34.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.681 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.678, bf16[4,4]{1,0} %broadcast.679), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.682 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p36.676, bf16[4,4]{1,0} %multiply.681), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p33.665 = bf16[4,4]{1,0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p32.664 = bf16[] parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.666 = bf16[4,4]{1,0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.667 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p33.665, bf16[4,4]{1,0} %broadcast.666), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p27.576 = bf16[4,4]{1,0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p7.25 = bf16[] parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p6.24 = bf16[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %divide.1 = bf16[] divide(bf16[] %p7.25, bf16[] %p6.24), metadata={op_type="aten__div" op_name="aten__div"}
  %broadcast.61 = bf16[1,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p9.84 = bf16[1,4]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.20 = bf16[1,4]{1,0} custom-call(bf16[1,4]{1,0} %p9.84), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.23 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %broadcast.61, bf16[1,4]{1,0} %custom-call.20), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.232 = bf16[4]{0} reshape(bf16[1,4]{1,0} %multiply.23), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.9 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %reshape.232), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p11.144 = bf16[4,4]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.22 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p11.144), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.154 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %broadcast.9, bf16[4,4]{1,0} %custom-call.22), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p13.204 = bf16[4,4]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.24 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p13.204), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.214 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.154, bf16[4,4]{1,0} %custom-call.24), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p15.264 = bf16[4,4]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.26 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p15.264), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.274 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.214, bf16[4,4]{1,0} %custom-call.26), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p22.368 = bf16[4,4]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model_nxd.py" source_line=155}
  %transpose.565 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %p22.368), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.1 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.274, bf16[4,4]{0,1} %transpose.565), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.37 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.577 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p27.576, bf16[4,4]{1,0} %custom-call.37), metadata={op_type="aten__add" op_name="aten__add"}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=430}
  %convert.578 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.586 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %add.577, bf16[] %convert.578), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.582, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.587 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.586), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %constant.1 = bf16[1]{0} constant({1})
  %p28.601 = bf16[1]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.590 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.587, bf16[4,4]{1,0} %get-tuple-element.587), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.591 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.597 = bf16[] reduce(bf16[4,4]{1,0} %multiply.590, bf16[] %constant.591), dimensions={0,1}, to_apply=%AddComputation.593, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.598 = bf16[] sqrt(bf16[] %reduce.597), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.600 = bf16[] multiply(bf16[] %sqrt.598, bf16[] %sqrt.598), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.600), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.603 = bf16[1]{0} add(bf16[1]{0} %p28.601, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p26.533 = bf16[4,4]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p21.359 = bf16[4,4]{1,0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.28 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p21.359), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.367 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.28), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.369 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %p22.368, bf16[4,4]{0,1} %transpose.367), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p20.351 = bf16[4]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.29 = bf16[4]{0} custom-call(bf16[4]{0} %p20.351), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.373 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.29), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.374 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.369, bf16[4,4]{1,0} %broadcast.373), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.522 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.374), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.2 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.214, bf16[4,4]{0,1} %transpose.522), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.36 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.2), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.534 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p26.533, bf16[4,4]{1,0} %custom-call.36), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.535 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.543 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %add.534, bf16[] %convert.535), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.539, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.544 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.543), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.547 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.544, bf16[4,4]{1,0} %get-tuple-element.544), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.548 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.554 = bf16[] reduce(bf16[4,4]{1,0} %multiply.547, bf16[] %constant.548), dimensions={0,1}, to_apply=%AddComputation.550, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.555 = bf16[] sqrt(bf16[] %reduce.554), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.557 = bf16[] multiply(bf16[] %sqrt.555, bf16[] %sqrt.555), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.19 = bf16[1]{0} reshape(bf16[] %multiply.557), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.605 = bf16[1]{0} add(bf16[1]{0} %add.603, bf16[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p25.490 = bf16[4,4]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %transpose.350 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.26), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.375 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.374, bf16[4,4]{0,1} %transpose.350), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p19.342 = bf16[4]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.30 = bf16[4]{0} custom-call(bf16[4]{0} %p19.342), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.379 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.30), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.380 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.375, bf16[4,4]{1,0} %broadcast.379), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.479 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.380), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.3 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.154, bf16[4,4]{0,1} %transpose.479), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.35 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.3), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.491 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p25.490, bf16[4,4]{1,0} %custom-call.35), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.492 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.500 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %add.491, bf16[] %convert.492), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.496, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.501 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.500), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.504 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.501, bf16[4,4]{1,0} %get-tuple-element.501), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.505 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.511 = bf16[] reduce(bf16[4,4]{1,0} %multiply.504, bf16[] %constant.505), dimensions={0,1}, to_apply=%AddComputation.507, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.512 = bf16[] sqrt(bf16[] %reduce.511), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.514 = bf16[] multiply(bf16[] %sqrt.512, bf16[] %sqrt.512), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.25 = bf16[1]{0} reshape(bf16[] %multiply.514), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.607 = bf16[1]{0} add(bf16[1]{0} %add.605, bf16[1]{0} %reshape.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p24.447 = bf16[4,4]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %transpose.341 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.24), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.381 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.380, bf16[4,4]{0,1} %transpose.341), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p18.333 = bf16[4]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.31 = bf16[4]{0} custom-call(bf16[4]{0} %p18.333), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.385 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.31), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.386 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.381, bf16[4,4]{1,0} %broadcast.385), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.436 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.386), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.4 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %broadcast.9, bf16[4,4]{0,1} %transpose.436), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.34 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.4), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.448 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p24.447, bf16[4,4]{1,0} %custom-call.34), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.449 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.457 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %add.448, bf16[] %convert.449), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.453, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.458 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.457), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.461 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.458, bf16[4,4]{1,0} %get-tuple-element.458), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.462 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.468 = bf16[] reduce(bf16[4,4]{1,0} %multiply.461, bf16[] %constant.462), dimensions={0,1}, to_apply=%AddComputation.464, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.469 = bf16[] sqrt(bf16[] %reduce.468), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.471 = bf16[] multiply(bf16[] %sqrt.469, bf16[] %sqrt.469), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.37 = bf16[1]{0} reshape(bf16[] %multiply.471), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.609 = bf16[1]{0} add(bf16[1]{0} %add.607, bf16[1]{0} %reshape.37), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p23.404 = bf16[1,4]{1,0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %transpose.332 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.22), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.387 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.386, bf16[4,4]{0,1} %transpose.332), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p17.324 = bf16[4]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.32 = bf16[4]{0} custom-call(bf16[4]{0} %p17.324), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.391 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.32), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.392 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.387, bf16[4,4]{1,0} %broadcast.391), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.63 = bf16[4,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.24 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.392, bf16[4,4]{1,0} %broadcast.63)
  %convert.2 = f32[4,4]{1,0} convert(bf16[4,4]{1,0} %multiply.24)
  %constant = f32[] constant(0)
  %reduce = f32[4]{0} reduce(f32[4,4]{1,0} %convert.2, f32[] %constant), dimensions={0}, to_apply=%scalar_add_computation
  %convert.1 = bf16[4]{0} convert(f32[4]{0} %reduce), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.44 = bf16[1,4]{0,1} reshape(bf16[4]{0} %convert.1), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.33 = bf16[1,4]{1,0} custom-call(bf16[1,4]{0,1} %reshape.44), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.405 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %p23.404, bf16[1,4]{1,0} %custom-call.33), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.406 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.414 = (bf16[1,4]{1,0}, bf16[]) reduce-scatter(bf16[1,4]{1,0} %add.405, bf16[] %convert.406), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.410, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.415 = bf16[1,4]{1,0} get-tuple-element((bf16[1,4]{1,0}, bf16[]) %reduce-scatter.414), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.418 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.415, bf16[1,4]{1,0} %get-tuple-element.415), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.419 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.425 = bf16[] reduce(bf16[1,4]{1,0} %multiply.418, bf16[] %constant.419), dimensions={0,1}, to_apply=%AddComputation.421, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.426 = bf16[] sqrt(bf16[] %reduce.425), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.428 = bf16[] multiply(bf16[] %sqrt.426, bf16[] %sqrt.426), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.48 = bf16[1]{0} reshape(bf16[] %multiply.428), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.611 = bf16[1]{0} add(bf16[1]{0} %add.609, bf16[1]{0} %reshape.48), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p16.292 = bf16[4]{0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.275 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.281 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.274, bf16[] %constant.275), dimensions={0}, to_apply=%AddComputation.277, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.27 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.281), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.293 = bf16[4]{0} add(bf16[4]{0} %p16.292, bf16[4]{0} %custom-call.27), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.294 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.302 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %add.293, bf16[] %convert.294), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.298, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.303 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.302), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.306 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.303, bf16[4]{0} %get-tuple-element.303), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.307 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.313 = bf16[] reduce(bf16[4]{0} %multiply.306, bf16[] %constant.307), dimensions={0}, to_apply=%AddComputation.309, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.314 = bf16[] sqrt(bf16[] %reduce.313), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.316 = bf16[] multiply(bf16[] %sqrt.314, bf16[] %sqrt.314), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.52 = bf16[1]{0} reshape(bf16[] %multiply.316), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.613 = bf16[1]{0} add(bf16[1]{0} %add.611, bf16[1]{0} %reshape.52), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p14.232 = bf16[4]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.215 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.221 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.214, bf16[] %constant.215), dimensions={0}, to_apply=%AddComputation.217, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.25 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.221), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.233 = bf16[4]{0} add(bf16[4]{0} %p14.232, bf16[4]{0} %custom-call.25), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.234 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.242 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %add.233, bf16[] %convert.234), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.238, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.243 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.242), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.246 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.243, bf16[4]{0} %get-tuple-element.243), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.247 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.253 = bf16[] reduce(bf16[4]{0} %multiply.246, bf16[] %constant.247), dimensions={0}, to_apply=%AddComputation.249, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.254 = bf16[] sqrt(bf16[] %reduce.253), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.256 = bf16[] multiply(bf16[] %sqrt.254, bf16[] %sqrt.254), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.56 = bf16[1]{0} reshape(bf16[] %multiply.256), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.615 = bf16[1]{0} add(bf16[1]{0} %add.613, bf16[1]{0} %reshape.56), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p12.172 = bf16[4]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.155 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.161 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.154, bf16[] %constant.155), dimensions={0}, to_apply=%AddComputation.157, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.23 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.161), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.173 = bf16[4]{0} add(bf16[4]{0} %p12.172, bf16[4]{0} %custom-call.23), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.174 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.182 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %add.173, bf16[] %convert.174), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.178, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.183 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.182), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.186 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.183, bf16[4]{0} %get-tuple-element.183), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.187 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.193 = bf16[] reduce(bf16[4]{0} %multiply.186, bf16[] %constant.187), dimensions={0}, to_apply=%AddComputation.189, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.194 = bf16[] sqrt(bf16[] %reduce.193), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.196 = bf16[] multiply(bf16[] %sqrt.194, bf16[] %sqrt.194), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.60 = bf16[1]{0} reshape(bf16[] %multiply.196), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.617 = bf16[1]{0} add(bf16[1]{0} %add.615, bf16[1]{0} %reshape.60), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p10.112 = bf16[4]{0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.95 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.101 = bf16[4]{0} reduce(bf16[4,4]{1,0} %broadcast.9, bf16[] %constant.95), dimensions={0}, to_apply=%AddComputation.97, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.21 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.101), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.113 = bf16[4]{0} add(bf16[4]{0} %p10.112, bf16[4]{0} %custom-call.21), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.114 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.122 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %add.113, bf16[] %convert.114), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.118, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.123 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.122), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.126 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.123, bf16[4]{0} %get-tuple-element.123), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.127 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.133 = bf16[] reduce(bf16[4]{0} %multiply.126, bf16[] %constant.127), dimensions={0}, to_apply=%AddComputation.129, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.134 = bf16[] sqrt(bf16[] %reduce.133), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.136 = bf16[] multiply(bf16[] %sqrt.134, bf16[] %sqrt.134), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.64 = bf16[1]{0} reshape(bf16[] %multiply.136), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.619 = bf16[1]{0} add(bf16[1]{0} %add.617, bf16[1]{0} %reshape.64), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p8.52 = bf16[1]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %broadcast.1 = bf16[4,1]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.35 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.41 = bf16[1]{0} reduce(bf16[4,1]{1,0} %broadcast.1, bf16[] %constant.35), dimensions={0}, to_apply=%AddComputation.37, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.19 = bf16[1]{0} custom-call(bf16[1]{0} %reduce.41), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.53 = bf16[1]{0} add(bf16[1]{0} %p8.52, bf16[1]{0} %custom-call.19), metadata={op_type="aten__add" op_name="aten__add"}
  %convert.54 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.62 = (bf16[1]{0}, bf16[]) reduce-scatter(bf16[1]{0} %add.53, bf16[] %convert.54), replica_groups={{0}}, dimensions={0}, to_apply=%AddComputation.58, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.63 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %reduce-scatter.62), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.25 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.63, bf16[1]{0} %get-tuple-element.63), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.621 = bf16[1]{0} add(bf16[1]{0} %add.619, bf16[1]{0} %multiply.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.5 = bf16[1]{0} constant({0.5})
  %power.624 = bf16[1]{0} power(bf16[1]{0} %add.621, bf16[1]{0} %constant.5), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p5.13 = bf16[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.71 = bf16[1]{0} reshape(bf16[] %p5.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.626 = bf16[1]{0} add(bf16[1]{0} %power.624, bf16[1]{0} %reshape.71), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.629 = bf16[1]{0} divide(bf16[1]{0} %constant.1, bf16[1]{0} %add.626), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.9 = bf16[1]{0} constant({1})
  %compare.636 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.9), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.10 = bf16[1]{0} constant({1})
  %select.638 = bf16[1]{0} select(pred[1]{0} %compare.636, bf16[1]{0} %divide.629, bf16[1]{0} %constant.10), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.640 = bf16[] reshape(bf16[1]{0} %select.638), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.642 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.640), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.643 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.587, bf16[4,4]{1,0} %broadcast.642), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p31.658 = bf16[] parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.662 = bf16[4,4]{1,0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.663 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.643, bf16[4,4]{1,0} %broadcast.662), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.668 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.667, bf16[4,4]{1,0} %multiply.663), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p30.645 = bf16[4,4]{1,0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p29.644 = bf16[] parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.646 = bf16[4,4]{1,0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.647 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p30.645, bf16[4,4]{1,0} %broadcast.646), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.649 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.643, bf16[4,4]{1,0} %multiply.643), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p4.7 = f32[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.648 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.650 = bf16[4,4]{1,0} broadcast(bf16[] %convert.648), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.651 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.649, bf16[4,4]{1,0} %broadcast.650), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.652 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.647, bf16[4,4]{1,0} %multiply.651), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.653 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.652), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p3.6 = bf16[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.654 = bf16[4,4]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.655 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.653, bf16[4,4]{1,0} %broadcast.654), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.4 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.656 = bf16[4,4]{1,0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.657 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.655, bf16[4,4]{1,0} %broadcast.656), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.684 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.668, bf16[4,4]{1,0} %add.657), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p1.2 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.683 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.685 = bf16[4,4]{1,0} broadcast(bf16[] %convert.683), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.686 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.684, bf16[4,4]{1,0} %broadcast.685), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.687 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.682, bf16[4,4]{1,0} %multiply.686), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.688 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.692 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.687, bf16[] %convert.688), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.693 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.692), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p51.997 = bf16[4]{0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.998 = bf16[4]{0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.999 = bf16[4]{0} multiply(bf16[4]{0} %p51.997, bf16[4]{0} %broadcast.998), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.14 = bf16[] constant(0)
  %broadcast.12 = bf16[4]{0} broadcast(bf16[] %constant.14), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1002 = bf16[4]{0} multiply(bf16[4]{0} %multiply.999, bf16[4]{0} %broadcast.12), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1003 = bf16[4]{0} subtract(bf16[4]{0} %p51.997, bf16[4]{0} %multiply.1002), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p50.987 = bf16[4]{0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.988 = bf16[4]{0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.989 = bf16[4]{0} multiply(bf16[4]{0} %p50.987, bf16[4]{0} %broadcast.988), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.17 = bf16[1]{0} constant({1})
  %compare.962 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.17), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.22 = bf16[1]{0} constant({1})
  %select.964 = bf16[1]{0} select(pred[1]{0} %compare.962, bf16[1]{0} %divide.629, bf16[1]{0} %constant.22), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.966 = bf16[] reshape(bf16[1]{0} %select.964), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.967 = bf16[4]{0} broadcast(bf16[] %reshape.966), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.968 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.303, bf16[4]{0} %broadcast.967), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.985 = bf16[4]{0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.986 = bf16[4]{0} multiply(bf16[4]{0} %multiply.968, bf16[4]{0} %broadcast.985), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.990 = bf16[4]{0} add(bf16[4]{0} %multiply.989, bf16[4]{0} %multiply.986), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p49.969 = bf16[4]{0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.970 = bf16[4]{0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.971 = bf16[4]{0} multiply(bf16[4]{0} %p49.969, bf16[4]{0} %broadcast.970), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.973 = bf16[4]{0} multiply(bf16[4]{0} %multiply.968, bf16[4]{0} %multiply.968), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.972 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.974 = bf16[4]{0} broadcast(bf16[] %convert.972), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.975 = bf16[4]{0} multiply(bf16[4]{0} %multiply.973, bf16[4]{0} %broadcast.974), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.976 = bf16[4]{0} add(bf16[4]{0} %multiply.971, bf16[4]{0} %multiply.975), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.977 = bf16[4]{0} sqrt(bf16[4]{0} %add.976), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.978 = bf16[4]{0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.979 = bf16[4]{0} divide(bf16[4]{0} %sqrt.977, bf16[4]{0} %broadcast.978), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.980 = bf16[4]{0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.981 = bf16[4]{0} add(bf16[4]{0} %divide.979, bf16[4]{0} %broadcast.980), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1005 = bf16[4]{0} divide(bf16[4]{0} %add.990, bf16[4]{0} %add.981), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1004 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1006 = bf16[4]{0} broadcast(bf16[] %convert.1004), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1007 = bf16[4]{0} multiply(bf16[4]{0} %divide.1005, bf16[4]{0} %broadcast.1006), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1008 = bf16[4]{0} add(bf16[4]{0} %subtract.1003, bf16[4]{0} %multiply.1007), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p48.933 = bf16[1,4]{1,0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.934 = bf16[1,4]{1,0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.935 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p48.933, bf16[1,4]{1,0} %broadcast.934), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.936 = bf16[1,4]{1,0} broadcast(bf16[] %p34.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.938 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.935, bf16[1,4]{1,0} %broadcast.936), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.939 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p48.933, bf16[1,4]{1,0} %multiply.938), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p47.924 = bf16[1,4]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.925 = bf16[1,4]{1,0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.926 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p47.924, bf16[1,4]{1,0} %broadcast.925), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.24 = bf16[1]{0} constant({1})
  %compare.898 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.24), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.25 = bf16[1]{0} constant({1})
  %select.900 = bf16[1]{0} select(pred[1]{0} %compare.898, bf16[1]{0} %divide.629, bf16[1]{0} %constant.25), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.902 = bf16[] reshape(bf16[1]{0} %select.900), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.48 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.902), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.905 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.415, bf16[1,4]{1,0} %broadcast.48), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.922 = bf16[1,4]{1,0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.923 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.905, bf16[1,4]{1,0} %broadcast.922), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.927 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.926, bf16[1,4]{1,0} %multiply.923), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p46.906 = bf16[1,4]{1,0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.907 = bf16[1,4]{1,0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.908 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p46.906, bf16[1,4]{1,0} %broadcast.907), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.910 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.905, bf16[1,4]{1,0} %multiply.905), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.909 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.911 = bf16[1,4]{1,0} broadcast(bf16[] %convert.909), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.912 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.910, bf16[1,4]{1,0} %broadcast.911), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.913 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.908, bf16[1,4]{1,0} %multiply.912), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.914 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.913), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.915 = bf16[1,4]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.916 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.914, bf16[1,4]{1,0} %broadcast.915), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.917 = bf16[1,4]{1,0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.918 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.916, bf16[1,4]{1,0} %broadcast.917), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.941 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.927, bf16[1,4]{1,0} %add.918), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.940 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.942 = bf16[1,4]{1,0} broadcast(bf16[] %convert.940), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.943 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.941, bf16[1,4]{1,0} %broadcast.942), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.944 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.939, bf16[1,4]{1,0} %multiply.943), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p45.869 = bf16[4,4]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.870 = bf16[4,4]{1,0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.871 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p45.869, bf16[4,4]{1,0} %broadcast.870), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.872 = bf16[4,4]{1,0} broadcast(bf16[] %p34.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.874 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.871, bf16[4,4]{1,0} %broadcast.872), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.875 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p45.869, bf16[4,4]{1,0} %multiply.874), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p44.860 = bf16[4,4]{1,0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.861 = bf16[4,4]{1,0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.862 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p44.860, bf16[4,4]{1,0} %broadcast.861), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.28 = bf16[1]{0} constant({1})
  %compare.834 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.28), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.29 = bf16[1]{0} constant({1})
  %select.836 = bf16[1]{0} select(pred[1]{0} %compare.834, bf16[1]{0} %divide.629, bf16[1]{0} %constant.29), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.838 = bf16[] reshape(bf16[1]{0} %select.836), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.840 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.838), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.841 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.458, bf16[4,4]{1,0} %broadcast.840), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.858 = bf16[4,4]{1,0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.859 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.841, bf16[4,4]{1,0} %broadcast.858), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.863 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.862, bf16[4,4]{1,0} %multiply.859), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p43.842 = bf16[4,4]{1,0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.843 = bf16[4,4]{1,0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.844 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p43.842, bf16[4,4]{1,0} %broadcast.843), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.846 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.841, bf16[4,4]{1,0} %multiply.841), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.845 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.847 = bf16[4,4]{1,0} broadcast(bf16[] %convert.845), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.848 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.846, bf16[4,4]{1,0} %broadcast.847), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.849 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.844, bf16[4,4]{1,0} %multiply.848), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.850 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.849), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.851 = bf16[4,4]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.852 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.850, bf16[4,4]{1,0} %broadcast.851), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.853 = bf16[4,4]{1,0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.854 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.852, bf16[4,4]{1,0} %broadcast.853), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.877 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.863, bf16[4,4]{1,0} %add.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.876 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.878 = bf16[4,4]{1,0} broadcast(bf16[] %convert.876), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.879 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.877, bf16[4,4]{1,0} %broadcast.878), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.880 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.875, bf16[4,4]{1,0} %multiply.879), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p42.805 = bf16[4,4]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.806 = bf16[4,4]{1,0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.807 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p42.805, bf16[4,4]{1,0} %broadcast.806), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.808 = bf16[4,4]{1,0} broadcast(bf16[] %p34.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.810 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.807, bf16[4,4]{1,0} %broadcast.808), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.811 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p42.805, bf16[4,4]{1,0} %multiply.810), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p41.796 = bf16[4,4]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.797 = bf16[4,4]{1,0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.798 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p41.796, bf16[4,4]{1,0} %broadcast.797), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.31 = bf16[1]{0} constant({1})
  %compare.770 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.31), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.32 = bf16[1]{0} constant({1})
  %select.772 = bf16[1]{0} select(pred[1]{0} %compare.770, bf16[1]{0} %divide.629, bf16[1]{0} %constant.32), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.774 = bf16[] reshape(bf16[1]{0} %select.772), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.776 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.774), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.777 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.501, bf16[4,4]{1,0} %broadcast.776), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.794 = bf16[4,4]{1,0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.795 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.777, bf16[4,4]{1,0} %broadcast.794), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.799 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.798, bf16[4,4]{1,0} %multiply.795), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p40.778 = bf16[4,4]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.779 = bf16[4,4]{1,0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.780 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p40.778, bf16[4,4]{1,0} %broadcast.779), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.782 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.777, bf16[4,4]{1,0} %multiply.777), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.781 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.783 = bf16[4,4]{1,0} broadcast(bf16[] %convert.781), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.784 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.782, bf16[4,4]{1,0} %broadcast.783), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.785 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.780, bf16[4,4]{1,0} %multiply.784), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.786 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.785), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.787 = bf16[4,4]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.788 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.786, bf16[4,4]{1,0} %broadcast.787), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.789 = bf16[4,4]{1,0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.790 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.788, bf16[4,4]{1,0} %broadcast.789), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.813 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.799, bf16[4,4]{1,0} %add.790), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.812 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.814 = bf16[4,4]{1,0} broadcast(bf16[] %convert.812), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.815 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.813, bf16[4,4]{1,0} %broadcast.814), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.816 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.811, bf16[4,4]{1,0} %multiply.815), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p39.741 = bf16[4,4]{1,0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.742 = bf16[4,4]{1,0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.743 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p39.741, bf16[4,4]{1,0} %broadcast.742), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.744 = bf16[4,4]{1,0} broadcast(bf16[] %p34.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.746 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.743, bf16[4,4]{1,0} %broadcast.744), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.747 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p39.741, bf16[4,4]{1,0} %multiply.746), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p38.732 = bf16[4,4]{1,0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.733 = bf16[4,4]{1,0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.734 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p38.732, bf16[4,4]{1,0} %broadcast.733), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.34 = bf16[1]{0} constant({1})
  %compare.706 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.34), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.37 = bf16[1]{0} constant({1})
  %select.708 = bf16[1]{0} select(pred[1]{0} %compare.706, bf16[1]{0} %divide.629, bf16[1]{0} %constant.37), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.710 = bf16[] reshape(bf16[1]{0} %select.708), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.712 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.710), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.713 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.544, bf16[4,4]{1,0} %broadcast.712), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.730 = bf16[4,4]{1,0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.731 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.713, bf16[4,4]{1,0} %broadcast.730), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.735 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.734, bf16[4,4]{1,0} %multiply.731), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p37.714 = bf16[4,4]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.715 = bf16[4,4]{1,0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.716 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p37.714, bf16[4,4]{1,0} %broadcast.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.718 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.713, bf16[4,4]{1,0} %multiply.713), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.717 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.719 = bf16[4,4]{1,0} broadcast(bf16[] %convert.717), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.720 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.718, bf16[4,4]{1,0} %broadcast.719), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.721 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.716, bf16[4,4]{1,0} %multiply.720), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.722 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.721), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.723 = bf16[4,4]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.724 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.722, bf16[4,4]{1,0} %broadcast.723), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.725 = bf16[4,4]{1,0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.726 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.724, bf16[4,4]{1,0} %broadcast.725), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.749 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.735, bf16[4,4]{1,0} %add.726), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.748 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.750 = bf16[4,4]{1,0} broadcast(bf16[] %convert.748), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.751 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.749, bf16[4,4]{1,0} %broadcast.750), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.752 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.747, bf16[4,4]{1,0} %multiply.751), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.756 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.692), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.757 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.752, bf16[] %get-tuple-element.756), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.820 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.757), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.821 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.816, bf16[] %get-tuple-element.820), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.884 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.821), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.885 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.880, bf16[] %get-tuple-element.884), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.948 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.885), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.949 = (bf16[1,4]{1,0}, bf16[]) all-gather(bf16[1,4]{1,0} %add.944, bf16[] %get-tuple-element.948), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1012 = bf16[] get-tuple-element((bf16[1,4]{1,0}, bf16[]) %all-gather.949), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1013 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.1008, bf16[] %get-tuple-element.1012), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1014 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1013), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.758 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.757), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p54.1063 = bf16[4]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1064 = bf16[4]{0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1065 = bf16[4]{0} multiply(bf16[4]{0} %p54.1063, bf16[4]{0} %broadcast.1064), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.39 = bf16[] constant(0)
  %broadcast.19 = bf16[4]{0} broadcast(bf16[] %constant.39), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1068 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1065, bf16[4]{0} %broadcast.19), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1069 = bf16[4]{0} subtract(bf16[4]{0} %p54.1063, bf16[4]{0} %multiply.1068), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p53.1053 = bf16[4]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1054 = bf16[4]{0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1055 = bf16[4]{0} multiply(bf16[4]{0} %p53.1053, bf16[4]{0} %broadcast.1054), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.41 = bf16[1]{0} constant({1})
  %compare.1028 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.41), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.42 = bf16[1]{0} constant({1})
  %select.1030 = bf16[1]{0} select(pred[1]{0} %compare.1028, bf16[1]{0} %divide.629, bf16[1]{0} %constant.42), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1032 = bf16[] reshape(bf16[1]{0} %select.1030), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1033 = bf16[4]{0} broadcast(bf16[] %reshape.1032), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1034 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.243, bf16[4]{0} %broadcast.1033), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1051 = bf16[4]{0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1052 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1034, bf16[4]{0} %broadcast.1051), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1056 = bf16[4]{0} add(bf16[4]{0} %multiply.1055, bf16[4]{0} %multiply.1052), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p52.1035 = bf16[4]{0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1036 = bf16[4]{0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1037 = bf16[4]{0} multiply(bf16[4]{0} %p52.1035, bf16[4]{0} %broadcast.1036), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1039 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1034, bf16[4]{0} %multiply.1034), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1038 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1040 = bf16[4]{0} broadcast(bf16[] %convert.1038), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1041 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1039, bf16[4]{0} %broadcast.1040), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1042 = bf16[4]{0} add(bf16[4]{0} %multiply.1037, bf16[4]{0} %multiply.1041), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1043 = bf16[4]{0} sqrt(bf16[4]{0} %add.1042), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1044 = bf16[4]{0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1045 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1043, bf16[4]{0} %broadcast.1044), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1046 = bf16[4]{0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1047 = bf16[4]{0} add(bf16[4]{0} %divide.1045, bf16[4]{0} %broadcast.1046), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1071 = bf16[4]{0} divide(bf16[4]{0} %add.1056, bf16[4]{0} %add.1047), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1070 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1072 = bf16[4]{0} broadcast(bf16[] %convert.1070), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1073 = bf16[4]{0} multiply(bf16[4]{0} %divide.1071, bf16[4]{0} %broadcast.1072), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1074 = bf16[4]{0} add(bf16[4]{0} %subtract.1069, bf16[4]{0} %multiply.1073), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1078 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1013), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1079 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.1074, bf16[] %get-tuple-element.1078), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1080 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1079), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.822 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.821), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p57.1129 = bf16[4]{0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1130 = bf16[4]{0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1131 = bf16[4]{0} multiply(bf16[4]{0} %p57.1129, bf16[4]{0} %broadcast.1130), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.44 = bf16[] constant(0)
  %broadcast.20 = bf16[4]{0} broadcast(bf16[] %constant.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1134 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1131, bf16[4]{0} %broadcast.20), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1135 = bf16[4]{0} subtract(bf16[4]{0} %p57.1129, bf16[4]{0} %multiply.1134), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p56.1119 = bf16[4]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1120 = bf16[4]{0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1121 = bf16[4]{0} multiply(bf16[4]{0} %p56.1119, bf16[4]{0} %broadcast.1120), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.46 = bf16[1]{0} constant({1})
  %compare.1094 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.46), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.47 = bf16[1]{0} constant({1})
  %select.1096 = bf16[1]{0} select(pred[1]{0} %compare.1094, bf16[1]{0} %divide.629, bf16[1]{0} %constant.47), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1098 = bf16[] reshape(bf16[1]{0} %select.1096), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1099 = bf16[4]{0} broadcast(bf16[] %reshape.1098), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1100 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.183, bf16[4]{0} %broadcast.1099), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1117 = bf16[4]{0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1118 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1100, bf16[4]{0} %broadcast.1117), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1122 = bf16[4]{0} add(bf16[4]{0} %multiply.1121, bf16[4]{0} %multiply.1118), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p55.1101 = bf16[4]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1102 = bf16[4]{0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1103 = bf16[4]{0} multiply(bf16[4]{0} %p55.1101, bf16[4]{0} %broadcast.1102), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1105 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1100, bf16[4]{0} %multiply.1100), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1104 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1106 = bf16[4]{0} broadcast(bf16[] %convert.1104), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1107 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1105, bf16[4]{0} %broadcast.1106), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1108 = bf16[4]{0} add(bf16[4]{0} %multiply.1103, bf16[4]{0} %multiply.1107), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1109 = bf16[4]{0} sqrt(bf16[4]{0} %add.1108), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1110 = bf16[4]{0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1111 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1109, bf16[4]{0} %broadcast.1110), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1112 = bf16[4]{0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1113 = bf16[4]{0} add(bf16[4]{0} %divide.1111, bf16[4]{0} %broadcast.1112), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1137 = bf16[4]{0} divide(bf16[4]{0} %add.1122, bf16[4]{0} %add.1113), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1136 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1138 = bf16[4]{0} broadcast(bf16[] %convert.1136), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1139 = bf16[4]{0} multiply(bf16[4]{0} %divide.1137, bf16[4]{0} %broadcast.1138), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1140 = bf16[4]{0} add(bf16[4]{0} %subtract.1135, bf16[4]{0} %multiply.1139), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1144 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1079), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1145 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.1140, bf16[] %get-tuple-element.1144), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1146 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1145), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.886 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.885), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p60.1195 = bf16[4]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1196 = bf16[4]{0} broadcast(bf16[] %p35.675), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1197 = bf16[4]{0} multiply(bf16[4]{0} %p60.1195, bf16[4]{0} %broadcast.1196), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.49 = bf16[] constant(0)
  %broadcast.21 = bf16[4]{0} broadcast(bf16[] %constant.49), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1200 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1197, bf16[4]{0} %broadcast.21), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1201 = bf16[4]{0} subtract(bf16[4]{0} %p60.1195, bf16[4]{0} %multiply.1200), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p59.1185 = bf16[4]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1186 = bf16[4]{0} broadcast(bf16[] %p32.664), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1187 = bf16[4]{0} multiply(bf16[4]{0} %p59.1185, bf16[4]{0} %broadcast.1186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.51 = bf16[1]{0} constant({1})
  %compare.1160 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.51), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.52 = bf16[1]{0} constant({1})
  %select.1162 = bf16[1]{0} select(pred[1]{0} %compare.1160, bf16[1]{0} %divide.629, bf16[1]{0} %constant.52), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1164 = bf16[] reshape(bf16[1]{0} %select.1162), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1165 = bf16[4]{0} broadcast(bf16[] %reshape.1164), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1166 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.123, bf16[4]{0} %broadcast.1165), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1183 = bf16[4]{0} broadcast(bf16[] %p31.658), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1184 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1166, bf16[4]{0} %broadcast.1183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1188 = bf16[4]{0} add(bf16[4]{0} %multiply.1187, bf16[4]{0} %multiply.1184), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p58.1167 = bf16[4]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1168 = bf16[4]{0} broadcast(bf16[] %p29.644), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1169 = bf16[4]{0} multiply(bf16[4]{0} %p58.1167, bf16[4]{0} %broadcast.1168), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1171 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1166, bf16[4]{0} %multiply.1166), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1170 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1172 = bf16[4]{0} broadcast(bf16[] %convert.1170), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1173 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1171, bf16[4]{0} %broadcast.1172), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1174 = bf16[4]{0} add(bf16[4]{0} %multiply.1169, bf16[4]{0} %multiply.1173), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1175 = bf16[4]{0} sqrt(bf16[4]{0} %add.1174), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1176 = bf16[4]{0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1177 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1175, bf16[4]{0} %broadcast.1176), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1178 = bf16[4]{0} broadcast(bf16[] %p2.4), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1179 = bf16[4]{0} add(bf16[4]{0} %divide.1177, bf16[4]{0} %broadcast.1178), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1203 = bf16[4]{0} divide(bf16[4]{0} %add.1188, bf16[4]{0} %add.1179), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1202 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1204 = bf16[4]{0} broadcast(bf16[] %convert.1202), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1205 = bf16[4]{0} multiply(bf16[4]{0} %divide.1203, bf16[4]{0} %broadcast.1204), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1206 = bf16[4]{0} add(bf16[4]{0} %subtract.1201, bf16[4]{0} %multiply.1205), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1210 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1145), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1211 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.1206, bf16[] %get-tuple-element.1210), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1212 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1211), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.950 = bf16[1,4]{1,0} get-tuple-element((bf16[1,4]{1,0}, bf16[]) %all-gather.949), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p63.1254 = bf16[1]{0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape.172 = bf16[1]{0} reshape(bf16[] %p35.675), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1256 = bf16[1]{0} multiply(bf16[1]{0} %p63.1254, bf16[1]{0} %reshape.172), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.53 = bf16[1]{0} constant({0})
  %multiply.1259 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1256, bf16[1]{0} %constant.53), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1260 = bf16[1]{0} subtract(bf16[1]{0} %p63.1254, bf16[1]{0} %multiply.1259), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p62.1246 = bf16[1]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.175 = bf16[1]{0} reshape(bf16[] %p32.664), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1248 = bf16[1]{0} multiply(bf16[1]{0} %p62.1246, bf16[1]{0} %reshape.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.56 = bf16[1]{0} constant({1})
  %compare.1226 = pred[1]{0} compare(bf16[1]{0} %divide.629, bf16[1]{0} %constant.56), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.57 = bf16[1]{0} constant({1})
  %select.1228 = bf16[1]{0} select(pred[1]{0} %compare.1226, bf16[1]{0} %divide.629, bf16[1]{0} %constant.57), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1229 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.63, bf16[1]{0} %select.1228), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.180 = bf16[1]{0} reshape(bf16[] %p31.658), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1245 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1229, bf16[1]{0} %reshape.180), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1249 = bf16[1]{0} add(bf16[1]{0} %multiply.1248, bf16[1]{0} %multiply.1245), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p61.1230 = bf16[1]{0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.181 = bf16[1]{0} reshape(bf16[] %p29.644), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1232 = bf16[1]{0} multiply(bf16[1]{0} %p61.1230, bf16[1]{0} %reshape.181), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1234 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1229, bf16[1]{0} %multiply.1229), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1233 = bf16[] convert(f32[] %p4.7), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.182 = bf16[1]{0} reshape(bf16[] %convert.1233), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1236 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1234, bf16[1]{0} %reshape.182), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1237 = bf16[1]{0} add(bf16[1]{0} %multiply.1232, bf16[1]{0} %multiply.1236), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1238 = bf16[1]{0} sqrt(bf16[1]{0} %add.1237), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.183 = bf16[1]{0} reshape(bf16[] %p3.6), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1240 = bf16[1]{0} divide(bf16[1]{0} %sqrt.1238, bf16[1]{0} %reshape.183), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.184 = bf16[1]{0} reshape(bf16[] %p2.4), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1242 = bf16[1]{0} add(bf16[1]{0} %divide.1240, bf16[1]{0} %reshape.184), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1262 = bf16[1]{0} divide(bf16[1]{0} %add.1249, bf16[1]{0} %add.1242), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1261 = bf16[] convert(f32[] %p1.2), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.185 = bf16[1]{0} reshape(bf16[] %convert.1261), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1264 = bf16[1]{0} multiply(bf16[1]{0} %divide.1262, bf16[1]{0} %reshape.185), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1265 = bf16[1]{0} add(bf16[1]{0} %subtract.1260, bf16[1]{0} %multiply.1264), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1269 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.1211), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1270 = (bf16[1]{0}, bf16[]) all-gather(bf16[1]{0} %add.1265, bf16[] %get-tuple-element.1269), replica_groups={{0}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1271 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-gather.1270), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  ROOT %tuple.1275 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=5*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[1]{0}, /*index=10*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[1,4]{1,0}, /*index=15*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1]{0}, /*index=20*/bf16[1]{0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, /*index=25*/bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=30*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=35*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[1,4]{1,0}, /*index=40*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=45*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1]{0}, bf16[1]{0}, /*index=50*/bf16[4,4]{1,0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %get-tuple-element.693, bf16[4]{0} %get-tuple-element.1014, bf16[4,4]{1,0} %get-tuple-element.758, bf16[4]{0} %get-tuple-element.1080, bf16[4,4]{1,0} %get-tuple-element.822, /*index=5*/bf16[4]{0} %get-tuple-element.1146, bf16[4,4]{1,0} %get-tuple-element.886, bf16[4]{0} %get-tuple-element.1212, bf16[1,4]{1,0} %get-tuple-element.950, bf16[1]{0} %get-tuple-element.1271, /*index=10*/bf16[4,4]{1,0} %add.687, bf16[4,4]{1,0} %add.752, bf16[4,4]{1,0} %add.816, bf16[4,4]{1,0} %add.880, bf16[1,4]{1,0} %add.944, /*index=15*/bf16[4]{0} %add.1008, bf16[4]{0} %add.1074, bf16[4]{0} %add.1140, bf16[4]{0} %add.1206, bf16[1]{0} %add.1265, /*index=20*/bf16[1]{0} %add.53, bf16[1,4]{1,0} %add.405, bf16[4]{0} %add.113, bf16[4,4]{1,0} %add.448, bf16[4]{0} %add.173, /*index=25*/bf16[4,4]{1,0} %add.491, bf16[4]{0} %add.233, bf16[4,4]{1,0} %add.534, bf16[4]{0} %add.293, bf16[4,4]{1,0} %add.577, /*index=30*/bf16[4,4]{1,0} %add.668, bf16[4,4]{1,0} %add.652, bf16[4,4]{1,0} %add.735, bf16[4,4]{1,0} %add.721, bf16[4,4]{1,0} %add.799, /*index=35*/bf16[4,4]{1,0} %add.785, bf16[4,4]{1,0} %add.863, bf16[4,4]{1,0} %add.849, bf16[1,4]{1,0} %add.927, bf16[1,4]{1,0} %add.913, /*index=40*/bf16[4]{0} %add.990, bf16[4]{0} %add.976, bf16[4]{0} %add.1056, bf16[4]{0} %add.1042, bf16[4]{0} %add.1122, /*index=45*/bf16[4]{0} %add.1108, bf16[4]{0} %add.1188, bf16[4]{0} %add.1174, bf16[1]{0} %add.1249, bf16[1]{0} %add.1237, /*index=50*/bf16[4,4]{1,0} %p22.368, bf16[1]{0} %power.624), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51"}
}



`

export default text;
