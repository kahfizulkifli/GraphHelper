const text = `
HloModule SyncTensorsGraph.2118, input_output_alias={ {0}: (15, {}, must-alias), {1}: (14, {}, must-alias), {2}: (10, {}, must-alias), {3}: (13, {}, must-alias), {4}: (9, {}, must-alias), {5}: (12, {}, must-alias), {6}: (8, {}, must-alias), {7}: (11, {}, must-alias), {8}: (7, {}, must-alias), {9}: (27, {}, must-alias), {40}: (25, {}, must-alias) }

%AddComputation.37 (x.38: bf16[], y.39: bf16[]) -> bf16[] {
  %x.38 = bf16[] parameter(0)
  %y.39 = bf16[] parameter(1)
  ROOT %add.40 = bf16[] add(bf16[] %x.38, bf16[] %y.39)
}

%AddComputation.76 (x.77: bf16[], y.78: bf16[]) -> bf16[] {
  %x.77 = bf16[] parameter(0)
  %y.78 = bf16[] parameter(1)
  ROOT %add.79 = bf16[] add(bf16[] %x.77, bf16[] %y.78)
}

%AddComputation.119 (x.120: bf16[], y.121: bf16[]) -> bf16[] {
  %x.120 = bf16[] parameter(0)
  %y.121 = bf16[] parameter(1)
  ROOT %add.122 = bf16[] add(bf16[] %x.120, bf16[] %y.121)
}

%AddComputation.138 (x.139: bf16[], y.140: bf16[]) -> bf16[] {
  %x.139 = bf16[] parameter(0)
  %y.140 = bf16[] parameter(1)
  ROOT %add.141 = bf16[] add(bf16[] %x.139, bf16[] %y.140)
}

%AddComputation.162 (x.163: bf16[], y.164: bf16[]) -> bf16[] {
  %x.163 = bf16[] parameter(0)
  %y.164 = bf16[] parameter(1)
  ROOT %add.165 = bf16[] add(bf16[] %x.163, bf16[] %y.164)
}

%AddComputation.181 (x.182: bf16[], y.183: bf16[]) -> bf16[] {
  %x.182 = bf16[] parameter(0)
  %y.183 = bf16[] parameter(1)
  ROOT %add.184 = bf16[] add(bf16[] %x.182, bf16[] %y.183)
}

%AddComputation.205 (x.206: bf16[], y.207: bf16[]) -> bf16[] {
  %x.206 = bf16[] parameter(0)
  %y.207 = bf16[] parameter(1)
  ROOT %add.208 = bf16[] add(bf16[] %x.206, bf16[] %y.207)
}

%AddComputation.224 (x.225: bf16[], y.226: bf16[]) -> bf16[] {
  %x.225 = bf16[] parameter(0)
  %y.226 = bf16[] parameter(1)
  ROOT %add.227 = bf16[] add(bf16[] %x.225, bf16[] %y.226)
}

%AddComputation.248 (x.249: bf16[], y.250: bf16[]) -> bf16[] {
  %x.249 = bf16[] parameter(0)
  %y.250 = bf16[] parameter(1)
  ROOT %add.251 = bf16[] add(bf16[] %x.249, bf16[] %y.250)
}

%AddComputation.267 (x.268: bf16[], y.269: bf16[]) -> bf16[] {
  %x.268 = bf16[] parameter(0)
  %y.269 = bf16[] parameter(1)
  ROOT %add.270 = bf16[] add(bf16[] %x.268, bf16[] %y.269)
}

%AddComputation.362 (x.363: bf16[], y.364: bf16[]) -> bf16[] {
  %x.363 = bf16[] parameter(0)
  %y.364 = bf16[] parameter(1)
  ROOT %add.365 = bf16[] add(bf16[] %x.363, bf16[] %y.364)
}

%AddComputation.388 (x.389: bf16[], y.390: bf16[]) -> bf16[] {
  %x.389 = bf16[] parameter(0)
  %y.390 = bf16[] parameter(1)
  ROOT %add.391 = bf16[] add(bf16[] %x.389, bf16[] %y.390)
}

%AddComputation.414 (x.415: bf16[], y.416: bf16[]) -> bf16[] {
  %x.415 = bf16[] parameter(0)
  %y.416 = bf16[] parameter(1)
  ROOT %add.417 = bf16[] add(bf16[] %x.415, bf16[] %y.416)
}

%AddComputation.440 (x.441: bf16[], y.442: bf16[]) -> bf16[] {
  %x.441 = bf16[] parameter(0)
  %y.442 = bf16[] parameter(1)
  ROOT %add.443 = bf16[] add(bf16[] %x.441, bf16[] %y.442)
}

%AddComputation.466 (x.467: bf16[], y.468: bf16[]) -> bf16[] {
  %x.467 = bf16[] parameter(0)
  %y.468 = bf16[] parameter(1)
  ROOT %add.469 = bf16[] add(bf16[] %x.467, bf16[] %y.468)
}

%AddComputation.617 (x.618: bf16[], y.619: bf16[]) -> bf16[] {
  %x.618 = bf16[] parameter(0)
  %y.619 = bf16[] parameter(1)
  ROOT %add.620 = bf16[] add(bf16[] %x.618, bf16[] %y.619)
}

%AddComputation.652 (x.653: bf16[], y.654: bf16[]) -> bf16[] {
  %x.653 = bf16[] parameter(0)
  %y.654 = bf16[] parameter(1)
  ROOT %add.655 = bf16[] add(bf16[] %x.653, bf16[] %y.654)
}

%AddComputation.743 (x.744: bf16[], y.745: bf16[]) -> bf16[] {
  %x.744 = bf16[] parameter(0)
  %y.745 = bf16[] parameter(1)
  ROOT %add.746 = bf16[] add(bf16[] %x.744, bf16[] %y.745)
}

%AddComputation.778 (x.779: bf16[], y.780: bf16[]) -> bf16[] {
  %x.779 = bf16[] parameter(0)
  %y.780 = bf16[] parameter(1)
  ROOT %add.781 = bf16[] add(bf16[] %x.779, bf16[] %y.780)
}

%AddComputation.869 (x.870: bf16[], y.871: bf16[]) -> bf16[] {
  %x.870 = bf16[] parameter(0)
  %y.871 = bf16[] parameter(1)
  ROOT %add.872 = bf16[] add(bf16[] %x.870, bf16[] %y.871)
}

%AddComputation.904 (x.905: bf16[], y.906: bf16[]) -> bf16[] {
  %x.905 = bf16[] parameter(0)
  %y.906 = bf16[] parameter(1)
  ROOT %add.907 = bf16[] add(bf16[] %x.905, bf16[] %y.906)
}

%AddComputation.995 (x.996: bf16[], y.997: bf16[]) -> bf16[] {
  %x.996 = bf16[] parameter(0)
  %y.997 = bf16[] parameter(1)
  ROOT %add.998 = bf16[] add(bf16[] %x.996, bf16[] %y.997)
}

%AddComputation.1030 (x.1031: bf16[], y.1032: bf16[]) -> bf16[] {
  %x.1031 = bf16[] parameter(0)
  %y.1032 = bf16[] parameter(1)
  ROOT %add.1033 = bf16[] add(bf16[] %x.1031, bf16[] %y.1032)
}

%AddComputation.1386 (x.1387: bf16[], y.1388: bf16[]) -> bf16[] {
  %x.1387 = bf16[] parameter(0)
  %y.1388 = bf16[] parameter(1)
  ROOT %add.1389 = bf16[] add(bf16[] %x.1387, bf16[] %y.1388)
}

%AddComputation.1419 (x.1420: bf16[], y.1421: bf16[]) -> bf16[] {
  %x.1420 = bf16[] parameter(0)
  %y.1421 = bf16[] parameter(1)
  ROOT %add.1422 = bf16[] add(bf16[] %x.1420, bf16[] %y.1421)
}

%AddComputation.1452 (x.1453: bf16[], y.1454: bf16[]) -> bf16[] {
  %x.1453 = bf16[] parameter(0)
  %y.1454 = bf16[] parameter(1)
  ROOT %add.1455 = bf16[] add(bf16[] %x.1453, bf16[] %y.1454)
}

%AddComputation.1485 (x.1486: bf16[], y.1487: bf16[]) -> bf16[] {
  %x.1486 = bf16[] parameter(0)
  %y.1487 = bf16[] parameter(1)
  ROOT %add.1488 = bf16[] add(bf16[] %x.1486, bf16[] %y.1487)
}

%AddComputation.1518 (x.1519: bf16[], y.1520: bf16[]) -> bf16[] {
  %x.1519 = bf16[] parameter(0)
  %y.1520 = bf16[] parameter(1)
  ROOT %add.1521 = bf16[] add(bf16[] %x.1519, bf16[] %y.1520)
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.2118 (p0.1: f32[], p1.3: bf16[], p2.5: bf16[], p3.6: f32[], p4.12: bf16[], p5.24: bf16[], p6.25: bf16[], p7.106: bf16[1,4], p8.149: bf16[4,4], p9.192: bf16[4,4], p10.235: bf16[4,4], p11.278: bf16[4], p12.287: bf16[4], p13.296: bf16[4], p14.305: bf16[4], p15.313: bf16[4,4], p16.322: bf16[4,4], p17.474: bf16[1], p18.535: f32[], p19.538: bf16[], p20.554: bf16[], p21.572: bf16[], p22.578: bf16[], p23.592: bf16[], p24.593: bf16[], p25.1344: bf16[4,4], p26.1526: bf16[1], p27.2094: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=5*/bf16[4], bf16[4,4], bf16[4], bf16[1,4], bf16[1], /*index=10*/bf16[1], bf16[1,4], bf16[4], bf16[4,4], bf16[4], /*index=15*/bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=20*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=25*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[1,4], bf16[1,4], /*index=30*/bf16[4], bf16[4], bf16[4], bf16[4], bf16[4], /*index=35*/bf16[4], bf16[4], bf16[4], bf16[1], bf16[1], /*index=40*/bf16[4,4], bf16[1]) {
  %p15.313 = bf16[4,4]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %p24.593 = bf16[] parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1325 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1326 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p15.313, bf16[4,4]{1,0} %broadcast.1325), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p23.592 = bf16[] parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1327 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1329 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1326, bf16[4,4]{1,0} %broadcast.1327), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1330 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p15.313, bf16[4,4]{1,0} %multiply.1329), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.3 = bf16[] constant(0)
  %p22.578 = bf16[] parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.0 = bf16[] multiply(bf16[] %constant.3, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %p6.25 = bf16[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p5.24 = bf16[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %divide.2 = bf16[] divide(bf16[] %p6.25, bf16[] %p5.24), metadata={op_type="aten__div" op_name="aten__div"}
  %broadcast.185 = bf16[1,4]{1,0} broadcast(bf16[] %divide.2), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p7.106 = bf16[1,4]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.38 = bf16[1,4]{1,0} custom-call(bf16[1,4]{1,0} %p7.106), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.68 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %broadcast.185, bf16[1,4]{1,0} %custom-call.38), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.520 = bf16[4]{0} reshape(bf16[1,4]{1,0} %multiply.68), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.12 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %reshape.520), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p8.149 = bf16[4,4]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.39 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p8.149), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.159 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %broadcast.12, bf16[4,4]{1,0} %custom-call.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p9.192 = bf16[4,4]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.40 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p9.192), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.202 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.159, bf16[4,4]{1,0} %custom-call.40), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p10.235 = bf16[4,4]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.41 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p10.235), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.245 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.202, bf16[4,4]{1,0} %custom-call.41), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p16.322 = bf16[4,4]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model_nxd.py" source_line=148}
  %transpose.451 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %p16.322), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.1 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.245, bf16[4,4]{0,1} %transpose.451), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.42 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.4 = bf16[1]{0} constant({1})
  %p17.474 = bf16[1]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.463 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.42, bf16[4,4]{1,0} %custom-call.42), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.464 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.470 = bf16[] reduce(bf16[4,4]{1,0} %multiply.463, bf16[] %constant.464), dimensions={0,1}, to_apply=%AddComputation.466, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.471 = bf16[] sqrt(bf16[] %reduce.470), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.473 = bf16[] multiply(bf16[] %sqrt.471, bf16[] %sqrt.471), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.473), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.476 = bf16[1]{0} add(bf16[1]{0} %p17.474, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %custom-call.43 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p15.313), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.321 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.43), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.323 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %p16.322, bf16[4,4]{0,1} %transpose.321), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p14.305 = bf16[4]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.44 = bf16[4]{0} custom-call(bf16[4]{0} %p14.305), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.327 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.44), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.328 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.323, bf16[4,4]{1,0} %broadcast.327), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.425 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.328), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.2 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.202, bf16[4,4]{0,1} %transpose.425), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.45 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.2), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.437 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.45, bf16[4,4]{1,0} %custom-call.45), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.438 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.444 = bf16[] reduce(bf16[4,4]{1,0} %multiply.437, bf16[] %constant.438), dimensions={0,1}, to_apply=%AddComputation.440, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.445 = bf16[] sqrt(bf16[] %reduce.444), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.447 = bf16[] multiply(bf16[] %sqrt.445, bf16[] %sqrt.445), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.17 = bf16[1]{0} reshape(bf16[] %multiply.447), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.478 = bf16[1]{0} add(bf16[1]{0} %add.476, bf16[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.304 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.41), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.329 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.328, bf16[4,4]{0,1} %transpose.304), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p13.296 = bf16[4]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.47 = bf16[4]{0} custom-call(bf16[4]{0} %p13.296), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.333 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.47), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.334 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.329, bf16[4,4]{1,0} %broadcast.333), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.399 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.334), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.3 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.159, bf16[4,4]{0,1} %transpose.399), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.48 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.3), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.411 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.48, bf16[4,4]{1,0} %custom-call.48), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.412 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.418 = bf16[] reduce(bf16[4,4]{1,0} %multiply.411, bf16[] %constant.412), dimensions={0,1}, to_apply=%AddComputation.414, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.419 = bf16[] sqrt(bf16[] %reduce.418), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.421 = bf16[] multiply(bf16[] %sqrt.419, bf16[] %sqrt.419), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.20 = bf16[1]{0} reshape(bf16[] %multiply.421), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.480 = bf16[1]{0} add(bf16[1]{0} %add.478, bf16[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.295 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.40), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.335 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.334, bf16[4,4]{0,1} %transpose.295), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p12.287 = bf16[4]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.49 = bf16[4]{0} custom-call(bf16[4]{0} %p12.287), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.339 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.49), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.340 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.335, bf16[4,4]{1,0} %broadcast.339), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.373 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.340), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.4 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %broadcast.12, bf16[4,4]{0,1} %transpose.373), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.50 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.4), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.385 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.50, bf16[4,4]{1,0} %custom-call.50), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.386 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.392 = bf16[] reduce(bf16[4,4]{1,0} %multiply.385, bf16[] %constant.386), dimensions={0,1}, to_apply=%AddComputation.388, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.393 = bf16[] sqrt(bf16[] %reduce.392), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.395 = bf16[] multiply(bf16[] %sqrt.393, bf16[] %sqrt.393), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.30 = bf16[1]{0} reshape(bf16[] %multiply.395), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.482 = bf16[1]{0} add(bf16[1]{0} %add.480, bf16[1]{0} %reshape.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.286 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.39), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.341 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.340, bf16[4,4]{0,1} %transpose.286), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p11.278 = bf16[4]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.51 = bf16[4]{0} custom-call(bf16[4]{0} %p11.278), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.345 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.51), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.346 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.341, bf16[4,4]{1,0} %broadcast.345), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.187 = bf16[4,4]{1,0} broadcast(bf16[] %divide.2), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.72 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.346, bf16[4,4]{1,0} %broadcast.187)
  %convert.4 = f32[4,4]{1,0} convert(bf16[4,4]{1,0} %multiply.72)
  %constant = f32[] constant(0)
  %reduce = f32[4]{0} reduce(f32[4,4]{1,0} %convert.4, f32[] %constant), dimensions={0}, to_apply=%scalar_add_computation
  %convert.1 = bf16[4]{0} convert(f32[4]{0} %reduce), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.36 = bf16[1,4]{0,1} reshape(bf16[4]{0} %convert.1), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.52 = bf16[1,4]{1,0} custom-call(bf16[1,4]{0,1} %reshape.36), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.359 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %custom-call.52, bf16[1,4]{1,0} %custom-call.52), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.360 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.366 = bf16[] reduce(bf16[1,4]{1,0} %multiply.359, bf16[] %constant.360), dimensions={0,1}, to_apply=%AddComputation.362, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.367 = bf16[] sqrt(bf16[] %reduce.366), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.369 = bf16[] multiply(bf16[] %sqrt.367, bf16[] %sqrt.367), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.37 = bf16[1]{0} reshape(bf16[] %multiply.369), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.484 = bf16[1]{0} add(bf16[1]{0} %add.482, bf16[1]{0} %reshape.37), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.246 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.252 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.245, bf16[] %constant.246), dimensions={0}, to_apply=%AddComputation.248, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.53 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.252), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.264 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.53, bf16[4]{0} %custom-call.53), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.265 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.271 = bf16[] reduce(bf16[4]{0} %multiply.264, bf16[] %constant.265), dimensions={0}, to_apply=%AddComputation.267, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.272 = bf16[] sqrt(bf16[] %reduce.271), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.274 = bf16[] multiply(bf16[] %sqrt.272, bf16[] %sqrt.272), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.39 = bf16[1]{0} reshape(bf16[] %multiply.274), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.486 = bf16[1]{0} add(bf16[1]{0} %add.484, bf16[1]{0} %reshape.39), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.203 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.209 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.202, bf16[] %constant.203), dimensions={0}, to_apply=%AddComputation.205, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.54 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.209), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.221 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.54, bf16[4]{0} %custom-call.54), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.222 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.228 = bf16[] reduce(bf16[4]{0} %multiply.221, bf16[] %constant.222), dimensions={0}, to_apply=%AddComputation.224, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.229 = bf16[] sqrt(bf16[] %reduce.228), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.231 = bf16[] multiply(bf16[] %sqrt.229, bf16[] %sqrt.229), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.41 = bf16[1]{0} reshape(bf16[] %multiply.231), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.488 = bf16[1]{0} add(bf16[1]{0} %add.486, bf16[1]{0} %reshape.41), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.160 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.166 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.159, bf16[] %constant.160), dimensions={0}, to_apply=%AddComputation.162, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.55 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.166), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.178 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.55, bf16[4]{0} %custom-call.55), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.179 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.185 = bf16[] reduce(bf16[4]{0} %multiply.178, bf16[] %constant.179), dimensions={0}, to_apply=%AddComputation.181, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.186 = bf16[] sqrt(bf16[] %reduce.185), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.188 = bf16[] multiply(bf16[] %sqrt.186, bf16[] %sqrt.186), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.45 = bf16[1]{0} reshape(bf16[] %multiply.188), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.490 = bf16[1]{0} add(bf16[1]{0} %add.488, bf16[1]{0} %reshape.45), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.117 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.123 = bf16[4]{0} reduce(bf16[4,4]{1,0} %broadcast.12, bf16[] %constant.117), dimensions={0}, to_apply=%AddComputation.119, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.56 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.123), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.135 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.56, bf16[4]{0} %custom-call.56), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.136 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.142 = bf16[] reduce(bf16[4]{0} %multiply.135, bf16[] %constant.136), dimensions={0}, to_apply=%AddComputation.138, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.143 = bf16[] sqrt(bf16[] %reduce.142), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.145 = bf16[] multiply(bf16[] %sqrt.143, bf16[] %sqrt.143), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.47 = bf16[1]{0} reshape(bf16[] %multiply.145), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.492 = bf16[1]{0} add(bf16[1]{0} %add.490, bf16[1]{0} %reshape.47), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %broadcast.4 = bf16[4,1]{1,0} broadcast(bf16[] %divide.2), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.74 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.80 = bf16[1]{0} reduce(bf16[4,1]{1,0} %broadcast.4, bf16[] %constant.74), dimensions={0}, to_apply=%AddComputation.76, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.57 = bf16[1]{0} custom-call(bf16[1]{0} %reduce.80), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.74 = bf16[1]{0} multiply(bf16[1]{0} %custom-call.57, bf16[1]{0} %custom-call.57), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.494 = bf16[1]{0} add(bf16[1]{0} %add.492, bf16[1]{0} %multiply.74), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.8 = bf16[1]{0} constant({0.5})
  %power.497 = bf16[1]{0} power(bf16[1]{0} %add.494, bf16[1]{0} %constant.8), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p4.12 = bf16[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.55 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.499 = bf16[1]{0} add(bf16[1]{0} %power.497, bf16[1]{0} %reshape.55), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.502 = bf16[1]{0} divide(bf16[1]{0} %constant.4, bf16[1]{0} %add.499), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.13 = bf16[1]{0} constant({1})
  %compare.1282 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.13), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.15 = bf16[1]{0} constant({1})
  %select.1284 = bf16[1]{0} select(pred[1]{0} %compare.1282, bf16[1]{0} %divide.502, bf16[1]{0} %constant.15), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1286 = bf16[] reshape(bf16[1]{0} %select.1284), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1288 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.1286), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1289 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.42, bf16[4,4]{1,0} %broadcast.1288), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p21.572 = bf16[] parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1310 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1311 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1289, bf16[4,4]{1,0} %broadcast.1310), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1319 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.2, bf16[4,4]{1,0} %multiply.1311), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.16 = bf16[] constant(0)
  %p20.554 = bf16[] parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.15 = bf16[] multiply(bf16[] %constant.16, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.17 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.15), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.1298 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1289, bf16[4,4]{1,0} %multiply.1289), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1297 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1299 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1297), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1300 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1298, bf16[4,4]{1,0} %broadcast.1299), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1301 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.17, bf16[4,4]{1,0} %multiply.1300), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1302 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.1301), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p19.538 = bf16[] parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1303 = bf16[4,4]{1,0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1304 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.1302, bf16[4,4]{1,0} %broadcast.1303), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = bf16[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1305 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1306 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.1304, bf16[4,4]{1,0} %broadcast.1305), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1332 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.1319, bf16[4,4]{1,0} %add.1306), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p18.535 = f32[] parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1331 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1333 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1331), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1334 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.1332, bf16[4,4]{1,0} %broadcast.1333), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1335 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.1330, bf16[4,4]{1,0} %multiply.1334), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1594 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1595 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1335, bf16[4,4]{1,0} %broadcast.1594), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1596 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1598 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1595, bf16[4,4]{1,0} %broadcast.1596), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1599 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %add.1335, bf16[4,4]{1,0} %multiply.1598), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1586 = bf16[4,4]{1,0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1587 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1319, bf16[4,4]{1,0} %broadcast.1586), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %divide.3 = bf16[] divide(bf16[] %p6.25, bf16[] %p5.24), metadata={op_type="aten__div" op_name="aten__div"}
  %broadcast.189 = bf16[1,4]{1,0} broadcast(bf16[] %divide.3), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.594 = bf16[1,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.595 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p7.106, bf16[1,4]{1,0} %broadcast.594), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.596 = bf16[1,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.598 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.595, bf16[1,4]{1,0} %broadcast.596), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.599 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p7.106, bf16[1,4]{1,0} %multiply.598), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.149 = bf16[] constant(0)
  %multiply.69 = bf16[] multiply(bf16[] %constant.149, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.22 = bf16[1,4]{1,0} broadcast(bf16[] %multiply.69), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.24 = bf16[1]{0} constant({1})
  %compare.546 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.24), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.25 = bf16[1]{0} constant({1})
  %select.548 = bf16[1]{0} select(pred[1]{0} %compare.546, bf16[1]{0} %divide.502, bf16[1]{0} %constant.25), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.550 = bf16[] reshape(bf16[1]{0} %select.548), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.135 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.550), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.553 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %custom-call.52, bf16[1,4]{1,0} %broadcast.135), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.576 = bf16[1,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.577 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.553, bf16[1,4]{1,0} %broadcast.576), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.586 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %broadcast.22, bf16[1,4]{1,0} %multiply.577), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.150 = bf16[] constant(0)
  %multiply.70 = bf16[] multiply(bf16[] %constant.150, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.26 = bf16[1,4]{1,0} broadcast(bf16[] %multiply.70), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.563 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.553, bf16[1,4]{1,0} %multiply.553), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.562 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.564 = bf16[1,4]{1,0} broadcast(bf16[] %convert.562), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.565 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.563, bf16[1,4]{1,0} %broadcast.564), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.566 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %broadcast.26, bf16[1,4]{1,0} %multiply.565), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.567 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.566), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.568 = bf16[1,4]{1,0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.569 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.567, bf16[1,4]{1,0} %broadcast.568), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.570 = bf16[1,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.571 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.569, bf16[1,4]{1,0} %broadcast.570), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.601 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.586, bf16[1,4]{1,0} %add.571), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.600 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.602 = bf16[1,4]{1,0} broadcast(bf16[] %convert.600), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.603 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.601, bf16[1,4]{1,0} %broadcast.602), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.604 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.599, bf16[1,4]{1,0} %multiply.603), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.58 = bf16[1,4]{1,0} custom-call(bf16[1,4]{1,0} %add.604), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.71 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %broadcast.189, bf16[1,4]{1,0} %custom-call.58), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.534 = bf16[4]{0} reshape(bf16[1,4]{1,0} %multiply.71), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.94 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %reshape.534), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.720 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.721 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p8.149, bf16[4,4]{1,0} %broadcast.720), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.722 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.724 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.721, bf16[4,4]{1,0} %broadcast.722), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.725 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p8.149, bf16[4,4]{1,0} %multiply.724), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.28 = bf16[] constant(0)
  %multiply.18 = bf16[] multiply(bf16[] %constant.28, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.31 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.18), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.30 = bf16[1]{0} constant({1})
  %compare.677 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.30), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.31 = bf16[1]{0} constant({1})
  %select.679 = bf16[1]{0} select(pred[1]{0} %compare.677, bf16[1]{0} %divide.502, bf16[1]{0} %constant.31), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.681 = bf16[] reshape(bf16[1]{0} %select.679), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.683 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.681), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.684 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.50, bf16[4,4]{1,0} %broadcast.683), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.705 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.706 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.684, bf16[4,4]{1,0} %broadcast.705), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.714 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.31, bf16[4,4]{1,0} %multiply.706), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.32 = bf16[] constant(0)
  %multiply.19 = bf16[] multiply(bf16[] %constant.32, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.37 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.19), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.693 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.684, bf16[4,4]{1,0} %multiply.684), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.692 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.694 = bf16[4,4]{1,0} broadcast(bf16[] %convert.692), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.695 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.693, bf16[4,4]{1,0} %broadcast.694), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.696 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.37, bf16[4,4]{1,0} %multiply.695), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.697 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.696), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.698 = bf16[4,4]{1,0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.699 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.697, bf16[4,4]{1,0} %broadcast.698), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.700 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.701 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.699, bf16[4,4]{1,0} %broadcast.700), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.727 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.714, bf16[4,4]{1,0} %add.701), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.726 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.728 = bf16[4,4]{1,0} broadcast(bf16[] %convert.726), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.729 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.727, bf16[4,4]{1,0} %broadcast.728), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.730 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.725, bf16[4,4]{1,0} %multiply.729), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.59 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %add.730), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.740 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %broadcast.94, bf16[4,4]{1,0} %custom-call.59), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.846 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.847 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p9.192, bf16[4,4]{1,0} %broadcast.846), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.848 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.850 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.847, bf16[4,4]{1,0} %broadcast.848), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.851 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p9.192, bf16[4,4]{1,0} %multiply.850), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.33 = bf16[] constant(0)
  %multiply.20 = bf16[] multiply(bf16[] %constant.33, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.40 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.20), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.37 = bf16[1]{0} constant({1})
  %compare.803 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.38 = bf16[1]{0} constant({1})
  %select.805 = bf16[1]{0} select(pred[1]{0} %compare.803, bf16[1]{0} %divide.502, bf16[1]{0} %constant.38), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.807 = bf16[] reshape(bf16[1]{0} %select.805), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.809 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.807), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.810 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.48, bf16[4,4]{1,0} %broadcast.809), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.831 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.832 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.810, bf16[4,4]{1,0} %broadcast.831), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.840 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.40, bf16[4,4]{1,0} %multiply.832), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.39 = bf16[] constant(0)
  %multiply.21 = bf16[] multiply(bf16[] %constant.39, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.44 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.21), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.819 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.810, bf16[4,4]{1,0} %multiply.810), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.818 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.820 = bf16[4,4]{1,0} broadcast(bf16[] %convert.818), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.821 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.819, bf16[4,4]{1,0} %broadcast.820), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.822 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.44, bf16[4,4]{1,0} %multiply.821), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.823 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.822), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.824 = bf16[4,4]{1,0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.825 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.823, bf16[4,4]{1,0} %broadcast.824), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.826 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.827 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.825, bf16[4,4]{1,0} %broadcast.826), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.853 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.840, bf16[4,4]{1,0} %add.827), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.852 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.854 = bf16[4,4]{1,0} broadcast(bf16[] %convert.852), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.855 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.853, bf16[4,4]{1,0} %broadcast.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.856 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.851, bf16[4,4]{1,0} %multiply.855), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.60 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %add.856), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.866 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.740, bf16[4,4]{1,0} %custom-call.60), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.972 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.973 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p10.235, bf16[4,4]{1,0} %broadcast.972), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.974 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.976 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.973, bf16[4,4]{1,0} %broadcast.974), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.977 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p10.235, bf16[4,4]{1,0} %multiply.976), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.40 = bf16[] constant(0)
  %multiply.22 = bf16[] multiply(bf16[] %constant.40, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.47 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.22), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.42 = bf16[1]{0} constant({1})
  %compare.929 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.42), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.43 = bf16[1]{0} constant({1})
  %select.931 = bf16[1]{0} select(pred[1]{0} %compare.929, bf16[1]{0} %divide.502, bf16[1]{0} %constant.43), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.933 = bf16[] reshape(bf16[1]{0} %select.931), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.935 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.933), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.936 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.45, bf16[4,4]{1,0} %broadcast.935), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.957 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.958 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.936, bf16[4,4]{1,0} %broadcast.957), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.966 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.47, bf16[4,4]{1,0} %multiply.958), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.44 = bf16[] constant(0)
  %multiply.23 = bf16[] multiply(bf16[] %constant.44, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.51 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.23), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.945 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.936, bf16[4,4]{1,0} %multiply.936), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.944 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.946 = bf16[4,4]{1,0} broadcast(bf16[] %convert.944), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.947 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.945, bf16[4,4]{1,0} %broadcast.946), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.948 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.51, bf16[4,4]{1,0} %multiply.947), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.949 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.948), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.950 = bf16[4,4]{1,0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.951 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.949, bf16[4,4]{1,0} %broadcast.950), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.952 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.953 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.951, bf16[4,4]{1,0} %broadcast.952), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.979 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.966, bf16[4,4]{1,0} %add.953), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.978 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.980 = bf16[4,4]{1,0} broadcast(bf16[] %convert.978), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.981 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.979, bf16[4,4]{1,0} %broadcast.980), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.982 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.977, bf16[4,4]{1,0} %multiply.981), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.61 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %add.982), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.992 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.866, bf16[4,4]{1,0} %custom-call.61), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p25.1344 = bf16[4,4]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model_nxd.py" source_line=148}
  %transpose.1501 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %p25.1344), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.7 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.992, bf16[4,4]{0,1} %transpose.1501), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.62 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.7), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1512 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1289, bf16[4,4]{1,0} %custom-call.62), metadata={op_type="aten__add" op_name="aten__add"}
  %constant.45 = bf16[1]{0} constant({1})
  %p26.1526 = bf16[1]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.1515 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1512, bf16[4,4]{1,0} %add.1512), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1516 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1522 = bf16[] reduce(bf16[4,4]{1,0} %multiply.1515, bf16[] %constant.1516), dimensions={0,1}, to_apply=%AddComputation.1518, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1523 = bf16[] sqrt(bf16[] %reduce.1522), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1525 = bf16[] multiply(bf16[] %sqrt.1523, bf16[] %sqrt.1523), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.145 = bf16[1]{0} reshape(bf16[] %multiply.1525), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1528 = bf16[1]{0} add(bf16[1]{0} %p26.1526, bf16[1]{0} %reshape.145), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %custom-call.63 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %add.1335), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.1343 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.63), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.1345 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %p25.1344, bf16[4,4]{0,1} %transpose.1343), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1255 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1256 = bf16[4]{0} multiply(bf16[4]{0} %p14.305, bf16[4]{0} %broadcast.1255), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.47 = bf16[] constant(0)
  %broadcast.52 = bf16[4]{0} broadcast(bf16[] %constant.47), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1259 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1256, bf16[4]{0} %broadcast.52), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1260 = bf16[4]{0} subtract(bf16[4]{0} %p14.305, bf16[4]{0} %multiply.1259), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.48 = bf16[] constant(0)
  %multiply.27 = bf16[] multiply(bf16[] %constant.48, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.56 = bf16[4]{0} broadcast(bf16[] %multiply.27), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.50 = bf16[1]{0} constant({1})
  %compare.1017 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.50), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.51 = bf16[1]{0} constant({1})
  %select.1019 = bf16[1]{0} select(pred[1]{0} %compare.1017, bf16[1]{0} %divide.502, bf16[1]{0} %constant.51), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1021 = bf16[] reshape(bf16[1]{0} %select.1019), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1022 = bf16[4]{0} broadcast(bf16[] %reshape.1021), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1023 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.53, bf16[4]{0} %broadcast.1022), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1239 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1240 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1023, bf16[4]{0} %broadcast.1239), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1248 = bf16[4]{0} add(bf16[4]{0} %broadcast.56, bf16[4]{0} %multiply.1240), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.53 = bf16[] constant(0)
  %multiply.29 = bf16[] multiply(bf16[] %constant.53, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.59 = bf16[4]{0} broadcast(bf16[] %multiply.29), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.1227 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1023, bf16[4]{0} %multiply.1023), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1226 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1228 = bf16[4]{0} broadcast(bf16[] %convert.1226), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1229 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1227, bf16[4]{0} %broadcast.1228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1230 = bf16[4]{0} add(bf16[4]{0} %broadcast.59, bf16[4]{0} %multiply.1229), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1231 = bf16[4]{0} sqrt(bf16[4]{0} %add.1230), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1232 = bf16[4]{0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1233 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1231, bf16[4]{0} %broadcast.1232), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1234 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1235 = bf16[4]{0} add(bf16[4]{0} %divide.1233, bf16[4]{0} %broadcast.1234), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1262 = bf16[4]{0} divide(bf16[4]{0} %add.1248, bf16[4]{0} %add.1235), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1261 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1263 = bf16[4]{0} broadcast(bf16[] %convert.1261), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1264 = bf16[4]{0} multiply(bf16[4]{0} %divide.1262, bf16[4]{0} %broadcast.1263), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1265 = bf16[4]{0} add(bf16[4]{0} %subtract.1260, bf16[4]{0} %multiply.1264), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.64 = bf16[4]{0} custom-call(bf16[4]{0} %add.1265), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1349 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.64), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.1350 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.1345, bf16[4,4]{1,0} %broadcast.1349), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.1468 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.1350), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.8 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.866, bf16[4,4]{0,1} %transpose.1468), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.65 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.8), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1479 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.936, bf16[4,4]{1,0} %custom-call.65), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1482 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1479, bf16[4,4]{1,0} %add.1479), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1483 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1489 = bf16[] reduce(bf16[4,4]{1,0} %multiply.1482, bf16[] %constant.1483), dimensions={0,1}, to_apply=%AddComputation.1485, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1490 = bf16[] sqrt(bf16[] %reduce.1489), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1492 = bf16[] multiply(bf16[] %sqrt.1490, bf16[] %sqrt.1490), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.164 = bf16[1]{0} reshape(bf16[] %multiply.1492), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1530 = bf16[1]{0} add(bf16[1]{0} %add.1528, bf16[1]{0} %reshape.164), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.1216 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.61), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.1351 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.1350, bf16[4,4]{0,1} %transpose.1216), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1198 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1199 = bf16[4]{0} multiply(bf16[4]{0} %p13.296, bf16[4]{0} %broadcast.1198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.57 = bf16[] constant(0)
  %broadcast.61 = bf16[4]{0} broadcast(bf16[] %constant.57), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1202 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1199, bf16[4]{0} %broadcast.61), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1203 = bf16[4]{0} subtract(bf16[4]{0} %p13.296, bf16[4]{0} %multiply.1202), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.59 = bf16[] constant(0)
  %multiply.33 = bf16[] multiply(bf16[] %constant.59, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.64 = bf16[4]{0} broadcast(bf16[] %multiply.33), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.66 = bf16[1]{0} constant({1})
  %compare.891 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.66), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.67 = bf16[1]{0} constant({1})
  %select.893 = bf16[1]{0} select(pred[1]{0} %compare.891, bf16[1]{0} %divide.502, bf16[1]{0} %constant.67), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.895 = bf16[] reshape(bf16[1]{0} %select.893), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.896 = bf16[4]{0} broadcast(bf16[] %reshape.895), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.897 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.54, bf16[4]{0} %broadcast.896), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1182 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1183 = bf16[4]{0} multiply(bf16[4]{0} %multiply.897, bf16[4]{0} %broadcast.1182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1191 = bf16[4]{0} add(bf16[4]{0} %broadcast.64, bf16[4]{0} %multiply.1183), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.68 = bf16[] constant(0)
  %multiply.34 = bf16[] multiply(bf16[] %constant.68, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.68 = bf16[4]{0} broadcast(bf16[] %multiply.34), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.1170 = bf16[4]{0} multiply(bf16[4]{0} %multiply.897, bf16[4]{0} %multiply.897), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1169 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1171 = bf16[4]{0} broadcast(bf16[] %convert.1169), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1172 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1170, bf16[4]{0} %broadcast.1171), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1173 = bf16[4]{0} add(bf16[4]{0} %broadcast.68, bf16[4]{0} %multiply.1172), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1174 = bf16[4]{0} sqrt(bf16[4]{0} %add.1173), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1175 = bf16[4]{0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1176 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1174, bf16[4]{0} %broadcast.1175), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1177 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1178 = bf16[4]{0} add(bf16[4]{0} %divide.1176, bf16[4]{0} %broadcast.1177), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1205 = bf16[4]{0} divide(bf16[4]{0} %add.1191, bf16[4]{0} %add.1178), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1204 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1206 = bf16[4]{0} broadcast(bf16[] %convert.1204), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1207 = bf16[4]{0} multiply(bf16[4]{0} %divide.1205, bf16[4]{0} %broadcast.1206), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1208 = bf16[4]{0} add(bf16[4]{0} %subtract.1203, bf16[4]{0} %multiply.1207), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.66 = bf16[4]{0} custom-call(bf16[4]{0} %add.1208), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1355 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.66), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.1356 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.1351, bf16[4,4]{1,0} %broadcast.1355), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.1435 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.1356), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.9 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.740, bf16[4,4]{0,1} %transpose.1435), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.67 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.9), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1446 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.810, bf16[4,4]{1,0} %custom-call.67), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1449 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1446, bf16[4,4]{1,0} %add.1446), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1450 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1456 = bf16[] reduce(bf16[4,4]{1,0} %multiply.1449, bf16[] %constant.1450), dimensions={0,1}, to_apply=%AddComputation.1452, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1457 = bf16[] sqrt(bf16[] %reduce.1456), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1459 = bf16[] multiply(bf16[] %sqrt.1457, bf16[] %sqrt.1457), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.185 = bf16[1]{0} reshape(bf16[] %multiply.1459), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1532 = bf16[1]{0} add(bf16[1]{0} %add.1530, bf16[1]{0} %reshape.185), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.1159 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.60), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.1357 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.1356, bf16[4,4]{0,1} %transpose.1159), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1141 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1142 = bf16[4]{0} multiply(bf16[4]{0} %p12.287, bf16[4]{0} %broadcast.1141), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.70 = bf16[] constant(0)
  %broadcast.70 = bf16[4]{0} broadcast(bf16[] %constant.70), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1145 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1142, bf16[4]{0} %broadcast.70), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1146 = bf16[4]{0} subtract(bf16[4]{0} %p12.287, bf16[4]{0} %multiply.1145), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.71 = bf16[] constant(0)
  %multiply.38 = bf16[] multiply(bf16[] %constant.71, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.75 = bf16[4]{0} broadcast(bf16[] %multiply.38), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.73 = bf16[1]{0} constant({1})
  %compare.765 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.73), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.76 = bf16[1]{0} constant({1})
  %select.767 = bf16[1]{0} select(pred[1]{0} %compare.765, bf16[1]{0} %divide.502, bf16[1]{0} %constant.76), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.769 = bf16[] reshape(bf16[1]{0} %select.767), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.770 = bf16[4]{0} broadcast(bf16[] %reshape.769), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.771 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.55, bf16[4]{0} %broadcast.770), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1125 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1126 = bf16[4]{0} multiply(bf16[4]{0} %multiply.771, bf16[4]{0} %broadcast.1125), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1134 = bf16[4]{0} add(bf16[4]{0} %broadcast.75, bf16[4]{0} %multiply.1126), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.77 = bf16[] constant(0)
  %multiply.39 = bf16[] multiply(bf16[] %constant.77, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.78 = bf16[4]{0} broadcast(bf16[] %multiply.39), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.1113 = bf16[4]{0} multiply(bf16[4]{0} %multiply.771, bf16[4]{0} %multiply.771), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1112 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1114 = bf16[4]{0} broadcast(bf16[] %convert.1112), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1115 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1113, bf16[4]{0} %broadcast.1114), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1116 = bf16[4]{0} add(bf16[4]{0} %broadcast.78, bf16[4]{0} %multiply.1115), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1117 = bf16[4]{0} sqrt(bf16[4]{0} %add.1116), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1118 = bf16[4]{0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1119 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1117, bf16[4]{0} %broadcast.1118), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1120 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1121 = bf16[4]{0} add(bf16[4]{0} %divide.1119, bf16[4]{0} %broadcast.1120), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1148 = bf16[4]{0} divide(bf16[4]{0} %add.1134, bf16[4]{0} %add.1121), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1147 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1149 = bf16[4]{0} broadcast(bf16[] %convert.1147), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1150 = bf16[4]{0} multiply(bf16[4]{0} %divide.1148, bf16[4]{0} %broadcast.1149), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1151 = bf16[4]{0} add(bf16[4]{0} %subtract.1146, bf16[4]{0} %multiply.1150), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.68 = bf16[4]{0} custom-call(bf16[4]{0} %add.1151), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1361 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.68), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.1362 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.1357, bf16[4,4]{1,0} %broadcast.1361), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.1402 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.1362), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.10 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %broadcast.94, bf16[4,4]{0,1} %transpose.1402), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.69 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.10), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1413 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.684, bf16[4,4]{1,0} %custom-call.69), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1416 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1413, bf16[4,4]{1,0} %add.1413), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1417 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1423 = bf16[] reduce(bf16[4,4]{1,0} %multiply.1416, bf16[] %constant.1417), dimensions={0,1}, to_apply=%AddComputation.1419, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1424 = bf16[] sqrt(bf16[] %reduce.1423), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1426 = bf16[] multiply(bf16[] %sqrt.1424, bf16[] %sqrt.1424), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.209 = bf16[1]{0} reshape(bf16[] %multiply.1426), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1534 = bf16[1]{0} add(bf16[1]{0} %add.1532, bf16[1]{0} %reshape.209), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.1102 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.59), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.1363 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.1362, bf16[4,4]{0,1} %transpose.1102), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1084 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1085 = bf16[4]{0} multiply(bf16[4]{0} %p11.278, bf16[4]{0} %broadcast.1084), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.79 = bf16[] constant(0)
  %broadcast.83 = bf16[4]{0} broadcast(bf16[] %constant.79), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1088 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1085, bf16[4]{0} %broadcast.83), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1089 = bf16[4]{0} subtract(bf16[4]{0} %p11.278, bf16[4]{0} %multiply.1088), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.80 = bf16[] constant(0)
  %multiply.44 = bf16[] multiply(bf16[] %constant.80, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.86 = bf16[4]{0} broadcast(bf16[] %multiply.44), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.82 = bf16[1]{0} constant({1})
  %compare.639 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.82), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.83 = bf16[1]{0} constant({1})
  %select.641 = bf16[1]{0} select(pred[1]{0} %compare.639, bf16[1]{0} %divide.502, bf16[1]{0} %constant.83), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.643 = bf16[] reshape(bf16[1]{0} %select.641), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.644 = bf16[4]{0} broadcast(bf16[] %reshape.643), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.645 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.56, bf16[4]{0} %broadcast.644), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1068 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1069 = bf16[4]{0} multiply(bf16[4]{0} %multiply.645, bf16[4]{0} %broadcast.1068), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1077 = bf16[4]{0} add(bf16[4]{0} %broadcast.86, bf16[4]{0} %multiply.1069), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.84 = bf16[] constant(0)
  %multiply.45 = bf16[] multiply(bf16[] %constant.84, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.89 = bf16[4]{0} broadcast(bf16[] %multiply.45), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.1056 = bf16[4]{0} multiply(bf16[4]{0} %multiply.645, bf16[4]{0} %multiply.645), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1055 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1057 = bf16[4]{0} broadcast(bf16[] %convert.1055), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1058 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1056, bf16[4]{0} %broadcast.1057), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1059 = bf16[4]{0} add(bf16[4]{0} %broadcast.89, bf16[4]{0} %multiply.1058), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1060 = bf16[4]{0} sqrt(bf16[4]{0} %add.1059), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1061 = bf16[4]{0} broadcast(bf16[] %p19.538), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1062 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1060, bf16[4]{0} %broadcast.1061), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1063 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1064 = bf16[4]{0} add(bf16[4]{0} %divide.1062, bf16[4]{0} %broadcast.1063), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1091 = bf16[4]{0} divide(bf16[4]{0} %add.1077, bf16[4]{0} %add.1064), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1090 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1092 = bf16[4]{0} broadcast(bf16[] %convert.1090), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1093 = bf16[4]{0} multiply(bf16[4]{0} %divide.1091, bf16[4]{0} %broadcast.1092), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1094 = bf16[4]{0} add(bf16[4]{0} %subtract.1089, bf16[4]{0} %multiply.1093), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %custom-call.70 = bf16[4]{0} custom-call(bf16[4]{0} %add.1094), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.1367 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.70), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.1368 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.1363, bf16[4,4]{1,0} %broadcast.1367), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.193 = bf16[4,4]{1,0} broadcast(bf16[] %divide.3), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.73 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1368, bf16[4,4]{1,0} %broadcast.193)
  %convert.5 = f32[4,4]{1,0} convert(bf16[4,4]{1,0} %multiply.73)
  %constant.1 = f32[] constant(0)
  %reduce.1 = f32[4]{0} reduce(f32[4,4]{1,0} %convert.5, f32[] %constant.1), dimensions={0}, to_apply=%scalar_add_computation
  %convert.3 = bf16[4]{0} convert(f32[4]{0} %reduce.1), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.230 = bf16[1,4]{0,1} reshape(bf16[4]{0} %convert.3), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.71 = bf16[1,4]{1,0} custom-call(bf16[1,4]{0,1} %reshape.230), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1380 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.553, bf16[1,4]{1,0} %custom-call.71), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1383 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.1380, bf16[1,4]{1,0} %add.1380), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1384 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1390 = bf16[] reduce(bf16[1,4]{1,0} %multiply.1383, bf16[] %constant.1384), dimensions={0,1}, to_apply=%AddComputation.1386, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1391 = bf16[] sqrt(bf16[] %reduce.1390), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1393 = bf16[] multiply(bf16[] %sqrt.1391, bf16[] %sqrt.1391), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.234 = bf16[1]{0} reshape(bf16[] %multiply.1393), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1536 = bf16[1]{0} add(bf16[1]{0} %add.1534, bf16[1]{0} %reshape.234), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.993 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.999 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.992, bf16[] %constant.993), dimensions={0}, to_apply=%AddComputation.995, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.72 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.999), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1024 = bf16[4]{0} add(bf16[4]{0} %multiply.1023, bf16[4]{0} %custom-call.72), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.1027 = bf16[4]{0} multiply(bf16[4]{0} %add.1024, bf16[4]{0} %add.1024), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.1028 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.1034 = bf16[] reduce(bf16[4]{0} %multiply.1027, bf16[] %constant.1028), dimensions={0}, to_apply=%AddComputation.1030, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.1035 = bf16[] sqrt(bf16[] %reduce.1034), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.1037 = bf16[] multiply(bf16[] %sqrt.1035, bf16[] %sqrt.1035), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.238 = bf16[1]{0} reshape(bf16[] %multiply.1037), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1538 = bf16[1]{0} add(bf16[1]{0} %add.1536, bf16[1]{0} %reshape.238), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.867 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.873 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.866, bf16[] %constant.867), dimensions={0}, to_apply=%AddComputation.869, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.73 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.873), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.898 = bf16[4]{0} add(bf16[4]{0} %multiply.897, bf16[4]{0} %custom-call.73), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.901 = bf16[4]{0} multiply(bf16[4]{0} %add.898, bf16[4]{0} %add.898), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.902 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.908 = bf16[] reduce(bf16[4]{0} %multiply.901, bf16[] %constant.902), dimensions={0}, to_apply=%AddComputation.904, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.909 = bf16[] sqrt(bf16[] %reduce.908), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.911 = bf16[] multiply(bf16[] %sqrt.909, bf16[] %sqrt.909), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.242 = bf16[1]{0} reshape(bf16[] %multiply.911), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1540 = bf16[1]{0} add(bf16[1]{0} %add.1538, bf16[1]{0} %reshape.242), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.741 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.747 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.740, bf16[] %constant.741), dimensions={0}, to_apply=%AddComputation.743, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.74 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.747), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.772 = bf16[4]{0} add(bf16[4]{0} %multiply.771, bf16[4]{0} %custom-call.74), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.775 = bf16[4]{0} multiply(bf16[4]{0} %add.772, bf16[4]{0} %add.772), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.776 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.782 = bf16[] reduce(bf16[4]{0} %multiply.775, bf16[] %constant.776), dimensions={0}, to_apply=%AddComputation.778, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.783 = bf16[] sqrt(bf16[] %reduce.782), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.785 = bf16[] multiply(bf16[] %sqrt.783, bf16[] %sqrt.783), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.246 = bf16[1]{0} reshape(bf16[] %multiply.785), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1542 = bf16[1]{0} add(bf16[1]{0} %add.1540, bf16[1]{0} %reshape.246), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.615 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.621 = bf16[4]{0} reduce(bf16[4,4]{1,0} %broadcast.94, bf16[] %constant.615), dimensions={0}, to_apply=%AddComputation.617, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.75 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.621), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.646 = bf16[4]{0} add(bf16[4]{0} %multiply.645, bf16[4]{0} %custom-call.75), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.649 = bf16[4]{0} multiply(bf16[4]{0} %add.646, bf16[4]{0} %add.646), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.650 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.656 = bf16[] reduce(bf16[4]{0} %multiply.649, bf16[] %constant.650), dimensions={0}, to_apply=%AddComputation.652, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.657 = bf16[] sqrt(bf16[] %reduce.656), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.659 = bf16[] multiply(bf16[] %sqrt.657, bf16[] %sqrt.657), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.250 = bf16[1]{0} reshape(bf16[] %multiply.659), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.1544 = bf16[1]{0} add(bf16[1]{0} %add.1542, bf16[1]{0} %reshape.250), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.86 = bf16[1]{0} constant({1})
  %compare.509 = pred[1]{0} compare(bf16[1]{0} %divide.502, bf16[1]{0} %constant.86), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.87 = bf16[1]{0} constant({1})
  %select.511 = bf16[1]{0} select(pred[1]{0} %compare.509, bf16[1]{0} %divide.502, bf16[1]{0} %constant.87), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.512 = bf16[1]{0} multiply(bf16[1]{0} %custom-call.57, bf16[1]{0} %select.511), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.19 = bf16[4,1]{1,0} broadcast(bf16[] %divide.3), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.35 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.41 = bf16[1]{0} reduce(bf16[4,1]{1,0} %broadcast.19, bf16[] %constant.35), dimensions={0}, to_apply=%AddComputation.37, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.76 = bf16[1]{0} custom-call(bf16[1]{0} %reduce.41), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.513 = bf16[1]{0} add(bf16[1]{0} %multiply.512, bf16[1]{0} %custom-call.76), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.75 = bf16[1]{0} multiply(bf16[1]{0} %add.513, bf16[1]{0} %add.513), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.1546 = bf16[1]{0} add(bf16[1]{0} %add.1544, bf16[1]{0} %multiply.75), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.91 = bf16[1]{0} constant({0.5})
  %power.1549 = bf16[1]{0} power(bf16[1]{0} %add.1546, bf16[1]{0} %constant.91), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %reshape.264 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.1551 = bf16[1]{0} add(bf16[1]{0} %power.1549, bf16[1]{0} %reshape.264), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.1554 = bf16[1]{0} divide(bf16[1]{0} %constant.45, bf16[1]{0} %add.1551), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.96 = bf16[1]{0} constant({1})
  %compare.1561 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.96), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.97 = bf16[1]{0} constant({1})
  %select.1563 = bf16[1]{0} select(pred[1]{0} %compare.1561, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.97), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1565 = bf16[] reshape(bf16[1]{0} %select.1563), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1567 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.1565), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1568 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1512, bf16[4,4]{1,0} %broadcast.1567), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1584 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1585 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1568, bf16[4,4]{1,0} %broadcast.1584), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1588 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1587, bf16[4,4]{1,0} %multiply.1585), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1569 = bf16[4,4]{1,0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1570 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1301, bf16[4,4]{1,0} %broadcast.1569), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1572 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1568, bf16[4,4]{1,0} %multiply.1568), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1571 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1573 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1571), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1574 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1572, bf16[4,4]{1,0} %broadcast.1573), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1575 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1570, bf16[4,4]{1,0} %multiply.1574), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1576 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.1575), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1577 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1578 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.1576, bf16[4,4]{1,0} %broadcast.1577), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1579 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1580 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.1578, bf16[4,4]{1,0} %broadcast.1579), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1601 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.1588, bf16[4,4]{1,0} %add.1580), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1600 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1602 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1600), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1603 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.1601, bf16[4,4]{1,0} %broadcast.1602), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1604 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.1599, bf16[4,4]{1,0} %multiply.1603), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1647 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1648 = bf16[4]{0} multiply(bf16[4]{0} %add.1265, bf16[4]{0} %broadcast.1647), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.99 = bf16[] constant(0)
  %broadcast.96 = bf16[4]{0} broadcast(bf16[] %constant.99), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1651 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1648, bf16[4]{0} %broadcast.96), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1652 = bf16[4]{0} subtract(bf16[4]{0} %add.1265, bf16[4]{0} %multiply.1651), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1638 = bf16[4]{0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1639 = bf16[4]{0} multiply(bf16[4]{0} %add.1248, bf16[4]{0} %broadcast.1638), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.101 = bf16[1]{0} constant({1})
  %compare.1614 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.101), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.102 = bf16[1]{0} constant({1})
  %select.1616 = bf16[1]{0} select(pred[1]{0} %compare.1614, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.102), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1618 = bf16[] reshape(bf16[1]{0} %select.1616), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1619 = bf16[4]{0} broadcast(bf16[] %reshape.1618), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1620 = bf16[4]{0} multiply(bf16[4]{0} %add.1024, bf16[4]{0} %broadcast.1619), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1636 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1637 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1620, bf16[4]{0} %broadcast.1636), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1640 = bf16[4]{0} add(bf16[4]{0} %multiply.1639, bf16[4]{0} %multiply.1637), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1621 = bf16[4]{0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1622 = bf16[4]{0} multiply(bf16[4]{0} %add.1230, bf16[4]{0} %broadcast.1621), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1624 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1620, bf16[4]{0} %multiply.1620), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1623 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1625 = bf16[4]{0} broadcast(bf16[] %convert.1623), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1626 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1624, bf16[4]{0} %broadcast.1625), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1627 = bf16[4]{0} add(bf16[4]{0} %multiply.1622, bf16[4]{0} %multiply.1626), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1628 = bf16[4]{0} sqrt(bf16[4]{0} %add.1627), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1629 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1630 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1628, bf16[4]{0} %broadcast.1629), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1631 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1632 = bf16[4]{0} add(bf16[4]{0} %divide.1630, bf16[4]{0} %broadcast.1631), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1654 = bf16[4]{0} divide(bf16[4]{0} %add.1640, bf16[4]{0} %add.1632), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1653 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1655 = bf16[4]{0} broadcast(bf16[] %convert.1653), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1656 = bf16[4]{0} multiply(bf16[4]{0} %divide.1654, bf16[4]{0} %broadcast.1655), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1657 = bf16[4]{0} add(bf16[4]{0} %subtract.1652, bf16[4]{0} %multiply.1656), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1700 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1701 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.982, bf16[4,4]{1,0} %broadcast.1700), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1702 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1704 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1701, bf16[4,4]{1,0} %broadcast.1702), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1705 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %add.982, bf16[4,4]{1,0} %multiply.1704), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1692 = bf16[4,4]{1,0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1693 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.966, bf16[4,4]{1,0} %broadcast.1692), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.107 = bf16[1]{0} constant({1})
  %compare.1667 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.107), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.108 = bf16[1]{0} constant({1})
  %select.1669 = bf16[1]{0} select(pred[1]{0} %compare.1667, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.108), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1671 = bf16[] reshape(bf16[1]{0} %select.1669), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1673 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.1671), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1674 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1479, bf16[4,4]{1,0} %broadcast.1673), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1690 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1691 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1674, bf16[4,4]{1,0} %broadcast.1690), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1694 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1693, bf16[4,4]{1,0} %multiply.1691), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1675 = bf16[4,4]{1,0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1676 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.948, bf16[4,4]{1,0} %broadcast.1675), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1678 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1674, bf16[4,4]{1,0} %multiply.1674), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1677 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1679 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1677), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1680 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1678, bf16[4,4]{1,0} %broadcast.1679), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1681 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1676, bf16[4,4]{1,0} %multiply.1680), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1682 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.1681), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1683 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1684 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.1682, bf16[4,4]{1,0} %broadcast.1683), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1685 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1686 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.1684, bf16[4,4]{1,0} %broadcast.1685), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1707 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.1694, bf16[4,4]{1,0} %add.1686), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1706 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1708 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1706), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1709 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.1707, bf16[4,4]{1,0} %broadcast.1708), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1710 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.1705, bf16[4,4]{1,0} %multiply.1709), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1753 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1754 = bf16[4]{0} multiply(bf16[4]{0} %add.1208, bf16[4]{0} %broadcast.1753), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.110 = bf16[] constant(0)
  %broadcast.98 = bf16[4]{0} broadcast(bf16[] %constant.110), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1757 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1754, bf16[4]{0} %broadcast.98), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1758 = bf16[4]{0} subtract(bf16[4]{0} %add.1208, bf16[4]{0} %multiply.1757), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1744 = bf16[4]{0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1745 = bf16[4]{0} multiply(bf16[4]{0} %add.1191, bf16[4]{0} %broadcast.1744), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.112 = bf16[1]{0} constant({1})
  %compare.1720 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.112), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.113 = bf16[1]{0} constant({1})
  %select.1722 = bf16[1]{0} select(pred[1]{0} %compare.1720, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.113), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1724 = bf16[] reshape(bf16[1]{0} %select.1722), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1725 = bf16[4]{0} broadcast(bf16[] %reshape.1724), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1726 = bf16[4]{0} multiply(bf16[4]{0} %add.898, bf16[4]{0} %broadcast.1725), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1742 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1743 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1726, bf16[4]{0} %broadcast.1742), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1746 = bf16[4]{0} add(bf16[4]{0} %multiply.1745, bf16[4]{0} %multiply.1743), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1727 = bf16[4]{0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1728 = bf16[4]{0} multiply(bf16[4]{0} %add.1173, bf16[4]{0} %broadcast.1727), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1730 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1726, bf16[4]{0} %multiply.1726), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1729 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1731 = bf16[4]{0} broadcast(bf16[] %convert.1729), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1732 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1730, bf16[4]{0} %broadcast.1731), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1733 = bf16[4]{0} add(bf16[4]{0} %multiply.1728, bf16[4]{0} %multiply.1732), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1734 = bf16[4]{0} sqrt(bf16[4]{0} %add.1733), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1735 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1736 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1734, bf16[4]{0} %broadcast.1735), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1737 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1738 = bf16[4]{0} add(bf16[4]{0} %divide.1736, bf16[4]{0} %broadcast.1737), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1760 = bf16[4]{0} divide(bf16[4]{0} %add.1746, bf16[4]{0} %add.1738), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1759 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1761 = bf16[4]{0} broadcast(bf16[] %convert.1759), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1762 = bf16[4]{0} multiply(bf16[4]{0} %divide.1760, bf16[4]{0} %broadcast.1761), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1763 = bf16[4]{0} add(bf16[4]{0} %subtract.1758, bf16[4]{0} %multiply.1762), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1806 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1807 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.856, bf16[4,4]{1,0} %broadcast.1806), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1808 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1810 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1807, bf16[4,4]{1,0} %broadcast.1808), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1811 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %add.856, bf16[4,4]{1,0} %multiply.1810), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1798 = bf16[4,4]{1,0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1799 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.840, bf16[4,4]{1,0} %broadcast.1798), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.115 = bf16[1]{0} constant({1})
  %compare.1773 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.115), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.116 = bf16[1]{0} constant({1})
  %select.1775 = bf16[1]{0} select(pred[1]{0} %compare.1773, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.116), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1777 = bf16[] reshape(bf16[1]{0} %select.1775), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1779 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.1777), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1780 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1446, bf16[4,4]{1,0} %broadcast.1779), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1796 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1797 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1780, bf16[4,4]{1,0} %broadcast.1796), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1800 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1799, bf16[4,4]{1,0} %multiply.1797), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1781 = bf16[4,4]{1,0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1782 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.822, bf16[4,4]{1,0} %broadcast.1781), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1784 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1780, bf16[4,4]{1,0} %multiply.1780), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1783 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1785 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1783), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1786 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1784, bf16[4,4]{1,0} %broadcast.1785), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1787 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1782, bf16[4,4]{1,0} %multiply.1786), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1788 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.1787), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1789 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1790 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.1788, bf16[4,4]{1,0} %broadcast.1789), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1791 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1792 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.1790, bf16[4,4]{1,0} %broadcast.1791), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1813 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.1800, bf16[4,4]{1,0} %add.1792), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1812 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1814 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1812), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1815 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.1813, bf16[4,4]{1,0} %broadcast.1814), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1816 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.1811, bf16[4,4]{1,0} %multiply.1815), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1859 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1860 = bf16[4]{0} multiply(bf16[4]{0} %add.1151, bf16[4]{0} %broadcast.1859), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.120 = bf16[] constant(0)
  %broadcast.100 = bf16[4]{0} broadcast(bf16[] %constant.120), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1863 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1860, bf16[4]{0} %broadcast.100), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1864 = bf16[4]{0} subtract(bf16[4]{0} %add.1151, bf16[4]{0} %multiply.1863), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1850 = bf16[4]{0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1851 = bf16[4]{0} multiply(bf16[4]{0} %add.1134, bf16[4]{0} %broadcast.1850), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.122 = bf16[1]{0} constant({1})
  %compare.1826 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.122), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.123 = bf16[1]{0} constant({1})
  %select.1828 = bf16[1]{0} select(pred[1]{0} %compare.1826, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.123), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1830 = bf16[] reshape(bf16[1]{0} %select.1828), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1831 = bf16[4]{0} broadcast(bf16[] %reshape.1830), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1832 = bf16[4]{0} multiply(bf16[4]{0} %add.772, bf16[4]{0} %broadcast.1831), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1848 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1849 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1832, bf16[4]{0} %broadcast.1848), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1852 = bf16[4]{0} add(bf16[4]{0} %multiply.1851, bf16[4]{0} %multiply.1849), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1833 = bf16[4]{0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1834 = bf16[4]{0} multiply(bf16[4]{0} %add.1116, bf16[4]{0} %broadcast.1833), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1836 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1832, bf16[4]{0} %multiply.1832), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1835 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1837 = bf16[4]{0} broadcast(bf16[] %convert.1835), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1838 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1836, bf16[4]{0} %broadcast.1837), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1839 = bf16[4]{0} add(bf16[4]{0} %multiply.1834, bf16[4]{0} %multiply.1838), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1840 = bf16[4]{0} sqrt(bf16[4]{0} %add.1839), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1841 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1842 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1840, bf16[4]{0} %broadcast.1841), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1843 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1844 = bf16[4]{0} add(bf16[4]{0} %divide.1842, bf16[4]{0} %broadcast.1843), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1866 = bf16[4]{0} divide(bf16[4]{0} %add.1852, bf16[4]{0} %add.1844), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1865 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1867 = bf16[4]{0} broadcast(bf16[] %convert.1865), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1868 = bf16[4]{0} multiply(bf16[4]{0} %divide.1866, bf16[4]{0} %broadcast.1867), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1869 = bf16[4]{0} add(bf16[4]{0} %subtract.1864, bf16[4]{0} %multiply.1868), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1912 = bf16[4,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1913 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.730, bf16[4,4]{1,0} %broadcast.1912), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1914 = bf16[4,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1916 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1913, bf16[4,4]{1,0} %broadcast.1914), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1917 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %add.730, bf16[4,4]{1,0} %multiply.1916), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1904 = bf16[4,4]{1,0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1905 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.714, bf16[4,4]{1,0} %broadcast.1904), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.125 = bf16[1]{0} constant({1})
  %compare.1879 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.125), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.126 = bf16[1]{0} constant({1})
  %select.1881 = bf16[1]{0} select(pred[1]{0} %compare.1879, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.126), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1883 = bf16[] reshape(bf16[1]{0} %select.1881), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1885 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.1883), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1886 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.1413, bf16[4,4]{1,0} %broadcast.1885), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1902 = bf16[4,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1903 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1886, bf16[4,4]{1,0} %broadcast.1902), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1906 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1905, bf16[4,4]{1,0} %multiply.1903), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1887 = bf16[4,4]{1,0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1888 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.696, bf16[4,4]{1,0} %broadcast.1887), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1890 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1886, bf16[4,4]{1,0} %multiply.1886), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1889 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1891 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1889), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1892 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.1890, bf16[4,4]{1,0} %broadcast.1891), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1893 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.1888, bf16[4,4]{1,0} %multiply.1892), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1894 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.1893), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1895 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1896 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.1894, bf16[4,4]{1,0} %broadcast.1895), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1897 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1898 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.1896, bf16[4,4]{1,0} %broadcast.1897), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1919 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.1906, bf16[4,4]{1,0} %add.1898), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1918 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1920 = bf16[4,4]{1,0} broadcast(bf16[] %convert.1918), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1921 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.1919, bf16[4,4]{1,0} %broadcast.1920), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1922 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.1917, bf16[4,4]{1,0} %multiply.1921), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1965 = bf16[4]{0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1966 = bf16[4]{0} multiply(bf16[4]{0} %add.1094, bf16[4]{0} %broadcast.1965), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.128 = bf16[] constant(0)
  %broadcast.102 = bf16[4]{0} broadcast(bf16[] %constant.128), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1969 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1966, bf16[4]{0} %broadcast.102), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1970 = bf16[4]{0} subtract(bf16[4]{0} %add.1094, bf16[4]{0} %multiply.1969), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1956 = bf16[4]{0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1957 = bf16[4]{0} multiply(bf16[4]{0} %add.1077, bf16[4]{0} %broadcast.1956), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.130 = bf16[1]{0} constant({1})
  %compare.1932 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.130), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.131 = bf16[1]{0} constant({1})
  %select.1934 = bf16[1]{0} select(pred[1]{0} %compare.1932, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.131), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1936 = bf16[] reshape(bf16[1]{0} %select.1934), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1937 = bf16[4]{0} broadcast(bf16[] %reshape.1936), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1938 = bf16[4]{0} multiply(bf16[4]{0} %add.646, bf16[4]{0} %broadcast.1937), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1954 = bf16[4]{0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1955 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1938, bf16[4]{0} %broadcast.1954), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1958 = bf16[4]{0} add(bf16[4]{0} %multiply.1957, bf16[4]{0} %multiply.1955), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1939 = bf16[4]{0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1940 = bf16[4]{0} multiply(bf16[4]{0} %add.1059, bf16[4]{0} %broadcast.1939), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1942 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1938, bf16[4]{0} %multiply.1938), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1941 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1943 = bf16[4]{0} broadcast(bf16[] %convert.1941), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1944 = bf16[4]{0} multiply(bf16[4]{0} %multiply.1942, bf16[4]{0} %broadcast.1943), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1945 = bf16[4]{0} add(bf16[4]{0} %multiply.1940, bf16[4]{0} %multiply.1944), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1946 = bf16[4]{0} sqrt(bf16[4]{0} %add.1945), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1947 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1948 = bf16[4]{0} divide(bf16[4]{0} %sqrt.1946, bf16[4]{0} %broadcast.1947), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1949 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1950 = bf16[4]{0} add(bf16[4]{0} %divide.1948, bf16[4]{0} %broadcast.1949), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1972 = bf16[4]{0} divide(bf16[4]{0} %add.1958, bf16[4]{0} %add.1950), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1971 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1973 = bf16[4]{0} broadcast(bf16[] %convert.1971), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1974 = bf16[4]{0} multiply(bf16[4]{0} %divide.1972, bf16[4]{0} %broadcast.1973), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1975 = bf16[4]{0} add(bf16[4]{0} %subtract.1970, bf16[4]{0} %multiply.1974), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2018 = bf16[1,4]{1,0} broadcast(bf16[] %p24.593), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2019 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.604, bf16[1,4]{1,0} %broadcast.2018), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2020 = bf16[1,4]{1,0} broadcast(bf16[] %p23.592), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2022 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.2019, bf16[1,4]{1,0} %broadcast.2020), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2023 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %add.604, bf16[1,4]{1,0} %multiply.2022), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2010 = bf16[1,4]{1,0} broadcast(bf16[] %p22.578), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2011 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.586, bf16[1,4]{1,0} %broadcast.2010), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.133 = bf16[1]{0} constant({1})
  %compare.1985 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.133), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.134 = bf16[1]{0} constant({1})
  %select.1987 = bf16[1]{0} select(pred[1]{0} %compare.1985, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.134), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1989 = bf16[] reshape(bf16[1]{0} %select.1987), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.181 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.1989), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1992 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.1380, bf16[1,4]{1,0} %broadcast.181), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2008 = bf16[1,4]{1,0} broadcast(bf16[] %p21.572), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2009 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.1992, bf16[1,4]{1,0} %broadcast.2008), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2012 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.2011, bf16[1,4]{1,0} %multiply.2009), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1993 = bf16[1,4]{1,0} broadcast(bf16[] %p20.554), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1994 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.566, bf16[1,4]{1,0} %broadcast.1993), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1996 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.1992, bf16[1,4]{1,0} %multiply.1992), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1995 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1997 = bf16[1,4]{1,0} broadcast(bf16[] %convert.1995), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1998 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.1996, bf16[1,4]{1,0} %broadcast.1997), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1999 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.1994, bf16[1,4]{1,0} %multiply.1998), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2000 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.1999), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2001 = bf16[1,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2002 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.2000, bf16[1,4]{1,0} %broadcast.2001), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2003 = bf16[1,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2004 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.2002, bf16[1,4]{1,0} %broadcast.2003), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2025 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.2012, bf16[1,4]{1,0} %add.2004), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2024 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2026 = bf16[1,4]{1,0} broadcast(bf16[] %convert.2024), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2027 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.2025, bf16[1,4]{1,0} %broadcast.2026), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2028 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.2023, bf16[1,4]{1,0} %multiply.2027), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p27.2094 = bf16[1]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %reshape.365 = bf16[1]{0} reshape(bf16[] %p24.593), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2096 = bf16[1]{0} multiply(bf16[1]{0} %p27.2094, bf16[1]{0} %reshape.365), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.135 = bf16[1]{0} constant({0})
  %multiply.2099 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2096, bf16[1]{0} %constant.135), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2100 = bf16[1]{0} subtract(bf16[1]{0} %p27.2094, bf16[1]{0} %multiply.2099), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.151 = bf16[] constant(0)
  %multiply.66 = bf16[] multiply(bf16[] %constant.151, bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.514 = bf16[1]{0} reshape(bf16[] %multiply.66), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.370 = bf16[1]{0} reshape(bf16[] %p21.572), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2069 = bf16[1]{0} multiply(bf16[1]{0} %multiply.512, bf16[1]{0} %reshape.370), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2075 = bf16[1]{0} add(bf16[1]{0} %reshape.514, bf16[1]{0} %multiply.2069), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.152 = bf16[] constant(0)
  %multiply.65 = bf16[] multiply(bf16[] %constant.152, bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.511 = bf16[1]{0} reshape(bf16[] %multiply.65), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2048 = bf16[1]{0} multiply(bf16[1]{0} %multiply.512, bf16[1]{0} %multiply.512), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2047 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.373 = bf16[1]{0} reshape(bf16[] %convert.2047), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2050 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2048, bf16[1]{0} %reshape.373), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2051 = bf16[1]{0} add(bf16[1]{0} %reshape.511, bf16[1]{0} %multiply.2050), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2085 = bf16[1]{0} sqrt(bf16[1]{0} %add.2051), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.374 = bf16[1]{0} reshape(bf16[] %p19.538), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2087 = bf16[1]{0} divide(bf16[1]{0} %sqrt.2085, bf16[1]{0} %reshape.374), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.375 = bf16[1]{0} reshape(bf16[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2089 = bf16[1]{0} add(bf16[1]{0} %divide.2087, bf16[1]{0} %reshape.375), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2102 = bf16[1]{0} divide(bf16[1]{0} %add.2075, bf16[1]{0} %add.2089), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2101 = bf16[] convert(f32[] %p18.535), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.376 = bf16[1]{0} reshape(bf16[] %convert.2101), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2104 = bf16[1]{0} multiply(bf16[1]{0} %divide.2102, bf16[1]{0} %reshape.376), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2105 = bf16[1]{0} add(bf16[1]{0} %subtract.2100, bf16[1]{0} %multiply.2104), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.377 = bf16[1]{0} reshape(bf16[] %p24.593), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2107 = bf16[1]{0} multiply(bf16[1]{0} %add.2105, bf16[1]{0} %reshape.377), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.141 = bf16[1]{0} constant({0})
  %multiply.2110 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2107, bf16[1]{0} %constant.141), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2111 = bf16[1]{0} subtract(bf16[1]{0} %add.2105, bf16[1]{0} %multiply.2110), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape.380 = bf16[1]{0} reshape(bf16[] %p22.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2077 = bf16[1]{0} multiply(bf16[1]{0} %add.2075, bf16[1]{0} %reshape.380), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.144 = bf16[1]{0} constant({1})
  %compare.2038 = pred[1]{0} compare(bf16[1]{0} %divide.1554, bf16[1]{0} %constant.144), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.145 = bf16[1]{0} constant({1})
  %select.2040 = bf16[1]{0} select(pred[1]{0} %compare.2038, bf16[1]{0} %divide.1554, bf16[1]{0} %constant.145), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2041 = bf16[1]{0} multiply(bf16[1]{0} %add.513, bf16[1]{0} %select.2040), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.385 = bf16[1]{0} reshape(bf16[] %p21.572), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2066 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2041, bf16[1]{0} %reshape.385), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2078 = bf16[1]{0} add(bf16[1]{0} %multiply.2077, bf16[1]{0} %multiply.2066), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.386 = bf16[1]{0} reshape(bf16[] %p20.554), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2053 = bf16[1]{0} multiply(bf16[1]{0} %add.2051, bf16[1]{0} %reshape.386), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2055 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2041, bf16[1]{0} %multiply.2041), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2054 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.387 = bf16[1]{0} reshape(bf16[] %convert.2054), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2057 = bf16[1]{0} multiply(bf16[1]{0} %multiply.2055, bf16[1]{0} %reshape.387), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2058 = bf16[1]{0} add(bf16[1]{0} %multiply.2053, bf16[1]{0} %multiply.2057), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2059 = bf16[1]{0} sqrt(bf16[1]{0} %add.2058), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.388 = bf16[1]{0} reshape(bf16[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2061 = bf16[1]{0} divide(bf16[1]{0} %sqrt.2059, bf16[1]{0} %reshape.388), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.389 = bf16[1]{0} reshape(bf16[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2063 = bf16[1]{0} add(bf16[1]{0} %divide.2061, bf16[1]{0} %reshape.389), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2113 = bf16[1]{0} divide(bf16[1]{0} %add.2078, bf16[1]{0} %add.2063), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2112 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.390 = bf16[1]{0} reshape(bf16[] %convert.2112), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2115 = bf16[1]{0} multiply(bf16[1]{0} %divide.2113, bf16[1]{0} %reshape.390), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2116 = bf16[1]{0} add(bf16[1]{0} %subtract.2111, bf16[1]{0} %multiply.2115), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.2117 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=5*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[1]{0}, /*index=10*/bf16[1]{0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, /*index=15*/bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=20*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=25*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[1,4]{1,0}, /*index=30*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=35*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[1]{0}, bf16[1]{0}, /*index=40*/bf16[4,4]{1,0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %add.1604, bf16[4]{0} %add.1657, bf16[4,4]{1,0} %add.1710, bf16[4]{0} %add.1763, bf16[4,4]{1,0} %add.1816, /*index=5*/bf16[4]{0} %add.1869, bf16[4,4]{1,0} %add.1922, bf16[4]{0} %add.1975, bf16[1,4]{1,0} %add.2028, bf16[1]{0} %add.2116, /*index=10*/bf16[1]{0} %multiply.2041, bf16[1,4]{1,0} %multiply.1992, bf16[4]{0} %multiply.1938, bf16[4,4]{1,0} %multiply.1886, bf16[4]{0} %multiply.1832, /*index=15*/bf16[4,4]{1,0} %multiply.1780, bf16[4]{0} %multiply.1726, bf16[4,4]{1,0} %multiply.1674, bf16[4]{0} %multiply.1620, bf16[4,4]{1,0} %multiply.1568, /*index=20*/bf16[4,4]{1,0} %add.1588, bf16[4,4]{1,0} %add.1575, bf16[4,4]{1,0} %add.1694, bf16[4,4]{1,0} %add.1681, bf16[4,4]{1,0} %add.1800, /*index=25*/bf16[4,4]{1,0} %add.1787, bf16[4,4]{1,0} %add.1906, bf16[4,4]{1,0} %add.1893, bf16[1,4]{1,0} %add.2012, bf16[1,4]{1,0} %add.1999, /*index=30*/bf16[4]{0} %add.1640, bf16[4]{0} %add.1627, bf16[4]{0} %add.1746, bf16[4]{0} %add.1733, bf16[4]{0} %add.1852, /*index=35*/bf16[4]{0} %add.1839, bf16[4]{0} %add.1958, bf16[4]{0} %add.1945, bf16[1]{0} %add.2078, bf16[1]{0} %add.2058, /*index=40*/bf16[4,4]{1,0} %p25.1344, bf16[1]{0} %power.1549), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41"}
}


`

export default text;
