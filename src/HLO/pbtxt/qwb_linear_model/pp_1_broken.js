const text = `
HloModule SyncTensorsGraph.872, input_output_alias={ {0}: (17, {}, must-alias), {1}: (16, {}, must-alias), {2}: (12, {}, must-alias), {3}: (15, {}, must-alias), {4}: (10, {}, must-alias), {5}: (14, {}, must-alias), {6}: (8, {}, must-alias), {7}: (45, {}, must-alias), {8}: (7, {}, must-alias), {9}: (19, {}, must-alias), {10}: (9, {}, must-alias), {11}: (20, {}, must-alias), {12}: (11, {}, must-alias), {13}: (21, {}, must-alias), {14}: (13, {}, must-alias), {15}: (22, {}, must-alias), {16}: (28, {}, must-alias), {17}: (25, {}, must-alias), {18}: (34, {}, must-alias), {19}: (33, {}, must-alias), {20}: (38, {}, must-alias), {21}: (37, {}, must-alias), {22}: (42, {}, must-alias), {23}: (41, {}, must-alias), {24}: (32, {}, must-alias), {25}: (31, {}, must-alias), {26}: (36, {}, must-alias), {27}: (35, {}, must-alias), {28}: (40, {}, must-alias), {29}: (39, {}, must-alias), {30}: (44, {}, must-alias), {31}: (43, {}, must-alias), {32}: (18, {}, must-alias) }

%AddComputation.37 (x.38: bf16[], y.39: bf16[]) -> bf16[] {
  %x.38 = bf16[] parameter(0)
  %y.39 = bf16[] parameter(1)
  ROOT %add.40 = bf16[] add(bf16[] %x.38, bf16[] %y.39)
}

%AddComputation.88 (x.89: bf16[], y.90: bf16[]) -> bf16[] {
  %x.89 = bf16[] parameter(0)
  %y.90 = bf16[] parameter(1)
  ROOT %add.91 = bf16[] add(bf16[] %x.89, bf16[] %y.90)
}

%AddComputation.110 (x.111: bf16[], y.112: bf16[]) -> bf16[] {
  %x.111 = bf16[] parameter(0)
  %y.112 = bf16[] parameter(1)
  ROOT %add.113 = bf16[] add(bf16[] %x.111, bf16[] %y.112)
}

%AddComputation.139 (x.140: bf16[], y.141: bf16[]) -> bf16[] {
  %x.140 = bf16[] parameter(0)
  %y.141 = bf16[] parameter(1)
  ROOT %add.142 = bf16[] add(bf16[] %x.140, bf16[] %y.141)
}

%AddComputation.161 (x.162: bf16[], y.163: bf16[]) -> bf16[] {
  %x.162 = bf16[] parameter(0)
  %y.163 = bf16[] parameter(1)
  ROOT %add.164 = bf16[] add(bf16[] %x.162, bf16[] %y.163)
}

%AddComputation.190 (x.191: bf16[], y.192: bf16[]) -> bf16[] {
  %x.191 = bf16[] parameter(0)
  %y.192 = bf16[] parameter(1)
  ROOT %add.193 = bf16[] add(bf16[] %x.191, bf16[] %y.192)
}

%AddComputation.212 (x.213: bf16[], y.214: bf16[]) -> bf16[] {
  %x.213 = bf16[] parameter(0)
  %y.214 = bf16[] parameter(1)
  ROOT %add.215 = bf16[] add(bf16[] %x.213, bf16[] %y.214)
}

%AddComputation.300 (x.301: bf16[], y.302: bf16[]) -> bf16[] {
  %x.301 = bf16[] parameter(0)
  %y.302 = bf16[] parameter(1)
  ROOT %add.303 = bf16[] add(bf16[] %x.301, bf16[] %y.302)
}

%AddComputation.334 (x.335: bf16[], y.336: bf16[]) -> bf16[] {
  %x.335 = bf16[] parameter(0)
  %y.336 = bf16[] parameter(1)
  ROOT %add.337 = bf16[] add(bf16[] %x.335, bf16[] %y.336)
}

%AddComputation.368 (x.369: bf16[], y.370: bf16[]) -> bf16[] {
  %x.369 = bf16[] parameter(0)
  %y.370 = bf16[] parameter(1)
  ROOT %add.371 = bf16[] add(bf16[] %x.369, bf16[] %y.370)
}

%AddComputation.402 (x.403: bf16[], y.404: bf16[]) -> bf16[] {
  %x.403 = bf16[] parameter(0)
  %y.404 = bf16[] parameter(1)
  ROOT %add.405 = bf16[] add(bf16[] %x.403, bf16[] %y.404)
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.872 (p0.1: f32[], p1.3: bf16[], p2.5: bf16[], p3.6: f32[], p4.12: bf16[], p5.24: bf16[], p6.25: bf16[], p7.52: bf16[1], p8.75: bf16[1,4], p9.103: bf16[4], p10.126: bf16[4,4], p11.154: bf16[4], p12.177: bf16[4,4], p13.205: bf16[4], p14.228: bf16[4], p15.237: bf16[4], p16.246: bf16[4], p17.254: bf16[4,4], p18.263: bf16[4,4], p19.293: bf16[1,4], p20.327: bf16[4,4], p21.361: bf16[4,4], p22.395: bf16[4,4], p23.410: bf16[1], p24.449: bf16[], p25.450: bf16[4,4], p26.463: bf16[], p27.469: bf16[], p28.470: bf16[4,4], p29.479: bf16[], p30.480: bf16[], p31.508: bf16[4], p32.526: bf16[4], p33.564: bf16[4,4], p34.582: bf16[4,4], p35.618: bf16[4], p36.636: bf16[4], p37.674: bf16[4,4], p38.692: bf16[4,4], p39.728: bf16[4], p40.746: bf16[4], p41.784: bf16[1,4], p42.802: bf16[1,4], p43.835: bf16[1], p44.851: bf16[1], p45.859: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=5*/bf16[4], bf16[1,4], bf16[1], bf16[1], bf16[1,4], /*index=10*/bf16[4], bf16[4,4], bf16[4], bf16[4,4], bf16[4], /*index=15*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=20*/bf16[4,4], bf16[4,4], bf16[1,4], bf16[1,4], bf16[4], /*index=25*/bf16[4], bf16[4], bf16[4], bf16[4], bf16[4], /*index=30*/bf16[1], bf16[1], bf16[4,4], bf16[1]) {
  %p17.254 = bf16[4,4]{1,0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p30.480 = bf16[] parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.481 = bf16[4,4]{1,0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.482 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p17.254, bf16[4,4]{1,0} %broadcast.481), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p29.479 = bf16[] parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.483 = bf16[4,4]{1,0} broadcast(bf16[] %p29.479), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.485 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.482, bf16[4,4]{1,0} %broadcast.483), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.486 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p17.254, bf16[4,4]{1,0} %multiply.485), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p28.470 = bf16[4,4]{1,0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p27.469 = bf16[] parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.471 = bf16[4,4]{1,0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.472 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p28.470, bf16[4,4]{1,0} %broadcast.471), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p22.395 = bf16[4,4]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p6.25 = bf16[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p5.24 = bf16[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %divide.1 = bf16[] divide(bf16[] %p6.25, bf16[] %p5.24), metadata={op_type="aten__div" op_name="aten__div"}
  %broadcast.53 = bf16[1,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p8.75 = bf16[1,4]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.15 = bf16[1,4]{1,0} custom-call(bf16[1,4]{1,0} %p8.75), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.19 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %broadcast.53, bf16[1,4]{1,0} %custom-call.15), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.197 = bf16[4]{0} reshape(bf16[1,4]{1,0} %multiply.19), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.10 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %reshape.197), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p10.126 = bf16[4,4]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.16 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p10.126), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.136 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %broadcast.10, bf16[4,4]{1,0} %custom-call.16), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p12.177 = bf16[4,4]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.17 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p12.177), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.187 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.136, bf16[4,4]{1,0} %custom-call.17), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p18.263 = bf16[4,4]{1,0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model_nxd.py" source_line=155}
  %transpose.384 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %p18.263), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.1 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.187, bf16[4,4]{0,1} %transpose.384), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.18 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.396 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p22.395, bf16[4,4]{1,0} %custom-call.18), metadata={op_type="aten__add" op_name="aten__add"}
  %constant.1 = bf16[1]{0} constant({1})
  %p23.410 = bf16[1]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.399 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.396, bf16[4,4]{1,0} %add.396), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.400 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.406 = bf16[] reduce(bf16[4,4]{1,0} %multiply.399, bf16[] %constant.400), dimensions={0,1}, to_apply=%AddComputation.402, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.407 = bf16[] sqrt(bf16[] %reduce.406), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.409 = bf16[] multiply(bf16[] %sqrt.407, bf16[] %sqrt.407), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.409), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.412 = bf16[1]{0} add(bf16[1]{0} %p23.410, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p21.361 = bf16[4,4]{1,0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %custom-call.19 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p17.254), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.262 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.19), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.264 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %p18.263, bf16[4,4]{0,1} %transpose.262), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p16.246 = bf16[4]{0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.20 = bf16[4]{0} custom-call(bf16[4]{0} %p16.246), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.268 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.20), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.269 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.264, bf16[4,4]{1,0} %broadcast.268), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.350 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.269), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.2 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.136, bf16[4,4]{0,1} %transpose.350), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.21 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.2), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.362 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p21.361, bf16[4,4]{1,0} %custom-call.21), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.365 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.362, bf16[4,4]{1,0} %add.362), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.366 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.372 = bf16[] reduce(bf16[4,4]{1,0} %multiply.365, bf16[] %constant.366), dimensions={0,1}, to_apply=%AddComputation.368, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.373 = bf16[] sqrt(bf16[] %reduce.372), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.375 = bf16[] multiply(bf16[] %sqrt.373, bf16[] %sqrt.373), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.19 = bf16[1]{0} reshape(bf16[] %multiply.375), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.414 = bf16[1]{0} add(bf16[1]{0} %add.412, bf16[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p20.327 = bf16[4,4]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %transpose.245 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.17), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.270 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.269, bf16[4,4]{0,1} %transpose.245), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p15.237 = bf16[4]{0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.22 = bf16[4]{0} custom-call(bf16[4]{0} %p15.237), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.274 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.22), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.275 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.270, bf16[4,4]{1,0} %broadcast.274), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.316 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.275), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.3 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %broadcast.10, bf16[4,4]{0,1} %transpose.316), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.23 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.3), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.328 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %p20.327, bf16[4,4]{1,0} %custom-call.23), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.331 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.328, bf16[4,4]{1,0} %add.328), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.332 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.338 = bf16[] reduce(bf16[4,4]{1,0} %multiply.331, bf16[] %constant.332), dimensions={0,1}, to_apply=%AddComputation.334, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.339 = bf16[] sqrt(bf16[] %reduce.338), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.341 = bf16[] multiply(bf16[] %sqrt.339, bf16[] %sqrt.339), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.32 = bf16[1]{0} reshape(bf16[] %multiply.341), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.416 = bf16[1]{0} add(bf16[1]{0} %add.414, bf16[1]{0} %reshape.32), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p19.293 = bf16[1,4]{1,0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %transpose.236 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.16), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.276 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.275, bf16[4,4]{0,1} %transpose.236), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p14.228 = bf16[4]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.24 = bf16[4]{0} custom-call(bf16[4]{0} %p14.228), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.280 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.24), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.281 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.276, bf16[4,4]{1,0} %broadcast.280), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.56 = bf16[4,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.20 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.281, bf16[4,4]{1,0} %broadcast.56)
  %convert.2 = f32[4,4]{1,0} convert(bf16[4,4]{1,0} %multiply.20)
  %constant = f32[] constant(0)
  %reduce = f32[4]{0} reduce(f32[4,4]{1,0} %convert.2, f32[] %constant), dimensions={0}, to_apply=%scalar_add_computation
  %convert.1 = bf16[4]{0} convert(f32[4]{0} %reduce), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.37 = bf16[1,4]{0,1} reshape(bf16[4]{0} %convert.1), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.25 = bf16[1,4]{1,0} custom-call(bf16[1,4]{0,1} %reshape.37), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.294 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %p19.293, bf16[1,4]{1,0} %custom-call.25), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.297 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.294, bf16[1,4]{1,0} %add.294), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.298 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.304 = bf16[] reduce(bf16[1,4]{1,0} %multiply.297, bf16[] %constant.298), dimensions={0,1}, to_apply=%AddComputation.300, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.305 = bf16[] sqrt(bf16[] %reduce.304), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.307 = bf16[] multiply(bf16[] %sqrt.305, bf16[] %sqrt.305), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.41 = bf16[1]{0} reshape(bf16[] %multiply.307), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.418 = bf16[1]{0} add(bf16[1]{0} %add.416, bf16[1]{0} %reshape.41), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p13.205 = bf16[4]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.188 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.194 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.187, bf16[] %constant.188), dimensions={0}, to_apply=%AddComputation.190, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.26 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.194), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.206 = bf16[4]{0} add(bf16[4]{0} %p13.205, bf16[4]{0} %custom-call.26), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.209 = bf16[4]{0} multiply(bf16[4]{0} %add.206, bf16[4]{0} %add.206), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.210 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.216 = bf16[] reduce(bf16[4]{0} %multiply.209, bf16[] %constant.210), dimensions={0}, to_apply=%AddComputation.212, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.217 = bf16[] sqrt(bf16[] %reduce.216), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.219 = bf16[] multiply(bf16[] %sqrt.217, bf16[] %sqrt.217), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.47 = bf16[1]{0} reshape(bf16[] %multiply.219), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.420 = bf16[1]{0} add(bf16[1]{0} %add.418, bf16[1]{0} %reshape.47), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p11.154 = bf16[4]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.137 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.143 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.136, bf16[] %constant.137), dimensions={0}, to_apply=%AddComputation.139, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.27 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.143), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.155 = bf16[4]{0} add(bf16[4]{0} %p11.154, bf16[4]{0} %custom-call.27), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.158 = bf16[4]{0} multiply(bf16[4]{0} %add.155, bf16[4]{0} %add.155), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.159 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.165 = bf16[] reduce(bf16[4]{0} %multiply.158, bf16[] %constant.159), dimensions={0}, to_apply=%AddComputation.161, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.166 = bf16[] sqrt(bf16[] %reduce.165), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.168 = bf16[] multiply(bf16[] %sqrt.166, bf16[] %sqrt.166), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.51 = bf16[1]{0} reshape(bf16[] %multiply.168), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.422 = bf16[1]{0} add(bf16[1]{0} %add.420, bf16[1]{0} %reshape.51), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p9.103 = bf16[4]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %constant.86 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.92 = bf16[4]{0} reduce(bf16[4,4]{1,0} %broadcast.10, bf16[] %constant.86), dimensions={0}, to_apply=%AddComputation.88, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.28 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.92), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.104 = bf16[4]{0} add(bf16[4]{0} %p9.103, bf16[4]{0} %custom-call.28), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.107 = bf16[4]{0} multiply(bf16[4]{0} %add.104, bf16[4]{0} %add.104), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.108 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.114 = bf16[] reduce(bf16[4]{0} %multiply.107, bf16[] %constant.108), dimensions={0}, to_apply=%AddComputation.110, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.115 = bf16[] sqrt(bf16[] %reduce.114), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.117 = bf16[] multiply(bf16[] %sqrt.115, bf16[] %sqrt.115), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.55 = bf16[1]{0} reshape(bf16[] %multiply.117), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.424 = bf16[1]{0} add(bf16[1]{0} %add.422, bf16[1]{0} %reshape.55), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p7.52 = bf16[1]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %broadcast.1 = bf16[4,1]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.35 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.41 = bf16[1]{0} reduce(bf16[4,1]{1,0} %broadcast.1, bf16[] %constant.35), dimensions={0}, to_apply=%AddComputation.37, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.29 = bf16[1]{0} custom-call(bf16[1]{0} %reduce.41), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.53 = bf16[1]{0} add(bf16[1]{0} %p7.52, bf16[1]{0} %custom-call.29), metadata={op_type="aten__add" op_name="aten__add"}
  %multiply.21 = bf16[1]{0} multiply(bf16[1]{0} %add.53, bf16[1]{0} %add.53), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.426 = bf16[1]{0} add(bf16[1]{0} %add.424, bf16[1]{0} %multiply.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.6 = bf16[1]{0} constant({0.5})
  %power.429 = bf16[1]{0} power(bf16[1]{0} %add.426, bf16[1]{0} %constant.6), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p4.12 = bf16[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.63 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.431 = bf16[1]{0} add(bf16[1]{0} %power.429, bf16[1]{0} %reshape.63), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.434 = bf16[1]{0} divide(bf16[1]{0} %constant.1, bf16[1]{0} %add.431), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.12 = bf16[1]{0} constant({1})
  %compare.441 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.12), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.13 = bf16[1]{0} constant({1})
  %select.443 = bf16[1]{0} select(pred[1]{0} %compare.441, bf16[1]{0} %divide.434, bf16[1]{0} %constant.13), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.445 = bf16[] reshape(bf16[1]{0} %select.443), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.447 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.445), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.448 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.396, bf16[4,4]{1,0} %broadcast.447), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p26.463 = bf16[] parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.467 = bf16[4,4]{1,0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.468 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.448, bf16[4,4]{1,0} %broadcast.467), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.473 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.472, bf16[4,4]{1,0} %multiply.468), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p25.450 = bf16[4,4]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p24.449 = bf16[] parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.451 = bf16[4,4]{1,0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.452 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p25.450, bf16[4,4]{1,0} %broadcast.451), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.454 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.448, bf16[4,4]{1,0} %multiply.448), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.453 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.455 = bf16[4,4]{1,0} broadcast(bf16[] %convert.453), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.456 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.454, bf16[4,4]{1,0} %broadcast.455), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.457 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.452, bf16[4,4]{1,0} %multiply.456), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.458 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.457), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.459 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.460 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.458, bf16[4,4]{1,0} %broadcast.459), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = bf16[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.461 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.462 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.460, bf16[4,4]{1,0} %broadcast.461), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.488 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.473, bf16[4,4]{1,0} %add.462), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.487 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.489 = bf16[4,4]{1,0} broadcast(bf16[] %convert.487), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.490 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.488, bf16[4,4]{1,0} %broadcast.489), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.491 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.486, bf16[4,4]{1,0} %multiply.490), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.536 = bf16[4]{0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.537 = bf16[4]{0} multiply(bf16[4]{0} %p16.246, bf16[4]{0} %broadcast.536), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.16 = bf16[] constant(0)
  %broadcast.12 = bf16[4]{0} broadcast(bf16[] %constant.16), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.540 = bf16[4]{0} multiply(bf16[4]{0} %multiply.537, bf16[4]{0} %broadcast.12), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.541 = bf16[4]{0} subtract(bf16[4]{0} %p16.246, bf16[4]{0} %multiply.540), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p32.526 = bf16[4]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.527 = bf16[4]{0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.528 = bf16[4]{0} multiply(bf16[4]{0} %p32.526, bf16[4]{0} %broadcast.527), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.23 = bf16[1]{0} constant({1})
  %compare.501 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.23), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.24 = bf16[1]{0} constant({1})
  %select.503 = bf16[1]{0} select(pred[1]{0} %compare.501, bf16[1]{0} %divide.434, bf16[1]{0} %constant.24), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.505 = bf16[] reshape(bf16[1]{0} %select.503), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.506 = bf16[4]{0} broadcast(bf16[] %reshape.505), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.507 = bf16[4]{0} multiply(bf16[4]{0} %add.206, bf16[4]{0} %broadcast.506), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.524 = bf16[4]{0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.525 = bf16[4]{0} multiply(bf16[4]{0} %multiply.507, bf16[4]{0} %broadcast.524), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.529 = bf16[4]{0} add(bf16[4]{0} %multiply.528, bf16[4]{0} %multiply.525), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p31.508 = bf16[4]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.509 = bf16[4]{0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.510 = bf16[4]{0} multiply(bf16[4]{0} %p31.508, bf16[4]{0} %broadcast.509), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.512 = bf16[4]{0} multiply(bf16[4]{0} %multiply.507, bf16[4]{0} %multiply.507), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.511 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.513 = bf16[4]{0} broadcast(bf16[] %convert.511), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.514 = bf16[4]{0} multiply(bf16[4]{0} %multiply.512, bf16[4]{0} %broadcast.513), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.515 = bf16[4]{0} add(bf16[4]{0} %multiply.510, bf16[4]{0} %multiply.514), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.516 = bf16[4]{0} sqrt(bf16[4]{0} %add.515), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.517 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.518 = bf16[4]{0} divide(bf16[4]{0} %sqrt.516, bf16[4]{0} %broadcast.517), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.519 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.520 = bf16[4]{0} add(bf16[4]{0} %divide.518, bf16[4]{0} %broadcast.519), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.543 = bf16[4]{0} divide(bf16[4]{0} %add.529, bf16[4]{0} %add.520), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.542 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.544 = bf16[4]{0} broadcast(bf16[] %convert.542), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.545 = bf16[4]{0} multiply(bf16[4]{0} %divide.543, bf16[4]{0} %broadcast.544), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.546 = bf16[4]{0} add(bf16[4]{0} %subtract.541, bf16[4]{0} %multiply.545), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.591 = bf16[4,4]{1,0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.592 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p12.177, bf16[4,4]{1,0} %broadcast.591), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.593 = bf16[4,4]{1,0} broadcast(bf16[] %p29.479), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.595 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.592, bf16[4,4]{1,0} %broadcast.593), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.596 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p12.177, bf16[4,4]{1,0} %multiply.595), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p34.582 = bf16[4,4]{1,0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.583 = bf16[4,4]{1,0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.584 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p34.582, bf16[4,4]{1,0} %broadcast.583), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.27 = bf16[1]{0} constant({1})
  %compare.556 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.27), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.28 = bf16[1]{0} constant({1})
  %select.558 = bf16[1]{0} select(pred[1]{0} %compare.556, bf16[1]{0} %divide.434, bf16[1]{0} %constant.28), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.560 = bf16[] reshape(bf16[1]{0} %select.558), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.562 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.560), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.563 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.362, bf16[4,4]{1,0} %broadcast.562), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.580 = bf16[4,4]{1,0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.581 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.563, bf16[4,4]{1,0} %broadcast.580), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.585 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.584, bf16[4,4]{1,0} %multiply.581), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p33.564 = bf16[4,4]{1,0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.565 = bf16[4,4]{1,0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.566 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p33.564, bf16[4,4]{1,0} %broadcast.565), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.568 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.563, bf16[4,4]{1,0} %multiply.563), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.567 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.569 = bf16[4,4]{1,0} broadcast(bf16[] %convert.567), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.570 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.568, bf16[4,4]{1,0} %broadcast.569), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.571 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.566, bf16[4,4]{1,0} %multiply.570), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.572 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.571), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.573 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.574 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.572, bf16[4,4]{1,0} %broadcast.573), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.575 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.576 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.574, bf16[4,4]{1,0} %broadcast.575), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.598 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.585, bf16[4,4]{1,0} %add.576), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.597 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.599 = bf16[4,4]{1,0} broadcast(bf16[] %convert.597), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.600 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.598, bf16[4,4]{1,0} %broadcast.599), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.601 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.596, bf16[4,4]{1,0} %multiply.600), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.646 = bf16[4]{0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.647 = bf16[4]{0} multiply(bf16[4]{0} %p15.237, bf16[4]{0} %broadcast.646), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.30 = bf16[] constant(0)
  %broadcast.14 = bf16[4]{0} broadcast(bf16[] %constant.30), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.650 = bf16[4]{0} multiply(bf16[4]{0} %multiply.647, bf16[4]{0} %broadcast.14), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.651 = bf16[4]{0} subtract(bf16[4]{0} %p15.237, bf16[4]{0} %multiply.650), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p36.636 = bf16[4]{0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.637 = bf16[4]{0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.638 = bf16[4]{0} multiply(bf16[4]{0} %p36.636, bf16[4]{0} %broadcast.637), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.32 = bf16[1]{0} constant({1})
  %compare.611 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.32), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.33 = bf16[1]{0} constant({1})
  %select.613 = bf16[1]{0} select(pred[1]{0} %compare.611, bf16[1]{0} %divide.434, bf16[1]{0} %constant.33), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.615 = bf16[] reshape(bf16[1]{0} %select.613), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.616 = bf16[4]{0} broadcast(bf16[] %reshape.615), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.617 = bf16[4]{0} multiply(bf16[4]{0} %add.155, bf16[4]{0} %broadcast.616), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.634 = bf16[4]{0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.635 = bf16[4]{0} multiply(bf16[4]{0} %multiply.617, bf16[4]{0} %broadcast.634), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.639 = bf16[4]{0} add(bf16[4]{0} %multiply.638, bf16[4]{0} %multiply.635), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p35.618 = bf16[4]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.619 = bf16[4]{0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.620 = bf16[4]{0} multiply(bf16[4]{0} %p35.618, bf16[4]{0} %broadcast.619), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.622 = bf16[4]{0} multiply(bf16[4]{0} %multiply.617, bf16[4]{0} %multiply.617), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.621 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.623 = bf16[4]{0} broadcast(bf16[] %convert.621), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.624 = bf16[4]{0} multiply(bf16[4]{0} %multiply.622, bf16[4]{0} %broadcast.623), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.625 = bf16[4]{0} add(bf16[4]{0} %multiply.620, bf16[4]{0} %multiply.624), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.626 = bf16[4]{0} sqrt(bf16[4]{0} %add.625), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.627 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.628 = bf16[4]{0} divide(bf16[4]{0} %sqrt.626, bf16[4]{0} %broadcast.627), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.629 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.630 = bf16[4]{0} add(bf16[4]{0} %divide.628, bf16[4]{0} %broadcast.629), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.653 = bf16[4]{0} divide(bf16[4]{0} %add.639, bf16[4]{0} %add.630), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.652 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.654 = bf16[4]{0} broadcast(bf16[] %convert.652), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.655 = bf16[4]{0} multiply(bf16[4]{0} %divide.653, bf16[4]{0} %broadcast.654), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.656 = bf16[4]{0} add(bf16[4]{0} %subtract.651, bf16[4]{0} %multiply.655), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.701 = bf16[4,4]{1,0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.702 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p10.126, bf16[4,4]{1,0} %broadcast.701), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.703 = bf16[4,4]{1,0} broadcast(bf16[] %p29.479), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.705 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.702, bf16[4,4]{1,0} %broadcast.703), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.706 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p10.126, bf16[4,4]{1,0} %multiply.705), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p38.692 = bf16[4,4]{1,0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.693 = bf16[4,4]{1,0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.694 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p38.692, bf16[4,4]{1,0} %broadcast.693), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.37 = bf16[1]{0} constant({1})
  %compare.666 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.38 = bf16[1]{0} constant({1})
  %select.668 = bf16[1]{0} select(pred[1]{0} %compare.666, bf16[1]{0} %divide.434, bf16[1]{0} %constant.38), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.670 = bf16[] reshape(bf16[1]{0} %select.668), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.672 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.670), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.673 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.328, bf16[4,4]{1,0} %broadcast.672), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.690 = bf16[4,4]{1,0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.691 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.673, bf16[4,4]{1,0} %broadcast.690), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.695 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.694, bf16[4,4]{1,0} %multiply.691), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p37.674 = bf16[4,4]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.675 = bf16[4,4]{1,0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.676 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p37.674, bf16[4,4]{1,0} %broadcast.675), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.678 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.673, bf16[4,4]{1,0} %multiply.673), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.677 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.679 = bf16[4,4]{1,0} broadcast(bf16[] %convert.677), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.680 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.678, bf16[4,4]{1,0} %broadcast.679), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.681 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.676, bf16[4,4]{1,0} %multiply.680), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.682 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.681), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.683 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.684 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.682, bf16[4,4]{1,0} %broadcast.683), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.685 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.686 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.684, bf16[4,4]{1,0} %broadcast.685), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.708 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.695, bf16[4,4]{1,0} %add.686), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.707 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.709 = bf16[4,4]{1,0} broadcast(bf16[] %convert.707), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.710 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.708, bf16[4,4]{1,0} %broadcast.709), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.711 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.706, bf16[4,4]{1,0} %multiply.710), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.756 = bf16[4]{0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.757 = bf16[4]{0} multiply(bf16[4]{0} %p14.228, bf16[4]{0} %broadcast.756), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.40 = bf16[] constant(0)
  %broadcast.17 = bf16[4]{0} broadcast(bf16[] %constant.40), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.760 = bf16[4]{0} multiply(bf16[4]{0} %multiply.757, bf16[4]{0} %broadcast.17), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.761 = bf16[4]{0} subtract(bf16[4]{0} %p14.228, bf16[4]{0} %multiply.760), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p40.746 = bf16[4]{0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.747 = bf16[4]{0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.748 = bf16[4]{0} multiply(bf16[4]{0} %p40.746, bf16[4]{0} %broadcast.747), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.42 = bf16[1]{0} constant({1})
  %compare.721 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.42), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.43 = bf16[1]{0} constant({1})
  %select.723 = bf16[1]{0} select(pred[1]{0} %compare.721, bf16[1]{0} %divide.434, bf16[1]{0} %constant.43), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.725 = bf16[] reshape(bf16[1]{0} %select.723), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.726 = bf16[4]{0} broadcast(bf16[] %reshape.725), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.727 = bf16[4]{0} multiply(bf16[4]{0} %add.104, bf16[4]{0} %broadcast.726), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.744 = bf16[4]{0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.745 = bf16[4]{0} multiply(bf16[4]{0} %multiply.727, bf16[4]{0} %broadcast.744), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.749 = bf16[4]{0} add(bf16[4]{0} %multiply.748, bf16[4]{0} %multiply.745), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p39.728 = bf16[4]{0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.729 = bf16[4]{0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.730 = bf16[4]{0} multiply(bf16[4]{0} %p39.728, bf16[4]{0} %broadcast.729), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.732 = bf16[4]{0} multiply(bf16[4]{0} %multiply.727, bf16[4]{0} %multiply.727), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.731 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.733 = bf16[4]{0} broadcast(bf16[] %convert.731), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.734 = bf16[4]{0} multiply(bf16[4]{0} %multiply.732, bf16[4]{0} %broadcast.733), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.735 = bf16[4]{0} add(bf16[4]{0} %multiply.730, bf16[4]{0} %multiply.734), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.736 = bf16[4]{0} sqrt(bf16[4]{0} %add.735), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.737 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.738 = bf16[4]{0} divide(bf16[4]{0} %sqrt.736, bf16[4]{0} %broadcast.737), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.739 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.740 = bf16[4]{0} add(bf16[4]{0} %divide.738, bf16[4]{0} %broadcast.739), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.763 = bf16[4]{0} divide(bf16[4]{0} %add.749, bf16[4]{0} %add.740), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.762 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.764 = bf16[4]{0} broadcast(bf16[] %convert.762), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.765 = bf16[4]{0} multiply(bf16[4]{0} %divide.763, bf16[4]{0} %broadcast.764), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.766 = bf16[4]{0} add(bf16[4]{0} %subtract.761, bf16[4]{0} %multiply.765), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.811 = bf16[1,4]{1,0} broadcast(bf16[] %p30.480), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.812 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p8.75, bf16[1,4]{1,0} %broadcast.811), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.813 = bf16[1,4]{1,0} broadcast(bf16[] %p29.479), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.815 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.812, bf16[1,4]{1,0} %broadcast.813), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.816 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p8.75, bf16[1,4]{1,0} %multiply.815), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p42.802 = bf16[1,4]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.803 = bf16[1,4]{1,0} broadcast(bf16[] %p27.469), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.804 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p42.802, bf16[1,4]{1,0} %broadcast.803), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.45 = bf16[1]{0} constant({1})
  %compare.776 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.45), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.46 = bf16[1]{0} constant({1})
  %select.778 = bf16[1]{0} select(pred[1]{0} %compare.776, bf16[1]{0} %divide.434, bf16[1]{0} %constant.46), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.780 = bf16[] reshape(bf16[1]{0} %select.778), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.49 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.780), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.783 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %add.294, bf16[1,4]{1,0} %broadcast.49), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.800 = bf16[1,4]{1,0} broadcast(bf16[] %p26.463), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.801 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.783, bf16[1,4]{1,0} %broadcast.800), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.805 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.804, bf16[1,4]{1,0} %multiply.801), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p41.784 = bf16[1,4]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.785 = bf16[1,4]{1,0} broadcast(bf16[] %p24.449), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.786 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p41.784, bf16[1,4]{1,0} %broadcast.785), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.788 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.783, bf16[1,4]{1,0} %multiply.783), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.787 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.789 = bf16[1,4]{1,0} broadcast(bf16[] %convert.787), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.790 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.788, bf16[1,4]{1,0} %broadcast.789), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.791 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.786, bf16[1,4]{1,0} %multiply.790), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.792 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.791), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.793 = bf16[1,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.794 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.792, bf16[1,4]{1,0} %broadcast.793), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.795 = bf16[1,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.796 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.794, bf16[1,4]{1,0} %broadcast.795), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.818 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.805, bf16[1,4]{1,0} %add.796), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.817 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.819 = bf16[1,4]{1,0} broadcast(bf16[] %convert.817), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.820 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.818, bf16[1,4]{1,0} %broadcast.819), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.821 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.816, bf16[1,4]{1,0} %multiply.820), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p45.859 = bf16[1]{0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.142 = bf16[1]{0} reshape(bf16[] %p30.480), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.861 = bf16[1]{0} multiply(bf16[1]{0} %p45.859, bf16[1]{0} %reshape.142), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.47 = bf16[1]{0} constant({0})
  %multiply.864 = bf16[1]{0} multiply(bf16[1]{0} %multiply.861, bf16[1]{0} %constant.47), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.865 = bf16[1]{0} subtract(bf16[1]{0} %p45.859, bf16[1]{0} %multiply.864), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p44.851 = bf16[1]{0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.147 = bf16[1]{0} reshape(bf16[] %p27.469), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.853 = bf16[1]{0} multiply(bf16[1]{0} %p44.851, bf16[1]{0} %reshape.147), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.50 = bf16[1]{0} constant({1})
  %compare.831 = pred[1]{0} compare(bf16[1]{0} %divide.434, bf16[1]{0} %constant.50), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.51 = bf16[1]{0} constant({1})
  %select.833 = bf16[1]{0} select(pred[1]{0} %compare.831, bf16[1]{0} %divide.434, bf16[1]{0} %constant.51), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.834 = bf16[1]{0} multiply(bf16[1]{0} %add.53, bf16[1]{0} %select.833), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.152 = bf16[1]{0} reshape(bf16[] %p26.463), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.850 = bf16[1]{0} multiply(bf16[1]{0} %multiply.834, bf16[1]{0} %reshape.152), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.854 = bf16[1]{0} add(bf16[1]{0} %multiply.853, bf16[1]{0} %multiply.850), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p43.835 = bf16[1]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.153 = bf16[1]{0} reshape(bf16[] %p24.449), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.837 = bf16[1]{0} multiply(bf16[1]{0} %p43.835, bf16[1]{0} %reshape.153), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.839 = bf16[1]{0} multiply(bf16[1]{0} %multiply.834, bf16[1]{0} %multiply.834), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.838 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.154 = bf16[1]{0} reshape(bf16[] %convert.838), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.841 = bf16[1]{0} multiply(bf16[1]{0} %multiply.839, bf16[1]{0} %reshape.154), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.842 = bf16[1]{0} add(bf16[1]{0} %multiply.837, bf16[1]{0} %multiply.841), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.843 = bf16[1]{0} sqrt(bf16[1]{0} %add.842), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.155 = bf16[1]{0} reshape(bf16[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.845 = bf16[1]{0} divide(bf16[1]{0} %sqrt.843, bf16[1]{0} %reshape.155), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.156 = bf16[1]{0} reshape(bf16[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.847 = bf16[1]{0} add(bf16[1]{0} %divide.845, bf16[1]{0} %reshape.156), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.867 = bf16[1]{0} divide(bf16[1]{0} %add.854, bf16[1]{0} %add.847), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.866 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.157 = bf16[1]{0} reshape(bf16[] %convert.866), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.869 = bf16[1]{0} multiply(bf16[1]{0} %divide.867, bf16[1]{0} %reshape.157), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.870 = bf16[1]{0} add(bf16[1]{0} %subtract.865, bf16[1]{0} %multiply.869), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.871 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=5*/bf16[4]{0}, bf16[1,4]{1,0}, bf16[1]{0}, bf16[1]{0}, bf16[1,4]{1,0}, /*index=10*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, /*index=15*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=20*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[1,4]{1,0}, bf16[4]{0}, /*index=25*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=30*/bf16[1]{0}, bf16[1]{0}, bf16[4,4]{1,0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %add.491, bf16[4]{0} %add.546, bf16[4,4]{1,0} %add.601, bf16[4]{0} %add.656, bf16[4,4]{1,0} %add.711, /*index=5*/bf16[4]{0} %add.766, bf16[1,4]{1,0} %add.821, bf16[1]{0} %add.870, bf16[1]{0} %multiply.834, bf16[1,4]{1,0} %multiply.783, /*index=10*/bf16[4]{0} %multiply.727, bf16[4,4]{1,0} %multiply.673, bf16[4]{0} %multiply.617, bf16[4,4]{1,0} %multiply.563, bf16[4]{0} %multiply.507, /*index=15*/bf16[4,4]{1,0} %multiply.448, bf16[4,4]{1,0} %add.473, bf16[4,4]{1,0} %add.457, bf16[4,4]{1,0} %add.585, bf16[4,4]{1,0} %add.571, /*index=20*/bf16[4,4]{1,0} %add.695, bf16[4,4]{1,0} %add.681, bf16[1,4]{1,0} %add.805, bf16[1,4]{1,0} %add.791, bf16[4]{0} %add.529, /*index=25*/bf16[4]{0} %add.515, bf16[4]{0} %add.639, bf16[4]{0} %add.625, bf16[4]{0} %add.749, bf16[4]{0} %add.735, /*index=30*/bf16[1]{0} %add.854, bf16[1]{0} %add.842, bf16[4,4]{1,0} %p18.263, bf16[1]{0} %power.429), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33"}
}


`

export default text;
