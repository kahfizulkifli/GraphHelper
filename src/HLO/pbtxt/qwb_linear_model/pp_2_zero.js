const text = `
HloModule SyncTensorsGraph.594, input_output_alias={ {6}: (20, {}, must-alias), {7}: (23, {}, must-alias), {8}: (26, {}, must-alias), {9}: (29, {}, must-alias), {10}: (32, {}, must-alias), {11}: (35, {}, must-alias), {12}: (17, {}, must-alias), {13}: (14, {}, must-alias), {14}: (22, {}, must-alias), {15}: (21, {}, must-alias), {16}: (25, {}, must-alias), {17}: (24, {}, must-alias), {18}: (28, {}, must-alias), {19}: (27, {}, must-alias), {20}: (31, {}, must-alias), {21}: (30, {}, must-alias), {22}: (34, {}, must-alias), {23}: (33, {}, must-alias) }

%AddComputation.10 (x.11: bf16[], y.12: bf16[]) -> bf16[] {
  %x.11 = bf16[] parameter(0)
  %y.12 = bf16[] parameter(1)
  ROOT %add.13 = bf16[] add(bf16[] %x.11, bf16[] %y.12)
}

%AddComputation.36 (x.37: bf16[], y.38: bf16[]) -> bf16[] {
  %x.37 = bf16[] parameter(0)
  %y.38 = bf16[] parameter(1)
  ROOT %add.39 = bf16[] add(bf16[] %x.37, bf16[] %y.38)
}

%AddComputation.47 (x.48: bf16[], y.49: bf16[]) -> bf16[] {
  %x.48 = bf16[] parameter(0)
  %y.49 = bf16[] parameter(1)
  ROOT %add.50 = bf16[] add(bf16[] %x.48, bf16[] %y.49)
}

%AddComputation.62 (x.63: bf16[], y.64: bf16[]) -> bf16[] {
  %x.63 = bf16[] parameter(0)
  %y.64 = bf16[] parameter(1)
  ROOT %add.65 = bf16[] add(bf16[] %x.63, bf16[] %y.64)
}

%AddComputation.73 (x.74: bf16[], y.75: bf16[]) -> bf16[] {
  %x.74 = bf16[] parameter(0)
  %y.75 = bf16[] parameter(1)
  ROOT %add.76 = bf16[] add(bf16[] %x.74, bf16[] %y.75)
}

%AddComputation.88 (x.89: bf16[], y.90: bf16[]) -> bf16[] {
  %x.89 = bf16[] parameter(0)
  %y.90 = bf16[] parameter(1)
  ROOT %add.91 = bf16[] add(bf16[] %x.89, bf16[] %y.90)
}

%AddComputation.99 (x.100: bf16[], y.101: bf16[]) -> bf16[] {
  %x.100 = bf16[] parameter(0)
  %y.101 = bf16[] parameter(1)
  ROOT %add.102 = bf16[] add(bf16[] %x.100, bf16[] %y.101)
}

%AddComputation.114 (x.115: bf16[], y.116: bf16[]) -> bf16[] {
  %x.115 = bf16[] parameter(0)
  %y.116 = bf16[] parameter(1)
  ROOT %add.117 = bf16[] add(bf16[] %x.115, bf16[] %y.116)
}

%AddComputation.125 (x.126: bf16[], y.127: bf16[]) -> bf16[] {
  %x.126 = bf16[] parameter(0)
  %y.127 = bf16[] parameter(1)
  ROOT %add.128 = bf16[] add(bf16[] %x.126, bf16[] %y.127)
}

%AddComputation.140 (x.141: bf16[], y.142: bf16[]) -> bf16[] {
  %x.141 = bf16[] parameter(0)
  %y.142 = bf16[] parameter(1)
  ROOT %add.143 = bf16[] add(bf16[] %x.141, bf16[] %y.142)
}

%AddComputation.151 (x.152: bf16[], y.153: bf16[]) -> bf16[] {
  %x.152 = bf16[] parameter(0)
  %y.153 = bf16[] parameter(1)
  ROOT %add.154 = bf16[] add(bf16[] %x.152, bf16[] %y.153)
}

%AddComputation.178 (x.179: bf16[], y.180: bf16[]) -> bf16[] {
  %x.179 = bf16[] parameter(0)
  %y.180 = bf16[] parameter(1)
  ROOT %add.181 = bf16[] add(bf16[] %x.179, bf16[] %y.180)
}

ENTRY %SyncTensorsGraph.594 (p0.1: f32[], p1.5: bf16[1], p2.31: bf16[4], p3.57: bf16[4], p4.83: bf16[1,4], p5.109: bf16[4,4], p6.135: bf16[4,4], p7.159: bf16[1], p8.186: f32[], p9.188: bf16[], p10.190: bf16[], p11.191: f32[], p12.197: bf16[], p13.222: bf16[], p14.223: bf16[4,4], p15.236: bf16[], p16.242: bf16[], p17.243: bf16[4,4], p18.252: bf16[], p19.253: bf16[], p20.254: bf16[4,4], p21.292: bf16[4,4], p22.310: bf16[4,4], p23.319: bf16[4,4], p24.356: bf16[1,4], p25.374: bf16[1,4], p26.383: bf16[1,4], p27.419: bf16[4], p28.437: bf16[4], p29.447: bf16[4], p30.485: bf16[4], p31.503: bf16[4], p32.513: bf16[4], p33.548: bf16[1], p34.564: bf16[1], p35.572: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[1,4], /*index=5*/bf16[1], bf16[4,4], bf16[4,4], bf16[1,4], bf16[4], /*index=10*/bf16[4], bf16[1], bf16[4,4], bf16[4,4], bf16[4,4], /*index=15*/bf16[4,4], bf16[1,4], bf16[1,4], bf16[4], bf16[4], /*index=20*/bf16[4], bf16[4], bf16[1], bf16[1], bf16[1]) {
  %p20.254 = bf16[4,4]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p19.253 = bf16[] parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.255 = bf16[4,4]{1,0} broadcast(bf16[] %p19.253), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.256 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p20.254, bf16[4,4]{1,0} %broadcast.255), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p18.252 = bf16[] parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.257 = bf16[4,4]{1,0} broadcast(bf16[] %p18.252), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.259 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.256, bf16[4,4]{1,0} %broadcast.257), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.260 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p20.254, bf16[4,4]{1,0} %multiply.259), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p17.243 = bf16[4,4]{1,0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p16.242 = bf16[] parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.244 = bf16[4,4]{1,0} broadcast(bf16[] %p16.242), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.245 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p17.243, bf16[4,4]{1,0} %broadcast.244), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p6.135 = bf16[4,4]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=430}
  %convert.136 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.144 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %p6.135, bf16[] %convert.136), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.140, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.145 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.144), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %constant.5 = bf16[1]{0} constant({1})
  %p7.159 = bf16[1]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.148 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.145, bf16[4,4]{1,0} %get-tuple-element.145), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.149 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.155 = bf16[] reduce(bf16[4,4]{1,0} %multiply.148, bf16[] %constant.149), dimensions={0,1}, to_apply=%AddComputation.151, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.156 = bf16[] sqrt(bf16[] %reduce.155), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.158 = bf16[] multiply(bf16[] %sqrt.156, bf16[] %sqrt.156), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.5 = bf16[1]{0} reshape(bf16[] %multiply.158), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.161 = bf16[1]{0} add(bf16[1]{0} %p7.159, bf16[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p5.109 = bf16[4,4]{1,0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %convert.110 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.118 = (bf16[4,4]{1,0}, bf16[]) reduce-scatter(bf16[4,4]{1,0} %p5.109, bf16[] %convert.110), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.114, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.119 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %reduce-scatter.118), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.122 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.119, bf16[4,4]{1,0} %get-tuple-element.119), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.123 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.129 = bf16[] reduce(bf16[4,4]{1,0} %multiply.122, bf16[] %constant.123), dimensions={0,1}, to_apply=%AddComputation.125, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.130 = bf16[] sqrt(bf16[] %reduce.129), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.132 = bf16[] multiply(bf16[] %sqrt.130, bf16[] %sqrt.130), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.6 = bf16[1]{0} reshape(bf16[] %multiply.132), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.163 = bf16[1]{0} add(bf16[1]{0} %add.161, bf16[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p4.83 = bf16[1,4]{1,0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %convert.84 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.92 = (bf16[1,4]{1,0}, bf16[]) reduce-scatter(bf16[1,4]{1,0} %p4.83, bf16[] %convert.84), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.88, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.93 = bf16[1,4]{1,0} get-tuple-element((bf16[1,4]{1,0}, bf16[]) %reduce-scatter.92), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.96 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.93, bf16[1,4]{1,0} %get-tuple-element.93), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.97 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.103 = bf16[] reduce(bf16[1,4]{1,0} %multiply.96, bf16[] %constant.97), dimensions={0,1}, to_apply=%AddComputation.99, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.104 = bf16[] sqrt(bf16[] %reduce.103), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.106 = bf16[] multiply(bf16[] %sqrt.104, bf16[] %sqrt.104), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.7 = bf16[1]{0} reshape(bf16[] %multiply.106), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.165 = bf16[1]{0} add(bf16[1]{0} %add.163, bf16[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p3.57 = bf16[4]{0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %convert.58 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.66 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %p3.57, bf16[] %convert.58), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.62, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.67 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.66), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.70 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.67, bf16[4]{0} %get-tuple-element.67), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.71 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.77 = bf16[] reduce(bf16[4]{0} %multiply.70, bf16[] %constant.71), dimensions={0}, to_apply=%AddComputation.73, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.78 = bf16[] sqrt(bf16[] %reduce.77), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.80 = bf16[] multiply(bf16[] %sqrt.78, bf16[] %sqrt.78), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.8 = bf16[1]{0} reshape(bf16[] %multiply.80), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.167 = bf16[1]{0} add(bf16[1]{0} %add.165, bf16[1]{0} %reshape.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p2.31 = bf16[4]{0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %convert.32 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.40 = (bf16[4]{0}, bf16[]) reduce-scatter(bf16[4]{0} %p2.31, bf16[] %convert.32), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.36, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.41 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %reduce-scatter.40), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.44 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.41, bf16[4]{0} %get-tuple-element.41), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.45 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.51 = bf16[] reduce(bf16[4]{0} %multiply.44, bf16[] %constant.45), dimensions={0}, to_apply=%AddComputation.47, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.52 = bf16[] sqrt(bf16[] %reduce.51), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.54 = bf16[] multiply(bf16[] %sqrt.52, bf16[] %sqrt.52), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.9 = bf16[1]{0} reshape(bf16[] %multiply.54), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.169 = bf16[1]{0} add(bf16[1]{0} %add.167, bf16[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p1.5 = bf16[1]{0} parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %convert.6 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.14 = (bf16[1]{0}, bf16[]) reduce-scatter(bf16[1]{0} %p1.5, bf16[] %convert.6), replica_groups={{0},{1}}, dimensions={0}, to_apply=%AddComputation.10, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.15 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %reduce-scatter.14), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.10 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.15, bf16[1]{0} %get-tuple-element.15), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.171 = bf16[1]{0} add(bf16[1]{0} %add.169, bf16[1]{0} %multiply.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %convert.174 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.182 = (bf16[1]{0}, bf16[]) all-reduce(bf16[1]{0} %add.171, bf16[] %convert.174), replica_groups={}, to_apply=%AddComputation.178, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.183 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.182), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.7 = bf16[1]{0} constant({0.5})
  %power.202 = bf16[1]{0} power(bf16[1]{0} %get-tuple-element.183, bf16[1]{0} %constant.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p12.197 = bf16[] parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %p12.197), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.204 = bf16[1]{0} add(bf16[1]{0} %power.202, bf16[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.207 = bf16[1]{0} divide(bf16[1]{0} %constant.5, bf16[1]{0} %add.204), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.33 = bf16[1]{0} constant({1})
  %compare.214 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.33), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.34 = bf16[1]{0} constant({1})
  %select.216 = bf16[1]{0} select(pred[1]{0} %compare.214, bf16[1]{0} %divide.207, bf16[1]{0} %constant.34), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.218 = bf16[] reshape(bf16[1]{0} %select.216), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.220 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.218), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.221 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.145, bf16[4,4]{1,0} %broadcast.220), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p15.236 = bf16[] parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.240 = bf16[4,4]{1,0} broadcast(bf16[] %p15.236), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.241 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.221, bf16[4,4]{1,0} %broadcast.240), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.246 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.245, bf16[4,4]{1,0} %multiply.241), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p14.223 = bf16[4,4]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p13.222 = bf16[] parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.224 = bf16[4,4]{1,0} broadcast(bf16[] %p13.222), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.225 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p14.223, bf16[4,4]{1,0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.227 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.221, bf16[4,4]{1,0} %multiply.221), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p11.191 = f32[] parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.226 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.228 = bf16[4,4]{1,0} broadcast(bf16[] %convert.226), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.229 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.227, bf16[4,4]{1,0} %broadcast.228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.230 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.225, bf16[4,4]{1,0} %multiply.229), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.231 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.230), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p10.190 = bf16[] parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.232 = bf16[4,4]{1,0} broadcast(bf16[] %p10.190), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.233 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.231, bf16[4,4]{1,0} %broadcast.232), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p9.188 = bf16[] parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.234 = bf16[4,4]{1,0} broadcast(bf16[] %p9.188), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.235 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.233, bf16[4,4]{1,0} %broadcast.234), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.262 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.246, bf16[4,4]{1,0} %add.235), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p8.186 = f32[] parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.261 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.263 = bf16[4,4]{1,0} broadcast(bf16[] %convert.261), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.264 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.262, bf16[4,4]{1,0} %broadcast.263), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.265 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.260, bf16[4,4]{1,0} %multiply.264), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.269 = bf16[] get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.182), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-gather.270 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.265, bf16[] %get-tuple-element.269), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.271 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.270), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p29.447 = bf16[4]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.448 = bf16[4]{0} broadcast(bf16[] %p19.253), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.449 = bf16[4]{0} multiply(bf16[4]{0} %p29.447, bf16[4]{0} %broadcast.448), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.18 = bf16[] constant(0)
  %broadcast.1 = bf16[4]{0} broadcast(bf16[] %constant.18), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.452 = bf16[4]{0} multiply(bf16[4]{0} %multiply.449, bf16[4]{0} %broadcast.1), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.453 = bf16[4]{0} subtract(bf16[4]{0} %p29.447, bf16[4]{0} %multiply.452), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p28.437 = bf16[4]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.438 = bf16[4]{0} broadcast(bf16[] %p16.242), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.439 = bf16[4]{0} multiply(bf16[4]{0} %p28.437, bf16[4]{0} %broadcast.438), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.22 = bf16[1]{0} constant({1})
  %compare.412 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.22), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.23 = bf16[1]{0} constant({1})
  %select.414 = bf16[1]{0} select(pred[1]{0} %compare.412, bf16[1]{0} %divide.207, bf16[1]{0} %constant.23), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.416 = bf16[] reshape(bf16[1]{0} %select.414), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.417 = bf16[4]{0} broadcast(bf16[] %reshape.416), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.418 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.67, bf16[4]{0} %broadcast.417), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.435 = bf16[4]{0} broadcast(bf16[] %p15.236), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.436 = bf16[4]{0} multiply(bf16[4]{0} %multiply.418, bf16[4]{0} %broadcast.435), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.440 = bf16[4]{0} add(bf16[4]{0} %multiply.439, bf16[4]{0} %multiply.436), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p27.419 = bf16[4]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.420 = bf16[4]{0} broadcast(bf16[] %p13.222), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.421 = bf16[4]{0} multiply(bf16[4]{0} %p27.419, bf16[4]{0} %broadcast.420), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.423 = bf16[4]{0} multiply(bf16[4]{0} %multiply.418, bf16[4]{0} %multiply.418), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.422 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.424 = bf16[4]{0} broadcast(bf16[] %convert.422), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.425 = bf16[4]{0} multiply(bf16[4]{0} %multiply.423, bf16[4]{0} %broadcast.424), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.426 = bf16[4]{0} add(bf16[4]{0} %multiply.421, bf16[4]{0} %multiply.425), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.427 = bf16[4]{0} sqrt(bf16[4]{0} %add.426), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.428 = bf16[4]{0} broadcast(bf16[] %p10.190), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.429 = bf16[4]{0} divide(bf16[4]{0} %sqrt.427, bf16[4]{0} %broadcast.428), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.430 = bf16[4]{0} broadcast(bf16[] %p9.188), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.431 = bf16[4]{0} add(bf16[4]{0} %divide.429, bf16[4]{0} %broadcast.430), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.455 = bf16[4]{0} divide(bf16[4]{0} %add.440, bf16[4]{0} %add.431), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.454 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.456 = bf16[4]{0} broadcast(bf16[] %convert.454), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.457 = bf16[4]{0} multiply(bf16[4]{0} %divide.455, bf16[4]{0} %broadcast.456), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.458 = bf16[4]{0} add(bf16[4]{0} %subtract.453, bf16[4]{0} %multiply.457), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p26.383 = bf16[1,4]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.384 = bf16[1,4]{1,0} broadcast(bf16[] %p19.253), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.385 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p26.383, bf16[1,4]{1,0} %broadcast.384), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.386 = bf16[1,4]{1,0} broadcast(bf16[] %p18.252), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.388 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.385, bf16[1,4]{1,0} %broadcast.386), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.389 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p26.383, bf16[1,4]{1,0} %multiply.388), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p25.374 = bf16[1,4]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.375 = bf16[1,4]{1,0} broadcast(bf16[] %p16.242), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.376 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p25.374, bf16[1,4]{1,0} %broadcast.375), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.25 = bf16[1]{0} constant({1})
  %compare.348 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.26 = bf16[1]{0} constant({1})
  %select.350 = bf16[1]{0} select(pred[1]{0} %compare.348, bf16[1]{0} %divide.207, bf16[1]{0} %constant.26), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.352 = bf16[] reshape(bf16[1]{0} %select.350), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.9 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.352), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.355 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %get-tuple-element.93, bf16[1,4]{1,0} %broadcast.9), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.372 = bf16[1,4]{1,0} broadcast(bf16[] %p15.236), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.373 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.355, bf16[1,4]{1,0} %broadcast.372), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.377 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.376, bf16[1,4]{1,0} %multiply.373), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p24.356 = bf16[1,4]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.357 = bf16[1,4]{1,0} broadcast(bf16[] %p13.222), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.358 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p24.356, bf16[1,4]{1,0} %broadcast.357), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.360 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.355, bf16[1,4]{1,0} %multiply.355), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.359 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.361 = bf16[1,4]{1,0} broadcast(bf16[] %convert.359), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.362 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.360, bf16[1,4]{1,0} %broadcast.361), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.363 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %multiply.358, bf16[1,4]{1,0} %multiply.362), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.364 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.363), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.365 = bf16[1,4]{1,0} broadcast(bf16[] %p10.190), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.366 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.364, bf16[1,4]{1,0} %broadcast.365), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.367 = bf16[1,4]{1,0} broadcast(bf16[] %p9.188), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.368 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.366, bf16[1,4]{1,0} %broadcast.367), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.391 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.377, bf16[1,4]{1,0} %add.368), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.390 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.392 = bf16[1,4]{1,0} broadcast(bf16[] %convert.390), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.393 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.391, bf16[1,4]{1,0} %broadcast.392), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.394 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.389, bf16[1,4]{1,0} %multiply.393), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p23.319 = bf16[4,4]{1,0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.320 = bf16[4,4]{1,0} broadcast(bf16[] %p19.253), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.321 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p23.319, bf16[4,4]{1,0} %broadcast.320), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.322 = bf16[4,4]{1,0} broadcast(bf16[] %p18.252), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.324 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.321, bf16[4,4]{1,0} %broadcast.322), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.325 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p23.319, bf16[4,4]{1,0} %multiply.324), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p22.310 = bf16[4,4]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.311 = bf16[4,4]{1,0} broadcast(bf16[] %p16.242), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.312 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p22.310, bf16[4,4]{1,0} %broadcast.311), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.28 = bf16[1]{0} constant({1})
  %compare.284 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.28), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.31 = bf16[1]{0} constant({1})
  %select.286 = bf16[1]{0} select(pred[1]{0} %compare.284, bf16[1]{0} %divide.207, bf16[1]{0} %constant.31), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.288 = bf16[] reshape(bf16[1]{0} %select.286), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.290 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.288), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.291 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.119, bf16[4,4]{1,0} %broadcast.290), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.308 = bf16[4,4]{1,0} broadcast(bf16[] %p15.236), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.309 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.291, bf16[4,4]{1,0} %broadcast.308), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.313 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.312, bf16[4,4]{1,0} %multiply.309), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p21.292 = bf16[4,4]{1,0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.293 = bf16[4,4]{1,0} broadcast(bf16[] %p13.222), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.294 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p21.292, bf16[4,4]{1,0} %broadcast.293), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.296 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.291, bf16[4,4]{1,0} %multiply.291), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.295 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.297 = bf16[4,4]{1,0} broadcast(bf16[] %convert.295), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.298 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.296, bf16[4,4]{1,0} %broadcast.297), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.299 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.294, bf16[4,4]{1,0} %multiply.298), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.300 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.299), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.301 = bf16[4,4]{1,0} broadcast(bf16[] %p10.190), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.302 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.300, bf16[4,4]{1,0} %broadcast.301), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.303 = bf16[4,4]{1,0} broadcast(bf16[] %p9.188), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.304 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.302, bf16[4,4]{1,0} %broadcast.303), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.327 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.313, bf16[4,4]{1,0} %add.304), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.326 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.328 = bf16[4,4]{1,0} broadcast(bf16[] %convert.326), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.329 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.327, bf16[4,4]{1,0} %broadcast.328), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.330 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.325, bf16[4,4]{1,0} %multiply.329), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.334 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.270), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.335 = (bf16[4,4]{1,0}, bf16[]) all-gather(bf16[4,4]{1,0} %add.330, bf16[] %get-tuple-element.334), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.398 = bf16[] get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.335), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.399 = (bf16[1,4]{1,0}, bf16[]) all-gather(bf16[1,4]{1,0} %add.394, bf16[] %get-tuple-element.398), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.462 = bf16[] get-tuple-element((bf16[1,4]{1,0}, bf16[]) %all-gather.399), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.463 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.458, bf16[] %get-tuple-element.462), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.464 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.463), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.336 = bf16[4,4]{1,0} get-tuple-element((bf16[4,4]{1,0}, bf16[]) %all-gather.335), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p32.513 = bf16[4]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.514 = bf16[4]{0} broadcast(bf16[] %p19.253), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.515 = bf16[4]{0} multiply(bf16[4]{0} %p32.513, bf16[4]{0} %broadcast.514), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.13 = bf16[] constant(0)
  %broadcast = bf16[4]{0} broadcast(bf16[] %constant.13), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.518 = bf16[4]{0} multiply(bf16[4]{0} %multiply.515, bf16[4]{0} %broadcast), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.519 = bf16[4]{0} subtract(bf16[4]{0} %p32.513, bf16[4]{0} %multiply.518), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p31.503 = bf16[4]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.504 = bf16[4]{0} broadcast(bf16[] %p16.242), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.505 = bf16[4]{0} multiply(bf16[4]{0} %p31.503, bf16[4]{0} %broadcast.504), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.15 = bf16[1]{0} constant({1})
  %compare.478 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.15), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.16 = bf16[1]{0} constant({1})
  %select.480 = bf16[1]{0} select(pred[1]{0} %compare.478, bf16[1]{0} %divide.207, bf16[1]{0} %constant.16), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.482 = bf16[] reshape(bf16[1]{0} %select.480), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.483 = bf16[4]{0} broadcast(bf16[] %reshape.482), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.484 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.41, bf16[4]{0} %broadcast.483), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.501 = bf16[4]{0} broadcast(bf16[] %p15.236), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.502 = bf16[4]{0} multiply(bf16[4]{0} %multiply.484, bf16[4]{0} %broadcast.501), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.506 = bf16[4]{0} add(bf16[4]{0} %multiply.505, bf16[4]{0} %multiply.502), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p30.485 = bf16[4]{0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.486 = bf16[4]{0} broadcast(bf16[] %p13.222), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.487 = bf16[4]{0} multiply(bf16[4]{0} %p30.485, bf16[4]{0} %broadcast.486), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.489 = bf16[4]{0} multiply(bf16[4]{0} %multiply.484, bf16[4]{0} %multiply.484), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.488 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.490 = bf16[4]{0} broadcast(bf16[] %convert.488), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.491 = bf16[4]{0} multiply(bf16[4]{0} %multiply.489, bf16[4]{0} %broadcast.490), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.492 = bf16[4]{0} add(bf16[4]{0} %multiply.487, bf16[4]{0} %multiply.491), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.493 = bf16[4]{0} sqrt(bf16[4]{0} %add.492), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.494 = bf16[4]{0} broadcast(bf16[] %p10.190), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.495 = bf16[4]{0} divide(bf16[4]{0} %sqrt.493, bf16[4]{0} %broadcast.494), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.496 = bf16[4]{0} broadcast(bf16[] %p9.188), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.497 = bf16[4]{0} add(bf16[4]{0} %divide.495, bf16[4]{0} %broadcast.496), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.521 = bf16[4]{0} divide(bf16[4]{0} %add.506, bf16[4]{0} %add.497), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.520 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.522 = bf16[4]{0} broadcast(bf16[] %convert.520), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.523 = bf16[4]{0} multiply(bf16[4]{0} %divide.521, bf16[4]{0} %broadcast.522), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.524 = bf16[4]{0} add(bf16[4]{0} %subtract.519, bf16[4]{0} %multiply.523), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.528 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.463), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.529 = (bf16[4]{0}, bf16[]) all-gather(bf16[4]{0} %add.524, bf16[] %get-tuple-element.528), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.530 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.529), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.400 = bf16[1,4]{1,0} get-tuple-element((bf16[1,4]{1,0}, bf16[]) %all-gather.399), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p35.572 = bf16[1]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape = bf16[1]{0} reshape(bf16[] %p19.253), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.574 = bf16[1]{0} multiply(bf16[1]{0} %p35.572, bf16[1]{0} %reshape), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant = bf16[1]{0} constant({0})
  %multiply.577 = bf16[1]{0} multiply(bf16[1]{0} %multiply.574, bf16[1]{0} %constant), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.578 = bf16[1]{0} subtract(bf16[1]{0} %p35.572, bf16[1]{0} %multiply.577), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p34.564 = bf16[1]{0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.3 = bf16[1]{0} reshape(bf16[] %p16.242), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.566 = bf16[1]{0} multiply(bf16[1]{0} %p34.564, bf16[1]{0} %reshape.3), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.10 = bf16[1]{0} constant({1})
  %compare.544 = pred[1]{0} compare(bf16[1]{0} %divide.207, bf16[1]{0} %constant.10), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.11 = bf16[1]{0} constant({1})
  %select.546 = bf16[1]{0} select(pred[1]{0} %compare.544, bf16[1]{0} %divide.207, bf16[1]{0} %constant.11), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.547 = bf16[1]{0} multiply(bf16[1]{0} %get-tuple-element.15, bf16[1]{0} %select.546), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.20 = bf16[1]{0} reshape(bf16[] %p15.236), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.563 = bf16[1]{0} multiply(bf16[1]{0} %multiply.547, bf16[1]{0} %reshape.20), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.567 = bf16[1]{0} add(bf16[1]{0} %multiply.566, bf16[1]{0} %multiply.563), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p33.548 = bf16[1]{0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.21 = bf16[1]{0} reshape(bf16[] %p13.222), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.550 = bf16[1]{0} multiply(bf16[1]{0} %p33.548, bf16[1]{0} %reshape.21), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.552 = bf16[1]{0} multiply(bf16[1]{0} %multiply.547, bf16[1]{0} %multiply.547), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.551 = bf16[] convert(f32[] %p11.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.22 = bf16[1]{0} reshape(bf16[] %convert.551), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.554 = bf16[1]{0} multiply(bf16[1]{0} %multiply.552, bf16[1]{0} %reshape.22), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.555 = bf16[1]{0} add(bf16[1]{0} %multiply.550, bf16[1]{0} %multiply.554), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.556 = bf16[1]{0} sqrt(bf16[1]{0} %add.555), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.23 = bf16[1]{0} reshape(bf16[] %p10.190), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.558 = bf16[1]{0} divide(bf16[1]{0} %sqrt.556, bf16[1]{0} %reshape.23), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.24 = bf16[1]{0} reshape(bf16[] %p9.188), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.560 = bf16[1]{0} add(bf16[1]{0} %divide.558, bf16[1]{0} %reshape.24), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.580 = bf16[1]{0} divide(bf16[1]{0} %add.567, bf16[1]{0} %add.560), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.579 = bf16[] convert(f32[] %p8.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.25 = bf16[1]{0} reshape(bf16[] %convert.579), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.582 = bf16[1]{0} multiply(bf16[1]{0} %divide.580, bf16[1]{0} %reshape.25), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.583 = bf16[1]{0} add(bf16[1]{0} %subtract.578, bf16[1]{0} %multiply.582), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.587 = bf16[] get-tuple-element((bf16[4]{0}, bf16[]) %all-gather.529), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.588 = (bf16[1]{0}, bf16[]) all-gather(bf16[1]{0} %add.583, bf16[] %get-tuple-element.587), replica_groups={{0},{1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.589 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-gather.588), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  ROOT %tuple.593 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[1,4]{1,0}, /*index=5*/bf16[1]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[4]{0}, /*index=10*/bf16[4]{0}, bf16[1]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=15*/bf16[4,4]{1,0}, bf16[1,4]{1,0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4]{0}, /*index=20*/bf16[4]{0}, bf16[4]{0}, bf16[1]{0}, bf16[1]{0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %get-tuple-element.271, bf16[4]{0} %get-tuple-element.464, bf16[4,4]{1,0} %get-tuple-element.336, bf16[4]{0} %get-tuple-element.530, bf16[1,4]{1,0} %get-tuple-element.400, /*index=5*/bf16[1]{0} %get-tuple-element.589, bf16[4,4]{1,0} %add.265, bf16[4,4]{1,0} %add.330, bf16[1,4]{1,0} %add.394, bf16[4]{0} %add.458, /*index=10*/bf16[4]{0} %add.524, bf16[1]{0} %add.583, bf16[4,4]{1,0} %add.246, bf16[4,4]{1,0} %add.230, bf16[4,4]{1,0} %add.313, /*index=15*/bf16[4,4]{1,0} %add.299, bf16[1,4]{1,0} %add.377, bf16[1,4]{1,0} %add.363, bf16[4]{0} %add.440, bf16[4]{0} %add.426, /*index=20*/bf16[4]{0} %add.506, bf16[4]{0} %add.492, bf16[1]{0} %add.567, bf16[1]{0} %add.555, bf16[1]{0} %power.202), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24"}
}


`

export default text;
