const text = `
HloModule SyncTensorsGraph.1084, input_output_alias={ {0}: (15, {}, must-alias), {1}: (14, {}, must-alias), {2}: (10, {}, must-alias), {3}: (13, {}, must-alias), {4}: (9, {}, must-alias), {5}: (12, {}, must-alias), {6}: (8, {}, must-alias), {7}: (11, {}, must-alias), {8}: (7, {}, must-alias), {9}: (23, {}, must-alias), {10}: (16, {}, must-alias) }

%AddComputation.34 (x.35: bf16[], y.36: bf16[]) -> bf16[] {
  %x.35 = bf16[] parameter(0)
  %y.36 = bf16[] parameter(1)
  ROOT %add.37 = bf16[] add(bf16[] %x.35, bf16[] %y.36)
}

%AddComputation.77 (x.78: bf16[], y.79: bf16[]) -> bf16[] {
  %x.78 = bf16[] parameter(0)
  %y.79 = bf16[] parameter(1)
  ROOT %add.80 = bf16[] add(bf16[] %x.78, bf16[] %y.79)
}

%AddComputation.96 (x.97: bf16[], y.98: bf16[]) -> bf16[] {
  %x.97 = bf16[] parameter(0)
  %y.98 = bf16[] parameter(1)
  ROOT %add.99 = bf16[] add(bf16[] %x.97, bf16[] %y.98)
}

%AddComputation.120 (x.121: bf16[], y.122: bf16[]) -> bf16[] {
  %x.121 = bf16[] parameter(0)
  %y.122 = bf16[] parameter(1)
  ROOT %add.123 = bf16[] add(bf16[] %x.121, bf16[] %y.122)
}

%AddComputation.139 (x.140: bf16[], y.141: bf16[]) -> bf16[] {
  %x.140 = bf16[] parameter(0)
  %y.141 = bf16[] parameter(1)
  ROOT %add.142 = bf16[] add(bf16[] %x.140, bf16[] %y.141)
}

%AddComputation.163 (x.164: bf16[], y.165: bf16[]) -> bf16[] {
  %x.164 = bf16[] parameter(0)
  %y.165 = bf16[] parameter(1)
  ROOT %add.166 = bf16[] add(bf16[] %x.164, bf16[] %y.165)
}

%AddComputation.182 (x.183: bf16[], y.184: bf16[]) -> bf16[] {
  %x.183 = bf16[] parameter(0)
  %y.184 = bf16[] parameter(1)
  ROOT %add.185 = bf16[] add(bf16[] %x.183, bf16[] %y.184)
}

%AddComputation.206 (x.207: bf16[], y.208: bf16[]) -> bf16[] {
  %x.207 = bf16[] parameter(0)
  %y.208 = bf16[] parameter(1)
  ROOT %add.209 = bf16[] add(bf16[] %x.207, bf16[] %y.208)
}

%AddComputation.225 (x.226: bf16[], y.227: bf16[]) -> bf16[] {
  %x.226 = bf16[] parameter(0)
  %y.227 = bf16[] parameter(1)
  ROOT %add.228 = bf16[] add(bf16[] %x.226, bf16[] %y.227)
}

%AddComputation.320 (x.321: bf16[], y.322: bf16[]) -> bf16[] {
  %x.321 = bf16[] parameter(0)
  %y.322 = bf16[] parameter(1)
  ROOT %add.323 = bf16[] add(bf16[] %x.321, bf16[] %y.322)
}

%AddComputation.346 (x.347: bf16[], y.348: bf16[]) -> bf16[] {
  %x.347 = bf16[] parameter(0)
  %y.348 = bf16[] parameter(1)
  ROOT %add.349 = bf16[] add(bf16[] %x.347, bf16[] %y.348)
}

%AddComputation.372 (x.373: bf16[], y.374: bf16[]) -> bf16[] {
  %x.373 = bf16[] parameter(0)
  %y.374 = bf16[] parameter(1)
  ROOT %add.375 = bf16[] add(bf16[] %x.373, bf16[] %y.374)
}

%AddComputation.398 (x.399: bf16[], y.400: bf16[]) -> bf16[] {
  %x.399 = bf16[] parameter(0)
  %y.400 = bf16[] parameter(1)
  ROOT %add.401 = bf16[] add(bf16[] %x.399, bf16[] %y.400)
}

%AddComputation.424 (x.425: bf16[], y.426: bf16[]) -> bf16[] {
  %x.425 = bf16[] parameter(0)
  %y.426 = bf16[] parameter(1)
  ROOT %add.427 = bf16[] add(bf16[] %x.425, bf16[] %y.426)
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.1084 (p0.1: f32[], p1.3: bf16[], p2.5: bf16[], p3.6: f32[], p4.12: bf16[], p5.21: bf16[], p6.22: bf16[], p7.64: bf16[1,4], p8.107: bf16[4,4], p9.150: bf16[4,4], p10.193: bf16[4,4], p11.236: bf16[4], p12.245: bf16[4], p13.254: bf16[4], p14.263: bf16[4], p15.271: bf16[4,4], p16.280: bf16[4,4], p17.432: bf16[1], p18.475: bf16[], p19.493: bf16[], p20.499: bf16[], p21.513: bf16[], p22.514: bf16[], p23.1071: bf16[1]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4,4], /*index=5*/bf16[4], bf16[4,4], bf16[4], bf16[1,4], bf16[1], /*index=10*/bf16[4,4], bf16[1], bf16[1,4], bf16[4], bf16[4,4], /*index=15*/bf16[4], bf16[4,4], bf16[4], bf16[4,4], bf16[4], /*index=20*/bf16[4,4], bf16[1], bf16[4,4], bf16[4,4], bf16[4,4], /*index=25*/bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=30*/bf16[1,4], bf16[1,4], bf16[4], bf16[4], bf16[4], /*index=35*/bf16[4], bf16[4], bf16[4], bf16[4], bf16[4], /*index=40*/bf16[1], bf16[1]) {
  %p15.271 = bf16[4,4]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %p22.514 = bf16[] parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.515 = bf16[4,4]{1,0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.516 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p15.271, bf16[4,4]{1,0} %broadcast.515), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p21.513 = bf16[] parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.517 = bf16[4,4]{1,0} broadcast(bf16[] %p21.513), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.519 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.516, bf16[4,4]{1,0} %broadcast.517), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.520 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p15.271, bf16[4,4]{1,0} %multiply.519), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.1 = bf16[] constant(0)
  %p20.499 = bf16[] parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.0 = bf16[] multiply(bf16[] %constant.1, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %p6.22 = bf16[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %p5.21 = bf16[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data"}
  %divide.1 = bf16[] divide(bf16[] %p6.22, bf16[] %p5.21), metadata={op_type="aten__div" op_name="aten__div"}
  %broadcast.124 = bf16[1,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p7.64 = bf16[1,4]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.19 = bf16[1,4]{1,0} custom-call(bf16[1,4]{1,0} %p7.64), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.44 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %broadcast.124, bf16[1,4]{1,0} %custom-call.19), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.304 = bf16[4]{0} reshape(bf16[1,4]{1,0} %multiply.44), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.12 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %reshape.304), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p8.107 = bf16[4,4]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.20 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p8.107), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.117 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %broadcast.12, bf16[4,4]{1,0} %custom-call.20), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p9.150 = bf16[4,4]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.21 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p9.150), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.160 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.117, bf16[4,4]{1,0} %custom-call.21), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p10.193 = bf16[4,4]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.22 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p10.193), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %dot.203 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %dot.160, bf16[4,4]{1,0} %custom-call.22), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p16.280 = bf16[4,4]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model_nxd.py" source_line=155}
  %transpose.409 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %p16.280), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.1 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.203, bf16[4,4]{0,1} %transpose.409), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.23 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.1), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.3 = bf16[1]{0} constant({1})
  %p17.432 = bf16[1]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.421 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.23, bf16[4,4]{1,0} %custom-call.23), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.422 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.428 = bf16[] reduce(bf16[4,4]{1,0} %multiply.421, bf16[] %constant.422), dimensions={0,1}, to_apply=%AddComputation.424, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.429 = bf16[] sqrt(bf16[] %reduce.428), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.431 = bf16[] multiply(bf16[] %sqrt.429, bf16[] %sqrt.429), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.431), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.434 = bf16[1]{0} add(bf16[1]{0} %p17.432, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %custom-call.24 = bf16[4,4]{1,0} custom-call(bf16[4,4]{1,0} %p15.271), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %transpose.279 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.24), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.281 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %p16.280, bf16[4,4]{0,1} %transpose.279), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p14.263 = bf16[4]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.25 = bf16[4]{0} custom-call(bf16[4]{0} %p14.263), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.285 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.25), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.286 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.281, bf16[4,4]{1,0} %broadcast.285), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.383 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.286), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.2 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.160, bf16[4,4]{0,1} %transpose.383), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.26 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.2), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.395 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.26, bf16[4,4]{1,0} %custom-call.26), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.396 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.402 = bf16[] reduce(bf16[4,4]{1,0} %multiply.395, bf16[] %constant.396), dimensions={0,1}, to_apply=%AddComputation.398, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.403 = bf16[] sqrt(bf16[] %reduce.402), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.405 = bf16[] multiply(bf16[] %sqrt.403, bf16[] %sqrt.403), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.17 = bf16[1]{0} reshape(bf16[] %multiply.405), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.436 = bf16[1]{0} add(bf16[1]{0} %add.434, bf16[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.262 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.22), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.287 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.286, bf16[4,4]{0,1} %transpose.262), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p13.254 = bf16[4]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.27 = bf16[4]{0} custom-call(bf16[4]{0} %p13.254), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.291 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.27), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.292 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.287, bf16[4,4]{1,0} %broadcast.291), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.357 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.292), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.3 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %dot.117, bf16[4,4]{0,1} %transpose.357), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.28 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.3), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.369 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.28, bf16[4,4]{1,0} %custom-call.28), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.370 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.376 = bf16[] reduce(bf16[4,4]{1,0} %multiply.369, bf16[] %constant.370), dimensions={0,1}, to_apply=%AddComputation.372, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.377 = bf16[] sqrt(bf16[] %reduce.376), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.379 = bf16[] multiply(bf16[] %sqrt.377, bf16[] %sqrt.377), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.20 = bf16[1]{0} reshape(bf16[] %multiply.379), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.438 = bf16[1]{0} add(bf16[1]{0} %add.436, bf16[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.253 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.21), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.293 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.292, bf16[4,4]{0,1} %transpose.253), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p12.245 = bf16[4]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.29 = bf16[4]{0} custom-call(bf16[4]{0} %p12.245), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.297 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.29), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.298 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.293, bf16[4,4]{1,0} %broadcast.297), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %transpose.331 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %add.298), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute"}
  %dot.4 = bf16[4,4]{0,1} dot(bf16[4,4]{1,0} %broadcast.12, bf16[4,4]{0,1} %transpose.331), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.30 = bf16[4,4]{1,0} custom-call(bf16[4,4]{0,1} %dot.4), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.343 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.30, bf16[4,4]{1,0} %custom-call.30), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.344 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.350 = bf16[] reduce(bf16[4,4]{1,0} %multiply.343, bf16[] %constant.344), dimensions={0,1}, to_apply=%AddComputation.346, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.351 = bf16[] sqrt(bf16[] %reduce.350), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.353 = bf16[] multiply(bf16[] %sqrt.351, bf16[] %sqrt.351), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.30 = bf16[1]{0} reshape(bf16[] %multiply.353), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.440 = bf16[1]{0} add(bf16[1]{0} %add.438, bf16[1]{0} %reshape.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %transpose.244 = bf16[4,4]{0,1} transpose(bf16[4,4]{1,0} %custom-call.20), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %dot.299 = bf16[4,4]{1,0} dot(bf16[4,4]{1,0} %add.298, bf16[4,4]{0,1} %transpose.244), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %p11.236 = bf16[4]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %custom-call.31 = bf16[4]{0} custom-call(bf16[4]{0} %p11.236), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.303 = bf16[4,4]{1,0} broadcast(bf16[4]{0} %custom-call.31), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %add.304 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %dot.299, bf16[4,4]{1,0} %broadcast.303), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/linear.py" source_line=114}
  %broadcast.126 = bf16[4,4]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.47 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %add.304, bf16[4,4]{1,0} %broadcast.126)
  %convert.2 = f32[4,4]{1,0} convert(bf16[4,4]{1,0} %multiply.47)
  %constant = f32[] constant(0)
  %reduce = f32[4]{0} reduce(f32[4,4]{1,0} %convert.2, f32[] %constant), dimensions={0}, to_apply=%scalar_add_computation
  %convert.1 = bf16[4]{0} convert(f32[4]{0} %reduce), metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.35 = bf16[1,4]{0,1} reshape(bf16[4]{0} %convert.1), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.32 = bf16[1,4]{1,0} custom-call(bf16[1,4]{0,1} %reshape.35), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.317 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %custom-call.32, bf16[1,4]{1,0} %custom-call.32), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.318 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.324 = bf16[] reduce(bf16[1,4]{1,0} %multiply.317, bf16[] %constant.318), dimensions={0,1}, to_apply=%AddComputation.320, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.325 = bf16[] sqrt(bf16[] %reduce.324), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.327 = bf16[] multiply(bf16[] %sqrt.325, bf16[] %sqrt.325), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.36 = bf16[1]{0} reshape(bf16[] %multiply.327), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.442 = bf16[1]{0} add(bf16[1]{0} %add.440, bf16[1]{0} %reshape.36), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.204 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.210 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.203, bf16[] %constant.204), dimensions={0}, to_apply=%AddComputation.206, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.33 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.210), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.222 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.33, bf16[4]{0} %custom-call.33), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.223 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.229 = bf16[] reduce(bf16[4]{0} %multiply.222, bf16[] %constant.223), dimensions={0}, to_apply=%AddComputation.225, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.230 = bf16[] sqrt(bf16[] %reduce.229), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.232 = bf16[] multiply(bf16[] %sqrt.230, bf16[] %sqrt.230), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.38 = bf16[1]{0} reshape(bf16[] %multiply.232), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.444 = bf16[1]{0} add(bf16[1]{0} %add.442, bf16[1]{0} %reshape.38), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.161 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.167 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.160, bf16[] %constant.161), dimensions={0}, to_apply=%AddComputation.163, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.34 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.167), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.179 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.34, bf16[4]{0} %custom-call.34), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.180 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.186 = bf16[] reduce(bf16[4]{0} %multiply.179, bf16[] %constant.180), dimensions={0}, to_apply=%AddComputation.182, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.187 = bf16[] sqrt(bf16[] %reduce.186), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.189 = bf16[] multiply(bf16[] %sqrt.187, bf16[] %sqrt.187), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.42 = bf16[1]{0} reshape(bf16[] %multiply.189), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.446 = bf16[1]{0} add(bf16[1]{0} %add.444, bf16[1]{0} %reshape.42), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.118 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.124 = bf16[4]{0} reduce(bf16[4,4]{1,0} %dot.117, bf16[] %constant.118), dimensions={0}, to_apply=%AddComputation.120, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.35 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.124), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.136 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.35, bf16[4]{0} %custom-call.35), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.137 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.143 = bf16[] reduce(bf16[4]{0} %multiply.136, bf16[] %constant.137), dimensions={0}, to_apply=%AddComputation.139, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.144 = bf16[] sqrt(bf16[] %reduce.143), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.146 = bf16[] multiply(bf16[] %sqrt.144, bf16[] %sqrt.144), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.44 = bf16[1]{0} reshape(bf16[] %multiply.146), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.448 = bf16[1]{0} add(bf16[1]{0} %add.446, bf16[1]{0} %reshape.44), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.75 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.81 = bf16[4]{0} reduce(bf16[4,4]{1,0} %broadcast.12, bf16[] %constant.75), dimensions={0}, to_apply=%AddComputation.77, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.36 = bf16[4]{0} custom-call(bf16[4]{0} %reduce.81), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.93 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.36, bf16[4]{0} %custom-call.36), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.94 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.100 = bf16[] reduce(bf16[4]{0} %multiply.93, bf16[] %constant.94), dimensions={0}, to_apply=%AddComputation.96, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.101 = bf16[] sqrt(bf16[] %reduce.100), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.103 = bf16[] multiply(bf16[] %sqrt.101, bf16[] %sqrt.101), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.46 = bf16[1]{0} reshape(bf16[] %multiply.103), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.450 = bf16[1]{0} add(bf16[1]{0} %add.448, bf16[1]{0} %reshape.46), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %broadcast.4 = bf16[4,1]{1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand"}
  %constant.32 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum"}
  %reduce.38 = bf16[1]{0} reduce(bf16[4,1]{1,0} %broadcast.4, bf16[] %constant.32), dimensions={0}, to_apply=%AddComputation.34, metadata={op_type="aten__sum" op_name="aten__sum"}
  %custom-call.37 = bf16[1]{0} custom-call(bf16[1]{0} %reduce.38), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.48 = bf16[1]{0} multiply(bf16[1]{0} %custom-call.37, bf16[1]{0} %custom-call.37), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %add.452 = bf16[1]{0} add(bf16[1]{0} %add.450, bf16[1]{0} %multiply.48), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %constant.6 = bf16[1]{0} constant({0.5})
  %power.455 = bf16[1]{0} power(bf16[1]{0} %add.452, bf16[1]{0} %constant.6), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p4.12 = bf16[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.53 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.457 = bf16[1]{0} add(bf16[1]{0} %power.455, bf16[1]{0} %reshape.53), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.460 = bf16[1]{0} divide(bf16[1]{0} %constant.3, bf16[1]{0} %add.457), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.12 = bf16[1]{0} constant({1})
  %compare.467 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.12), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.13 = bf16[1]{0} constant({1})
  %select.469 = bf16[1]{0} select(pred[1]{0} %compare.467, bf16[1]{0} %divide.460, bf16[1]{0} %constant.13), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.471 = bf16[] reshape(bf16[1]{0} %select.469), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.473 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.471), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.474 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.23, bf16[4,4]{1,0} %broadcast.473), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p19.493 = bf16[] parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.497 = bf16[4,4]{1,0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.498 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.474, bf16[4,4]{1,0} %broadcast.497), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.507 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.2, bf16[4,4]{1,0} %multiply.498), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.15 = bf16[] constant(0)
  %p18.475 = bf16[] parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.15 = bf16[] multiply(bf16[] %constant.15, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.17 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.15), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.484 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.474, bf16[4,4]{1,0} %multiply.474), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.483 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.485 = bf16[4,4]{1,0} broadcast(bf16[] %convert.483), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.486 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.484, bf16[4,4]{1,0} %broadcast.485), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.487 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.17, bf16[4,4]{1,0} %multiply.486), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.488 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.487), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.489 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.490 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.488, bf16[4,4]{1,0} %broadcast.489), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = bf16[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.491 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.492 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.490, bf16[4,4]{1,0} %broadcast.491), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.522 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.507, bf16[4,4]{1,0} %add.492), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.521 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.523 = bf16[4,4]{1,0} broadcast(bf16[] %convert.521), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.524 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.522, bf16[4,4]{1,0} %broadcast.523), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.525 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.520, bf16[4,4]{1,0} %multiply.524), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.578 = bf16[4]{0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.579 = bf16[4]{0} multiply(bf16[4]{0} %p14.263, bf16[4]{0} %broadcast.578), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.21 = bf16[] constant(0)
  %broadcast.18 = bf16[4]{0} broadcast(bf16[] %constant.21), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.582 = bf16[4]{0} multiply(bf16[4]{0} %multiply.579, bf16[4]{0} %broadcast.18), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.583 = bf16[4]{0} subtract(bf16[4]{0} %p14.263, bf16[4]{0} %multiply.582), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.22 = bf16[] constant(0)
  %multiply.18 = bf16[] multiply(bf16[] %constant.22, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.21 = bf16[4]{0} broadcast(bf16[] %multiply.18), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.25 = bf16[1]{0} constant({1})
  %compare.535 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.26 = bf16[1]{0} constant({1})
  %select.537 = bf16[1]{0} select(pred[1]{0} %compare.535, bf16[1]{0} %divide.460, bf16[1]{0} %constant.26), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.539 = bf16[] reshape(bf16[1]{0} %select.537), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.540 = bf16[4]{0} broadcast(bf16[] %reshape.539), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.541 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.33, bf16[4]{0} %broadcast.540), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.562 = bf16[4]{0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.563 = bf16[4]{0} multiply(bf16[4]{0} %multiply.541, bf16[4]{0} %broadcast.562), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.571 = bf16[4]{0} add(bf16[4]{0} %broadcast.21, bf16[4]{0} %multiply.563), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.27 = bf16[] constant(0)
  %multiply.19 = bf16[] multiply(bf16[] %constant.27, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.25 = bf16[4]{0} broadcast(bf16[] %multiply.19), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.550 = bf16[4]{0} multiply(bf16[4]{0} %multiply.541, bf16[4]{0} %multiply.541), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.549 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.551 = bf16[4]{0} broadcast(bf16[] %convert.549), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.552 = bf16[4]{0} multiply(bf16[4]{0} %multiply.550, bf16[4]{0} %broadcast.551), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.553 = bf16[4]{0} add(bf16[4]{0} %broadcast.25, bf16[4]{0} %multiply.552), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.554 = bf16[4]{0} sqrt(bf16[4]{0} %add.553), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.555 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.556 = bf16[4]{0} divide(bf16[4]{0} %sqrt.554, bf16[4]{0} %broadcast.555), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.557 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.558 = bf16[4]{0} add(bf16[4]{0} %divide.556, bf16[4]{0} %broadcast.557), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.585 = bf16[4]{0} divide(bf16[4]{0} %add.571, bf16[4]{0} %add.558), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.584 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.586 = bf16[4]{0} broadcast(bf16[] %convert.584), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.587 = bf16[4]{0} multiply(bf16[4]{0} %divide.585, bf16[4]{0} %broadcast.586), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.588 = bf16[4]{0} add(bf16[4]{0} %subtract.583, bf16[4]{0} %multiply.587), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.641 = bf16[4,4]{1,0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.642 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p10.193, bf16[4,4]{1,0} %broadcast.641), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.643 = bf16[4,4]{1,0} broadcast(bf16[] %p21.513), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.645 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.642, bf16[4,4]{1,0} %broadcast.643), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.646 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p10.193, bf16[4,4]{1,0} %multiply.645), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.28 = bf16[] constant(0)
  %multiply.20 = bf16[] multiply(bf16[] %constant.28, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.31 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.20), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.30 = bf16[1]{0} constant({1})
  %compare.598 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.30), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.31 = bf16[1]{0} constant({1})
  %select.600 = bf16[1]{0} select(pred[1]{0} %compare.598, bf16[1]{0} %divide.460, bf16[1]{0} %constant.31), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.602 = bf16[] reshape(bf16[1]{0} %select.600), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.604 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.602), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.605 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.26, bf16[4,4]{1,0} %broadcast.604), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.626 = bf16[4,4]{1,0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.627 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.605, bf16[4,4]{1,0} %broadcast.626), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.635 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.31, bf16[4,4]{1,0} %multiply.627), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.34 = bf16[] constant(0)
  %multiply.21 = bf16[] multiply(bf16[] %constant.34, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.35 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.21), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.614 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.605, bf16[4,4]{1,0} %multiply.605), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.613 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.615 = bf16[4,4]{1,0} broadcast(bf16[] %convert.613), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.616 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.614, bf16[4,4]{1,0} %broadcast.615), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.617 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.35, bf16[4,4]{1,0} %multiply.616), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.618 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.617), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.619 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.620 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.618, bf16[4,4]{1,0} %broadcast.619), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.621 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.622 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.620, bf16[4,4]{1,0} %broadcast.621), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.648 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.635, bf16[4,4]{1,0} %add.622), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.647 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.649 = bf16[4,4]{1,0} broadcast(bf16[] %convert.647), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.650 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.648, bf16[4,4]{1,0} %broadcast.649), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.651 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.646, bf16[4,4]{1,0} %multiply.650), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.704 = bf16[4]{0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.705 = bf16[4]{0} multiply(bf16[4]{0} %p13.254, bf16[4]{0} %broadcast.704), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.36 = bf16[] constant(0)
  %broadcast.36 = bf16[4]{0} broadcast(bf16[] %constant.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.708 = bf16[4]{0} multiply(bf16[4]{0} %multiply.705, bf16[4]{0} %broadcast.36), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.709 = bf16[4]{0} subtract(bf16[4]{0} %p13.254, bf16[4]{0} %multiply.708), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.37 = bf16[] constant(0)
  %multiply.24 = bf16[] multiply(bf16[] %constant.37, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.39 = bf16[4]{0} broadcast(bf16[] %multiply.24), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.39 = bf16[1]{0} constant({1})
  %compare.661 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.39), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.40 = bf16[1]{0} constant({1})
  %select.663 = bf16[1]{0} select(pred[1]{0} %compare.661, bf16[1]{0} %divide.460, bf16[1]{0} %constant.40), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.665 = bf16[] reshape(bf16[1]{0} %select.663), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.666 = bf16[4]{0} broadcast(bf16[] %reshape.665), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.667 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.34, bf16[4]{0} %broadcast.666), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.688 = bf16[4]{0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.689 = bf16[4]{0} multiply(bf16[4]{0} %multiply.667, bf16[4]{0} %broadcast.688), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.697 = bf16[4]{0} add(bf16[4]{0} %broadcast.39, bf16[4]{0} %multiply.689), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.41 = bf16[] constant(0)
  %multiply.26 = bf16[] multiply(bf16[] %constant.41, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.42 = bf16[4]{0} broadcast(bf16[] %multiply.26), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.676 = bf16[4]{0} multiply(bf16[4]{0} %multiply.667, bf16[4]{0} %multiply.667), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.675 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.677 = bf16[4]{0} broadcast(bf16[] %convert.675), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.678 = bf16[4]{0} multiply(bf16[4]{0} %multiply.676, bf16[4]{0} %broadcast.677), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.679 = bf16[4]{0} add(bf16[4]{0} %broadcast.42, bf16[4]{0} %multiply.678), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.680 = bf16[4]{0} sqrt(bf16[4]{0} %add.679), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.681 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.682 = bf16[4]{0} divide(bf16[4]{0} %sqrt.680, bf16[4]{0} %broadcast.681), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.683 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.684 = bf16[4]{0} add(bf16[4]{0} %divide.682, bf16[4]{0} %broadcast.683), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.711 = bf16[4]{0} divide(bf16[4]{0} %add.697, bf16[4]{0} %add.684), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.710 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.712 = bf16[4]{0} broadcast(bf16[] %convert.710), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.713 = bf16[4]{0} multiply(bf16[4]{0} %divide.711, bf16[4]{0} %broadcast.712), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.714 = bf16[4]{0} add(bf16[4]{0} %subtract.709, bf16[4]{0} %multiply.713), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.767 = bf16[4,4]{1,0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.768 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p9.150, bf16[4,4]{1,0} %broadcast.767), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.769 = bf16[4,4]{1,0} broadcast(bf16[] %p21.513), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.771 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.768, bf16[4,4]{1,0} %broadcast.769), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.772 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p9.150, bf16[4,4]{1,0} %multiply.771), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.42 = bf16[] constant(0)
  %multiply.27 = bf16[] multiply(bf16[] %constant.42, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.45 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.27), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.44 = bf16[1]{0} constant({1})
  %compare.724 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.44), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.45 = bf16[1]{0} constant({1})
  %select.726 = bf16[1]{0} select(pred[1]{0} %compare.724, bf16[1]{0} %divide.460, bf16[1]{0} %constant.45), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.728 = bf16[] reshape(bf16[1]{0} %select.726), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.730 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.728), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.731 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.28, bf16[4,4]{1,0} %broadcast.730), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.752 = bf16[4,4]{1,0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.753 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.731, bf16[4,4]{1,0} %broadcast.752), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.761 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.45, bf16[4,4]{1,0} %multiply.753), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.46 = bf16[] constant(0)
  %multiply.28 = bf16[] multiply(bf16[] %constant.46, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.50 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.28), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.740 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.731, bf16[4,4]{1,0} %multiply.731), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.739 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.741 = bf16[4,4]{1,0} broadcast(bf16[] %convert.739), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.742 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.740, bf16[4,4]{1,0} %broadcast.741), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.743 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.50, bf16[4,4]{1,0} %multiply.742), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.744 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.743), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.745 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.746 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.744, bf16[4,4]{1,0} %broadcast.745), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.747 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.748 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.746, bf16[4,4]{1,0} %broadcast.747), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.774 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.761, bf16[4,4]{1,0} %add.748), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.773 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.775 = bf16[4,4]{1,0} broadcast(bf16[] %convert.773), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.776 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.774, bf16[4,4]{1,0} %broadcast.775), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.777 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.772, bf16[4,4]{1,0} %multiply.776), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.830 = bf16[4]{0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.831 = bf16[4]{0} multiply(bf16[4]{0} %p12.245, bf16[4]{0} %broadcast.830), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.48 = bf16[] constant(0)
  %broadcast.51 = bf16[4]{0} broadcast(bf16[] %constant.48), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.834 = bf16[4]{0} multiply(bf16[4]{0} %multiply.831, bf16[4]{0} %broadcast.51), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.835 = bf16[4]{0} subtract(bf16[4]{0} %p12.245, bf16[4]{0} %multiply.834), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.49 = bf16[] constant(0)
  %multiply.31 = bf16[] multiply(bf16[] %constant.49, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.54 = bf16[4]{0} broadcast(bf16[] %multiply.31), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.53 = bf16[1]{0} constant({1})
  %compare.787 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.53), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.54 = bf16[1]{0} constant({1})
  %select.789 = bf16[1]{0} select(pred[1]{0} %compare.787, bf16[1]{0} %divide.460, bf16[1]{0} %constant.54), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.791 = bf16[] reshape(bf16[1]{0} %select.789), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.792 = bf16[4]{0} broadcast(bf16[] %reshape.791), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.793 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.35, bf16[4]{0} %broadcast.792), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.814 = bf16[4]{0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.815 = bf16[4]{0} multiply(bf16[4]{0} %multiply.793, bf16[4]{0} %broadcast.814), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.823 = bf16[4]{0} add(bf16[4]{0} %broadcast.54, bf16[4]{0} %multiply.815), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.55 = bf16[] constant(0)
  %multiply.32 = bf16[] multiply(bf16[] %constant.55, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.57 = bf16[4]{0} broadcast(bf16[] %multiply.32), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.802 = bf16[4]{0} multiply(bf16[4]{0} %multiply.793, bf16[4]{0} %multiply.793), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.801 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.803 = bf16[4]{0} broadcast(bf16[] %convert.801), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.804 = bf16[4]{0} multiply(bf16[4]{0} %multiply.802, bf16[4]{0} %broadcast.803), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.805 = bf16[4]{0} add(bf16[4]{0} %broadcast.57, bf16[4]{0} %multiply.804), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.806 = bf16[4]{0} sqrt(bf16[4]{0} %add.805), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.807 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.808 = bf16[4]{0} divide(bf16[4]{0} %sqrt.806, bf16[4]{0} %broadcast.807), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.809 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.810 = bf16[4]{0} add(bf16[4]{0} %divide.808, bf16[4]{0} %broadcast.809), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.837 = bf16[4]{0} divide(bf16[4]{0} %add.823, bf16[4]{0} %add.810), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.836 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.838 = bf16[4]{0} broadcast(bf16[] %convert.836), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.839 = bf16[4]{0} multiply(bf16[4]{0} %divide.837, bf16[4]{0} %broadcast.838), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.840 = bf16[4]{0} add(bf16[4]{0} %subtract.835, bf16[4]{0} %multiply.839), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.893 = bf16[4,4]{1,0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.894 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p8.107, bf16[4,4]{1,0} %broadcast.893), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.895 = bf16[4,4]{1,0} broadcast(bf16[] %p21.513), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.897 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.894, bf16[4,4]{1,0} %broadcast.895), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.898 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p8.107, bf16[4,4]{1,0} %multiply.897), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.56 = bf16[] constant(0)
  %multiply.33 = bf16[] multiply(bf16[] %constant.56, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.60 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.33), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.58 = bf16[1]{0} constant({1})
  %compare.850 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.58), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.59 = bf16[1]{0} constant({1})
  %select.852 = bf16[1]{0} select(pred[1]{0} %compare.850, bf16[1]{0} %divide.460, bf16[1]{0} %constant.59), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.854 = bf16[] reshape(bf16[1]{0} %select.852), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.856 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.854), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.857 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %custom-call.30, bf16[4,4]{1,0} %broadcast.856), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.878 = bf16[4,4]{1,0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.879 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.857, bf16[4,4]{1,0} %broadcast.878), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.887 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.60, bf16[4,4]{1,0} %multiply.879), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.60 = bf16[] constant(0)
  %multiply.34 = bf16[] multiply(bf16[] %constant.60, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.64 = bf16[4,4]{1,0} broadcast(bf16[] %multiply.34), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.866 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.857, bf16[4,4]{1,0} %multiply.857), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.865 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.867 = bf16[4,4]{1,0} broadcast(bf16[] %convert.865), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.868 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.866, bf16[4,4]{1,0} %broadcast.867), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.869 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %broadcast.64, bf16[4,4]{1,0} %multiply.868), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.870 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.869), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.871 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.872 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.870, bf16[4,4]{1,0} %broadcast.871), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.873 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.874 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.872, bf16[4,4]{1,0} %broadcast.873), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.900 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.887, bf16[4,4]{1,0} %add.874), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.899 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.901 = bf16[4,4]{1,0} broadcast(bf16[] %convert.899), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.902 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.900, bf16[4,4]{1,0} %broadcast.901), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.903 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.898, bf16[4,4]{1,0} %multiply.902), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.956 = bf16[4]{0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.957 = bf16[4]{0} multiply(bf16[4]{0} %p11.236, bf16[4]{0} %broadcast.956), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.65 = bf16[] constant(0)
  %broadcast.65 = bf16[4]{0} broadcast(bf16[] %constant.65), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.960 = bf16[4]{0} multiply(bf16[4]{0} %multiply.957, bf16[4]{0} %broadcast.65), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.961 = bf16[4]{0} subtract(bf16[4]{0} %p11.236, bf16[4]{0} %multiply.960), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.66 = bf16[] constant(0)
  %multiply.37 = bf16[] multiply(bf16[] %constant.66, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.68 = bf16[4]{0} broadcast(bf16[] %multiply.37), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.68 = bf16[1]{0} constant({1})
  %compare.913 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.68), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.69 = bf16[1]{0} constant({1})
  %select.915 = bf16[1]{0} select(pred[1]{0} %compare.913, bf16[1]{0} %divide.460, bf16[1]{0} %constant.69), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.917 = bf16[] reshape(bf16[1]{0} %select.915), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.918 = bf16[4]{0} broadcast(bf16[] %reshape.917), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.919 = bf16[4]{0} multiply(bf16[4]{0} %custom-call.36, bf16[4]{0} %broadcast.918), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.940 = bf16[4]{0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.941 = bf16[4]{0} multiply(bf16[4]{0} %multiply.919, bf16[4]{0} %broadcast.940), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.949 = bf16[4]{0} add(bf16[4]{0} %broadcast.68, bf16[4]{0} %multiply.941), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.70 = bf16[] constant(0)
  %multiply.38 = bf16[] multiply(bf16[] %constant.70, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.71 = bf16[4]{0} broadcast(bf16[] %multiply.38), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.928 = bf16[4]{0} multiply(bf16[4]{0} %multiply.919, bf16[4]{0} %multiply.919), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.927 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.929 = bf16[4]{0} broadcast(bf16[] %convert.927), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.930 = bf16[4]{0} multiply(bf16[4]{0} %multiply.928, bf16[4]{0} %broadcast.929), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.931 = bf16[4]{0} add(bf16[4]{0} %broadcast.71, bf16[4]{0} %multiply.930), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.932 = bf16[4]{0} sqrt(bf16[4]{0} %add.931), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.933 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.934 = bf16[4]{0} divide(bf16[4]{0} %sqrt.932, bf16[4]{0} %broadcast.933), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.935 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.936 = bf16[4]{0} add(bf16[4]{0} %divide.934, bf16[4]{0} %broadcast.935), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.963 = bf16[4]{0} divide(bf16[4]{0} %add.949, bf16[4]{0} %add.936), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.962 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.964 = bf16[4]{0} broadcast(bf16[] %convert.962), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.965 = bf16[4]{0} multiply(bf16[4]{0} %divide.963, bf16[4]{0} %broadcast.964), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.966 = bf16[4]{0} add(bf16[4]{0} %subtract.961, bf16[4]{0} %multiply.965), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1019 = bf16[1,4]{1,0} broadcast(bf16[] %p22.514), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1020 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %p7.64, bf16[1,4]{1,0} %broadcast.1019), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1021 = bf16[1,4]{1,0} broadcast(bf16[] %p21.513), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1023 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.1020, bf16[1,4]{1,0} %broadcast.1021), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1024 = bf16[1,4]{1,0} subtract(bf16[1,4]{1,0} %p7.64, bf16[1,4]{1,0} %multiply.1023), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.85 = bf16[] constant(0)
  %multiply.45 = bf16[] multiply(bf16[] %constant.85, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.74 = bf16[1,4]{1,0} broadcast(bf16[] %multiply.45), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=121}
  %constant.73 = bf16[1]{0} constant({1})
  %compare.976 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.73), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.74 = bf16[1]{0} constant({1})
  %select.978 = bf16[1]{0} select(pred[1]{0} %compare.976, bf16[1]{0} %divide.460, bf16[1]{0} %constant.74), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.980 = bf16[] reshape(bf16[1]{0} %select.978), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.119 = bf16[1,4]{1,0} broadcast(bf16[] %reshape.980), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.983 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %custom-call.32, bf16[1,4]{1,0} %broadcast.119), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1004 = bf16[1,4]{1,0} broadcast(bf16[] %p19.493), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1005 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.983, bf16[1,4]{1,0} %broadcast.1004), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1013 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %broadcast.74, bf16[1,4]{1,0} %multiply.1005), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.86 = bf16[] constant(0)
  %multiply.46 = bf16[] multiply(bf16[] %constant.86, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.77 = bf16[1,4]{1,0} broadcast(bf16[] %multiply.46), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/adamw.py" source_line=125}
  %multiply.992 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.983, bf16[1,4]{1,0} %multiply.983), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.991 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.993 = bf16[1,4]{1,0} broadcast(bf16[] %convert.991), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.994 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %multiply.992, bf16[1,4]{1,0} %broadcast.993), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.995 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %broadcast.77, bf16[1,4]{1,0} %multiply.994), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.996 = bf16[1,4]{1,0} sqrt(bf16[1,4]{1,0} %add.995), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.997 = bf16[1,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.998 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %sqrt.996, bf16[1,4]{1,0} %broadcast.997), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.999 = bf16[1,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1000 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %divide.998, bf16[1,4]{1,0} %broadcast.999), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1026 = bf16[1,4]{1,0} divide(bf16[1,4]{1,0} %add.1013, bf16[1,4]{1,0} %add.1000), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1025 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1027 = bf16[1,4]{1,0} broadcast(bf16[] %convert.1025), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1028 = bf16[1,4]{1,0} multiply(bf16[1,4]{1,0} %divide.1026, bf16[1,4]{1,0} %broadcast.1027), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1029 = bf16[1,4]{1,0} add(bf16[1,4]{1,0} %subtract.1024, bf16[1,4]{1,0} %multiply.1028), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p23.1071 = bf16[1]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/pytorch/torch/nn/modules/module.py" source_line=1158}
  %reshape.186 = bf16[1]{0} reshape(bf16[] %p22.514), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1073 = bf16[1]{0} multiply(bf16[1]{0} %p23.1071, bf16[1]{0} %reshape.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.78 = bf16[1]{0} constant({0})
  %multiply.1076 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1073, bf16[1]{0} %constant.78), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1077 = bf16[1]{0} subtract(bf16[1]{0} %p23.1071, bf16[1]{0} %multiply.1076), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.87 = bf16[] constant(0)
  %multiply.43 = bf16[] multiply(bf16[] %constant.87, bf16[] %p20.499), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.295 = bf16[1]{0} reshape(bf16[] %multiply.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.82 = bf16[1]{0} constant({1})
  %compare.1039 = pred[1]{0} compare(bf16[1]{0} %divide.460, bf16[1]{0} %constant.82), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.83 = bf16[1]{0} constant({1})
  %select.1041 = bf16[1]{0} select(pred[1]{0} %compare.1039, bf16[1]{0} %divide.460, bf16[1]{0} %constant.83), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1042 = bf16[1]{0} multiply(bf16[1]{0} %custom-call.37, bf16[1]{0} %select.1041), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.195 = bf16[1]{0} reshape(bf16[] %p19.493), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1060 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1042, bf16[1]{0} %reshape.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1066 = bf16[1]{0} add(bf16[1]{0} %reshape.295, bf16[1]{0} %multiply.1060), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.88 = bf16[] constant(0)
  %multiply.42 = bf16[] multiply(bf16[] %constant.88, bf16[] %p18.475), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.291 = bf16[1]{0} reshape(bf16[] %multiply.42), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1049 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1042, bf16[1]{0} %multiply.1042), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1048 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.198 = bf16[1]{0} reshape(bf16[] %convert.1048), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1051 = bf16[1]{0} multiply(bf16[1]{0} %multiply.1049, bf16[1]{0} %reshape.198), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1052 = bf16[1]{0} add(bf16[1]{0} %reshape.291, bf16[1]{0} %multiply.1051), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1053 = bf16[1]{0} sqrt(bf16[1]{0} %add.1052), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.199 = bf16[1]{0} reshape(bf16[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1055 = bf16[1]{0} divide(bf16[1]{0} %sqrt.1053, bf16[1]{0} %reshape.199), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.200 = bf16[1]{0} reshape(bf16[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1057 = bf16[1]{0} add(bf16[1]{0} %divide.1055, bf16[1]{0} %reshape.200), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1079 = bf16[1]{0} divide(bf16[1]{0} %add.1066, bf16[1]{0} %add.1057), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1078 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.201 = bf16[1]{0} reshape(bf16[] %convert.1078), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1081 = bf16[1]{0} multiply(bf16[1]{0} %divide.1079, bf16[1]{0} %reshape.201), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1082 = bf16[1]{0} add(bf16[1]{0} %subtract.1077, bf16[1]{0} %multiply.1081), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.1083 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=5*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[1,4]{1,0}, bf16[1]{0}, /*index=10*/bf16[4,4]{1,0}, bf16[1]{0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, /*index=15*/bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, /*index=20*/bf16[4,4]{1,0}, bf16[1]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=25*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=30*/bf16[1,4]{1,0}, bf16[1,4]{1,0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=35*/bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=40*/bf16[1]{0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %add.525, bf16[4]{0} %add.588, bf16[4,4]{1,0} %add.651, bf16[4]{0} %add.714, bf16[4,4]{1,0} %add.777, /*index=5*/bf16[4]{0} %add.840, bf16[4,4]{1,0} %add.903, bf16[4]{0} %add.966, bf16[1,4]{1,0} %add.1029, bf16[1]{0} %add.1082, /*index=10*/bf16[4,4]{1,0} %p16.280, bf16[1]{0} %multiply.1042, bf16[1,4]{1,0} %multiply.983, bf16[4]{0} %multiply.919, bf16[4,4]{1,0} %multiply.857, /*index=15*/bf16[4]{0} %multiply.793, bf16[4,4]{1,0} %multiply.731, bf16[4]{0} %multiply.667, bf16[4,4]{1,0} %multiply.605, bf16[4]{0} %multiply.541, /*index=20*/bf16[4,4]{1,0} %multiply.474, bf16[1]{0} %power.455, bf16[4,4]{1,0} %add.507, bf16[4,4]{1,0} %add.487, bf16[4,4]{1,0} %add.635, /*index=25*/bf16[4,4]{1,0} %add.617, bf16[4,4]{1,0} %add.761, bf16[4,4]{1,0} %add.743, bf16[4,4]{1,0} %add.887, bf16[4,4]{1,0} %add.869, /*index=30*/bf16[1,4]{1,0} %add.1013, bf16[1,4]{1,0} %add.995, bf16[4]{0} %add.571, bf16[4]{0} %add.553, bf16[4]{0} %add.697, /*index=35*/bf16[4]{0} %add.679, bf16[4]{0} %add.823, bf16[4]{0} %add.805, bf16[4]{0} %add.949, bf16[4]{0} %add.931, /*index=40*/bf16[1]{0} %add.1066, bf16[1]{0} %add.1052), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41"}
}

`

export default text;
