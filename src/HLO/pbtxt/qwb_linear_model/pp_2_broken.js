const text = `
HloModule SyncTensorsGraph.361, input_output_alias={ {0}: (18, {}, must-alias), {1}: (21, {}, must-alias), {2}: (24, {}, must-alias), {3}: (27, {}, must-alias), {4}: (9, {}, must-alias), {5}: (7, {}, must-alias), {6}: (8, {}, must-alias), {7}: (6, {}, must-alias), {8}: (15, {}, must-alias), {9}: (12, {}, must-alias), {10}: (23, {}, must-alias), {11}: (22, {}, must-alias), {12}: (20, {}, must-alias), {13}: (19, {}, must-alias), {14}: (26, {}, must-alias), {15}: (25, {}, must-alias) }

%AddComputation.41 (x.42: bf16[], y.43: bf16[]) -> bf16[] {
  %x.42 = bf16[] parameter(0)
  %y.43 = bf16[] parameter(1)
  ROOT %add.44 = bf16[] add(bf16[] %x.42, bf16[] %y.43)
}

%AddComputation.58 (x.59: bf16[], y.60: bf16[]) -> bf16[] {
  %x.59 = bf16[] parameter(0)
  %y.60 = bf16[] parameter(1)
  ROOT %add.61 = bf16[] add(bf16[] %x.59, bf16[] %y.60)
}

%AddComputation.71 (x.72: bf16[], y.73: bf16[]) -> bf16[] {
  %x.72 = bf16[] parameter(0)
  %y.73 = bf16[] parameter(1)
  ROOT %add.74 = bf16[] add(bf16[] %x.72, bf16[] %y.73)
}

%AddComputation.84 (x.85: bf16[], y.86: bf16[]) -> bf16[] {
  %x.85 = bf16[] parameter(0)
  %y.86 = bf16[] parameter(1)
  ROOT %add.87 = bf16[] add(bf16[] %x.85, bf16[] %y.86)
}

%AddComputation.97 (x.98: bf16[], y.99: bf16[]) -> bf16[] {
  %x.98 = bf16[] parameter(0)
  %y.99 = bf16[] parameter(1)
  ROOT %add.100 = bf16[] add(bf16[] %x.98, bf16[] %y.99)
}

%AddComputation.120 (x.121: bf16[], y.122: bf16[]) -> bf16[] {
  %x.121 = bf16[] parameter(0)
  %y.122 = bf16[] parameter(1)
  ROOT %add.123 = bf16[] add(bf16[] %x.121, bf16[] %y.122)
}

ENTRY %SyncTensorsGraph.361 (p0.1: f32[], p1.3: bf16[], p2.5: bf16[], p3.6: f32[], p4.12: bf16[], p5.17: f32[], p6.19: bf16[4,4], p7.23: bf16[4,4], p8.27: bf16[4], p9.31: bf16[4], p10.105: bf16[1], p11.148: bf16[], p12.149: bf16[4,4], p13.162: bf16[], p14.168: bf16[], p15.169: bf16[4,4], p16.178: bf16[], p17.179: bf16[], p18.180: bf16[4,4], p19.208: bf16[4], p20.226: bf16[4], p21.236: bf16[4], p22.265: bf16[4,4], p23.283: bf16[4,4], p24.292: bf16[4,4], p25.320: bf16[4], p26.338: bf16[4], p27.348: bf16[4]) -> (bf16[4,4], bf16[4], bf16[4,4], bf16[4], bf16[4], /*index=5*/bf16[4,4], bf16[4], bf16[4,4], bf16[4,4], bf16[4,4], /*index=10*/bf16[4,4], bf16[4,4], bf16[4], bf16[4], bf16[4], /*index=15*/bf16[4], bf16[1]) {
  %p18.180 = bf16[4,4]{1,0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %p17.179 = bf16[] parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.181 = bf16[4,4]{1,0} broadcast(bf16[] %p17.179), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.182 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p18.180, bf16[4,4]{1,0} %broadcast.181), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p16.178 = bf16[] parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.183 = bf16[4,4]{1,0} broadcast(bf16[] %p16.178), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.185 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.182, bf16[4,4]{1,0} %broadcast.183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.186 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p18.180, bf16[4,4]{1,0} %multiply.185), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p15.169 = bf16[4,4]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p14.168 = bf16[] parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.170 = bf16[4,4]{1,0} broadcast(bf16[] %p14.168), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.171 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p15.169, bf16[4,4]{1,0} %broadcast.170), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p9.31 = bf16[4]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p8.27 = bf16[4]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p7.23 = bf16[4,4]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p6.19 = bf16[4,4]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=220}
  %p5.17 = f32[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %convert.34 = bf16[] convert(f32[] %p5.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.45 = (bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) all-reduce(bf16[4]{0} %p9.31, bf16[4]{0} %p8.27, bf16[4,4]{1,0} %p7.23, bf16[4,4]{1,0} %p6.19, bf16[] %convert.34), replica_groups={{0},{1}}, constrain_layout=true, to_apply=%AddComputation.41, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.49 = bf16[4,4]{1,0} get-tuple-element((bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) %all-reduce.45), index=3, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.1 = bf16[1]{0} constant({1})
  %p10.105 = bf16[1]{0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %multiply.94 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.49, bf16[4,4]{1,0} %get-tuple-element.49), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.95 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.101 = bf16[] reduce(bf16[4,4]{1,0} %multiply.94, bf16[] %constant.95), dimensions={0,1}, to_apply=%AddComputation.97, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.102 = bf16[] sqrt(bf16[] %reduce.101), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.104 = bf16[] multiply(bf16[] %sqrt.102, bf16[] %sqrt.102), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape = bf16[1]{0} reshape(bf16[] %multiply.104), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.107 = bf16[1]{0} add(bf16[1]{0} %p10.105, bf16[1]{0} %reshape), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.48 = bf16[4,4]{1,0} get-tuple-element((bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) %all-reduce.45), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.81 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.48, bf16[4,4]{1,0} %get-tuple-element.48), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.82 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.88 = bf16[] reduce(bf16[4,4]{1,0} %multiply.81, bf16[] %constant.82), dimensions={0,1}, to_apply=%AddComputation.84, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.89 = bf16[] sqrt(bf16[] %reduce.88), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.91 = bf16[] multiply(bf16[] %sqrt.89, bf16[] %sqrt.89), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.1 = bf16[1]{0} reshape(bf16[] %multiply.91), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.109 = bf16[1]{0} add(bf16[1]{0} %add.107, bf16[1]{0} %reshape.1), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.47 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) %all-reduce.45), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.68 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.47, bf16[4]{0} %get-tuple-element.47), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.69 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.75 = bf16[] reduce(bf16[4]{0} %multiply.68, bf16[] %constant.69), dimensions={0}, to_apply=%AddComputation.71, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.76 = bf16[] sqrt(bf16[] %reduce.75), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.78 = bf16[] multiply(bf16[] %sqrt.76, bf16[] %sqrt.76), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.2 = bf16[1]{0} reshape(bf16[] %multiply.78), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.111 = bf16[1]{0} add(bf16[1]{0} %add.109, bf16[1]{0} %reshape.2), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.46 = bf16[4]{0} get-tuple-element((bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) %all-reduce.45), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %multiply.55 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.46, bf16[4]{0} %get-tuple-element.46), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.56 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.62 = bf16[] reduce(bf16[4]{0} %multiply.55, bf16[] %constant.56), dimensions={0}, to_apply=%AddComputation.58, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.63 = bf16[] sqrt(bf16[] %reduce.62), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.65 = bf16[] multiply(bf16[] %sqrt.63, bf16[] %sqrt.63), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.3 = bf16[1]{0} reshape(bf16[] %multiply.65), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.113 = bf16[1]{0} add(bf16[1]{0} %add.111, bf16[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.119 = bf16[] get-tuple-element((bf16[4]{0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[]) %all-reduce.45), index=4, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.124 = (bf16[1]{0}, bf16[]) all-reduce(bf16[1]{0} %add.113, bf16[] %get-tuple-element.119), replica_groups={{0,1}}, to_apply=%AddComputation.120, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.125 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.124), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.3 = bf16[1]{0} constant({0.5})
  %power.128 = bf16[1]{0} power(bf16[1]{0} %get-tuple-element.125, bf16[1]{0} %constant.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p4.12 = bf16[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.10 = bf16[1]{0} reshape(bf16[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.130 = bf16[1]{0} add(bf16[1]{0} %power.128, bf16[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.133 = bf16[1]{0} divide(bf16[1]{0} %constant.1, bf16[1]{0} %add.130), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.6 = bf16[1]{0} constant({1})
  %compare.140 = pred[1]{0} compare(bf16[1]{0} %divide.133, bf16[1]{0} %constant.6), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.8 = bf16[1]{0} constant({1})
  %select.142 = bf16[1]{0} select(pred[1]{0} %compare.140, bf16[1]{0} %divide.133, bf16[1]{0} %constant.8), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.144 = bf16[] reshape(bf16[1]{0} %select.142), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.146 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.144), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.147 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.49, bf16[4,4]{1,0} %broadcast.146), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p13.162 = bf16[] parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.166 = bf16[4,4]{1,0} broadcast(bf16[] %p13.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.167 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.147, bf16[4,4]{1,0} %broadcast.166), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.172 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.171, bf16[4,4]{1,0} %multiply.167), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p12.149 = bf16[4,4]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p11.148 = bf16[] parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.150 = bf16[4,4]{1,0} broadcast(bf16[] %p11.148), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.151 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p12.149, bf16[4,4]{1,0} %broadcast.150), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.153 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.147, bf16[4,4]{1,0} %multiply.147), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.152 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.154 = bf16[4,4]{1,0} broadcast(bf16[] %convert.152), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.155 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.153, bf16[4,4]{1,0} %broadcast.154), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.156 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.151, bf16[4,4]{1,0} %multiply.155), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.157 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.156), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = bf16[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.158 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.159 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.157, bf16[4,4]{1,0} %broadcast.158), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = bf16[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.160 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.161 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.159, bf16[4,4]{1,0} %broadcast.160), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.188 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.172, bf16[4,4]{1,0} %add.161), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.187 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.189 = bf16[4,4]{1,0} broadcast(bf16[] %convert.187), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.190 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.188, bf16[4,4]{1,0} %broadcast.189), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.191 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.186, bf16[4,4]{1,0} %multiply.190), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p21.236 = bf16[4]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.237 = bf16[4]{0} broadcast(bf16[] %p17.179), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.238 = bf16[4]{0} multiply(bf16[4]{0} %p21.236, bf16[4]{0} %broadcast.237), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.12 = bf16[] constant(0)
  %broadcast.1 = bf16[4]{0} broadcast(bf16[] %constant.12), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.241 = bf16[4]{0} multiply(bf16[4]{0} %multiply.238, bf16[4]{0} %broadcast.1), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.242 = bf16[4]{0} subtract(bf16[4]{0} %p21.236, bf16[4]{0} %multiply.241), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p20.226 = bf16[4]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.227 = bf16[4]{0} broadcast(bf16[] %p14.168), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.228 = bf16[4]{0} multiply(bf16[4]{0} %p20.226, bf16[4]{0} %broadcast.227), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.15 = bf16[1]{0} constant({1})
  %compare.201 = pred[1]{0} compare(bf16[1]{0} %divide.133, bf16[1]{0} %constant.15), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.16 = bf16[1]{0} constant({1})
  %select.203 = bf16[1]{0} select(pred[1]{0} %compare.201, bf16[1]{0} %divide.133, bf16[1]{0} %constant.16), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.205 = bf16[] reshape(bf16[1]{0} %select.203), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.206 = bf16[4]{0} broadcast(bf16[] %reshape.205), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.207 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.47, bf16[4]{0} %broadcast.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.224 = bf16[4]{0} broadcast(bf16[] %p13.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.225 = bf16[4]{0} multiply(bf16[4]{0} %multiply.207, bf16[4]{0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.229 = bf16[4]{0} add(bf16[4]{0} %multiply.228, bf16[4]{0} %multiply.225), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p19.208 = bf16[4]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.209 = bf16[4]{0} broadcast(bf16[] %p11.148), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.210 = bf16[4]{0} multiply(bf16[4]{0} %p19.208, bf16[4]{0} %broadcast.209), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.212 = bf16[4]{0} multiply(bf16[4]{0} %multiply.207, bf16[4]{0} %multiply.207), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.211 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.213 = bf16[4]{0} broadcast(bf16[] %convert.211), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.214 = bf16[4]{0} multiply(bf16[4]{0} %multiply.212, bf16[4]{0} %broadcast.213), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.215 = bf16[4]{0} add(bf16[4]{0} %multiply.210, bf16[4]{0} %multiply.214), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.216 = bf16[4]{0} sqrt(bf16[4]{0} %add.215), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.217 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.218 = bf16[4]{0} divide(bf16[4]{0} %sqrt.216, bf16[4]{0} %broadcast.217), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.219 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.220 = bf16[4]{0} add(bf16[4]{0} %divide.218, bf16[4]{0} %broadcast.219), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.244 = bf16[4]{0} divide(bf16[4]{0} %add.229, bf16[4]{0} %add.220), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.243 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.245 = bf16[4]{0} broadcast(bf16[] %convert.243), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.246 = bf16[4]{0} multiply(bf16[4]{0} %divide.244, bf16[4]{0} %broadcast.245), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.247 = bf16[4]{0} add(bf16[4]{0} %subtract.242, bf16[4]{0} %multiply.246), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p24.292 = bf16[4,4]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.293 = bf16[4,4]{1,0} broadcast(bf16[] %p17.179), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.294 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p24.292, bf16[4,4]{1,0} %broadcast.293), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.295 = bf16[4,4]{1,0} broadcast(bf16[] %p16.178), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.297 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.294, bf16[4,4]{1,0} %broadcast.295), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.298 = bf16[4,4]{1,0} subtract(bf16[4,4]{1,0} %p24.292, bf16[4,4]{1,0} %multiply.297), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p23.283 = bf16[4,4]{1,0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.284 = bf16[4,4]{1,0} broadcast(bf16[] %p14.168), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.285 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p23.283, bf16[4,4]{1,0} %broadcast.284), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.19 = bf16[1]{0} constant({1})
  %compare.257 = pred[1]{0} compare(bf16[1]{0} %divide.133, bf16[1]{0} %constant.19), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.20 = bf16[1]{0} constant({1})
  %select.259 = bf16[1]{0} select(pred[1]{0} %compare.257, bf16[1]{0} %divide.133, bf16[1]{0} %constant.20), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.261 = bf16[] reshape(bf16[1]{0} %select.259), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.263 = bf16[4,4]{1,0} broadcast(bf16[] %reshape.261), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.264 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %get-tuple-element.48, bf16[4,4]{1,0} %broadcast.263), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.281 = bf16[4,4]{1,0} broadcast(bf16[] %p13.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.282 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.264, bf16[4,4]{1,0} %broadcast.281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.286 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.285, bf16[4,4]{1,0} %multiply.282), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p22.265 = bf16[4,4]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.266 = bf16[4,4]{1,0} broadcast(bf16[] %p11.148), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.267 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %p22.265, bf16[4,4]{1,0} %broadcast.266), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.269 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.264, bf16[4,4]{1,0} %multiply.264), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.268 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.270 = bf16[4,4]{1,0} broadcast(bf16[] %convert.268), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.271 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %multiply.269, bf16[4,4]{1,0} %broadcast.270), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.272 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %multiply.267, bf16[4,4]{1,0} %multiply.271), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.273 = bf16[4,4]{1,0} sqrt(bf16[4,4]{1,0} %add.272), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.274 = bf16[4,4]{1,0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.275 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %sqrt.273, bf16[4,4]{1,0} %broadcast.274), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.276 = bf16[4,4]{1,0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.277 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %divide.275, bf16[4,4]{1,0} %broadcast.276), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.300 = bf16[4,4]{1,0} divide(bf16[4,4]{1,0} %add.286, bf16[4,4]{1,0} %add.277), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.299 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.301 = bf16[4,4]{1,0} broadcast(bf16[] %convert.299), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.302 = bf16[4,4]{1,0} multiply(bf16[4,4]{1,0} %divide.300, bf16[4,4]{1,0} %broadcast.301), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.303 = bf16[4,4]{1,0} add(bf16[4,4]{1,0} %subtract.298, bf16[4,4]{1,0} %multiply.302), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p27.348 = bf16[4]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.349 = bf16[4]{0} broadcast(bf16[] %p17.179), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.350 = bf16[4]{0} multiply(bf16[4]{0} %p27.348, bf16[4]{0} %broadcast.349), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.23 = bf16[] constant(0)
  %broadcast.3 = bf16[4]{0} broadcast(bf16[] %constant.23), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.353 = bf16[4]{0} multiply(bf16[4]{0} %multiply.350, bf16[4]{0} %broadcast.3), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.354 = bf16[4]{0} subtract(bf16[4]{0} %p27.348, bf16[4]{0} %multiply.353), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p26.338 = bf16[4]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.339 = bf16[4]{0} broadcast(bf16[] %p14.168), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.340 = bf16[4]{0} multiply(bf16[4]{0} %p26.338, bf16[4]{0} %broadcast.339), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.25 = bf16[1]{0} constant({1})
  %compare.313 = pred[1]{0} compare(bf16[1]{0} %divide.133, bf16[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.27 = bf16[1]{0} constant({1})
  %select.315 = bf16[1]{0} select(pred[1]{0} %compare.313, bf16[1]{0} %divide.133, bf16[1]{0} %constant.27), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.317 = bf16[] reshape(bf16[1]{0} %select.315), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.318 = bf16[4]{0} broadcast(bf16[] %reshape.317), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.319 = bf16[4]{0} multiply(bf16[4]{0} %get-tuple-element.46, bf16[4]{0} %broadcast.318), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.336 = bf16[4]{0} broadcast(bf16[] %p13.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.337 = bf16[4]{0} multiply(bf16[4]{0} %multiply.319, bf16[4]{0} %broadcast.336), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.341 = bf16[4]{0} add(bf16[4]{0} %multiply.340, bf16[4]{0} %multiply.337), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p25.320 = bf16[4]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.321 = bf16[4]{0} broadcast(bf16[] %p11.148), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.322 = bf16[4]{0} multiply(bf16[4]{0} %p25.320, bf16[4]{0} %broadcast.321), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.324 = bf16[4]{0} multiply(bf16[4]{0} %multiply.319, bf16[4]{0} %multiply.319), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.323 = bf16[] convert(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.325 = bf16[4]{0} broadcast(bf16[] %convert.323), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.326 = bf16[4]{0} multiply(bf16[4]{0} %multiply.324, bf16[4]{0} %broadcast.325), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.327 = bf16[4]{0} add(bf16[4]{0} %multiply.322, bf16[4]{0} %multiply.326), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.328 = bf16[4]{0} sqrt(bf16[4]{0} %add.327), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.329 = bf16[4]{0} broadcast(bf16[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.330 = bf16[4]{0} divide(bf16[4]{0} %sqrt.328, bf16[4]{0} %broadcast.329), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.331 = bf16[4]{0} broadcast(bf16[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.332 = bf16[4]{0} add(bf16[4]{0} %divide.330, bf16[4]{0} %broadcast.331), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.356 = bf16[4]{0} divide(bf16[4]{0} %add.341, bf16[4]{0} %add.332), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.355 = bf16[] convert(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.357 = bf16[4]{0} broadcast(bf16[] %convert.355), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.358 = bf16[4]{0} multiply(bf16[4]{0} %divide.356, bf16[4]{0} %broadcast.357), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.359 = bf16[4]{0} add(bf16[4]{0} %subtract.354, bf16[4]{0} %multiply.358), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.360 = (bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4]{0}, /*index=5*/bf16[4,4]{1,0}, bf16[4]{0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4,4]{1,0}, /*index=10*/bf16[4,4]{1,0}, bf16[4,4]{1,0}, bf16[4]{0}, bf16[4]{0}, bf16[4]{0}, /*index=15*/bf16[4]{0}, bf16[1]{0}) tuple(bf16[4,4]{1,0} %add.191, bf16[4]{0} %add.247, bf16[4,4]{1,0} %add.303, bf16[4]{0} %add.359, bf16[4]{0} %multiply.319, /*index=5*/bf16[4,4]{1,0} %multiply.264, bf16[4]{0} %multiply.207, bf16[4,4]{1,0} %multiply.147, bf16[4,4]{1,0} %add.172, bf16[4,4]{1,0} %add.156, /*index=10*/bf16[4,4]{1,0} %add.286, bf16[4,4]{1,0} %add.272, bf16[4]{0} %add.229, bf16[4]{0} %add.215, bf16[4]{0} %add.341, /*index=15*/bf16[4]{0} %add.327, bf16[1]{0} %power.128), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16"}
}



`

export default text;
