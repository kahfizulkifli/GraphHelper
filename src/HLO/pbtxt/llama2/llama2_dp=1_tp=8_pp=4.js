const text = `
HloModule SyncTensorsGraph.2690, input_output_alias={ {26}: (41, {}, must-alias), {27}: (44, {}, must-alias), {28}: (47, {}, must-alias), {29}: (50, {}, must-alias), {30}: (53, {}, must-alias), {31}: (56, {}, must-alias), {32}: (59, {}, must-alias), {33}: (62, {}, must-alias), {34}: (65, {}, must-alias), {35}: (68, {}, must-alias), {36}: (71, {}, must-alias), {37}: (74, {}, must-alias), {38}: (77, {}, must-alias), {39}: (80, {}, must-alias), {40}: (83, {}, must-alias), {41}: (86, {}, must-alias), {42}: (89, {}, must-alias), {43}: (92, {}, must-alias), {44}: (95, {}, must-alias), {45}: (98, {}, must-alias), {46}: (101, {}, must-alias), {47}: (104, {}, must-alias), {48}: (107, {}, must-alias), {49}: (110, {}, must-alias), {50}: (113, {}, must-alias), {51}: (116, {}, must-alias), {52}: (10, {}, must-alias), {53}: (9, {}, must-alias), {54}: (11, {}, must-alias), {55}: (12, {}, must-alias), {56}: (8, {}, must-alias), {57}: (13, {}, must-alias), {58}: (14, {}, must-alias), {59}: (7, {}, must-alias), {60}: (15, {}, must-alias), {61}: (16, {}, must-alias), {62}: (6, {}, must-alias), {63}: (17, {}, must-alias), {64}: (18, {}, must-alias), {65}: (5, {}, must-alias), {66}: (19, {}, must-alias), {67}: (20, {}, must-alias), {68}: (4, {}, must-alias), {69}: (21, {}, must-alias), {70}: (22, {}, must-alias), {71}: (3, {}, must-alias), {72}: (23, {}, must-alias), {73}: (24, {}, must-alias), {74}: (2, {}, must-alias), {75}: (25, {}, must-alias), {76}: (26, {}, must-alias), {77}: (1, {}, must-alias), {78}: (38, {}, must-alias), {79}: (35, {}, must-alias), {80}: (43, {}, must-alias), {81}: (42, {}, must-alias), {82}: (46, {}, must-alias), {83}: (45, {}, must-alias), {84}: (49, {}, must-alias), {85}: (48, {}, must-alias), {86}: (52, {}, must-alias), {87}: (51, {}, must-alias), {88}: (55, {}, must-alias), {89}: (54, {}, must-alias), {90}: (58, {}, must-alias), {91}: (57, {}, must-alias), {92}: (61, {}, must-alias), {93}: (60, {}, must-alias), {94}: (64, {}, must-alias), {95}: (63, {}, must-alias), {96}: (67, {}, must-alias), {97}: (66, {}, must-alias), {98}: (70, {}, must-alias), {99}: (69, {}, must-alias), {100}: (73, {}, must-alias), {101}: (72, {}, must-alias), {102}: (76, {}, must-alias), {103}: (75, {}, must-alias), {104}: (79, {}, must-alias), {105}: (78, {}, must-alias), {106}: (82, {}, must-alias), {107}: (81, {}, must-alias), {108}: (85, {}, must-alias), {109}: (84, {}, must-alias), {110}: (88, {}, must-alias), {111}: (87, {}, must-alias), {112}: (91, {}, must-alias), {113}: (90, {}, must-alias), {114}: (94, {}, must-alias), {115}: (93, {}, must-alias), {116}: (97, {}, must-alias), {117}: (96, {}, must-alias), {118}: (100, {}, must-alias), {119}: (99, {}, must-alias), {120}: (103, {}, must-alias), {121}: (102, {}, must-alias), {122}: (106, {}, must-alias), {123}: (105, {}, must-alias), {124}: (109, {}, must-alias), {125}: (108, {}, must-alias), {126}: (112, {}, must-alias), {127}: (111, {}, must-alias), {128}: (115, {}, must-alias), {129}: (114, {}, must-alias) }

%AddComputation.7 (x.8: bf16[], y.9: bf16[]) -> bf16[] {
  %x.8 = bf16[] parameter(0)
  %y.9 = bf16[] parameter(1)
  ROOT %add.10 = bf16[] add(bf16[] %x.8, bf16[] %y.9)
}

%AddComputation.20 (x.21: bf16[], y.22: bf16[]) -> bf16[] {
  %x.21 = bf16[] parameter(0)
  %y.22 = bf16[] parameter(1)
  ROOT %add.23 = bf16[] add(bf16[] %x.21, bf16[] %y.22)
}

%AddComputation.33 (x.34: bf16[], y.35: bf16[]) -> bf16[] {
  %x.34 = bf16[] parameter(0)
  %y.35 = bf16[] parameter(1)
  ROOT %add.36 = bf16[] add(bf16[] %x.34, bf16[] %y.35)
}

%AddComputation.46 (x.47: bf16[], y.48: bf16[]) -> bf16[] {
  %x.47 = bf16[] parameter(0)
  %y.48 = bf16[] parameter(1)
  ROOT %add.49 = bf16[] add(bf16[] %x.47, bf16[] %y.48)
}

%AddComputation.59 (x.60: bf16[], y.61: bf16[]) -> bf16[] {
  %x.60 = bf16[] parameter(0)
  %y.61 = bf16[] parameter(1)
  ROOT %add.62 = bf16[] add(bf16[] %x.60, bf16[] %y.61)
}

%AddComputation.72 (x.73: bf16[], y.74: bf16[]) -> bf16[] {
  %x.73 = bf16[] parameter(0)
  %y.74 = bf16[] parameter(1)
  ROOT %add.75 = bf16[] add(bf16[] %x.73, bf16[] %y.74)
}

%AddComputation.85 (x.86: bf16[], y.87: bf16[]) -> bf16[] {
  %x.86 = bf16[] parameter(0)
  %y.87 = bf16[] parameter(1)
  ROOT %add.88 = bf16[] add(bf16[] %x.86, bf16[] %y.87)
}

%AddComputation.98 (x.99: bf16[], y.100: bf16[]) -> bf16[] {
  %x.99 = bf16[] parameter(0)
  %y.100 = bf16[] parameter(1)
  ROOT %add.101 = bf16[] add(bf16[] %x.99, bf16[] %y.100)
}

%AddComputation.111 (x.112: bf16[], y.113: bf16[]) -> bf16[] {
  %x.112 = bf16[] parameter(0)
  %y.113 = bf16[] parameter(1)
  ROOT %add.114 = bf16[] add(bf16[] %x.112, bf16[] %y.113)
}

%AddComputation.126 (x.127: bf16[], y.128: bf16[]) -> bf16[] {
  %x.127 = bf16[] parameter(0)
  %y.128 = bf16[] parameter(1)
  ROOT %add.129 = bf16[] add(bf16[] %x.127, bf16[] %y.128)
}

%AddComputation.137 (x.138: bf16[], y.139: bf16[]) -> bf16[] {
  %x.138 = bf16[] parameter(0)
  %y.139 = bf16[] parameter(1)
  ROOT %add.140 = bf16[] add(bf16[] %x.138, bf16[] %y.139)
}

%AddComputation.152 (x.153: bf16[], y.154: bf16[]) -> bf16[] {
  %x.153 = bf16[] parameter(0)
  %y.154 = bf16[] parameter(1)
  ROOT %add.155 = bf16[] add(bf16[] %x.153, bf16[] %y.154)
}

%AddComputation.163 (x.164: bf16[], y.165: bf16[]) -> bf16[] {
  %x.164 = bf16[] parameter(0)
  %y.165 = bf16[] parameter(1)
  ROOT %add.166 = bf16[] add(bf16[] %x.164, bf16[] %y.165)
}

%AddComputation.178 (x.179: bf16[], y.180: bf16[]) -> bf16[] {
  %x.179 = bf16[] parameter(0)
  %y.180 = bf16[] parameter(1)
  ROOT %add.181 = bf16[] add(bf16[] %x.179, bf16[] %y.180)
}

%AddComputation.189 (x.190: bf16[], y.191: bf16[]) -> bf16[] {
  %x.190 = bf16[] parameter(0)
  %y.191 = bf16[] parameter(1)
  ROOT %add.192 = bf16[] add(bf16[] %x.190, bf16[] %y.191)
}

%AddComputation.204 (x.205: bf16[], y.206: bf16[]) -> bf16[] {
  %x.205 = bf16[] parameter(0)
  %y.206 = bf16[] parameter(1)
  ROOT %add.207 = bf16[] add(bf16[] %x.205, bf16[] %y.206)
}

%AddComputation.215 (x.216: bf16[], y.217: bf16[]) -> bf16[] {
  %x.216 = bf16[] parameter(0)
  %y.217 = bf16[] parameter(1)
  ROOT %add.218 = bf16[] add(bf16[] %x.216, bf16[] %y.217)
}

%AddComputation.230 (x.231: bf16[], y.232: bf16[]) -> bf16[] {
  %x.231 = bf16[] parameter(0)
  %y.232 = bf16[] parameter(1)
  ROOT %add.233 = bf16[] add(bf16[] %x.231, bf16[] %y.232)
}

%AddComputation.241 (x.242: bf16[], y.243: bf16[]) -> bf16[] {
  %x.242 = bf16[] parameter(0)
  %y.243 = bf16[] parameter(1)
  ROOT %add.244 = bf16[] add(bf16[] %x.242, bf16[] %y.243)
}

%AddComputation.256 (x.257: bf16[], y.258: bf16[]) -> bf16[] {
  %x.257 = bf16[] parameter(0)
  %y.258 = bf16[] parameter(1)
  ROOT %add.259 = bf16[] add(bf16[] %x.257, bf16[] %y.258)
}

%AddComputation.267 (x.268: bf16[], y.269: bf16[]) -> bf16[] {
  %x.268 = bf16[] parameter(0)
  %y.269 = bf16[] parameter(1)
  ROOT %add.270 = bf16[] add(bf16[] %x.268, bf16[] %y.269)
}

%AddComputation.282 (x.283: bf16[], y.284: bf16[]) -> bf16[] {
  %x.283 = bf16[] parameter(0)
  %y.284 = bf16[] parameter(1)
  ROOT %add.285 = bf16[] add(bf16[] %x.283, bf16[] %y.284)
}

%AddComputation.293 (x.294: bf16[], y.295: bf16[]) -> bf16[] {
  %x.294 = bf16[] parameter(0)
  %y.295 = bf16[] parameter(1)
  ROOT %add.296 = bf16[] add(bf16[] %x.294, bf16[] %y.295)
}

%AddComputation.308 (x.309: bf16[], y.310: bf16[]) -> bf16[] {
  %x.309 = bf16[] parameter(0)
  %y.310 = bf16[] parameter(1)
  ROOT %add.311 = bf16[] add(bf16[] %x.309, bf16[] %y.310)
}

%AddComputation.319 (x.320: bf16[], y.321: bf16[]) -> bf16[] {
  %x.320 = bf16[] parameter(0)
  %y.321 = bf16[] parameter(1)
  ROOT %add.322 = bf16[] add(bf16[] %x.320, bf16[] %y.321)
}

%AddComputation.334 (x.335: bf16[], y.336: bf16[]) -> bf16[] {
  %x.335 = bf16[] parameter(0)
  %y.336 = bf16[] parameter(1)
  ROOT %add.337 = bf16[] add(bf16[] %x.335, bf16[] %y.336)
}

%AddComputation.345 (x.346: bf16[], y.347: bf16[]) -> bf16[] {
  %x.346 = bf16[] parameter(0)
  %y.347 = bf16[] parameter(1)
  ROOT %add.348 = bf16[] add(bf16[] %x.346, bf16[] %y.347)
}

%AddComputation.360 (x.361: bf16[], y.362: bf16[]) -> bf16[] {
  %x.361 = bf16[] parameter(0)
  %y.362 = bf16[] parameter(1)
  ROOT %add.363 = bf16[] add(bf16[] %x.361, bf16[] %y.362)
}

%AddComputation.371 (x.372: bf16[], y.373: bf16[]) -> bf16[] {
  %x.372 = bf16[] parameter(0)
  %y.373 = bf16[] parameter(1)
  ROOT %add.374 = bf16[] add(bf16[] %x.372, bf16[] %y.373)
}

%AddComputation.386 (x.387: bf16[], y.388: bf16[]) -> bf16[] {
  %x.387 = bf16[] parameter(0)
  %y.388 = bf16[] parameter(1)
  ROOT %add.389 = bf16[] add(bf16[] %x.387, bf16[] %y.388)
}

%AddComputation.397 (x.398: bf16[], y.399: bf16[]) -> bf16[] {
  %x.398 = bf16[] parameter(0)
  %y.399 = bf16[] parameter(1)
  ROOT %add.400 = bf16[] add(bf16[] %x.398, bf16[] %y.399)
}

%AddComputation.412 (x.413: bf16[], y.414: bf16[]) -> bf16[] {
  %x.413 = bf16[] parameter(0)
  %y.414 = bf16[] parameter(1)
  ROOT %add.415 = bf16[] add(bf16[] %x.413, bf16[] %y.414)
}

%AddComputation.423 (x.424: bf16[], y.425: bf16[]) -> bf16[] {
  %x.424 = bf16[] parameter(0)
  %y.425 = bf16[] parameter(1)
  ROOT %add.426 = bf16[] add(bf16[] %x.424, bf16[] %y.425)
}

%AddComputation.438 (x.439: bf16[], y.440: bf16[]) -> bf16[] {
  %x.439 = bf16[] parameter(0)
  %y.440 = bf16[] parameter(1)
  ROOT %add.441 = bf16[] add(bf16[] %x.439, bf16[] %y.440)
}

%AddComputation.449 (x.450: bf16[], y.451: bf16[]) -> bf16[] {
  %x.450 = bf16[] parameter(0)
  %y.451 = bf16[] parameter(1)
  ROOT %add.452 = bf16[] add(bf16[] %x.450, bf16[] %y.451)
}

%AddComputation.464 (x.465: bf16[], y.466: bf16[]) -> bf16[] {
  %x.465 = bf16[] parameter(0)
  %y.466 = bf16[] parameter(1)
  ROOT %add.467 = bf16[] add(bf16[] %x.465, bf16[] %y.466)
}

%AddComputation.475 (x.476: bf16[], y.477: bf16[]) -> bf16[] {
  %x.476 = bf16[] parameter(0)
  %y.477 = bf16[] parameter(1)
  ROOT %add.478 = bf16[] add(bf16[] %x.476, bf16[] %y.477)
}

%AddComputation.490 (x.491: bf16[], y.492: bf16[]) -> bf16[] {
  %x.491 = bf16[] parameter(0)
  %y.492 = bf16[] parameter(1)
  ROOT %add.493 = bf16[] add(bf16[] %x.491, bf16[] %y.492)
}

%AddComputation.501 (x.502: bf16[], y.503: bf16[]) -> bf16[] {
  %x.502 = bf16[] parameter(0)
  %y.503 = bf16[] parameter(1)
  ROOT %add.504 = bf16[] add(bf16[] %x.502, bf16[] %y.503)
}

%AddComputation.516 (x.517: bf16[], y.518: bf16[]) -> bf16[] {
  %x.517 = bf16[] parameter(0)
  %y.518 = bf16[] parameter(1)
  ROOT %add.519 = bf16[] add(bf16[] %x.517, bf16[] %y.518)
}

%AddComputation.527 (x.528: bf16[], y.529: bf16[]) -> bf16[] {
  %x.528 = bf16[] parameter(0)
  %y.529 = bf16[] parameter(1)
  ROOT %add.530 = bf16[] add(bf16[] %x.528, bf16[] %y.529)
}

%AddComputation.542 (x.543: bf16[], y.544: bf16[]) -> bf16[] {
  %x.543 = bf16[] parameter(0)
  %y.544 = bf16[] parameter(1)
  ROOT %add.545 = bf16[] add(bf16[] %x.543, bf16[] %y.544)
}

%AddComputation.553 (x.554: bf16[], y.555: bf16[]) -> bf16[] {
  %x.554 = bf16[] parameter(0)
  %y.555 = bf16[] parameter(1)
  ROOT %add.556 = bf16[] add(bf16[] %x.554, bf16[] %y.555)
}

%AddComputation.568 (x.569: bf16[], y.570: bf16[]) -> bf16[] {
  %x.569 = bf16[] parameter(0)
  %y.570 = bf16[] parameter(1)
  ROOT %add.571 = bf16[] add(bf16[] %x.569, bf16[] %y.570)
}

%AddComputation.579 (x.580: bf16[], y.581: bf16[]) -> bf16[] {
  %x.580 = bf16[] parameter(0)
  %y.581 = bf16[] parameter(1)
  ROOT %add.582 = bf16[] add(bf16[] %x.580, bf16[] %y.581)
}

%AddComputation.593 (x.594: bf16[], y.595: bf16[]) -> bf16[] {
  %x.594 = bf16[] parameter(0)
  %y.595 = bf16[] parameter(1)
  ROOT %add.596 = bf16[] add(bf16[] %x.594, bf16[] %y.595)
}

%AddComputation.604 (x.605: bf16[], y.606: bf16[]) -> bf16[] {
  %x.605 = bf16[] parameter(0)
  %y.606 = bf16[] parameter(1)
  ROOT %add.607 = bf16[] add(bf16[] %x.605, bf16[] %y.606)
}

%AddComputation.618 (x.619: bf16[], y.620: bf16[]) -> bf16[] {
  %x.619 = bf16[] parameter(0)
  %y.620 = bf16[] parameter(1)
  ROOT %add.621 = bf16[] add(bf16[] %x.619, bf16[] %y.620)
}

%AddComputation.629 (x.630: bf16[], y.631: bf16[]) -> bf16[] {
  %x.630 = bf16[] parameter(0)
  %y.631 = bf16[] parameter(1)
  ROOT %add.632 = bf16[] add(bf16[] %x.630, bf16[] %y.631)
}

%AddComputation.643 (x.644: bf16[], y.645: bf16[]) -> bf16[] {
  %x.644 = bf16[] parameter(0)
  %y.645 = bf16[] parameter(1)
  ROOT %add.646 = bf16[] add(bf16[] %x.644, bf16[] %y.645)
}

%AddComputation.654 (x.655: bf16[], y.656: bf16[]) -> bf16[] {
  %x.655 = bf16[] parameter(0)
  %y.656 = bf16[] parameter(1)
  ROOT %add.657 = bf16[] add(bf16[] %x.655, bf16[] %y.656)
}

%AddComputation.668 (x.669: bf16[], y.670: bf16[]) -> bf16[] {
  %x.669 = bf16[] parameter(0)
  %y.670 = bf16[] parameter(1)
  ROOT %add.671 = bf16[] add(bf16[] %x.669, bf16[] %y.670)
}

%AddComputation.679 (x.680: bf16[], y.681: bf16[]) -> bf16[] {
  %x.680 = bf16[] parameter(0)
  %y.681 = bf16[] parameter(1)
  ROOT %add.682 = bf16[] add(bf16[] %x.680, bf16[] %y.681)
}

%AddComputation.693 (x.694: bf16[], y.695: bf16[]) -> bf16[] {
  %x.694 = bf16[] parameter(0)
  %y.695 = bf16[] parameter(1)
  ROOT %add.696 = bf16[] add(bf16[] %x.694, bf16[] %y.695)
}

%AddComputation.704 (x.705: bf16[], y.706: bf16[]) -> bf16[] {
  %x.705 = bf16[] parameter(0)
  %y.706 = bf16[] parameter(1)
  ROOT %add.707 = bf16[] add(bf16[] %x.705, bf16[] %y.706)
}

%AddComputation.718 (x.719: bf16[], y.720: bf16[]) -> bf16[] {
  %x.719 = bf16[] parameter(0)
  %y.720 = bf16[] parameter(1)
  ROOT %add.721 = bf16[] add(bf16[] %x.719, bf16[] %y.720)
}

%AddComputation.729 (x.730: bf16[], y.731: bf16[]) -> bf16[] {
  %x.730 = bf16[] parameter(0)
  %y.731 = bf16[] parameter(1)
  ROOT %add.732 = bf16[] add(bf16[] %x.730, bf16[] %y.731)
}

%AddComputation.743 (x.744: bf16[], y.745: bf16[]) -> bf16[] {
  %x.744 = bf16[] parameter(0)
  %y.745 = bf16[] parameter(1)
  ROOT %add.746 = bf16[] add(bf16[] %x.744, bf16[] %y.745)
}

%AddComputation.754 (x.755: bf16[], y.756: bf16[]) -> bf16[] {
  %x.755 = bf16[] parameter(0)
  %y.756 = bf16[] parameter(1)
  ROOT %add.757 = bf16[] add(bf16[] %x.755, bf16[] %y.756)
}

%AddComputation.768 (x.769: bf16[], y.770: bf16[]) -> bf16[] {
  %x.769 = bf16[] parameter(0)
  %y.770 = bf16[] parameter(1)
  ROOT %add.771 = bf16[] add(bf16[] %x.769, bf16[] %y.770)
}

%AddComputation.779 (x.780: bf16[], y.781: bf16[]) -> bf16[] {
  %x.780 = bf16[] parameter(0)
  %y.781 = bf16[] parameter(1)
  ROOT %add.782 = bf16[] add(bf16[] %x.780, bf16[] %y.781)
}

%AddComputation.846 (x.847: bf16[], y.848: bf16[]) -> bf16[] {
  %x.847 = bf16[] parameter(0)
  %y.848 = bf16[] parameter(1)
  ROOT %add.849 = bf16[] add(bf16[] %x.847, bf16[] %y.848)
}

ENTRY %SyncTensorsGraph.2690 (p0.1: f32[], p1.2: bf16[4096], p2.15: bf16[4096], p3.28: bf16[4096], p4.41: bf16[4096], p5.54: bf16[4096], p6.67: bf16[4096], p7.80: bf16[4096], p8.93: bf16[4096], p9.106: bf16[4096], p10.121: bf16[4000,4096], p11.147: bf16[4096,1376], p12.173: bf16[2752,4096], p13.199: bf16[4096,512], p14.225: bf16[1536,4096], p15.251: bf16[4096,1376], p16.277: bf16[2752,4096], p17.303: bf16[4096,512], p18.329: bf16[1536,4096], p19.355: bf16[4096,1376], p20.381: bf16[2752,4096], p21.407: bf16[4096,512], p22.433: bf16[1536,4096], p23.459: bf16[4096,1376], p24.485: bf16[2752,4096], p25.511: bf16[4096,512], p26.537: bf16[1536,4096], p27.561: bf16[], p28.787: bf16[1], p29.854: f32[], p30.856: bf16[], p31.858: bf16[], p32.859: f32[], p33.865: bf16[], p34.890: bf16[], p35.891: bf16[1536,4096], p36.904: bf16[], p37.910: bf16[], p38.911: bf16[1536,4096], p39.920: bf16[], p40.921: bf16[], p41.922: bf16[1536,4096], p42.960: bf16[4096,512], p43.978: bf16[4096,512], p44.987: bf16[4096,512], p45.1025: bf16[2752,4096], p46.1043: bf16[2752,4096], p47.1052: bf16[2752,4096], p48.1090: bf16[4096,1376], p49.1108: bf16[4096,1376], p50.1117: bf16[4096,1376], p51.1154: bf16[4096], p52.1172: bf16[4096], p53.1181: bf16[4096], p54.1218: bf16[4096], p55.1236: bf16[4096], p56.1245: bf16[4096], p57.1283: bf16[1536,4096], p58.1301: bf16[1536,4096], p59.1310: bf16[1536,4096], p60.1348: bf16[4096,512], p61.1366: bf16[4096,512], p62.1375: bf16[4096,512], p63.1413: bf16[2752,4096], p64.1431: bf16[2752,4096], p65.1440: bf16[2752,4096], p66.1478: bf16[4096,1376], p67.1496: bf16[4096,1376], p68.1505: bf16[4096,1376], p69.1542: bf16[4096], p70.1560: bf16[4096], p71.1569: bf16[4096], p72.1606: bf16[4096], p73.1624: bf16[4096], p74.1633: bf16[4096], p75.1671: bf16[1536,4096], p76.1689: bf16[1536,4096], p77.1698: bf16[1536,4096], p78.1736: bf16[4096,512], p79.1754: bf16[4096,512], p80.1763: bf16[4096,512], p81.1801: bf16[2752,4096], p82.1819: bf16[2752,4096], p83.1828: bf16[2752,4096], p84.1866: bf16[4096,1376], p85.1884: bf16[4096,1376], p86.1893: bf16[4096,1376], p87.1930: bf16[4096], p88.1948: bf16[4096], p89.1957: bf16[4096], p90.1994: bf16[4096], p91.2012: bf16[4096], p92.2021: bf16[4096], p93.2059: bf16[1536,4096], p94.2077: bf16[1536,4096], p95.2086: bf16[1536,4096], p96.2124: bf16[4096,512], p97.2142: bf16[4096,512], p98.2151: bf16[4096,512], p99.2189: bf16[2752,4096], p100.2207: bf16[2752,4096], p101.2216: bf16[2752,4096], p102.2254: bf16[4096,1376], p103.2272: bf16[4096,1376], p104.2281: bf16[4096,1376], p105.2318: bf16[4096], p106.2336: bf16[4096], p107.2345: bf16[4096], p108.2382: bf16[4096], p109.2400: bf16[4096], p110.2409: bf16[4096], p111.2446: bf16[4096], p112.2464: bf16[4096], p113.2473: bf16[4096], p114.2511: bf16[4000,4096], p115.2529: bf16[4000,4096], p116.2538: bf16[4000,4096]) -> (bf16[1536,4096], bf16[4096,512], bf16[2752,4096], bf16[4096,1376], bf16[4096], /*index=5*/bf16[4096], bf16[1536,4096], bf16[4096,512], bf16[2752,4096], bf16[4096,1376], /*index=10*/bf16[4096], bf16[4096], bf16[1536,4096], bf16[4096,512], bf16[2752,4096], /*index=15*/bf16[4096,1376], bf16[4096], bf16[4096], bf16[1536,4096], bf16[4096,512], /*index=20*/bf16[2752,4096], bf16[4096,1376], bf16[4096], bf16[4096], bf16[4096], /*index=25*/bf16[4000,4096], bf16[1536,4096], bf16[4096,512], bf16[2752,4096], bf16[4096,1376], /*index=30*/bf16[4096], bf16[4096], bf16[1536,4096], bf16[4096,512], bf16[2752,4096], /*index=35*/bf16[4096,1376], bf16[4096], bf16[4096], bf16[1536,4096], bf16[4096,512], /*index=40*/bf16[2752,4096], bf16[4096,1376], bf16[4096], bf16[4096], bf16[1536,4096], /*index=45*/bf16[4096,512], bf16[2752,4096], bf16[4096,1376], bf16[4096], bf16[4096], /*index=50*/bf16[4096], bf16[4000,4096], bf16[4000,4096], bf16[4096], bf16[4096,1376], /*index=55*/bf16[2752,4096], bf16[4096], bf16[4096,512], bf16[1536,4096], bf16[4096], /*index=60*/bf16[4096,1376], bf16[2752,4096], bf16[4096], bf16[4096,512], bf16[1536,4096], /*index=65*/bf16[4096], bf16[4096,1376], bf16[2752,4096], bf16[4096], bf16[4096,512], /*index=70*/bf16[1536,4096], bf16[4096], bf16[4096,1376], bf16[2752,4096], bf16[4096], /*index=75*/bf16[4096,512], bf16[1536,4096], bf16[4096], bf16[1536,4096], bf16[1536,4096], /*index=80*/bf16[4096,512], bf16[4096,512], bf16[2752,4096], bf16[2752,4096], bf16[4096,1376], /*index=85*/bf16[4096,1376], bf16[4096], bf16[4096], bf16[4096], bf16[4096], /*index=90*/bf16[1536,4096], bf16[1536,4096], bf16[4096,512], bf16[4096,512], bf16[2752,4096], /*index=95*/bf16[2752,4096], bf16[4096,1376], bf16[4096,1376], bf16[4096], bf16[4096], /*index=100*/bf16[4096], bf16[4096], bf16[1536,4096], bf16[1536,4096], bf16[4096,512], /*index=105*/bf16[4096,512], bf16[2752,4096], bf16[2752,4096], bf16[4096,1376], bf16[4096,1376], /*index=110*/bf16[4096], bf16[4096], bf16[4096], bf16[4096], bf16[1536,4096], /*index=115*/bf16[1536,4096], bf16[4096,512], bf16[4096,512], bf16[2752,4096], bf16[2752,4096], /*index=120*/bf16[4096,1376], bf16[4096,1376], bf16[4096], bf16[4096], bf16[4096], /*index=125*/bf16[4096], bf16[4096], bf16[4096], bf16[4000,4096], bf16[4000,4096], /*index=130*/bf16[1]) {
  %p41.922 = bf16[1536,4096]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p40.921 = bf16[] parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.923 = bf16[1536,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.924 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p41.922, bf16[1536,4096]{1,0} %broadcast.923), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p39.920 = bf16[] parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.925 = bf16[1536,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.927 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.924, bf16[1536,4096]{1,0} %broadcast.925), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.928 = bf16[1536,4096]{1,0} subtract(bf16[1536,4096]{1,0} %p41.922, bf16[1536,4096]{1,0} %multiply.927), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p38.911 = bf16[1536,4096]{1,0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p37.910 = bf16[] parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.912 = bf16[1536,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.913 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p38.911, bf16[1536,4096]{1,0} %broadcast.912), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p26.537 = bf16[1536,4096]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %p9.106 = bf16[4096]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p8.93 = bf16[4096]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p7.80 = bf16[4096]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p6.67 = bf16[4096]{0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p5.54 = bf16[4096]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p4.41 = bf16[4096]{0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p3.28 = bf16[4096]{0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p2.15 = bf16[4096]{0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p1.2 = bf16[4096]{0} parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %convert.3 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.11 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p1.2, bf16[] %convert.3), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.7, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.19 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.11), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.24 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p2.15, bf16[] %get-tuple-element.19), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.20, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.32 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.24), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.37 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p3.28, bf16[] %get-tuple-element.32), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.33, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.45 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.37), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.50 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p4.41, bf16[] %get-tuple-element.45), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.46, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.58 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.50), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.63 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p5.54, bf16[] %get-tuple-element.58), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.59, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.71 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.63), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.76 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p6.67, bf16[] %get-tuple-element.71), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.72, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.84 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.76), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.89 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p7.80, bf16[] %get-tuple-element.84), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.85, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.97 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.89), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.102 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p8.93, bf16[] %get-tuple-element.97), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.98, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.110 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.102), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.115 = (bf16[4096]{0}, bf16[]) all-reduce(bf16[4096]{0} %p9.106, bf16[] %get-tuple-element.110), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.111, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.845 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.115), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.546 = (bf16[1536,4096]{1,0}, bf16[]) reduce-scatter(bf16[1536,4096]{1,0} %p26.537, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.542, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.547 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %reduce-scatter.546), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %constant = bf16[1]{0} constant({1})
  %p28.787 = bf16[1]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %get-tuple-element.766 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.11), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.772 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.766, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.768, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.773 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.772), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.776 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.773, bf16[4096]{0} %get-tuple-element.773), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.777 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.783 = bf16[] reduce(bf16[4096]{0} %multiply.776, bf16[] %constant.777), dimensions={0}, to_apply=%AddComputation.779, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.784 = bf16[] sqrt(bf16[] %reduce.783), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.786 = bf16[] multiply(bf16[] %sqrt.784, bf16[] %sqrt.784), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.3 = bf16[1]{0} reshape(bf16[] %multiply.786), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.789 = bf16[1]{0} add(bf16[1]{0} %p28.787, bf16[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.741 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.24), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.747 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.741, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.743, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.748 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.747), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.751 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.748, bf16[4096]{0} %get-tuple-element.748), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.752 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.758 = bf16[] reduce(bf16[4096]{0} %multiply.751, bf16[] %constant.752), dimensions={0}, to_apply=%AddComputation.754, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.759 = bf16[] sqrt(bf16[] %reduce.758), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.761 = bf16[] multiply(bf16[] %sqrt.759, bf16[] %sqrt.759), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.4 = bf16[1]{0} reshape(bf16[] %multiply.761), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.791 = bf16[1]{0} add(bf16[1]{0} %add.789, bf16[1]{0} %reshape.4), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.716 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.37), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.722 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.716, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.718, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.723 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.722), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.726 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.723, bf16[4096]{0} %get-tuple-element.723), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.727 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.733 = bf16[] reduce(bf16[4096]{0} %multiply.726, bf16[] %constant.727), dimensions={0}, to_apply=%AddComputation.729, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.734 = bf16[] sqrt(bf16[] %reduce.733), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.736 = bf16[] multiply(bf16[] %sqrt.734, bf16[] %sqrt.734), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.5 = bf16[1]{0} reshape(bf16[] %multiply.736), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.793 = bf16[1]{0} add(bf16[1]{0} %add.791, bf16[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.691 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.50), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.697 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.691, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.693, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.698 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.697), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.701 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.698, bf16[4096]{0} %get-tuple-element.698), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.702 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.708 = bf16[] reduce(bf16[4096]{0} %multiply.701, bf16[] %constant.702), dimensions={0}, to_apply=%AddComputation.704, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.709 = bf16[] sqrt(bf16[] %reduce.708), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.711 = bf16[] multiply(bf16[] %sqrt.709, bf16[] %sqrt.709), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.6 = bf16[1]{0} reshape(bf16[] %multiply.711), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.795 = bf16[1]{0} add(bf16[1]{0} %add.793, bf16[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.666 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.63), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.672 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.666, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.668, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.673 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.672), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.676 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.673, bf16[4096]{0} %get-tuple-element.673), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.677 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.683 = bf16[] reduce(bf16[4096]{0} %multiply.676, bf16[] %constant.677), dimensions={0}, to_apply=%AddComputation.679, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.684 = bf16[] sqrt(bf16[] %reduce.683), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.686 = bf16[] multiply(bf16[] %sqrt.684, bf16[] %sqrt.684), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.7 = bf16[1]{0} reshape(bf16[] %multiply.686), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.797 = bf16[1]{0} add(bf16[1]{0} %add.795, bf16[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.641 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.76), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.647 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.641, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.643, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.648 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.647), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.651 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.648, bf16[4096]{0} %get-tuple-element.648), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.652 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.658 = bf16[] reduce(bf16[4096]{0} %multiply.651, bf16[] %constant.652), dimensions={0}, to_apply=%AddComputation.654, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.659 = bf16[] sqrt(bf16[] %reduce.658), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.661 = bf16[] multiply(bf16[] %sqrt.659, bf16[] %sqrt.659), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.8 = bf16[1]{0} reshape(bf16[] %multiply.661), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.799 = bf16[1]{0} add(bf16[1]{0} %add.797, bf16[1]{0} %reshape.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.616 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.89), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.622 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.616, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.618, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.623 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.622), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.626 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.623, bf16[4096]{0} %get-tuple-element.623), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.627 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.633 = bf16[] reduce(bf16[4096]{0} %multiply.626, bf16[] %constant.627), dimensions={0}, to_apply=%AddComputation.629, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.634 = bf16[] sqrt(bf16[] %reduce.633), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.636 = bf16[] multiply(bf16[] %sqrt.634, bf16[] %sqrt.634), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.9 = bf16[1]{0} reshape(bf16[] %multiply.636), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.801 = bf16[1]{0} add(bf16[1]{0} %add.799, bf16[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.591 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.102), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.597 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.591, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.593, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.598 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.597), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.601 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.598, bf16[4096]{0} %get-tuple-element.598), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.602 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.608 = bf16[] reduce(bf16[4096]{0} %multiply.601, bf16[] %constant.602), dimensions={0}, to_apply=%AddComputation.604, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.609 = bf16[] sqrt(bf16[] %reduce.608), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.611 = bf16[] multiply(bf16[] %sqrt.609, bf16[] %sqrt.609), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.10 = bf16[1]{0} reshape(bf16[] %multiply.611), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.803 = bf16[1]{0} add(bf16[1]{0} %add.801, bf16[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.566 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-reduce.115), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.572 = (bf16[4096]{0}, bf16[]) reduce-scatter(bf16[4096]{0} %get-tuple-element.566, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.568, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.573 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %reduce-scatter.572), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.576 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.573, bf16[4096]{0} %get-tuple-element.573), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.577 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.583 = bf16[] reduce(bf16[4096]{0} %multiply.576, bf16[] %constant.577), dimensions={0}, to_apply=%AddComputation.579, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.584 = bf16[] sqrt(bf16[] %reduce.583), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.586 = bf16[] multiply(bf16[] %sqrt.584, bf16[] %sqrt.584), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.11 = bf16[1]{0} reshape(bf16[] %multiply.586), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.805 = bf16[1]{0} add(bf16[1]{0} %add.803, bf16[1]{0} %reshape.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p27.561 = bf16[] parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %reshape.12 = bf16[1]{0} reshape(bf16[] %p27.561), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %divide.807 = bf16[1]{0} divide(bf16[1]{0} %add.805, bf16[1]{0} %reshape.12), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %multiply.550 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.547, bf16[1536,4096]{1,0} %get-tuple-element.547), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.551 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.557 = bf16[] reduce(bf16[1536,4096]{1,0} %multiply.550, bf16[] %constant.551), dimensions={0,1}, to_apply=%AddComputation.553, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.558 = bf16[] sqrt(bf16[] %reduce.557), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.560 = bf16[] multiply(bf16[] %sqrt.558, bf16[] %sqrt.558), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.560), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.809 = bf16[1]{0} add(bf16[1]{0} %divide.807, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p25.511 = bf16[4096,512]{1,0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.520 = (bf16[4096,512]{1,0}, bf16[]) reduce-scatter(bf16[4096,512]{1,0} %p25.511, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.516, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.521 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %reduce-scatter.520), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.524 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.521, bf16[4096,512]{1,0} %get-tuple-element.521), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.525 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.531 = bf16[] reduce(bf16[4096,512]{1,0} %multiply.524, bf16[] %constant.525), dimensions={0,1}, to_apply=%AddComputation.527, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.532 = bf16[] sqrt(bf16[] %reduce.531), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.534 = bf16[] multiply(bf16[] %sqrt.532, bf16[] %sqrt.532), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %multiply.534), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.811 = bf16[1]{0} add(bf16[1]{0} %add.809, bf16[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p24.485 = bf16[2752,4096]{1,0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.494 = (bf16[2752,4096]{1,0}, bf16[]) reduce-scatter(bf16[2752,4096]{1,0} %p24.485, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.490, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.495 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %reduce-scatter.494), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.498 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.495, bf16[2752,4096]{1,0} %get-tuple-element.495), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.499 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.505 = bf16[] reduce(bf16[2752,4096]{1,0} %multiply.498, bf16[] %constant.499), dimensions={0,1}, to_apply=%AddComputation.501, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.506 = bf16[] sqrt(bf16[] %reduce.505), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.508 = bf16[] multiply(bf16[] %sqrt.506, bf16[] %sqrt.506), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.15 = bf16[1]{0} reshape(bf16[] %multiply.508), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.813 = bf16[1]{0} add(bf16[1]{0} %add.811, bf16[1]{0} %reshape.15), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p23.459 = bf16[4096,1376]{1,0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.468 = (bf16[4096,1376]{1,0}, bf16[]) reduce-scatter(bf16[4096,1376]{1,0} %p23.459, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.464, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.469 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %reduce-scatter.468), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.472 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.469, bf16[4096,1376]{1,0} %get-tuple-element.469), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.473 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.479 = bf16[] reduce(bf16[4096,1376]{1,0} %multiply.472, bf16[] %constant.473), dimensions={0,1}, to_apply=%AddComputation.475, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.480 = bf16[] sqrt(bf16[] %reduce.479), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.482 = bf16[] multiply(bf16[] %sqrt.480, bf16[] %sqrt.480), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.16 = bf16[1]{0} reshape(bf16[] %multiply.482), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.815 = bf16[1]{0} add(bf16[1]{0} %add.813, bf16[1]{0} %reshape.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p22.433 = bf16[1536,4096]{1,0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.442 = (bf16[1536,4096]{1,0}, bf16[]) reduce-scatter(bf16[1536,4096]{1,0} %p22.433, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.438, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.443 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %reduce-scatter.442), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.446 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.443, bf16[1536,4096]{1,0} %get-tuple-element.443), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.447 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.453 = bf16[] reduce(bf16[1536,4096]{1,0} %multiply.446, bf16[] %constant.447), dimensions={0,1}, to_apply=%AddComputation.449, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.454 = bf16[] sqrt(bf16[] %reduce.453), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.456 = bf16[] multiply(bf16[] %sqrt.454, bf16[] %sqrt.454), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.17 = bf16[1]{0} reshape(bf16[] %multiply.456), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.817 = bf16[1]{0} add(bf16[1]{0} %add.815, bf16[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p21.407 = bf16[4096,512]{1,0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.416 = (bf16[4096,512]{1,0}, bf16[]) reduce-scatter(bf16[4096,512]{1,0} %p21.407, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.412, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.417 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %reduce-scatter.416), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.420 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.417, bf16[4096,512]{1,0} %get-tuple-element.417), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.421 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.427 = bf16[] reduce(bf16[4096,512]{1,0} %multiply.420, bf16[] %constant.421), dimensions={0,1}, to_apply=%AddComputation.423, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.428 = bf16[] sqrt(bf16[] %reduce.427), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.430 = bf16[] multiply(bf16[] %sqrt.428, bf16[] %sqrt.428), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.18 = bf16[1]{0} reshape(bf16[] %multiply.430), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.819 = bf16[1]{0} add(bf16[1]{0} %add.817, bf16[1]{0} %reshape.18), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p20.381 = bf16[2752,4096]{1,0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.390 = (bf16[2752,4096]{1,0}, bf16[]) reduce-scatter(bf16[2752,4096]{1,0} %p20.381, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.386, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.391 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %reduce-scatter.390), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.394 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.391, bf16[2752,4096]{1,0} %get-tuple-element.391), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.395 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.401 = bf16[] reduce(bf16[2752,4096]{1,0} %multiply.394, bf16[] %constant.395), dimensions={0,1}, to_apply=%AddComputation.397, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.402 = bf16[] sqrt(bf16[] %reduce.401), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.404 = bf16[] multiply(bf16[] %sqrt.402, bf16[] %sqrt.402), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.19 = bf16[1]{0} reshape(bf16[] %multiply.404), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.821 = bf16[1]{0} add(bf16[1]{0} %add.819, bf16[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p19.355 = bf16[4096,1376]{1,0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.364 = (bf16[4096,1376]{1,0}, bf16[]) reduce-scatter(bf16[4096,1376]{1,0} %p19.355, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.360, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.365 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %reduce-scatter.364), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.368 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.365, bf16[4096,1376]{1,0} %get-tuple-element.365), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.369 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.375 = bf16[] reduce(bf16[4096,1376]{1,0} %multiply.368, bf16[] %constant.369), dimensions={0,1}, to_apply=%AddComputation.371, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.376 = bf16[] sqrt(bf16[] %reduce.375), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.378 = bf16[] multiply(bf16[] %sqrt.376, bf16[] %sqrt.376), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.20 = bf16[1]{0} reshape(bf16[] %multiply.378), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.823 = bf16[1]{0} add(bf16[1]{0} %add.821, bf16[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p18.329 = bf16[1536,4096]{1,0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.338 = (bf16[1536,4096]{1,0}, bf16[]) reduce-scatter(bf16[1536,4096]{1,0} %p18.329, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.334, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.339 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %reduce-scatter.338), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.342 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.339, bf16[1536,4096]{1,0} %get-tuple-element.339), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.343 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.349 = bf16[] reduce(bf16[1536,4096]{1,0} %multiply.342, bf16[] %constant.343), dimensions={0,1}, to_apply=%AddComputation.345, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.350 = bf16[] sqrt(bf16[] %reduce.349), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.352 = bf16[] multiply(bf16[] %sqrt.350, bf16[] %sqrt.350), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.21 = bf16[1]{0} reshape(bf16[] %multiply.352), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.825 = bf16[1]{0} add(bf16[1]{0} %add.823, bf16[1]{0} %reshape.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p17.303 = bf16[4096,512]{1,0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.312 = (bf16[4096,512]{1,0}, bf16[]) reduce-scatter(bf16[4096,512]{1,0} %p17.303, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.308, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.313 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %reduce-scatter.312), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.316 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.313, bf16[4096,512]{1,0} %get-tuple-element.313), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.317 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.323 = bf16[] reduce(bf16[4096,512]{1,0} %multiply.316, bf16[] %constant.317), dimensions={0,1}, to_apply=%AddComputation.319, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.324 = bf16[] sqrt(bf16[] %reduce.323), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.326 = bf16[] multiply(bf16[] %sqrt.324, bf16[] %sqrt.324), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.22 = bf16[1]{0} reshape(bf16[] %multiply.326), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.827 = bf16[1]{0} add(bf16[1]{0} %add.825, bf16[1]{0} %reshape.22), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p16.277 = bf16[2752,4096]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.286 = (bf16[2752,4096]{1,0}, bf16[]) reduce-scatter(bf16[2752,4096]{1,0} %p16.277, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.282, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.287 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %reduce-scatter.286), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.290 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.287, bf16[2752,4096]{1,0} %get-tuple-element.287), metadata={op_type="aten__mul" op_name="aten__norm.20/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.291 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.297 = bf16[] reduce(bf16[2752,4096]{1,0} %multiply.290, bf16[] %constant.291), dimensions={0,1}, to_apply=%AddComputation.293, metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.298 = bf16[] sqrt(bf16[] %reduce.297), metadata={op_type="aten__sqrt" op_name="aten__norm.20/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.300 = bf16[] multiply(bf16[] %sqrt.298, bf16[] %sqrt.298), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.23 = bf16[1]{0} reshape(bf16[] %multiply.300), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.829 = bf16[1]{0} add(bf16[1]{0} %add.827, bf16[1]{0} %reshape.23), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p15.251 = bf16[4096,1376]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.260 = (bf16[4096,1376]{1,0}, bf16[]) reduce-scatter(bf16[4096,1376]{1,0} %p15.251, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.256, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.261 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %reduce-scatter.260), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.264 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.261, bf16[4096,1376]{1,0} %get-tuple-element.261), metadata={op_type="aten__mul" op_name="aten__norm.21/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.265 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.271 = bf16[] reduce(bf16[4096,1376]{1,0} %multiply.264, bf16[] %constant.265), dimensions={0,1}, to_apply=%AddComputation.267, metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.272 = bf16[] sqrt(bf16[] %reduce.271), metadata={op_type="aten__sqrt" op_name="aten__norm.21/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.274 = bf16[] multiply(bf16[] %sqrt.272, bf16[] %sqrt.272), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.24 = bf16[1]{0} reshape(bf16[] %multiply.274), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.831 = bf16[1]{0} add(bf16[1]{0} %add.829, bf16[1]{0} %reshape.24), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p14.225 = bf16[1536,4096]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.234 = (bf16[1536,4096]{1,0}, bf16[]) reduce-scatter(bf16[1536,4096]{1,0} %p14.225, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.230, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.235 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %reduce-scatter.234), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.238 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.235, bf16[1536,4096]{1,0} %get-tuple-element.235), metadata={op_type="aten__mul" op_name="aten__norm.22/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.239 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.245 = bf16[] reduce(bf16[1536,4096]{1,0} %multiply.238, bf16[] %constant.239), dimensions={0,1}, to_apply=%AddComputation.241, metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.246 = bf16[] sqrt(bf16[] %reduce.245), metadata={op_type="aten__sqrt" op_name="aten__norm.22/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.248 = bf16[] multiply(bf16[] %sqrt.246, bf16[] %sqrt.246), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.25 = bf16[1]{0} reshape(bf16[] %multiply.248), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.833 = bf16[1]{0} add(bf16[1]{0} %add.831, bf16[1]{0} %reshape.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p13.199 = bf16[4096,512]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.208 = (bf16[4096,512]{1,0}, bf16[]) reduce-scatter(bf16[4096,512]{1,0} %p13.199, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.204, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.209 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %reduce-scatter.208), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.212 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.209, bf16[4096,512]{1,0} %get-tuple-element.209), metadata={op_type="aten__mul" op_name="aten__norm.23/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.213 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.219 = bf16[] reduce(bf16[4096,512]{1,0} %multiply.212, bf16[] %constant.213), dimensions={0,1}, to_apply=%AddComputation.215, metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.220 = bf16[] sqrt(bf16[] %reduce.219), metadata={op_type="aten__sqrt" op_name="aten__norm.23/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.222 = bf16[] multiply(bf16[] %sqrt.220, bf16[] %sqrt.220), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.26 = bf16[1]{0} reshape(bf16[] %multiply.222), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.835 = bf16[1]{0} add(bf16[1]{0} %add.833, bf16[1]{0} %reshape.26), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p12.173 = bf16[2752,4096]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.182 = (bf16[2752,4096]{1,0}, bf16[]) reduce-scatter(bf16[2752,4096]{1,0} %p12.173, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.178, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.183 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %reduce-scatter.182), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.186 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.183, bf16[2752,4096]{1,0} %get-tuple-element.183), metadata={op_type="aten__mul" op_name="aten__norm.24/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.187 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.193 = bf16[] reduce(bf16[2752,4096]{1,0} %multiply.186, bf16[] %constant.187), dimensions={0,1}, to_apply=%AddComputation.189, metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.194 = bf16[] sqrt(bf16[] %reduce.193), metadata={op_type="aten__sqrt" op_name="aten__norm.24/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.196 = bf16[] multiply(bf16[] %sqrt.194, bf16[] %sqrt.194), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.27 = bf16[1]{0} reshape(bf16[] %multiply.196), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.837 = bf16[1]{0} add(bf16[1]{0} %add.835, bf16[1]{0} %reshape.27), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p11.147 = bf16[4096,1376]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.156 = (bf16[4096,1376]{1,0}, bf16[]) reduce-scatter(bf16[4096,1376]{1,0} %p11.147, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.152, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.157 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %reduce-scatter.156), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.160 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.157, bf16[4096,1376]{1,0} %get-tuple-element.157), metadata={op_type="aten__mul" op_name="aten__norm.25/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.161 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.167 = bf16[] reduce(bf16[4096,1376]{1,0} %multiply.160, bf16[] %constant.161), dimensions={0,1}, to_apply=%AddComputation.163, metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.168 = bf16[] sqrt(bf16[] %reduce.167), metadata={op_type="aten__sqrt" op_name="aten__norm.25/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.170 = bf16[] multiply(bf16[] %sqrt.168, bf16[] %sqrt.168), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.28 = bf16[1]{0} reshape(bf16[] %multiply.170), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.839 = bf16[1]{0} add(bf16[1]{0} %add.837, bf16[1]{0} %reshape.28), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p10.121 = bf16[4000,4096]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.130 = (bf16[4000,4096]{1,0}, bf16[]) reduce-scatter(bf16[4000,4096]{1,0} %p10.121, bf16[] %get-tuple-element.845), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, to_apply=%AddComputation.126, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.131 = bf16[4000,4096]{1,0} get-tuple-element((bf16[4000,4096]{1,0}, bf16[]) %reduce-scatter.130), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.134 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %get-tuple-element.131, bf16[4000,4096]{1,0} %get-tuple-element.131), metadata={op_type="aten__mul" op_name="aten__norm.26/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.135 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.141 = bf16[] reduce(bf16[4000,4096]{1,0} %multiply.134, bf16[] %constant.135), dimensions={0,1}, to_apply=%AddComputation.137, metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.142 = bf16[] sqrt(bf16[] %reduce.141), metadata={op_type="aten__sqrt" op_name="aten__norm.26/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.144 = bf16[] multiply(bf16[] %sqrt.142, bf16[] %sqrt.142), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.29 = bf16[1]{0} reshape(bf16[] %multiply.144), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.841 = bf16[1]{0} add(bf16[1]{0} %add.839, bf16[1]{0} %reshape.29), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %all-reduce.850 = (bf16[1]{0}, bf16[]) all-reduce(bf16[1]{0} %add.841, bf16[] %get-tuple-element.845), replica_groups={}, to_apply=%AddComputation.846, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.851 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.850), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.1 = bf16[1]{0} constant({0.5})
  %power.870 = bf16[1]{0} power(bf16[1]{0} %get-tuple-element.851, bf16[1]{0} %constant.1), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p33.865 = bf16[] parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.31 = bf16[1]{0} reshape(bf16[] %p33.865), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.872 = bf16[1]{0} add(bf16[1]{0} %power.870, bf16[1]{0} %reshape.31), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.875 = bf16[1]{0} divide(bf16[1]{0} %constant, bf16[1]{0} %add.872), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.79 = bf16[1]{0} constant({1})
  %compare.882 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.79), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.80 = bf16[1]{0} constant({1})
  %select.884 = bf16[1]{0} select(pred[1]{0} %compare.882, bf16[1]{0} %divide.875, bf16[1]{0} %constant.80), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.886 = bf16[] reshape(bf16[1]{0} %select.884), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.888 = bf16[1536,4096]{1,0} broadcast(bf16[] %reshape.886), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.889 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.547, bf16[1536,4096]{1,0} %broadcast.888), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p36.904 = bf16[] parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.908 = bf16[1536,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.909 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.889, bf16[1536,4096]{1,0} %broadcast.908), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.914 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.913, bf16[1536,4096]{1,0} %multiply.909), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p35.891 = bf16[1536,4096]{1,0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p34.890 = bf16[] parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.892 = bf16[1536,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.893 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p35.891, bf16[1536,4096]{1,0} %broadcast.892), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.895 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.889, bf16[1536,4096]{1,0} %multiply.889), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p32.859 = f32[] parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.894 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.896 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.894), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.897 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.895, bf16[1536,4096]{1,0} %broadcast.896), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.898 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.893, bf16[1536,4096]{1,0} %multiply.897), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.899 = bf16[1536,4096]{1,0} sqrt(bf16[1536,4096]{1,0} %add.898), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p31.858 = bf16[] parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.900 = bf16[1536,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.901 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %sqrt.899, bf16[1536,4096]{1,0} %broadcast.900), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p30.856 = bf16[] parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.902 = bf16[1536,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.903 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %divide.901, bf16[1536,4096]{1,0} %broadcast.902), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.930 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %add.914, bf16[1536,4096]{1,0} %add.903), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p29.854 = f32[] parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.929 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.931 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.929), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.932 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %divide.930, bf16[1536,4096]{1,0} %broadcast.931), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.933 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %subtract.928, bf16[1536,4096]{1,0} %multiply.932), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.937 = bf16[] get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.850), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-gather.938 = (bf16[1536,4096]{1,0}, bf16[]) all-gather(bf16[1536,4096]{1,0} %add.933, bf16[] %get-tuple-element.937), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.939 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.938), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p44.987 = bf16[4096,512]{1,0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.988 = bf16[4096,512]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.989 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p44.987, bf16[4096,512]{1,0} %broadcast.988), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.990 = bf16[4096,512]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.992 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.989, bf16[4096,512]{1,0} %broadcast.990), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.993 = bf16[4096,512]{1,0} subtract(bf16[4096,512]{1,0} %p44.987, bf16[4096,512]{1,0} %multiply.992), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p43.978 = bf16[4096,512]{1,0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.979 = bf16[4096,512]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.980 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p43.978, bf16[4096,512]{1,0} %broadcast.979), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.76 = bf16[1]{0} constant({1})
  %compare.952 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.76), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.77 = bf16[1]{0} constant({1})
  %select.954 = bf16[1]{0} select(pred[1]{0} %compare.952, bf16[1]{0} %divide.875, bf16[1]{0} %constant.77), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.956 = bf16[] reshape(bf16[1]{0} %select.954), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.958 = bf16[4096,512]{1,0} broadcast(bf16[] %reshape.956), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.959 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.521, bf16[4096,512]{1,0} %broadcast.958), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.976 = bf16[4096,512]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.977 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.959, bf16[4096,512]{1,0} %broadcast.976), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.981 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.980, bf16[4096,512]{1,0} %multiply.977), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p42.960 = bf16[4096,512]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.961 = bf16[4096,512]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.962 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p42.960, bf16[4096,512]{1,0} %broadcast.961), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.964 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.959, bf16[4096,512]{1,0} %multiply.959), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.963 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.965 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.963), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.966 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.964, bf16[4096,512]{1,0} %broadcast.965), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.967 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.962, bf16[4096,512]{1,0} %multiply.966), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.968 = bf16[4096,512]{1,0} sqrt(bf16[4096,512]{1,0} %add.967), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.969 = bf16[4096,512]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.970 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %sqrt.968, bf16[4096,512]{1,0} %broadcast.969), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.971 = bf16[4096,512]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.972 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %divide.970, bf16[4096,512]{1,0} %broadcast.971), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.995 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %add.981, bf16[4096,512]{1,0} %add.972), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.994 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.996 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.994), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.997 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %divide.995, bf16[4096,512]{1,0} %broadcast.996), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.998 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %subtract.993, bf16[4096,512]{1,0} %multiply.997), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1002 = bf16[] get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.938), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1003 = (bf16[4096,512]{1,0}, bf16[]) all-gather(bf16[4096,512]{1,0} %add.998, bf16[] %get-tuple-element.1002), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1004 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1003), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p47.1052 = bf16[2752,4096]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1053 = bf16[2752,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1054 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p47.1052, bf16[2752,4096]{1,0} %broadcast.1053), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1055 = bf16[2752,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1057 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1054, bf16[2752,4096]{1,0} %broadcast.1055), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1058 = bf16[2752,4096]{1,0} subtract(bf16[2752,4096]{1,0} %p47.1052, bf16[2752,4096]{1,0} %multiply.1057), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p46.1043 = bf16[2752,4096]{1,0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1044 = bf16[2752,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1045 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p46.1043, bf16[2752,4096]{1,0} %broadcast.1044), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.73 = bf16[1]{0} constant({1})
  %compare.1017 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.73), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.74 = bf16[1]{0} constant({1})
  %select.1019 = bf16[1]{0} select(pred[1]{0} %compare.1017, bf16[1]{0} %divide.875, bf16[1]{0} %constant.74), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1021 = bf16[] reshape(bf16[1]{0} %select.1019), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1023 = bf16[2752,4096]{1,0} broadcast(bf16[] %reshape.1021), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1024 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.495, bf16[2752,4096]{1,0} %broadcast.1023), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1041 = bf16[2752,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1042 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1024, bf16[2752,4096]{1,0} %broadcast.1041), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1046 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1045, bf16[2752,4096]{1,0} %multiply.1042), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p45.1025 = bf16[2752,4096]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1026 = bf16[2752,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1027 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p45.1025, bf16[2752,4096]{1,0} %broadcast.1026), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1029 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1024, bf16[2752,4096]{1,0} %multiply.1024), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1028 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1030 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1028), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1031 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1029, bf16[2752,4096]{1,0} %broadcast.1030), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1032 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1027, bf16[2752,4096]{1,0} %multiply.1031), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1033 = bf16[2752,4096]{1,0} sqrt(bf16[2752,4096]{1,0} %add.1032), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1034 = bf16[2752,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1035 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %sqrt.1033, bf16[2752,4096]{1,0} %broadcast.1034), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1036 = bf16[2752,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1037 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %divide.1035, bf16[2752,4096]{1,0} %broadcast.1036), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1060 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %add.1046, bf16[2752,4096]{1,0} %add.1037), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1059 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1061 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1059), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1062 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %divide.1060, bf16[2752,4096]{1,0} %broadcast.1061), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1063 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %subtract.1058, bf16[2752,4096]{1,0} %multiply.1062), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1067 = bf16[] get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1003), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1068 = (bf16[2752,4096]{1,0}, bf16[]) all-gather(bf16[2752,4096]{1,0} %add.1063, bf16[] %get-tuple-element.1067), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1069 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1068), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p50.1117 = bf16[4096,1376]{1,0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1118 = bf16[4096,1376]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1119 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p50.1117, bf16[4096,1376]{1,0} %broadcast.1118), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1120 = bf16[4096,1376]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1122 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1119, bf16[4096,1376]{1,0} %broadcast.1120), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1123 = bf16[4096,1376]{1,0} subtract(bf16[4096,1376]{1,0} %p50.1117, bf16[4096,1376]{1,0} %multiply.1122), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p49.1108 = bf16[4096,1376]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1109 = bf16[4096,1376]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1110 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p49.1108, bf16[4096,1376]{1,0} %broadcast.1109), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.70 = bf16[1]{0} constant({1})
  %compare.1082 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.70), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.71 = bf16[1]{0} constant({1})
  %select.1084 = bf16[1]{0} select(pred[1]{0} %compare.1082, bf16[1]{0} %divide.875, bf16[1]{0} %constant.71), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1086 = bf16[] reshape(bf16[1]{0} %select.1084), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1088 = bf16[4096,1376]{1,0} broadcast(bf16[] %reshape.1086), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1089 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.469, bf16[4096,1376]{1,0} %broadcast.1088), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1106 = bf16[4096,1376]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1107 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1089, bf16[4096,1376]{1,0} %broadcast.1106), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1111 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1110, bf16[4096,1376]{1,0} %multiply.1107), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p48.1090 = bf16[4096,1376]{1,0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1091 = bf16[4096,1376]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1092 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p48.1090, bf16[4096,1376]{1,0} %broadcast.1091), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1094 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1089, bf16[4096,1376]{1,0} %multiply.1089), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1093 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1095 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1093), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1096 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1094, bf16[4096,1376]{1,0} %broadcast.1095), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1097 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1092, bf16[4096,1376]{1,0} %multiply.1096), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1098 = bf16[4096,1376]{1,0} sqrt(bf16[4096,1376]{1,0} %add.1097), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1099 = bf16[4096,1376]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1100 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %sqrt.1098, bf16[4096,1376]{1,0} %broadcast.1099), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1101 = bf16[4096,1376]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1102 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %divide.1100, bf16[4096,1376]{1,0} %broadcast.1101), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1125 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %add.1111, bf16[4096,1376]{1,0} %add.1102), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1124 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1126 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1124), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1127 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %divide.1125, bf16[4096,1376]{1,0} %broadcast.1126), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1128 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %subtract.1123, bf16[4096,1376]{1,0} %multiply.1127), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1132 = bf16[] get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1068), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1133 = (bf16[4096,1376]{1,0}, bf16[]) all-gather(bf16[4096,1376]{1,0} %add.1128, bf16[] %get-tuple-element.1132), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1134 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1133), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p53.1181 = bf16[4096]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1182 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1183 = bf16[4096]{0} multiply(bf16[4096]{0} %p53.1181, bf16[4096]{0} %broadcast.1182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1184 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1186 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1183, bf16[4096]{0} %broadcast.1184), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1187 = bf16[4096]{0} subtract(bf16[4096]{0} %p53.1181, bf16[4096]{0} %multiply.1186), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p52.1172 = bf16[4096]{0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1173 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1174 = bf16[4096]{0} multiply(bf16[4096]{0} %p52.1172, bf16[4096]{0} %broadcast.1173), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.67 = bf16[1]{0} constant({1})
  %compare.1147 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.67), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.68 = bf16[1]{0} constant({1})
  %select.1149 = bf16[1]{0} select(pred[1]{0} %compare.1147, bf16[1]{0} %divide.875, bf16[1]{0} %constant.68), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1151 = bf16[] reshape(bf16[1]{0} %select.1149), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1152 = bf16[4096]{0} broadcast(bf16[] %reshape.1151), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1153 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.773, bf16[4096]{0} %broadcast.1152), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1170 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1171 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1153, bf16[4096]{0} %broadcast.1170), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1175 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1174, bf16[4096]{0} %multiply.1171), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p51.1154 = bf16[4096]{0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1155 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1156 = bf16[4096]{0} multiply(bf16[4096]{0} %p51.1154, bf16[4096]{0} %broadcast.1155), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1158 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1153, bf16[4096]{0} %multiply.1153), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1157 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1159 = bf16[4096]{0} broadcast(bf16[] %convert.1157), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1160 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1158, bf16[4096]{0} %broadcast.1159), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1161 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1156, bf16[4096]{0} %multiply.1160), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1162 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1161), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1163 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1164 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.1162, bf16[4096]{0} %broadcast.1163), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1165 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1166 = bf16[4096]{0} add(bf16[4096]{0} %divide.1164, bf16[4096]{0} %broadcast.1165), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1189 = bf16[4096]{0} divide(bf16[4096]{0} %add.1175, bf16[4096]{0} %add.1166), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1188 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1190 = bf16[4096]{0} broadcast(bf16[] %convert.1188), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1191 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1189, bf16[4096]{0} %broadcast.1190), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1192 = bf16[4096]{0} add(bf16[4096]{0} %subtract.1187, bf16[4096]{0} %multiply.1191), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1196 = bf16[] get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1133), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1197 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.1192, bf16[] %get-tuple-element.1196), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1198 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1197), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p56.1245 = bf16[4096]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1246 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1247 = bf16[4096]{0} multiply(bf16[4096]{0} %p56.1245, bf16[4096]{0} %broadcast.1246), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1248 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1250 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1247, bf16[4096]{0} %broadcast.1248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1251 = bf16[4096]{0} subtract(bf16[4096]{0} %p56.1245, bf16[4096]{0} %multiply.1250), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p55.1236 = bf16[4096]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1237 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1238 = bf16[4096]{0} multiply(bf16[4096]{0} %p55.1236, bf16[4096]{0} %broadcast.1237), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.64 = bf16[1]{0} constant({1})
  %compare.1211 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.64), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.65 = bf16[1]{0} constant({1})
  %select.1213 = bf16[1]{0} select(pred[1]{0} %compare.1211, bf16[1]{0} %divide.875, bf16[1]{0} %constant.65), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1215 = bf16[] reshape(bf16[1]{0} %select.1213), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1216 = bf16[4096]{0} broadcast(bf16[] %reshape.1215), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1217 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.748, bf16[4096]{0} %broadcast.1216), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1234 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1235 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1217, bf16[4096]{0} %broadcast.1234), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1239 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1238, bf16[4096]{0} %multiply.1235), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p54.1218 = bf16[4096]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1219 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1220 = bf16[4096]{0} multiply(bf16[4096]{0} %p54.1218, bf16[4096]{0} %broadcast.1219), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1222 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1217, bf16[4096]{0} %multiply.1217), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1221 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1223 = bf16[4096]{0} broadcast(bf16[] %convert.1221), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1224 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1222, bf16[4096]{0} %broadcast.1223), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1225 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1220, bf16[4096]{0} %multiply.1224), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1226 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1225), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1227 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1228 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.1226, bf16[4096]{0} %broadcast.1227), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1229 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1230 = bf16[4096]{0} add(bf16[4096]{0} %divide.1228, bf16[4096]{0} %broadcast.1229), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1253 = bf16[4096]{0} divide(bf16[4096]{0} %add.1239, bf16[4096]{0} %add.1230), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1252 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1254 = bf16[4096]{0} broadcast(bf16[] %convert.1252), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1255 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1253, bf16[4096]{0} %broadcast.1254), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1256 = bf16[4096]{0} add(bf16[4096]{0} %subtract.1251, bf16[4096]{0} %multiply.1255), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1260 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1197), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1261 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.1256, bf16[] %get-tuple-element.1260), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1262 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1261), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p59.1310 = bf16[1536,4096]{1,0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1311 = bf16[1536,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1312 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p59.1310, bf16[1536,4096]{1,0} %broadcast.1311), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1313 = bf16[1536,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1315 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1312, bf16[1536,4096]{1,0} %broadcast.1313), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1316 = bf16[1536,4096]{1,0} subtract(bf16[1536,4096]{1,0} %p59.1310, bf16[1536,4096]{1,0} %multiply.1315), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p58.1301 = bf16[1536,4096]{1,0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1302 = bf16[1536,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1303 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p58.1301, bf16[1536,4096]{1,0} %broadcast.1302), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.61 = bf16[1]{0} constant({1})
  %compare.1275 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.61), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.62 = bf16[1]{0} constant({1})
  %select.1277 = bf16[1]{0} select(pred[1]{0} %compare.1275, bf16[1]{0} %divide.875, bf16[1]{0} %constant.62), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1279 = bf16[] reshape(bf16[1]{0} %select.1277), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1281 = bf16[1536,4096]{1,0} broadcast(bf16[] %reshape.1279), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1282 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.443, bf16[1536,4096]{1,0} %broadcast.1281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1299 = bf16[1536,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1300 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1282, bf16[1536,4096]{1,0} %broadcast.1299), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1304 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.1303, bf16[1536,4096]{1,0} %multiply.1300), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p57.1283 = bf16[1536,4096]{1,0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1284 = bf16[1536,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1285 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p57.1283, bf16[1536,4096]{1,0} %broadcast.1284), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1287 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1282, bf16[1536,4096]{1,0} %multiply.1282), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1286 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1288 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.1286), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1289 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1287, bf16[1536,4096]{1,0} %broadcast.1288), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1290 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.1285, bf16[1536,4096]{1,0} %multiply.1289), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1291 = bf16[1536,4096]{1,0} sqrt(bf16[1536,4096]{1,0} %add.1290), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1292 = bf16[1536,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1293 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %sqrt.1291, bf16[1536,4096]{1,0} %broadcast.1292), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1294 = bf16[1536,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1295 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %divide.1293, bf16[1536,4096]{1,0} %broadcast.1294), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1318 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %add.1304, bf16[1536,4096]{1,0} %add.1295), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1317 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1319 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.1317), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1320 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %divide.1318, bf16[1536,4096]{1,0} %broadcast.1319), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1321 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %subtract.1316, bf16[1536,4096]{1,0} %multiply.1320), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1325 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1261), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1326 = (bf16[1536,4096]{1,0}, bf16[]) all-gather(bf16[1536,4096]{1,0} %add.1321, bf16[] %get-tuple-element.1325), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1327 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.1326), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p62.1375 = bf16[4096,512]{1,0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1376 = bf16[4096,512]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1377 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p62.1375, bf16[4096,512]{1,0} %broadcast.1376), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1378 = bf16[4096,512]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1380 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1377, bf16[4096,512]{1,0} %broadcast.1378), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1381 = bf16[4096,512]{1,0} subtract(bf16[4096,512]{1,0} %p62.1375, bf16[4096,512]{1,0} %multiply.1380), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p61.1366 = bf16[4096,512]{1,0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1367 = bf16[4096,512]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1368 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p61.1366, bf16[4096,512]{1,0} %broadcast.1367), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.58 = bf16[1]{0} constant({1})
  %compare.1340 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.58), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.59 = bf16[1]{0} constant({1})
  %select.1342 = bf16[1]{0} select(pred[1]{0} %compare.1340, bf16[1]{0} %divide.875, bf16[1]{0} %constant.59), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1344 = bf16[] reshape(bf16[1]{0} %select.1342), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1346 = bf16[4096,512]{1,0} broadcast(bf16[] %reshape.1344), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1347 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.417, bf16[4096,512]{1,0} %broadcast.1346), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1364 = bf16[4096,512]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1365 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1347, bf16[4096,512]{1,0} %broadcast.1364), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1369 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.1368, bf16[4096,512]{1,0} %multiply.1365), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p60.1348 = bf16[4096,512]{1,0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1349 = bf16[4096,512]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1350 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p60.1348, bf16[4096,512]{1,0} %broadcast.1349), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1352 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1347, bf16[4096,512]{1,0} %multiply.1347), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1351 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1353 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.1351), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1354 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1352, bf16[4096,512]{1,0} %broadcast.1353), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1355 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.1350, bf16[4096,512]{1,0} %multiply.1354), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1356 = bf16[4096,512]{1,0} sqrt(bf16[4096,512]{1,0} %add.1355), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1357 = bf16[4096,512]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1358 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %sqrt.1356, bf16[4096,512]{1,0} %broadcast.1357), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1359 = bf16[4096,512]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1360 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %divide.1358, bf16[4096,512]{1,0} %broadcast.1359), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1383 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %add.1369, bf16[4096,512]{1,0} %add.1360), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1382 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1384 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.1382), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1385 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %divide.1383, bf16[4096,512]{1,0} %broadcast.1384), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1386 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %subtract.1381, bf16[4096,512]{1,0} %multiply.1385), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1390 = bf16[] get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.1326), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1391 = (bf16[4096,512]{1,0}, bf16[]) all-gather(bf16[4096,512]{1,0} %add.1386, bf16[] %get-tuple-element.1390), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1392 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1391), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p65.1440 = bf16[2752,4096]{1,0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1441 = bf16[2752,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1442 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p65.1440, bf16[2752,4096]{1,0} %broadcast.1441), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1443 = bf16[2752,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1445 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1442, bf16[2752,4096]{1,0} %broadcast.1443), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1446 = bf16[2752,4096]{1,0} subtract(bf16[2752,4096]{1,0} %p65.1440, bf16[2752,4096]{1,0} %multiply.1445), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p64.1431 = bf16[2752,4096]{1,0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1432 = bf16[2752,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1433 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p64.1431, bf16[2752,4096]{1,0} %broadcast.1432), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.55 = bf16[1]{0} constant({1})
  %compare.1405 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.55), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.56 = bf16[1]{0} constant({1})
  %select.1407 = bf16[1]{0} select(pred[1]{0} %compare.1405, bf16[1]{0} %divide.875, bf16[1]{0} %constant.56), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1409 = bf16[] reshape(bf16[1]{0} %select.1407), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1411 = bf16[2752,4096]{1,0} broadcast(bf16[] %reshape.1409), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1412 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.391, bf16[2752,4096]{1,0} %broadcast.1411), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1429 = bf16[2752,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1430 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1412, bf16[2752,4096]{1,0} %broadcast.1429), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1434 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1433, bf16[2752,4096]{1,0} %multiply.1430), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p63.1413 = bf16[2752,4096]{1,0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1414 = bf16[2752,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1415 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p63.1413, bf16[2752,4096]{1,0} %broadcast.1414), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1417 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1412, bf16[2752,4096]{1,0} %multiply.1412), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1416 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1418 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1416), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1419 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1417, bf16[2752,4096]{1,0} %broadcast.1418), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1420 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1415, bf16[2752,4096]{1,0} %multiply.1419), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1421 = bf16[2752,4096]{1,0} sqrt(bf16[2752,4096]{1,0} %add.1420), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1422 = bf16[2752,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1423 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %sqrt.1421, bf16[2752,4096]{1,0} %broadcast.1422), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1424 = bf16[2752,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1425 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %divide.1423, bf16[2752,4096]{1,0} %broadcast.1424), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1448 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %add.1434, bf16[2752,4096]{1,0} %add.1425), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1447 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1449 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1447), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1450 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %divide.1448, bf16[2752,4096]{1,0} %broadcast.1449), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1451 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %subtract.1446, bf16[2752,4096]{1,0} %multiply.1450), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1455 = bf16[] get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1391), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1456 = (bf16[2752,4096]{1,0}, bf16[]) all-gather(bf16[2752,4096]{1,0} %add.1451, bf16[] %get-tuple-element.1455), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1457 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1456), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p68.1505 = bf16[4096,1376]{1,0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1506 = bf16[4096,1376]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1507 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p68.1505, bf16[4096,1376]{1,0} %broadcast.1506), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1508 = bf16[4096,1376]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1510 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1507, bf16[4096,1376]{1,0} %broadcast.1508), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1511 = bf16[4096,1376]{1,0} subtract(bf16[4096,1376]{1,0} %p68.1505, bf16[4096,1376]{1,0} %multiply.1510), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p67.1496 = bf16[4096,1376]{1,0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1497 = bf16[4096,1376]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1498 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p67.1496, bf16[4096,1376]{1,0} %broadcast.1497), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.52 = bf16[1]{0} constant({1})
  %compare.1470 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.52), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.53 = bf16[1]{0} constant({1})
  %select.1472 = bf16[1]{0} select(pred[1]{0} %compare.1470, bf16[1]{0} %divide.875, bf16[1]{0} %constant.53), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1474 = bf16[] reshape(bf16[1]{0} %select.1472), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1476 = bf16[4096,1376]{1,0} broadcast(bf16[] %reshape.1474), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1477 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.365, bf16[4096,1376]{1,0} %broadcast.1476), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1494 = bf16[4096,1376]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1495 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1477, bf16[4096,1376]{1,0} %broadcast.1494), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1499 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1498, bf16[4096,1376]{1,0} %multiply.1495), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p66.1478 = bf16[4096,1376]{1,0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1479 = bf16[4096,1376]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1480 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p66.1478, bf16[4096,1376]{1,0} %broadcast.1479), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1482 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1477, bf16[4096,1376]{1,0} %multiply.1477), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1481 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1483 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1481), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1484 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1482, bf16[4096,1376]{1,0} %broadcast.1483), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1485 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1480, bf16[4096,1376]{1,0} %multiply.1484), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1486 = bf16[4096,1376]{1,0} sqrt(bf16[4096,1376]{1,0} %add.1485), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1487 = bf16[4096,1376]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1488 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %sqrt.1486, bf16[4096,1376]{1,0} %broadcast.1487), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1489 = bf16[4096,1376]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1490 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %divide.1488, bf16[4096,1376]{1,0} %broadcast.1489), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1513 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %add.1499, bf16[4096,1376]{1,0} %add.1490), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1512 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1514 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1512), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1515 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %divide.1513, bf16[4096,1376]{1,0} %broadcast.1514), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1516 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %subtract.1511, bf16[4096,1376]{1,0} %multiply.1515), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1520 = bf16[] get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1456), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1521 = (bf16[4096,1376]{1,0}, bf16[]) all-gather(bf16[4096,1376]{1,0} %add.1516, bf16[] %get-tuple-element.1520), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1522 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1521), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p71.1569 = bf16[4096]{0} parameter(71), frontend_attributes={neff_input_names="input71"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1570 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1571 = bf16[4096]{0} multiply(bf16[4096]{0} %p71.1569, bf16[4096]{0} %broadcast.1570), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1572 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1574 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1571, bf16[4096]{0} %broadcast.1572), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1575 = bf16[4096]{0} subtract(bf16[4096]{0} %p71.1569, bf16[4096]{0} %multiply.1574), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p70.1560 = bf16[4096]{0} parameter(70), frontend_attributes={neff_input_names="input70"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1561 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1562 = bf16[4096]{0} multiply(bf16[4096]{0} %p70.1560, bf16[4096]{0} %broadcast.1561), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.49 = bf16[1]{0} constant({1})
  %compare.1535 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.49), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.50 = bf16[1]{0} constant({1})
  %select.1537 = bf16[1]{0} select(pred[1]{0} %compare.1535, bf16[1]{0} %divide.875, bf16[1]{0} %constant.50), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1539 = bf16[] reshape(bf16[1]{0} %select.1537), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1540 = bf16[4096]{0} broadcast(bf16[] %reshape.1539), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1541 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.723, bf16[4096]{0} %broadcast.1540), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1558 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1559 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1541, bf16[4096]{0} %broadcast.1558), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1563 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1562, bf16[4096]{0} %multiply.1559), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p69.1542 = bf16[4096]{0} parameter(69), frontend_attributes={neff_input_names="input69"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1543 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1544 = bf16[4096]{0} multiply(bf16[4096]{0} %p69.1542, bf16[4096]{0} %broadcast.1543), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1546 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1541, bf16[4096]{0} %multiply.1541), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1545 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1547 = bf16[4096]{0} broadcast(bf16[] %convert.1545), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1548 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1546, bf16[4096]{0} %broadcast.1547), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1549 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1544, bf16[4096]{0} %multiply.1548), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1550 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1549), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1551 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1552 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.1550, bf16[4096]{0} %broadcast.1551), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1553 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1554 = bf16[4096]{0} add(bf16[4096]{0} %divide.1552, bf16[4096]{0} %broadcast.1553), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1577 = bf16[4096]{0} divide(bf16[4096]{0} %add.1563, bf16[4096]{0} %add.1554), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1576 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1578 = bf16[4096]{0} broadcast(bf16[] %convert.1576), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1579 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1577, bf16[4096]{0} %broadcast.1578), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1580 = bf16[4096]{0} add(bf16[4096]{0} %subtract.1575, bf16[4096]{0} %multiply.1579), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1584 = bf16[] get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1521), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1585 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.1580, bf16[] %get-tuple-element.1584), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1586 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1585), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p74.1633 = bf16[4096]{0} parameter(74), frontend_attributes={neff_input_names="input74"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1634 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1635 = bf16[4096]{0} multiply(bf16[4096]{0} %p74.1633, bf16[4096]{0} %broadcast.1634), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1636 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1638 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1635, bf16[4096]{0} %broadcast.1636), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1639 = bf16[4096]{0} subtract(bf16[4096]{0} %p74.1633, bf16[4096]{0} %multiply.1638), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p73.1624 = bf16[4096]{0} parameter(73), frontend_attributes={neff_input_names="input73"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1625 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1626 = bf16[4096]{0} multiply(bf16[4096]{0} %p73.1624, bf16[4096]{0} %broadcast.1625), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.46 = bf16[1]{0} constant({1})
  %compare.1599 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.46), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.47 = bf16[1]{0} constant({1})
  %select.1601 = bf16[1]{0} select(pred[1]{0} %compare.1599, bf16[1]{0} %divide.875, bf16[1]{0} %constant.47), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1603 = bf16[] reshape(bf16[1]{0} %select.1601), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1604 = bf16[4096]{0} broadcast(bf16[] %reshape.1603), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1605 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.698, bf16[4096]{0} %broadcast.1604), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1622 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1623 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1605, bf16[4096]{0} %broadcast.1622), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1627 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1626, bf16[4096]{0} %multiply.1623), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p72.1606 = bf16[4096]{0} parameter(72), frontend_attributes={neff_input_names="input72"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1607 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1608 = bf16[4096]{0} multiply(bf16[4096]{0} %p72.1606, bf16[4096]{0} %broadcast.1607), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1610 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1605, bf16[4096]{0} %multiply.1605), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1609 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1611 = bf16[4096]{0} broadcast(bf16[] %convert.1609), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1612 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1610, bf16[4096]{0} %broadcast.1611), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1613 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1608, bf16[4096]{0} %multiply.1612), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1614 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1613), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1615 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1616 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.1614, bf16[4096]{0} %broadcast.1615), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1617 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1618 = bf16[4096]{0} add(bf16[4096]{0} %divide.1616, bf16[4096]{0} %broadcast.1617), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1641 = bf16[4096]{0} divide(bf16[4096]{0} %add.1627, bf16[4096]{0} %add.1618), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1640 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1642 = bf16[4096]{0} broadcast(bf16[] %convert.1640), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1643 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1641, bf16[4096]{0} %broadcast.1642), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1644 = bf16[4096]{0} add(bf16[4096]{0} %subtract.1639, bf16[4096]{0} %multiply.1643), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1648 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1585), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1649 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.1644, bf16[] %get-tuple-element.1648), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1650 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1649), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p77.1698 = bf16[1536,4096]{1,0} parameter(77), frontend_attributes={neff_input_names="input77"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1699 = bf16[1536,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1700 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p77.1698, bf16[1536,4096]{1,0} %broadcast.1699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1701 = bf16[1536,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1703 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1700, bf16[1536,4096]{1,0} %broadcast.1701), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1704 = bf16[1536,4096]{1,0} subtract(bf16[1536,4096]{1,0} %p77.1698, bf16[1536,4096]{1,0} %multiply.1703), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p76.1689 = bf16[1536,4096]{1,0} parameter(76), frontend_attributes={neff_input_names="input76"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1690 = bf16[1536,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1691 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p76.1689, bf16[1536,4096]{1,0} %broadcast.1690), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.43 = bf16[1]{0} constant({1})
  %compare.1663 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.43), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.44 = bf16[1]{0} constant({1})
  %select.1665 = bf16[1]{0} select(pred[1]{0} %compare.1663, bf16[1]{0} %divide.875, bf16[1]{0} %constant.44), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1667 = bf16[] reshape(bf16[1]{0} %select.1665), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1669 = bf16[1536,4096]{1,0} broadcast(bf16[] %reshape.1667), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1670 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.339, bf16[1536,4096]{1,0} %broadcast.1669), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1687 = bf16[1536,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1688 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1670, bf16[1536,4096]{1,0} %broadcast.1687), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1692 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.1691, bf16[1536,4096]{1,0} %multiply.1688), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p75.1671 = bf16[1536,4096]{1,0} parameter(75), frontend_attributes={neff_input_names="input75"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1672 = bf16[1536,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1673 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p75.1671, bf16[1536,4096]{1,0} %broadcast.1672), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1675 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1670, bf16[1536,4096]{1,0} %multiply.1670), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1674 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1676 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.1674), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1677 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.1675, bf16[1536,4096]{1,0} %broadcast.1676), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1678 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.1673, bf16[1536,4096]{1,0} %multiply.1677), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1679 = bf16[1536,4096]{1,0} sqrt(bf16[1536,4096]{1,0} %add.1678), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1680 = bf16[1536,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1681 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %sqrt.1679, bf16[1536,4096]{1,0} %broadcast.1680), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1682 = bf16[1536,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1683 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %divide.1681, bf16[1536,4096]{1,0} %broadcast.1682), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1706 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %add.1692, bf16[1536,4096]{1,0} %add.1683), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1705 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1707 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.1705), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1708 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %divide.1706, bf16[1536,4096]{1,0} %broadcast.1707), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1709 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %subtract.1704, bf16[1536,4096]{1,0} %multiply.1708), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1713 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1649), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1714 = (bf16[1536,4096]{1,0}, bf16[]) all-gather(bf16[1536,4096]{1,0} %add.1709, bf16[] %get-tuple-element.1713), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1715 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.1714), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p80.1763 = bf16[4096,512]{1,0} parameter(80), frontend_attributes={neff_input_names="input80"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1764 = bf16[4096,512]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1765 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p80.1763, bf16[4096,512]{1,0} %broadcast.1764), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1766 = bf16[4096,512]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1768 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1765, bf16[4096,512]{1,0} %broadcast.1766), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1769 = bf16[4096,512]{1,0} subtract(bf16[4096,512]{1,0} %p80.1763, bf16[4096,512]{1,0} %multiply.1768), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p79.1754 = bf16[4096,512]{1,0} parameter(79), frontend_attributes={neff_input_names="input79"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1755 = bf16[4096,512]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1756 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p79.1754, bf16[4096,512]{1,0} %broadcast.1755), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.40 = bf16[1]{0} constant({1})
  %compare.1728 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.40), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.41 = bf16[1]{0} constant({1})
  %select.1730 = bf16[1]{0} select(pred[1]{0} %compare.1728, bf16[1]{0} %divide.875, bf16[1]{0} %constant.41), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1732 = bf16[] reshape(bf16[1]{0} %select.1730), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1734 = bf16[4096,512]{1,0} broadcast(bf16[] %reshape.1732), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1735 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.313, bf16[4096,512]{1,0} %broadcast.1734), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1752 = bf16[4096,512]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1753 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1735, bf16[4096,512]{1,0} %broadcast.1752), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1757 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.1756, bf16[4096,512]{1,0} %multiply.1753), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p78.1736 = bf16[4096,512]{1,0} parameter(78), frontend_attributes={neff_input_names="input78"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1737 = bf16[4096,512]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1738 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p78.1736, bf16[4096,512]{1,0} %broadcast.1737), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1740 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1735, bf16[4096,512]{1,0} %multiply.1735), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1739 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1741 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.1739), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1742 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.1740, bf16[4096,512]{1,0} %broadcast.1741), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1743 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.1738, bf16[4096,512]{1,0} %multiply.1742), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1744 = bf16[4096,512]{1,0} sqrt(bf16[4096,512]{1,0} %add.1743), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1745 = bf16[4096,512]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1746 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %sqrt.1744, bf16[4096,512]{1,0} %broadcast.1745), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1747 = bf16[4096,512]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1748 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %divide.1746, bf16[4096,512]{1,0} %broadcast.1747), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1771 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %add.1757, bf16[4096,512]{1,0} %add.1748), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1770 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1772 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.1770), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1773 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %divide.1771, bf16[4096,512]{1,0} %broadcast.1772), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1774 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %subtract.1769, bf16[4096,512]{1,0} %multiply.1773), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1778 = bf16[] get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.1714), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1779 = (bf16[4096,512]{1,0}, bf16[]) all-gather(bf16[4096,512]{1,0} %add.1774, bf16[] %get-tuple-element.1778), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1780 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1779), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p83.1828 = bf16[2752,4096]{1,0} parameter(83), frontend_attributes={neff_input_names="input83"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1829 = bf16[2752,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1830 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p83.1828, bf16[2752,4096]{1,0} %broadcast.1829), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1831 = bf16[2752,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1833 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1830, bf16[2752,4096]{1,0} %broadcast.1831), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1834 = bf16[2752,4096]{1,0} subtract(bf16[2752,4096]{1,0} %p83.1828, bf16[2752,4096]{1,0} %multiply.1833), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p82.1819 = bf16[2752,4096]{1,0} parameter(82), frontend_attributes={neff_input_names="input82"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1820 = bf16[2752,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1821 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p82.1819, bf16[2752,4096]{1,0} %broadcast.1820), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.37 = bf16[1]{0} constant({1})
  %compare.1793 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.38 = bf16[1]{0} constant({1})
  %select.1795 = bf16[1]{0} select(pred[1]{0} %compare.1793, bf16[1]{0} %divide.875, bf16[1]{0} %constant.38), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1797 = bf16[] reshape(bf16[1]{0} %select.1795), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1799 = bf16[2752,4096]{1,0} broadcast(bf16[] %reshape.1797), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1800 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.287, bf16[2752,4096]{1,0} %broadcast.1799), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1817 = bf16[2752,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1818 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1800, bf16[2752,4096]{1,0} %broadcast.1817), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1822 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1821, bf16[2752,4096]{1,0} %multiply.1818), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p81.1801 = bf16[2752,4096]{1,0} parameter(81), frontend_attributes={neff_input_names="input81"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1802 = bf16[2752,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1803 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p81.1801, bf16[2752,4096]{1,0} %broadcast.1802), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1805 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1800, bf16[2752,4096]{1,0} %multiply.1800), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1804 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1806 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1804), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1807 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.1805, bf16[2752,4096]{1,0} %broadcast.1806), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1808 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.1803, bf16[2752,4096]{1,0} %multiply.1807), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1809 = bf16[2752,4096]{1,0} sqrt(bf16[2752,4096]{1,0} %add.1808), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1810 = bf16[2752,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1811 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %sqrt.1809, bf16[2752,4096]{1,0} %broadcast.1810), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1812 = bf16[2752,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1813 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %divide.1811, bf16[2752,4096]{1,0} %broadcast.1812), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1836 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %add.1822, bf16[2752,4096]{1,0} %add.1813), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1835 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1837 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.1835), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1838 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %divide.1836, bf16[2752,4096]{1,0} %broadcast.1837), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1839 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %subtract.1834, bf16[2752,4096]{1,0} %multiply.1838), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1843 = bf16[] get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.1779), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1844 = (bf16[2752,4096]{1,0}, bf16[]) all-gather(bf16[2752,4096]{1,0} %add.1839, bf16[] %get-tuple-element.1843), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1845 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1844), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p86.1893 = bf16[4096,1376]{1,0} parameter(86), frontend_attributes={neff_input_names="input86"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1894 = bf16[4096,1376]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1895 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p86.1893, bf16[4096,1376]{1,0} %broadcast.1894), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1896 = bf16[4096,1376]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1898 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1895, bf16[4096,1376]{1,0} %broadcast.1896), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1899 = bf16[4096,1376]{1,0} subtract(bf16[4096,1376]{1,0} %p86.1893, bf16[4096,1376]{1,0} %multiply.1898), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p85.1884 = bf16[4096,1376]{1,0} parameter(85), frontend_attributes={neff_input_names="input85"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1885 = bf16[4096,1376]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1886 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p85.1884, bf16[4096,1376]{1,0} %broadcast.1885), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.34 = bf16[1]{0} constant({1})
  %compare.1858 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.34), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.35 = bf16[1]{0} constant({1})
  %select.1860 = bf16[1]{0} select(pred[1]{0} %compare.1858, bf16[1]{0} %divide.875, bf16[1]{0} %constant.35), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1862 = bf16[] reshape(bf16[1]{0} %select.1860), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1864 = bf16[4096,1376]{1,0} broadcast(bf16[] %reshape.1862), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1865 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.261, bf16[4096,1376]{1,0} %broadcast.1864), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1882 = bf16[4096,1376]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1883 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1865, bf16[4096,1376]{1,0} %broadcast.1882), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1887 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1886, bf16[4096,1376]{1,0} %multiply.1883), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p84.1866 = bf16[4096,1376]{1,0} parameter(84), frontend_attributes={neff_input_names="input84"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1867 = bf16[4096,1376]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1868 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p84.1866, bf16[4096,1376]{1,0} %broadcast.1867), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1870 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1865, bf16[4096,1376]{1,0} %multiply.1865), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1869 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1871 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1869), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1872 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.1870, bf16[4096,1376]{1,0} %broadcast.1871), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1873 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.1868, bf16[4096,1376]{1,0} %multiply.1872), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1874 = bf16[4096,1376]{1,0} sqrt(bf16[4096,1376]{1,0} %add.1873), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1875 = bf16[4096,1376]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1876 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %sqrt.1874, bf16[4096,1376]{1,0} %broadcast.1875), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1877 = bf16[4096,1376]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1878 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %divide.1876, bf16[4096,1376]{1,0} %broadcast.1877), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1901 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %add.1887, bf16[4096,1376]{1,0} %add.1878), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1900 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1902 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.1900), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1903 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %divide.1901, bf16[4096,1376]{1,0} %broadcast.1902), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1904 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %subtract.1899, bf16[4096,1376]{1,0} %multiply.1903), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1908 = bf16[] get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.1844), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1909 = (bf16[4096,1376]{1,0}, bf16[]) all-gather(bf16[4096,1376]{1,0} %add.1904, bf16[] %get-tuple-element.1908), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1910 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1909), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p89.1957 = bf16[4096]{0} parameter(89), frontend_attributes={neff_input_names="input89"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1958 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1959 = bf16[4096]{0} multiply(bf16[4096]{0} %p89.1957, bf16[4096]{0} %broadcast.1958), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1960 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1962 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1959, bf16[4096]{0} %broadcast.1960), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1963 = bf16[4096]{0} subtract(bf16[4096]{0} %p89.1957, bf16[4096]{0} %multiply.1962), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p88.1948 = bf16[4096]{0} parameter(88), frontend_attributes={neff_input_names="input88"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1949 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1950 = bf16[4096]{0} multiply(bf16[4096]{0} %p88.1948, bf16[4096]{0} %broadcast.1949), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.31 = bf16[1]{0} constant({1})
  %compare.1923 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.31), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.32 = bf16[1]{0} constant({1})
  %select.1925 = bf16[1]{0} select(pred[1]{0} %compare.1923, bf16[1]{0} %divide.875, bf16[1]{0} %constant.32), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1927 = bf16[] reshape(bf16[1]{0} %select.1925), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1928 = bf16[4096]{0} broadcast(bf16[] %reshape.1927), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1929 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.673, bf16[4096]{0} %broadcast.1928), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1946 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1947 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1929, bf16[4096]{0} %broadcast.1946), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1951 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1950, bf16[4096]{0} %multiply.1947), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p87.1930 = bf16[4096]{0} parameter(87), frontend_attributes={neff_input_names="input87"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1931 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1932 = bf16[4096]{0} multiply(bf16[4096]{0} %p87.1930, bf16[4096]{0} %broadcast.1931), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1934 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1929, bf16[4096]{0} %multiply.1929), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1933 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1935 = bf16[4096]{0} broadcast(bf16[] %convert.1933), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1936 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1934, bf16[4096]{0} %broadcast.1935), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1937 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1932, bf16[4096]{0} %multiply.1936), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1938 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1937), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1939 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1940 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.1938, bf16[4096]{0} %broadcast.1939), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1941 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1942 = bf16[4096]{0} add(bf16[4096]{0} %divide.1940, bf16[4096]{0} %broadcast.1941), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1965 = bf16[4096]{0} divide(bf16[4096]{0} %add.1951, bf16[4096]{0} %add.1942), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1964 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1966 = bf16[4096]{0} broadcast(bf16[] %convert.1964), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1967 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1965, bf16[4096]{0} %broadcast.1966), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1968 = bf16[4096]{0} add(bf16[4096]{0} %subtract.1963, bf16[4096]{0} %multiply.1967), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1972 = bf16[] get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.1909), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1973 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.1968, bf16[] %get-tuple-element.1972), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1974 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1973), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p92.2021 = bf16[4096]{0} parameter(92), frontend_attributes={neff_input_names="input92"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2022 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2023 = bf16[4096]{0} multiply(bf16[4096]{0} %p92.2021, bf16[4096]{0} %broadcast.2022), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2024 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2026 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2023, bf16[4096]{0} %broadcast.2024), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2027 = bf16[4096]{0} subtract(bf16[4096]{0} %p92.2021, bf16[4096]{0} %multiply.2026), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p91.2012 = bf16[4096]{0} parameter(91), frontend_attributes={neff_input_names="input91"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2013 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2014 = bf16[4096]{0} multiply(bf16[4096]{0} %p91.2012, bf16[4096]{0} %broadcast.2013), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.28 = bf16[1]{0} constant({1})
  %compare.1987 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.28), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.29 = bf16[1]{0} constant({1})
  %select.1989 = bf16[1]{0} select(pred[1]{0} %compare.1987, bf16[1]{0} %divide.875, bf16[1]{0} %constant.29), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1991 = bf16[] reshape(bf16[1]{0} %select.1989), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1992 = bf16[4096]{0} broadcast(bf16[] %reshape.1991), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1993 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.648, bf16[4096]{0} %broadcast.1992), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2010 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2011 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1993, bf16[4096]{0} %broadcast.2010), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2015 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2014, bf16[4096]{0} %multiply.2011), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p90.1994 = bf16[4096]{0} parameter(90), frontend_attributes={neff_input_names="input90"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1995 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1996 = bf16[4096]{0} multiply(bf16[4096]{0} %p90.1994, bf16[4096]{0} %broadcast.1995), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1998 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1993, bf16[4096]{0} %multiply.1993), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1997 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1999 = bf16[4096]{0} broadcast(bf16[] %convert.1997), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2000 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1998, bf16[4096]{0} %broadcast.1999), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2001 = bf16[4096]{0} add(bf16[4096]{0} %multiply.1996, bf16[4096]{0} %multiply.2000), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2002 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.2001), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2003 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2004 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.2002, bf16[4096]{0} %broadcast.2003), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2005 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2006 = bf16[4096]{0} add(bf16[4096]{0} %divide.2004, bf16[4096]{0} %broadcast.2005), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2029 = bf16[4096]{0} divide(bf16[4096]{0} %add.2015, bf16[4096]{0} %add.2006), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2028 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2030 = bf16[4096]{0} broadcast(bf16[] %convert.2028), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2031 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.2029, bf16[4096]{0} %broadcast.2030), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2032 = bf16[4096]{0} add(bf16[4096]{0} %subtract.2027, bf16[4096]{0} %multiply.2031), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2036 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.1973), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2037 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.2032, bf16[] %get-tuple-element.2036), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2038 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2037), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p95.2086 = bf16[1536,4096]{1,0} parameter(95), frontend_attributes={neff_input_names="input95"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2087 = bf16[1536,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2088 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p95.2086, bf16[1536,4096]{1,0} %broadcast.2087), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2089 = bf16[1536,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2091 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.2088, bf16[1536,4096]{1,0} %broadcast.2089), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2092 = bf16[1536,4096]{1,0} subtract(bf16[1536,4096]{1,0} %p95.2086, bf16[1536,4096]{1,0} %multiply.2091), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p94.2077 = bf16[1536,4096]{1,0} parameter(94), frontend_attributes={neff_input_names="input94"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2078 = bf16[1536,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2079 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p94.2077, bf16[1536,4096]{1,0} %broadcast.2078), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.25 = bf16[1]{0} constant({1})
  %compare.2051 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.26 = bf16[1]{0} constant({1})
  %select.2053 = bf16[1]{0} select(pred[1]{0} %compare.2051, bf16[1]{0} %divide.875, bf16[1]{0} %constant.26), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2055 = bf16[] reshape(bf16[1]{0} %select.2053), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2057 = bf16[1536,4096]{1,0} broadcast(bf16[] %reshape.2055), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2058 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %get-tuple-element.235, bf16[1536,4096]{1,0} %broadcast.2057), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2075 = bf16[1536,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2076 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.2058, bf16[1536,4096]{1,0} %broadcast.2075), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2080 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.2079, bf16[1536,4096]{1,0} %multiply.2076), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p93.2059 = bf16[1536,4096]{1,0} parameter(93), frontend_attributes={neff_input_names="input93"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2060 = bf16[1536,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2061 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %p93.2059, bf16[1536,4096]{1,0} %broadcast.2060), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2063 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.2058, bf16[1536,4096]{1,0} %multiply.2058), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2062 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2064 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.2062), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2065 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %multiply.2063, bf16[1536,4096]{1,0} %broadcast.2064), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2066 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %multiply.2061, bf16[1536,4096]{1,0} %multiply.2065), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2067 = bf16[1536,4096]{1,0} sqrt(bf16[1536,4096]{1,0} %add.2066), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2068 = bf16[1536,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2069 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %sqrt.2067, bf16[1536,4096]{1,0} %broadcast.2068), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2070 = bf16[1536,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2071 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %divide.2069, bf16[1536,4096]{1,0} %broadcast.2070), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2094 = bf16[1536,4096]{1,0} divide(bf16[1536,4096]{1,0} %add.2080, bf16[1536,4096]{1,0} %add.2071), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2093 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2095 = bf16[1536,4096]{1,0} broadcast(bf16[] %convert.2093), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2096 = bf16[1536,4096]{1,0} multiply(bf16[1536,4096]{1,0} %divide.2094, bf16[1536,4096]{1,0} %broadcast.2095), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2097 = bf16[1536,4096]{1,0} add(bf16[1536,4096]{1,0} %subtract.2092, bf16[1536,4096]{1,0} %multiply.2096), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2101 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2037), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2102 = (bf16[1536,4096]{1,0}, bf16[]) all-gather(bf16[1536,4096]{1,0} %add.2097, bf16[] %get-tuple-element.2101), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2103 = bf16[1536,4096]{1,0} get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.2102), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p98.2151 = bf16[4096,512]{1,0} parameter(98), frontend_attributes={neff_input_names="input98"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2152 = bf16[4096,512]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2153 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p98.2151, bf16[4096,512]{1,0} %broadcast.2152), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2154 = bf16[4096,512]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2156 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.2153, bf16[4096,512]{1,0} %broadcast.2154), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2157 = bf16[4096,512]{1,0} subtract(bf16[4096,512]{1,0} %p98.2151, bf16[4096,512]{1,0} %multiply.2156), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p97.2142 = bf16[4096,512]{1,0} parameter(97), frontend_attributes={neff_input_names="input97"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2143 = bf16[4096,512]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2144 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p97.2142, bf16[4096,512]{1,0} %broadcast.2143), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.22 = bf16[1]{0} constant({1})
  %compare.2116 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.22), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.23 = bf16[1]{0} constant({1})
  %select.2118 = bf16[1]{0} select(pred[1]{0} %compare.2116, bf16[1]{0} %divide.875, bf16[1]{0} %constant.23), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2120 = bf16[] reshape(bf16[1]{0} %select.2118), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2122 = bf16[4096,512]{1,0} broadcast(bf16[] %reshape.2120), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2123 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %get-tuple-element.209, bf16[4096,512]{1,0} %broadcast.2122), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2140 = bf16[4096,512]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2141 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.2123, bf16[4096,512]{1,0} %broadcast.2140), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2145 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.2144, bf16[4096,512]{1,0} %multiply.2141), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p96.2124 = bf16[4096,512]{1,0} parameter(96), frontend_attributes={neff_input_names="input96"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2125 = bf16[4096,512]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2126 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %p96.2124, bf16[4096,512]{1,0} %broadcast.2125), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2128 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.2123, bf16[4096,512]{1,0} %multiply.2123), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2127 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2129 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.2127), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2130 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %multiply.2128, bf16[4096,512]{1,0} %broadcast.2129), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2131 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %multiply.2126, bf16[4096,512]{1,0} %multiply.2130), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2132 = bf16[4096,512]{1,0} sqrt(bf16[4096,512]{1,0} %add.2131), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2133 = bf16[4096,512]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2134 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %sqrt.2132, bf16[4096,512]{1,0} %broadcast.2133), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2135 = bf16[4096,512]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2136 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %divide.2134, bf16[4096,512]{1,0} %broadcast.2135), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2159 = bf16[4096,512]{1,0} divide(bf16[4096,512]{1,0} %add.2145, bf16[4096,512]{1,0} %add.2136), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2158 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2160 = bf16[4096,512]{1,0} broadcast(bf16[] %convert.2158), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2161 = bf16[4096,512]{1,0} multiply(bf16[4096,512]{1,0} %divide.2159, bf16[4096,512]{1,0} %broadcast.2160), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2162 = bf16[4096,512]{1,0} add(bf16[4096,512]{1,0} %subtract.2157, bf16[4096,512]{1,0} %multiply.2161), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2166 = bf16[] get-tuple-element((bf16[1536,4096]{1,0}, bf16[]) %all-gather.2102), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2167 = (bf16[4096,512]{1,0}, bf16[]) all-gather(bf16[4096,512]{1,0} %add.2162, bf16[] %get-tuple-element.2166), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2168 = bf16[4096,512]{1,0} get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.2167), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p101.2216 = bf16[2752,4096]{1,0} parameter(101), frontend_attributes={neff_input_names="input101"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2217 = bf16[2752,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2218 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p101.2216, bf16[2752,4096]{1,0} %broadcast.2217), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2219 = bf16[2752,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2221 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.2218, bf16[2752,4096]{1,0} %broadcast.2219), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2222 = bf16[2752,4096]{1,0} subtract(bf16[2752,4096]{1,0} %p101.2216, bf16[2752,4096]{1,0} %multiply.2221), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p100.2207 = bf16[2752,4096]{1,0} parameter(100), frontend_attributes={neff_input_names="input100"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2208 = bf16[2752,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2209 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p100.2207, bf16[2752,4096]{1,0} %broadcast.2208), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.19 = bf16[1]{0} constant({1})
  %compare.2181 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.19), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.20 = bf16[1]{0} constant({1})
  %select.2183 = bf16[1]{0} select(pred[1]{0} %compare.2181, bf16[1]{0} %divide.875, bf16[1]{0} %constant.20), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2185 = bf16[] reshape(bf16[1]{0} %select.2183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2187 = bf16[2752,4096]{1,0} broadcast(bf16[] %reshape.2185), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2188 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %get-tuple-element.183, bf16[2752,4096]{1,0} %broadcast.2187), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2205 = bf16[2752,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2206 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.2188, bf16[2752,4096]{1,0} %broadcast.2205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2210 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.2209, bf16[2752,4096]{1,0} %multiply.2206), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p99.2189 = bf16[2752,4096]{1,0} parameter(99), frontend_attributes={neff_input_names="input99"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2190 = bf16[2752,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2191 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %p99.2189, bf16[2752,4096]{1,0} %broadcast.2190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2193 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.2188, bf16[2752,4096]{1,0} %multiply.2188), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2192 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2194 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.2192), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2195 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %multiply.2193, bf16[2752,4096]{1,0} %broadcast.2194), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2196 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %multiply.2191, bf16[2752,4096]{1,0} %multiply.2195), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2197 = bf16[2752,4096]{1,0} sqrt(bf16[2752,4096]{1,0} %add.2196), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2198 = bf16[2752,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2199 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %sqrt.2197, bf16[2752,4096]{1,0} %broadcast.2198), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2200 = bf16[2752,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2201 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %divide.2199, bf16[2752,4096]{1,0} %broadcast.2200), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2224 = bf16[2752,4096]{1,0} divide(bf16[2752,4096]{1,0} %add.2210, bf16[2752,4096]{1,0} %add.2201), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2223 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2225 = bf16[2752,4096]{1,0} broadcast(bf16[] %convert.2223), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2226 = bf16[2752,4096]{1,0} multiply(bf16[2752,4096]{1,0} %divide.2224, bf16[2752,4096]{1,0} %broadcast.2225), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2227 = bf16[2752,4096]{1,0} add(bf16[2752,4096]{1,0} %subtract.2222, bf16[2752,4096]{1,0} %multiply.2226), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2231 = bf16[] get-tuple-element((bf16[4096,512]{1,0}, bf16[]) %all-gather.2167), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2232 = (bf16[2752,4096]{1,0}, bf16[]) all-gather(bf16[2752,4096]{1,0} %add.2227, bf16[] %get-tuple-element.2231), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2233 = bf16[2752,4096]{1,0} get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.2232), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p104.2281 = bf16[4096,1376]{1,0} parameter(104), frontend_attributes={neff_input_names="input104"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2282 = bf16[4096,1376]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2283 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p104.2281, bf16[4096,1376]{1,0} %broadcast.2282), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2284 = bf16[4096,1376]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2286 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.2283, bf16[4096,1376]{1,0} %broadcast.2284), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2287 = bf16[4096,1376]{1,0} subtract(bf16[4096,1376]{1,0} %p104.2281, bf16[4096,1376]{1,0} %multiply.2286), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p103.2272 = bf16[4096,1376]{1,0} parameter(103), frontend_attributes={neff_input_names="input103"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2273 = bf16[4096,1376]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2274 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p103.2272, bf16[4096,1376]{1,0} %broadcast.2273), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.16 = bf16[1]{0} constant({1})
  %compare.2246 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.16), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.17 = bf16[1]{0} constant({1})
  %select.2248 = bf16[1]{0} select(pred[1]{0} %compare.2246, bf16[1]{0} %divide.875, bf16[1]{0} %constant.17), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2250 = bf16[] reshape(bf16[1]{0} %select.2248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2252 = bf16[4096,1376]{1,0} broadcast(bf16[] %reshape.2250), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2253 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %get-tuple-element.157, bf16[4096,1376]{1,0} %broadcast.2252), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2270 = bf16[4096,1376]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2271 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.2253, bf16[4096,1376]{1,0} %broadcast.2270), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2275 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.2274, bf16[4096,1376]{1,0} %multiply.2271), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p102.2254 = bf16[4096,1376]{1,0} parameter(102), frontend_attributes={neff_input_names="input102"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2255 = bf16[4096,1376]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2256 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %p102.2254, bf16[4096,1376]{1,0} %broadcast.2255), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2258 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.2253, bf16[4096,1376]{1,0} %multiply.2253), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2257 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2259 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.2257), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2260 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %multiply.2258, bf16[4096,1376]{1,0} %broadcast.2259), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2261 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %multiply.2256, bf16[4096,1376]{1,0} %multiply.2260), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2262 = bf16[4096,1376]{1,0} sqrt(bf16[4096,1376]{1,0} %add.2261), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2263 = bf16[4096,1376]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2264 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %sqrt.2262, bf16[4096,1376]{1,0} %broadcast.2263), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2265 = bf16[4096,1376]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2266 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %divide.2264, bf16[4096,1376]{1,0} %broadcast.2265), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2289 = bf16[4096,1376]{1,0} divide(bf16[4096,1376]{1,0} %add.2275, bf16[4096,1376]{1,0} %add.2266), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2288 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2290 = bf16[4096,1376]{1,0} broadcast(bf16[] %convert.2288), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2291 = bf16[4096,1376]{1,0} multiply(bf16[4096,1376]{1,0} %divide.2289, bf16[4096,1376]{1,0} %broadcast.2290), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2292 = bf16[4096,1376]{1,0} add(bf16[4096,1376]{1,0} %subtract.2287, bf16[4096,1376]{1,0} %multiply.2291), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2296 = bf16[] get-tuple-element((bf16[2752,4096]{1,0}, bf16[]) %all-gather.2232), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2297 = (bf16[4096,1376]{1,0}, bf16[]) all-gather(bf16[4096,1376]{1,0} %add.2292, bf16[] %get-tuple-element.2296), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2298 = bf16[4096,1376]{1,0} get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.2297), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p107.2345 = bf16[4096]{0} parameter(107), frontend_attributes={neff_input_names="input107"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2346 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2347 = bf16[4096]{0} multiply(bf16[4096]{0} %p107.2345, bf16[4096]{0} %broadcast.2346), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2348 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2350 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2347, bf16[4096]{0} %broadcast.2348), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2351 = bf16[4096]{0} subtract(bf16[4096]{0} %p107.2345, bf16[4096]{0} %multiply.2350), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p106.2336 = bf16[4096]{0} parameter(106), frontend_attributes={neff_input_names="input106"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2337 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2338 = bf16[4096]{0} multiply(bf16[4096]{0} %p106.2336, bf16[4096]{0} %broadcast.2337), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.13 = bf16[1]{0} constant({1})
  %compare.2311 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.13), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.14 = bf16[1]{0} constant({1})
  %select.2313 = bf16[1]{0} select(pred[1]{0} %compare.2311, bf16[1]{0} %divide.875, bf16[1]{0} %constant.14), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2315 = bf16[] reshape(bf16[1]{0} %select.2313), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2316 = bf16[4096]{0} broadcast(bf16[] %reshape.2315), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2317 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.623, bf16[4096]{0} %broadcast.2316), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2334 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2335 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2317, bf16[4096]{0} %broadcast.2334), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2339 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2338, bf16[4096]{0} %multiply.2335), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p105.2318 = bf16[4096]{0} parameter(105), frontend_attributes={neff_input_names="input105"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2319 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2320 = bf16[4096]{0} multiply(bf16[4096]{0} %p105.2318, bf16[4096]{0} %broadcast.2319), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2322 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2317, bf16[4096]{0} %multiply.2317), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2321 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2323 = bf16[4096]{0} broadcast(bf16[] %convert.2321), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2324 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2322, bf16[4096]{0} %broadcast.2323), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2325 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2320, bf16[4096]{0} %multiply.2324), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2326 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.2325), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2327 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2328 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.2326, bf16[4096]{0} %broadcast.2327), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2329 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2330 = bf16[4096]{0} add(bf16[4096]{0} %divide.2328, bf16[4096]{0} %broadcast.2329), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2353 = bf16[4096]{0} divide(bf16[4096]{0} %add.2339, bf16[4096]{0} %add.2330), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2352 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2354 = bf16[4096]{0} broadcast(bf16[] %convert.2352), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2355 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.2353, bf16[4096]{0} %broadcast.2354), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2356 = bf16[4096]{0} add(bf16[4096]{0} %subtract.2351, bf16[4096]{0} %multiply.2355), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2360 = bf16[] get-tuple-element((bf16[4096,1376]{1,0}, bf16[]) %all-gather.2297), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2361 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.2356, bf16[] %get-tuple-element.2360), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2362 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2361), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p110.2409 = bf16[4096]{0} parameter(110), frontend_attributes={neff_input_names="input110"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2410 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2411 = bf16[4096]{0} multiply(bf16[4096]{0} %p110.2409, bf16[4096]{0} %broadcast.2410), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2412 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2414 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2411, bf16[4096]{0} %broadcast.2412), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2415 = bf16[4096]{0} subtract(bf16[4096]{0} %p110.2409, bf16[4096]{0} %multiply.2414), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p109.2400 = bf16[4096]{0} parameter(109), frontend_attributes={neff_input_names="input109"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2401 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2402 = bf16[4096]{0} multiply(bf16[4096]{0} %p109.2400, bf16[4096]{0} %broadcast.2401), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.10 = bf16[1]{0} constant({1})
  %compare.2375 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.10), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.11 = bf16[1]{0} constant({1})
  %select.2377 = bf16[1]{0} select(pred[1]{0} %compare.2375, bf16[1]{0} %divide.875, bf16[1]{0} %constant.11), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2379 = bf16[] reshape(bf16[1]{0} %select.2377), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2380 = bf16[4096]{0} broadcast(bf16[] %reshape.2379), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2381 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.598, bf16[4096]{0} %broadcast.2380), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2398 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2399 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2381, bf16[4096]{0} %broadcast.2398), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2403 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2402, bf16[4096]{0} %multiply.2399), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p108.2382 = bf16[4096]{0} parameter(108), frontend_attributes={neff_input_names="input108"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2383 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2384 = bf16[4096]{0} multiply(bf16[4096]{0} %p108.2382, bf16[4096]{0} %broadcast.2383), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2386 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2381, bf16[4096]{0} %multiply.2381), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2385 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2387 = bf16[4096]{0} broadcast(bf16[] %convert.2385), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2388 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2386, bf16[4096]{0} %broadcast.2387), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2389 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2384, bf16[4096]{0} %multiply.2388), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2390 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.2389), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2391 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2392 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.2390, bf16[4096]{0} %broadcast.2391), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2393 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2394 = bf16[4096]{0} add(bf16[4096]{0} %divide.2392, bf16[4096]{0} %broadcast.2393), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2417 = bf16[4096]{0} divide(bf16[4096]{0} %add.2403, bf16[4096]{0} %add.2394), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2416 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2418 = bf16[4096]{0} broadcast(bf16[] %convert.2416), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2419 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.2417, bf16[4096]{0} %broadcast.2418), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2420 = bf16[4096]{0} add(bf16[4096]{0} %subtract.2415, bf16[4096]{0} %multiply.2419), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2424 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2361), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2425 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.2420, bf16[] %get-tuple-element.2424), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2426 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2425), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p113.2473 = bf16[4096]{0} parameter(113), frontend_attributes={neff_input_names="input113"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2474 = bf16[4096]{0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2475 = bf16[4096]{0} multiply(bf16[4096]{0} %p113.2473, bf16[4096]{0} %broadcast.2474), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2476 = bf16[4096]{0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2478 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2475, bf16[4096]{0} %broadcast.2476), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2479 = bf16[4096]{0} subtract(bf16[4096]{0} %p113.2473, bf16[4096]{0} %multiply.2478), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p112.2464 = bf16[4096]{0} parameter(112), frontend_attributes={neff_input_names="input112"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2465 = bf16[4096]{0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2466 = bf16[4096]{0} multiply(bf16[4096]{0} %p112.2464, bf16[4096]{0} %broadcast.2465), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.7 = bf16[1]{0} constant({1})
  %compare.2439 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.7), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.8 = bf16[1]{0} constant({1})
  %select.2441 = bf16[1]{0} select(pred[1]{0} %compare.2439, bf16[1]{0} %divide.875, bf16[1]{0} %constant.8), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2443 = bf16[] reshape(bf16[1]{0} %select.2441), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2444 = bf16[4096]{0} broadcast(bf16[] %reshape.2443), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2445 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.573, bf16[4096]{0} %broadcast.2444), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2462 = bf16[4096]{0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2463 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2445, bf16[4096]{0} %broadcast.2462), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2467 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2466, bf16[4096]{0} %multiply.2463), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p111.2446 = bf16[4096]{0} parameter(111), frontend_attributes={neff_input_names="input111"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2447 = bf16[4096]{0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2448 = bf16[4096]{0} multiply(bf16[4096]{0} %p111.2446, bf16[4096]{0} %broadcast.2447), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2450 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2445, bf16[4096]{0} %multiply.2445), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2449 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2451 = bf16[4096]{0} broadcast(bf16[] %convert.2449), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2452 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.2450, bf16[4096]{0} %broadcast.2451), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2453 = bf16[4096]{0} add(bf16[4096]{0} %multiply.2448, bf16[4096]{0} %multiply.2452), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2454 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.2453), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2455 = bf16[4096]{0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2456 = bf16[4096]{0} divide(bf16[4096]{0} %sqrt.2454, bf16[4096]{0} %broadcast.2455), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2457 = bf16[4096]{0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2458 = bf16[4096]{0} add(bf16[4096]{0} %divide.2456, bf16[4096]{0} %broadcast.2457), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2481 = bf16[4096]{0} divide(bf16[4096]{0} %add.2467, bf16[4096]{0} %add.2458), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2480 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2482 = bf16[4096]{0} broadcast(bf16[] %convert.2480), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2483 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.2481, bf16[4096]{0} %broadcast.2482), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2484 = bf16[4096]{0} add(bf16[4096]{0} %subtract.2479, bf16[4096]{0} %multiply.2483), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2488 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2425), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2489 = (bf16[4096]{0}, bf16[]) all-gather(bf16[4096]{0} %add.2484, bf16[] %get-tuple-element.2488), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2490 = bf16[4096]{0} get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2489), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p116.2538 = bf16[4000,4096]{1,0} parameter(116), frontend_attributes={neff_input_names="input116"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2539 = bf16[4000,4096]{1,0} broadcast(bf16[] %p40.921), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2540 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %p116.2538, bf16[4000,4096]{1,0} %broadcast.2539), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.2541 = bf16[4000,4096]{1,0} broadcast(bf16[] %p39.920), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.2543 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %multiply.2540, bf16[4000,4096]{1,0} %broadcast.2541), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.2544 = bf16[4000,4096]{1,0} subtract(bf16[4000,4096]{1,0} %p116.2538, bf16[4000,4096]{1,0} %multiply.2543), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p115.2529 = bf16[4000,4096]{1,0} parameter(115), frontend_attributes={neff_input_names="input115"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2530 = bf16[4000,4096]{1,0} broadcast(bf16[] %p37.910), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2531 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %p115.2529, bf16[4000,4096]{1,0} %broadcast.2530), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.4 = bf16[1]{0} constant({1})
  %compare.2503 = pred[1]{0} compare(bf16[1]{0} %divide.875, bf16[1]{0} %constant.4), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.5 = bf16[1]{0} constant({1})
  %select.2505 = bf16[1]{0} select(pred[1]{0} %compare.2503, bf16[1]{0} %divide.875, bf16[1]{0} %constant.5), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.2507 = bf16[] reshape(bf16[1]{0} %select.2505), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2509 = bf16[4000,4096]{1,0} broadcast(bf16[] %reshape.2507), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.2510 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %get-tuple-element.131, bf16[4000,4096]{1,0} %broadcast.2509), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.2527 = bf16[4000,4096]{1,0} broadcast(bf16[] %p36.904), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.2528 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %multiply.2510, bf16[4000,4096]{1,0} %broadcast.2527), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.2532 = bf16[4000,4096]{1,0} add(bf16[4000,4096]{1,0} %multiply.2531, bf16[4000,4096]{1,0} %multiply.2528), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p114.2511 = bf16[4000,4096]{1,0} parameter(114), frontend_attributes={neff_input_names="input114"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2512 = bf16[4000,4096]{1,0} broadcast(bf16[] %p34.890), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2513 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %p114.2511, bf16[4000,4096]{1,0} %broadcast.2512), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2515 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %multiply.2510, bf16[4000,4096]{1,0} %multiply.2510), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.2514 = bf16[] convert(f32[] %p32.859), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.2516 = bf16[4000,4096]{1,0} broadcast(bf16[] %convert.2514), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.2517 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %multiply.2515, bf16[4000,4096]{1,0} %broadcast.2516), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.2518 = bf16[4000,4096]{1,0} add(bf16[4000,4096]{1,0} %multiply.2513, bf16[4000,4096]{1,0} %multiply.2517), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.2519 = bf16[4000,4096]{1,0} sqrt(bf16[4000,4096]{1,0} %add.2518), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2520 = bf16[4000,4096]{1,0} broadcast(bf16[] %p31.858), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2521 = bf16[4000,4096]{1,0} divide(bf16[4000,4096]{1,0} %sqrt.2519, bf16[4000,4096]{1,0} %broadcast.2520), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.2522 = bf16[4000,4096]{1,0} broadcast(bf16[] %p30.856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.2523 = bf16[4000,4096]{1,0} add(bf16[4000,4096]{1,0} %divide.2521, bf16[4000,4096]{1,0} %broadcast.2522), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.2546 = bf16[4000,4096]{1,0} divide(bf16[4000,4096]{1,0} %add.2532, bf16[4000,4096]{1,0} %add.2523), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.2545 = bf16[] convert(f32[] %p29.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.2547 = bf16[4000,4096]{1,0} broadcast(bf16[] %convert.2545), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.2548 = bf16[4000,4096]{1,0} multiply(bf16[4000,4096]{1,0} %divide.2546, bf16[4000,4096]{1,0} %broadcast.2547), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.2549 = bf16[4000,4096]{1,0} add(bf16[4000,4096]{1,0} %subtract.2544, bf16[4000,4096]{1,0} %multiply.2548), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.2553 = bf16[] get-tuple-element((bf16[4096]{0}, bf16[]) %all-gather.2489), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.2554 = (bf16[4000,4096]{1,0}, bf16[]) all-gather(bf16[4000,4096]{1,0} %add.2549, bf16[] %get-tuple-element.2553), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.2555 = bf16[4000,4096]{1,0} get-tuple-element((bf16[4000,4096]{1,0}, bf16[]) %all-gather.2554), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %constant.2559 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2563 = bf16[4000,4096]{1,0} broadcast(bf16[] %constant.2559), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2564 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2568 = bf16[4096]{0} broadcast(bf16[] %constant.2564), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2569 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2573 = bf16[4096,1376]{1,0} broadcast(bf16[] %constant.2569), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2574 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2578 = bf16[2752,4096]{1,0} broadcast(bf16[] %constant.2574), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2579 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2583 = bf16[4096]{0} broadcast(bf16[] %constant.2579), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2584 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2588 = bf16[4096,512]{1,0} broadcast(bf16[] %constant.2584), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2589 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2593 = bf16[1536,4096]{1,0} broadcast(bf16[] %constant.2589), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2594 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2598 = bf16[4096]{0} broadcast(bf16[] %constant.2594), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2599 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2603 = bf16[4096,1376]{1,0} broadcast(bf16[] %constant.2599), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2604 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2608 = bf16[2752,4096]{1,0} broadcast(bf16[] %constant.2604), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2609 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2613 = bf16[4096]{0} broadcast(bf16[] %constant.2609), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2614 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2618 = bf16[4096,512]{1,0} broadcast(bf16[] %constant.2614), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2619 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2623 = bf16[1536,4096]{1,0} broadcast(bf16[] %constant.2619), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2624 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2628 = bf16[4096]{0} broadcast(bf16[] %constant.2624), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2629 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2633 = bf16[4096,1376]{1,0} broadcast(bf16[] %constant.2629), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2634 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2638 = bf16[2752,4096]{1,0} broadcast(bf16[] %constant.2634), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2639 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2643 = bf16[4096]{0} broadcast(bf16[] %constant.2639), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2644 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2648 = bf16[4096,512]{1,0} broadcast(bf16[] %constant.2644), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2649 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2653 = bf16[1536,4096]{1,0} broadcast(bf16[] %constant.2649), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2654 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2658 = bf16[4096]{0} broadcast(bf16[] %constant.2654), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2659 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2663 = bf16[4096,1376]{1,0} broadcast(bf16[] %constant.2659), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2664 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2668 = bf16[2752,4096]{1,0} broadcast(bf16[] %constant.2664), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2669 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2673 = bf16[4096]{0} broadcast(bf16[] %constant.2669), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2674 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2678 = bf16[4096,512]{1,0} broadcast(bf16[] %constant.2674), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2679 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2683 = bf16[1536,4096]{1,0} broadcast(bf16[] %constant.2679), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.2684 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.2688 = bf16[4096]{0} broadcast(bf16[] %constant.2684), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  ROOT %tuple.2689 = (bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, /*index=5*/bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, /*index=10*/bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, /*index=15*/bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, /*index=20*/bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, /*index=25*/bf16[4000,4096]{1,0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, /*index=30*/bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, /*index=35*/bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, /*index=40*/bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, /*index=45*/bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, /*index=50*/bf16[4096]{0}, bf16[4000,4096]{1,0}, bf16[4000,4096]{1,0}, bf16[4096]{0}, bf16[4096,1376]{1,0}, /*index=55*/bf16[2752,4096]{1,0}, bf16[4096]{0}, bf16[4096,512]{1,0}, bf16[1536,4096]{1,0}, bf16[4096]{0}, /*index=60*/bf16[4096,1376]{1,0}, bf16[2752,4096]{1,0}, bf16[4096]{0}, bf16[4096,512]{1,0}, bf16[1536,4096]{1,0}, /*index=65*/bf16[4096]{0}, bf16[4096,1376]{1,0}, bf16[2752,4096]{1,0}, bf16[4096]{0}, bf16[4096,512]{1,0}, /*index=70*/bf16[1536,4096]{1,0}, bf16[4096]{0}, bf16[4096,1376]{1,0}, bf16[2752,4096]{1,0}, bf16[4096]{0}, /*index=75*/bf16[4096,512]{1,0}, bf16[1536,4096]{1,0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[1536,4096]{1,0}, /*index=80*/bf16[4096,512]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, /*index=85*/bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, /*index=90*/bf16[1536,4096]{1,0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, /*index=95*/bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, /*index=100*/bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, /*index=105*/bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[2752,4096]{1,0}, bf16[4096,1376]{1,0}, bf16[4096,1376]{1,0}, /*index=110*/bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, bf16[1536,4096]{1,0}, /*index=115*/bf16[1536,4096]{1,0}, bf16[4096,512]{1,0}, bf16[4096,512]{1,0}, bf16[2752,4096]{1,0}, bf16[2752,4096]{1,0}, /*index=120*/bf16[4096,1376]{1,0}, bf16[4096,1376]{1,0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, /*index=125*/bf16[4096]{0}, bf16[4096]{0}, bf16[4096]{0}, bf16[4000,4096]{1,0}, bf16[4000,4096]{1,0}, /*index=130*/bf16[1]{0}) tuple(bf16[1536,4096]{1,0} %get-tuple-element.939, bf16[4096,512]{1,0} %get-tuple-element.1004, bf16[2752,4096]{1,0} %get-tuple-element.1069, bf16[4096,1376]{1,0} %get-tuple-element.1134, bf16[4096]{0} %get-tuple-element.1198, /*index=5*/bf16[4096]{0} %get-tuple-element.1262, bf16[1536,4096]{1,0} %get-tuple-element.1327, bf16[4096,512]{1,0} %get-tuple-element.1392, bf16[2752,4096]{1,0} %get-tuple-element.1457, bf16[4096,1376]{1,0} %get-tuple-element.1522, /*index=10*/bf16[4096]{0} %get-tuple-element.1586, bf16[4096]{0} %get-tuple-element.1650, bf16[1536,4096]{1,0} %get-tuple-element.1715, bf16[4096,512]{1,0} %get-tuple-element.1780, bf16[2752,4096]{1,0} %get-tuple-element.1845, /*index=15*/bf16[4096,1376]{1,0} %get-tuple-element.1910, bf16[4096]{0} %get-tuple-element.1974, bf16[4096]{0} %get-tuple-element.2038, bf16[1536,4096]{1,0} %get-tuple-element.2103, bf16[4096,512]{1,0} %get-tuple-element.2168, /*index=20*/bf16[2752,4096]{1,0} %get-tuple-element.2233, bf16[4096,1376]{1,0} %get-tuple-element.2298, bf16[4096]{0} %get-tuple-element.2362, bf16[4096]{0} %get-tuple-element.2426, bf16[4096]{0} %get-tuple-element.2490, /*index=25*/bf16[4000,4096]{1,0} %get-tuple-element.2555, bf16[1536,4096]{1,0} %add.933, bf16[4096,512]{1,0} %add.998, bf16[2752,4096]{1,0} %add.1063, bf16[4096,1376]{1,0} %add.1128, /*index=30*/bf16[4096]{0} %add.1192, bf16[4096]{0} %add.1256, bf16[1536,4096]{1,0} %add.1321, bf16[4096,512]{1,0} %add.1386, bf16[2752,4096]{1,0} %add.1451, /*index=35*/bf16[4096,1376]{1,0} %add.1516, bf16[4096]{0} %add.1580, bf16[4096]{0} %add.1644, bf16[1536,4096]{1,0} %add.1709, bf16[4096,512]{1,0} %add.1774, /*index=40*/bf16[2752,4096]{1,0} %add.1839, bf16[4096,1376]{1,0} %add.1904, bf16[4096]{0} %add.1968, bf16[4096]{0} %add.2032, bf16[1536,4096]{1,0} %add.2097, /*index=45*/bf16[4096,512]{1,0} %add.2162, bf16[2752,4096]{1,0} %add.2227, bf16[4096,1376]{1,0} %add.2292, bf16[4096]{0} %add.2356, bf16[4096]{0} %add.2420, /*index=50*/bf16[4096]{0} %add.2484, bf16[4000,4096]{1,0} %add.2549, bf16[4000,4096]{1,0} %broadcast.2563, bf16[4096]{0} %broadcast.2568, bf16[4096,1376]{1,0} %broadcast.2573, /*index=55*/bf16[2752,4096]{1,0} %broadcast.2578, bf16[4096]{0} %broadcast.2583, bf16[4096,512]{1,0} %broadcast.2588, bf16[1536,4096]{1,0} %broadcast.2593, bf16[4096]{0} %broadcast.2598, /*index=60*/bf16[4096,1376]{1,0} %broadcast.2603, bf16[2752,4096]{1,0} %broadcast.2608, bf16[4096]{0} %broadcast.2613, bf16[4096,512]{1,0} %broadcast.2618, bf16[1536,4096]{1,0} %broadcast.2623, /*index=65*/bf16[4096]{0} %broadcast.2628, bf16[4096,1376]{1,0} %broadcast.2633, bf16[2752,4096]{1,0} %broadcast.2638, bf16[4096]{0} %broadcast.2643, bf16[4096,512]{1,0} %broadcast.2648, /*index=70*/bf16[1536,4096]{1,0} %broadcast.2653, bf16[4096]{0} %broadcast.2658, bf16[4096,1376]{1,0} %broadcast.2663, bf16[2752,4096]{1,0} %broadcast.2668, bf16[4096]{0} %broadcast.2673, /*index=75*/bf16[4096,512]{1,0} %broadcast.2678, bf16[1536,4096]{1,0} %broadcast.2683, bf16[4096]{0} %broadcast.2688, bf16[1536,4096]{1,0} %add.914, bf16[1536,4096]{1,0} %add.898, /*index=80*/bf16[4096,512]{1,0} %add.981, bf16[4096,512]{1,0} %add.967, bf16[2752,4096]{1,0} %add.1046, bf16[2752,4096]{1,0} %add.1032, bf16[4096,1376]{1,0} %add.1111, /*index=85*/bf16[4096,1376]{1,0} %add.1097, bf16[4096]{0} %add.1175, bf16[4096]{0} %add.1161, bf16[4096]{0} %add.1239, bf16[4096]{0} %add.1225, /*index=90*/bf16[1536,4096]{1,0} %add.1304, bf16[1536,4096]{1,0} %add.1290, bf16[4096,512]{1,0} %add.1369, bf16[4096,512]{1,0} %add.1355, bf16[2752,4096]{1,0} %add.1434, /*index=95*/bf16[2752,4096]{1,0} %add.1420, bf16[4096,1376]{1,0} %add.1499, bf16[4096,1376]{1,0} %add.1485, bf16[4096]{0} %add.1563, bf16[4096]{0} %add.1549, /*index=100*/bf16[4096]{0} %add.1627, bf16[4096]{0} %add.1613, bf16[1536,4096]{1,0} %add.1692, bf16[1536,4096]{1,0} %add.1678, bf16[4096,512]{1,0} %add.1757, /*index=105*/bf16[4096,512]{1,0} %add.1743, bf16[2752,4096]{1,0} %add.1822, bf16[2752,4096]{1,0} %add.1808, bf16[4096,1376]{1,0} %add.1887, bf16[4096,1376]{1,0} %add.1873, /*index=110*/bf16[4096]{0} %add.1951, bf16[4096]{0} %add.1937, bf16[4096]{0} %add.2015, bf16[4096]{0} %add.2001, bf16[1536,4096]{1,0} %add.2080, /*index=115*/bf16[1536,4096]{1,0} %add.2066, bf16[4096,512]{1,0} %add.2145, bf16[4096,512]{1,0} %add.2131, bf16[2752,4096]{1,0} %add.2210, bf16[2752,4096]{1,0} %add.2196, /*index=120*/bf16[4096,1376]{1,0} %add.2275, bf16[4096,1376]{1,0} %add.2261, bf16[4096]{0} %add.2339, bf16[4096]{0} %add.2325, bf16[4096]{0} %add.2403, /*index=125*/bf16[4096]{0} %add.2389, bf16[4096]{0} %add.2467, bf16[4096]{0} %add.2453, bf16[4000,4096]{1,0} %add.2532, bf16[4000,4096]{1,0} %add.2518, /*index=130*/bf16[1]{0} %power.870), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93,output94,output95,output96,output97,output98,output99,output100,output101,output102,output103,output104,output105,output106,output107,output108,output109,output110,output111,output112,output113,output114,output115,output116,output117,output118,output119,output120,output121,output122,output123,output124,output125,output126,output127,output128,output129,output130"}
}


`

export default text;
