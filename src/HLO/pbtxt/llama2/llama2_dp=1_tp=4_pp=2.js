const text = `
HloModule SyncTensorsGraph.1470, input_output_alias={ {14}: (29, {}, must-alias), {15}: (32, {}, must-alias), {16}: (35, {}, must-alias), {17}: (38, {}, must-alias), {18}: (41, {}, must-alias), {19}: (44, {}, must-alias), {20}: (47, {}, must-alias), {21}: (50, {}, must-alias), {22}: (53, {}, must-alias), {23}: (56, {}, must-alias), {24}: (59, {}, must-alias), {25}: (62, {}, must-alias), {26}: (65, {}, must-alias), {27}: (68, {}, must-alias), {28}: (6, {}, must-alias), {29}: (5, {}, must-alias), {30}: (7, {}, must-alias), {31}: (8, {}, must-alias), {32}: (4, {}, must-alias), {33}: (9, {}, must-alias), {34}: (10, {}, must-alias), {35}: (3, {}, must-alias), {36}: (11, {}, must-alias), {37}: (12, {}, must-alias), {38}: (2, {}, must-alias), {39}: (13, {}, must-alias), {40}: (14, {}, must-alias), {41}: (1, {}, must-alias), {42}: (26, {}, must-alias), {43}: (23, {}, must-alias), {44}: (31, {}, must-alias), {45}: (30, {}, must-alias), {46}: (34, {}, must-alias), {47}: (33, {}, must-alias), {48}: (37, {}, must-alias), {49}: (36, {}, must-alias), {50}: (40, {}, must-alias), {51}: (39, {}, must-alias), {52}: (43, {}, must-alias), {53}: (42, {}, must-alias), {54}: (46, {}, must-alias), {55}: (45, {}, must-alias), {56}: (49, {}, must-alias), {57}: (48, {}, must-alias), {58}: (52, {}, must-alias), {59}: (51, {}, must-alias), {60}: (55, {}, must-alias), {61}: (54, {}, must-alias), {62}: (58, {}, must-alias), {63}: (57, {}, must-alias), {64}: (61, {}, must-alias), {65}: (60, {}, must-alias), {66}: (64, {}, must-alias), {67}: (63, {}, must-alias), {68}: (67, {}, must-alias), {69}: (66, {}, must-alias) }

%AddComputation.7 (x.8: bf16[], y.9: bf16[]) -> bf16[] {
  %x.8 = bf16[] parameter(0)
  %y.9 = bf16[] parameter(1)
  ROOT %add.10 = bf16[] add(bf16[] %x.8, bf16[] %y.9)
}

%AddComputation.20 (x.21: bf16[], y.22: bf16[]) -> bf16[] {
  %x.21 = bf16[] parameter(0)
  %y.22 = bf16[] parameter(1)
  ROOT %add.23 = bf16[] add(bf16[] %x.21, bf16[] %y.22)
}

%AddComputation.33 (x.34: bf16[], y.35: bf16[]) -> bf16[] {
  %x.34 = bf16[] parameter(0)
  %y.35 = bf16[] parameter(1)
  ROOT %add.36 = bf16[] add(bf16[] %x.34, bf16[] %y.35)
}

%AddComputation.46 (x.47: bf16[], y.48: bf16[]) -> bf16[] {
  %x.47 = bf16[] parameter(0)
  %y.48 = bf16[] parameter(1)
  ROOT %add.49 = bf16[] add(bf16[] %x.47, bf16[] %y.48)
}

%AddComputation.59 (x.60: bf16[], y.61: bf16[]) -> bf16[] {
  %x.60 = bf16[] parameter(0)
  %y.61 = bf16[] parameter(1)
  ROOT %add.62 = bf16[] add(bf16[] %x.60, bf16[] %y.61)
}

%AddComputation.74 (x.75: bf16[], y.76: bf16[]) -> bf16[] {
  %x.75 = bf16[] parameter(0)
  %y.76 = bf16[] parameter(1)
  ROOT %add.77 = bf16[] add(bf16[] %x.75, bf16[] %y.76)
}

%AddComputation.85 (x.86: bf16[], y.87: bf16[]) -> bf16[] {
  %x.86 = bf16[] parameter(0)
  %y.87 = bf16[] parameter(1)
  ROOT %add.88 = bf16[] add(bf16[] %x.86, bf16[] %y.87)
}

%AddComputation.100 (x.101: bf16[], y.102: bf16[]) -> bf16[] {
  %x.101 = bf16[] parameter(0)
  %y.102 = bf16[] parameter(1)
  ROOT %add.103 = bf16[] add(bf16[] %x.101, bf16[] %y.102)
}

%AddComputation.111 (x.112: bf16[], y.113: bf16[]) -> bf16[] {
  %x.112 = bf16[] parameter(0)
  %y.113 = bf16[] parameter(1)
  ROOT %add.114 = bf16[] add(bf16[] %x.112, bf16[] %y.113)
}

%AddComputation.126 (x.127: bf16[], y.128: bf16[]) -> bf16[] {
  %x.127 = bf16[] parameter(0)
  %y.128 = bf16[] parameter(1)
  ROOT %add.129 = bf16[] add(bf16[] %x.127, bf16[] %y.128)
}

%AddComputation.137 (x.138: bf16[], y.139: bf16[]) -> bf16[] {
  %x.138 = bf16[] parameter(0)
  %y.139 = bf16[] parameter(1)
  ROOT %add.140 = bf16[] add(bf16[] %x.138, bf16[] %y.139)
}

%AddComputation.152 (x.153: bf16[], y.154: bf16[]) -> bf16[] {
  %x.153 = bf16[] parameter(0)
  %y.154 = bf16[] parameter(1)
  ROOT %add.155 = bf16[] add(bf16[] %x.153, bf16[] %y.154)
}

%AddComputation.163 (x.164: bf16[], y.165: bf16[]) -> bf16[] {
  %x.164 = bf16[] parameter(0)
  %y.165 = bf16[] parameter(1)
  ROOT %add.166 = bf16[] add(bf16[] %x.164, bf16[] %y.165)
}

%AddComputation.178 (x.179: bf16[], y.180: bf16[]) -> bf16[] {
  %x.179 = bf16[] parameter(0)
  %y.180 = bf16[] parameter(1)
  ROOT %add.181 = bf16[] add(bf16[] %x.179, bf16[] %y.180)
}

%AddComputation.189 (x.190: bf16[], y.191: bf16[]) -> bf16[] {
  %x.190 = bf16[] parameter(0)
  %y.191 = bf16[] parameter(1)
  ROOT %add.192 = bf16[] add(bf16[] %x.190, bf16[] %y.191)
}

%AddComputation.204 (x.205: bf16[], y.206: bf16[]) -> bf16[] {
  %x.205 = bf16[] parameter(0)
  %y.206 = bf16[] parameter(1)
  ROOT %add.207 = bf16[] add(bf16[] %x.205, bf16[] %y.206)
}

%AddComputation.215 (x.216: bf16[], y.217: bf16[]) -> bf16[] {
  %x.216 = bf16[] parameter(0)
  %y.217 = bf16[] parameter(1)
  ROOT %add.218 = bf16[] add(bf16[] %x.216, bf16[] %y.217)
}

%AddComputation.230 (x.231: bf16[], y.232: bf16[]) -> bf16[] {
  %x.231 = bf16[] parameter(0)
  %y.232 = bf16[] parameter(1)
  ROOT %add.233 = bf16[] add(bf16[] %x.231, bf16[] %y.232)
}

%AddComputation.241 (x.242: bf16[], y.243: bf16[]) -> bf16[] {
  %x.242 = bf16[] parameter(0)
  %y.243 = bf16[] parameter(1)
  ROOT %add.244 = bf16[] add(bf16[] %x.242, bf16[] %y.243)
}

%AddComputation.256 (x.257: bf16[], y.258: bf16[]) -> bf16[] {
  %x.257 = bf16[] parameter(0)
  %y.258 = bf16[] parameter(1)
  ROOT %add.259 = bf16[] add(bf16[] %x.257, bf16[] %y.258)
}

%AddComputation.267 (x.268: bf16[], y.269: bf16[]) -> bf16[] {
  %x.268 = bf16[] parameter(0)
  %y.269 = bf16[] parameter(1)
  ROOT %add.270 = bf16[] add(bf16[] %x.268, bf16[] %y.269)
}

%AddComputation.282 (x.283: bf16[], y.284: bf16[]) -> bf16[] {
  %x.283 = bf16[] parameter(0)
  %y.284 = bf16[] parameter(1)
  ROOT %add.285 = bf16[] add(bf16[] %x.283, bf16[] %y.284)
}

%AddComputation.293 (x.294: bf16[], y.295: bf16[]) -> bf16[] {
  %x.294 = bf16[] parameter(0)
  %y.295 = bf16[] parameter(1)
  ROOT %add.296 = bf16[] add(bf16[] %x.294, bf16[] %y.295)
}

%AddComputation.308 (x.309: bf16[], y.310: bf16[]) -> bf16[] {
  %x.309 = bf16[] parameter(0)
  %y.310 = bf16[] parameter(1)
  ROOT %add.311 = bf16[] add(bf16[] %x.309, bf16[] %y.310)
}

%AddComputation.319 (x.320: bf16[], y.321: bf16[]) -> bf16[] {
  %x.320 = bf16[] parameter(0)
  %y.321 = bf16[] parameter(1)
  ROOT %add.322 = bf16[] add(bf16[] %x.320, bf16[] %y.321)
}

%AddComputation.333 (x.334: bf16[], y.335: bf16[]) -> bf16[] {
  %x.334 = bf16[] parameter(0)
  %y.335 = bf16[] parameter(1)
  ROOT %add.336 = bf16[] add(bf16[] %x.334, bf16[] %y.335)
}

%AddComputation.344 (x.345: bf16[], y.346: bf16[]) -> bf16[] {
  %x.345 = bf16[] parameter(0)
  %y.346 = bf16[] parameter(1)
  ROOT %add.347 = bf16[] add(bf16[] %x.345, bf16[] %y.346)
}

%AddComputation.358 (x.359: bf16[], y.360: bf16[]) -> bf16[] {
  %x.359 = bf16[] parameter(0)
  %y.360 = bf16[] parameter(1)
  ROOT %add.361 = bf16[] add(bf16[] %x.359, bf16[] %y.360)
}

%AddComputation.369 (x.370: bf16[], y.371: bf16[]) -> bf16[] {
  %x.370 = bf16[] parameter(0)
  %y.371 = bf16[] parameter(1)
  ROOT %add.372 = bf16[] add(bf16[] %x.370, bf16[] %y.371)
}

%AddComputation.383 (x.384: bf16[], y.385: bf16[]) -> bf16[] {
  %x.384 = bf16[] parameter(0)
  %y.385 = bf16[] parameter(1)
  ROOT %add.386 = bf16[] add(bf16[] %x.384, bf16[] %y.385)
}

%AddComputation.394 (x.395: bf16[], y.396: bf16[]) -> bf16[] {
  %x.395 = bf16[] parameter(0)
  %y.396 = bf16[] parameter(1)
  ROOT %add.397 = bf16[] add(bf16[] %x.395, bf16[] %y.396)
}

%AddComputation.408 (x.409: bf16[], y.410: bf16[]) -> bf16[] {
  %x.409 = bf16[] parameter(0)
  %y.410 = bf16[] parameter(1)
  ROOT %add.411 = bf16[] add(bf16[] %x.409, bf16[] %y.410)
}

%AddComputation.419 (x.420: bf16[], y.421: bf16[]) -> bf16[] {
  %x.420 = bf16[] parameter(0)
  %y.421 = bf16[] parameter(1)
  ROOT %add.422 = bf16[] add(bf16[] %x.420, bf16[] %y.421)
}

%AddComputation.462 (x.463: bf16[], y.464: bf16[]) -> bf16[] {
  %x.463 = bf16[] parameter(0)
  %y.464 = bf16[] parameter(1)
  ROOT %add.465 = bf16[] add(bf16[] %x.463, bf16[] %y.464)
}

ENTRY %SyncTensorsGraph.1470 (p0.1: f32[], p1.2: bf16[32], p2.15: bf16[32], p3.28: bf16[32], p4.41: bf16[32], p5.54: bf16[32], p6.69: bf16[8000,32], p7.95: bf16[32,8], p8.121: bf16[16,32], p9.147: bf16[32,8], p10.173: bf16[24,32], p11.199: bf16[32,8], p12.225: bf16[16,32], p13.251: bf16[32,8], p14.277: bf16[24,32], p15.301: bf16[], p16.427: bf16[1], p17.470: f32[], p18.472: bf16[], p19.474: bf16[], p20.475: f32[], p21.481: bf16[], p22.506: bf16[], p23.507: bf16[24,32], p24.520: bf16[], p25.526: bf16[], p26.527: bf16[24,32], p27.536: bf16[], p28.537: bf16[], p29.538: bf16[24,32], p30.576: bf16[32,8], p31.594: bf16[32,8], p32.603: bf16[32,8], p33.641: bf16[16,32], p34.659: bf16[16,32], p35.668: bf16[16,32], p36.706: bf16[32,8], p37.724: bf16[32,8], p38.733: bf16[32,8], p39.770: bf16[32], p40.788: bf16[32], p41.797: bf16[32], p42.834: bf16[32], p43.852: bf16[32], p44.861: bf16[32], p45.899: bf16[24,32], p46.917: bf16[24,32], p47.926: bf16[24,32], p48.964: bf16[32,8], p49.982: bf16[32,8], p50.991: bf16[32,8], p51.1029: bf16[16,32], p52.1047: bf16[16,32], p53.1056: bf16[16,32], p54.1094: bf16[32,8], p55.1112: bf16[32,8], p56.1121: bf16[32,8], p57.1158: bf16[32], p58.1176: bf16[32], p59.1185: bf16[32], p60.1222: bf16[32], p61.1240: bf16[32], p62.1249: bf16[32], p63.1286: bf16[32], p64.1304: bf16[32], p65.1313: bf16[32], p66.1351: bf16[8000,32], p67.1369: bf16[8000,32], p68.1378: bf16[8000,32]) -> (bf16[24,32], bf16[32,8], bf16[16,32], bf16[32,8], bf16[32], /*index=5*/bf16[32], bf16[24,32], bf16[32,8], bf16[16,32], bf16[32,8], /*index=10*/bf16[32], bf16[32], bf16[32], bf16[8000,32], bf16[24,32], /*index=15*/bf16[32,8], bf16[16,32], bf16[32,8], bf16[32], bf16[32], /*index=20*/bf16[24,32], bf16[32,8], bf16[16,32], bf16[32,8], bf16[32], /*index=25*/bf16[32], bf16[32], bf16[8000,32], bf16[8000,32], bf16[32], /*index=30*/bf16[32,8], bf16[16,32], bf16[32], bf16[32,8], bf16[24,32], /*index=35*/bf16[32], bf16[32,8], bf16[16,32], bf16[32], bf16[32,8], /*index=40*/bf16[24,32], bf16[32], bf16[24,32], bf16[24,32], bf16[32,8], /*index=45*/bf16[32,8], bf16[16,32], bf16[16,32], bf16[32,8], bf16[32,8], /*index=50*/bf16[32], bf16[32], bf16[32], bf16[32], bf16[24,32], /*index=55*/bf16[24,32], bf16[32,8], bf16[32,8], bf16[16,32], bf16[16,32], /*index=60*/bf16[32,8], bf16[32,8], bf16[32], bf16[32], bf16[32], /*index=65*/bf16[32], bf16[32], bf16[32], bf16[8000,32], bf16[8000,32], /*index=70*/bf16[1]) {
  %p29.538 = bf16[24,32]{1,0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p28.537 = bf16[] parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.539 = bf16[24,32]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.540 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p29.538, bf16[24,32]{1,0} %broadcast.539), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p27.536 = bf16[] parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.541 = bf16[24,32]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.543 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.540, bf16[24,32]{1,0} %broadcast.541), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.544 = bf16[24,32]{1,0} subtract(bf16[24,32]{1,0} %p29.538, bf16[24,32]{1,0} %multiply.543), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p26.527 = bf16[24,32]{1,0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p25.526 = bf16[] parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.528 = bf16[24,32]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.529 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p26.527, bf16[24,32]{1,0} %broadcast.528), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p14.277 = bf16[24,32]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %p5.54 = bf16[32]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p4.41 = bf16[32]{0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p3.28 = bf16[32]{0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p2.15 = bf16[32]{0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p1.2 = bf16[32]{0} parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %convert.3 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.11 = (bf16[32]{0}, bf16[]) all-reduce(bf16[32]{0} %p1.2, bf16[] %convert.3), replica_groups={{0,1,2,3},{4,5,6,7}}, to_apply=%AddComputation.7, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.19 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.11), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.24 = (bf16[32]{0}, bf16[]) all-reduce(bf16[32]{0} %p2.15, bf16[] %get-tuple-element.19), replica_groups={{0,1,2,3},{4,5,6,7}}, to_apply=%AddComputation.20, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.32 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.24), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.37 = (bf16[32]{0}, bf16[]) all-reduce(bf16[32]{0} %p3.28, bf16[] %get-tuple-element.32), replica_groups={{0,1,2,3},{4,5,6,7}}, to_apply=%AddComputation.33, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.45 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.37), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.50 = (bf16[32]{0}, bf16[]) all-reduce(bf16[32]{0} %p4.41, bf16[] %get-tuple-element.45), replica_groups={{0,1,2,3},{4,5,6,7}}, to_apply=%AddComputation.46, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.58 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.50), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.63 = (bf16[32]{0}, bf16[]) all-reduce(bf16[32]{0} %p5.54, bf16[] %get-tuple-element.58), replica_groups={{0,1,2,3},{4,5,6,7}}, to_apply=%AddComputation.59, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.461 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.63), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.286 = (bf16[24,32]{1,0}, bf16[]) reduce-scatter(bf16[24,32]{1,0} %p14.277, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.282, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.287 = bf16[24,32]{1,0} get-tuple-element((bf16[24,32]{1,0}, bf16[]) %reduce-scatter.286), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %constant = bf16[1]{0} constant({1})
  %p16.427 = bf16[1]{0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=113}
  %get-tuple-element.406 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.11), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.412 = (bf16[32]{0}, bf16[]) reduce-scatter(bf16[32]{0} %get-tuple-element.406, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.408, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.413 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %reduce-scatter.412), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.416 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.413, bf16[32]{0} %get-tuple-element.413), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.417 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.423 = bf16[] reduce(bf16[32]{0} %multiply.416, bf16[] %constant.417), dimensions={0}, to_apply=%AddComputation.419, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.424 = bf16[] sqrt(bf16[] %reduce.423), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.426 = bf16[] multiply(bf16[] %sqrt.424, bf16[] %sqrt.424), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.3 = bf16[1]{0} reshape(bf16[] %multiply.426), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.429 = bf16[1]{0} add(bf16[1]{0} %p16.427, bf16[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.381 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.24), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.387 = (bf16[32]{0}, bf16[]) reduce-scatter(bf16[32]{0} %get-tuple-element.381, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.383, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.388 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %reduce-scatter.387), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.391 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.388, bf16[32]{0} %get-tuple-element.388), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.392 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.398 = bf16[] reduce(bf16[32]{0} %multiply.391, bf16[] %constant.392), dimensions={0}, to_apply=%AddComputation.394, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.399 = bf16[] sqrt(bf16[] %reduce.398), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.401 = bf16[] multiply(bf16[] %sqrt.399, bf16[] %sqrt.399), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.4 = bf16[1]{0} reshape(bf16[] %multiply.401), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.431 = bf16[1]{0} add(bf16[1]{0} %add.429, bf16[1]{0} %reshape.4), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.356 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.37), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.362 = (bf16[32]{0}, bf16[]) reduce-scatter(bf16[32]{0} %get-tuple-element.356, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.358, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.363 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %reduce-scatter.362), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.366 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.363, bf16[32]{0} %get-tuple-element.363), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.367 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.373 = bf16[] reduce(bf16[32]{0} %multiply.366, bf16[] %constant.367), dimensions={0}, to_apply=%AddComputation.369, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.374 = bf16[] sqrt(bf16[] %reduce.373), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.376 = bf16[] multiply(bf16[] %sqrt.374, bf16[] %sqrt.374), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.5 = bf16[1]{0} reshape(bf16[] %multiply.376), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.433 = bf16[1]{0} add(bf16[1]{0} %add.431, bf16[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.331 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.50), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.337 = (bf16[32]{0}, bf16[]) reduce-scatter(bf16[32]{0} %get-tuple-element.331, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.333, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.338 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %reduce-scatter.337), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.341 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.338, bf16[32]{0} %get-tuple-element.338), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.342 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.348 = bf16[] reduce(bf16[32]{0} %multiply.341, bf16[] %constant.342), dimensions={0}, to_apply=%AddComputation.344, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.349 = bf16[] sqrt(bf16[] %reduce.348), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.351 = bf16[] multiply(bf16[] %sqrt.349, bf16[] %sqrt.349), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.6 = bf16[1]{0} reshape(bf16[] %multiply.351), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.435 = bf16[1]{0} add(bf16[1]{0} %add.433, bf16[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %get-tuple-element.306 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-reduce.63), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %reduce-scatter.312 = (bf16[32]{0}, bf16[]) reduce-scatter(bf16[32]{0} %get-tuple-element.306, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.308, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.313 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %reduce-scatter.312), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.316 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.313, bf16[32]{0} %get-tuple-element.313), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.317 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.323 = bf16[] reduce(bf16[32]{0} %multiply.316, bf16[] %constant.317), dimensions={0}, to_apply=%AddComputation.319, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.324 = bf16[] sqrt(bf16[] %reduce.323), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.326 = bf16[] multiply(bf16[] %sqrt.324, bf16[] %sqrt.324), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.7 = bf16[1]{0} reshape(bf16[] %multiply.326), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %add.437 = bf16[1]{0} add(bf16[1]{0} %add.435, bf16[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=128}
  %p15.301 = bf16[] parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %reshape.8 = bf16[1]{0} reshape(bf16[] %p15.301), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %divide.439 = bf16[1]{0} divide(bf16[1]{0} %add.437, bf16[1]{0} %reshape.8), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %multiply.290 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %get-tuple-element.287, bf16[24,32]{1,0} %get-tuple-element.287), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.291 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.297 = bf16[] reduce(bf16[24,32]{1,0} %multiply.290, bf16[] %constant.291), dimensions={0,1}, to_apply=%AddComputation.293, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.298 = bf16[] sqrt(bf16[] %reduce.297), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.300 = bf16[] multiply(bf16[] %sqrt.298, bf16[] %sqrt.298), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.9 = bf16[1]{0} reshape(bf16[] %multiply.300), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.441 = bf16[1]{0} add(bf16[1]{0} %divide.439, bf16[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p13.251 = bf16[32,8]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.260 = (bf16[32,8]{1,0}, bf16[]) reduce-scatter(bf16[32,8]{1,0} %p13.251, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.256, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.261 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %reduce-scatter.260), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.264 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.261, bf16[32,8]{1,0} %get-tuple-element.261), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.265 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.271 = bf16[] reduce(bf16[32,8]{1,0} %multiply.264, bf16[] %constant.265), dimensions={0,1}, to_apply=%AddComputation.267, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.272 = bf16[] sqrt(bf16[] %reduce.271), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.274 = bf16[] multiply(bf16[] %sqrt.272, bf16[] %sqrt.272), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.10 = bf16[1]{0} reshape(bf16[] %multiply.274), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.443 = bf16[1]{0} add(bf16[1]{0} %add.441, bf16[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p12.225 = bf16[16,32]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.234 = (bf16[16,32]{1,0}, bf16[]) reduce-scatter(bf16[16,32]{1,0} %p12.225, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.230, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.235 = bf16[16,32]{1,0} get-tuple-element((bf16[16,32]{1,0}, bf16[]) %reduce-scatter.234), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.238 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %get-tuple-element.235, bf16[16,32]{1,0} %get-tuple-element.235), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.239 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.245 = bf16[] reduce(bf16[16,32]{1,0} %multiply.238, bf16[] %constant.239), dimensions={0,1}, to_apply=%AddComputation.241, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.246 = bf16[] sqrt(bf16[] %reduce.245), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.248 = bf16[] multiply(bf16[] %sqrt.246, bf16[] %sqrt.246), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.11 = bf16[1]{0} reshape(bf16[] %multiply.248), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.445 = bf16[1]{0} add(bf16[1]{0} %add.443, bf16[1]{0} %reshape.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p11.199 = bf16[32,8]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.208 = (bf16[32,8]{1,0}, bf16[]) reduce-scatter(bf16[32,8]{1,0} %p11.199, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.204, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.209 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %reduce-scatter.208), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.212 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.209, bf16[32,8]{1,0} %get-tuple-element.209), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.213 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.219 = bf16[] reduce(bf16[32,8]{1,0} %multiply.212, bf16[] %constant.213), dimensions={0,1}, to_apply=%AddComputation.215, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.220 = bf16[] sqrt(bf16[] %reduce.219), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.222 = bf16[] multiply(bf16[] %sqrt.220, bf16[] %sqrt.220), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.12 = bf16[1]{0} reshape(bf16[] %multiply.222), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.447 = bf16[1]{0} add(bf16[1]{0} %add.445, bf16[1]{0} %reshape.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p10.173 = bf16[24,32]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.182 = (bf16[24,32]{1,0}, bf16[]) reduce-scatter(bf16[24,32]{1,0} %p10.173, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.178, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.183 = bf16[24,32]{1,0} get-tuple-element((bf16[24,32]{1,0}, bf16[]) %reduce-scatter.182), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.186 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %get-tuple-element.183, bf16[24,32]{1,0} %get-tuple-element.183), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.187 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.193 = bf16[] reduce(bf16[24,32]{1,0} %multiply.186, bf16[] %constant.187), dimensions={0,1}, to_apply=%AddComputation.189, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.194 = bf16[] sqrt(bf16[] %reduce.193), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.196 = bf16[] multiply(bf16[] %sqrt.194, bf16[] %sqrt.194), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.196), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.449 = bf16[1]{0} add(bf16[1]{0} %add.447, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p9.147 = bf16[32,8]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.156 = (bf16[32,8]{1,0}, bf16[]) reduce-scatter(bf16[32,8]{1,0} %p9.147, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.152, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.157 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %reduce-scatter.156), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.160 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.157, bf16[32,8]{1,0} %get-tuple-element.157), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.161 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.167 = bf16[] reduce(bf16[32,8]{1,0} %multiply.160, bf16[] %constant.161), dimensions={0,1}, to_apply=%AddComputation.163, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.168 = bf16[] sqrt(bf16[] %reduce.167), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.170 = bf16[] multiply(bf16[] %sqrt.168, bf16[] %sqrt.168), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %multiply.170), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.451 = bf16[1]{0} add(bf16[1]{0} %add.449, bf16[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p8.121 = bf16[16,32]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.130 = (bf16[16,32]{1,0}, bf16[]) reduce-scatter(bf16[16,32]{1,0} %p8.121, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.126, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.131 = bf16[16,32]{1,0} get-tuple-element((bf16[16,32]{1,0}, bf16[]) %reduce-scatter.130), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.134 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %get-tuple-element.131, bf16[16,32]{1,0} %get-tuple-element.131), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.135 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.141 = bf16[] reduce(bf16[16,32]{1,0} %multiply.134, bf16[] %constant.135), dimensions={0,1}, to_apply=%AddComputation.137, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.142 = bf16[] sqrt(bf16[] %reduce.141), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.144 = bf16[] multiply(bf16[] %sqrt.142, bf16[] %sqrt.142), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.15 = bf16[1]{0} reshape(bf16[] %multiply.144), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.453 = bf16[1]{0} add(bf16[1]{0} %add.451, bf16[1]{0} %reshape.15), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p7.95 = bf16[32,8]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.104 = (bf16[32,8]{1,0}, bf16[]) reduce-scatter(bf16[32,8]{1,0} %p7.95, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.100, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.105 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %reduce-scatter.104), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.108 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.105, bf16[32,8]{1,0} %get-tuple-element.105), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.109 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.115 = bf16[] reduce(bf16[32,8]{1,0} %multiply.108, bf16[] %constant.109), dimensions={0,1}, to_apply=%AddComputation.111, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.116 = bf16[] sqrt(bf16[] %reduce.115), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.118 = bf16[] multiply(bf16[] %sqrt.116, bf16[] %sqrt.116), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.16 = bf16[1]{0} reshape(bf16[] %multiply.118), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.455 = bf16[1]{0} add(bf16[1]{0} %add.453, bf16[1]{0} %reshape.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %p6.69 = bf16[8000,32]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %reduce-scatter.78 = (bf16[8000,32]{1,0}, bf16[]) reduce-scatter(bf16[8000,32]{1,0} %p6.69, bf16[] %get-tuple-element.461), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, to_apply=%AddComputation.74, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %get-tuple-element.79 = bf16[8000,32]{1,0} get-tuple-element((bf16[8000,32]{1,0}, bf16[]) %reduce-scatter.78), index=0, metadata={op_type="xla__reduce_scatter" op_name="xla__reduce_scatter" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=825}
  %multiply.82 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %get-tuple-element.79, bf16[8000,32]{1,0} %get-tuple-element.79), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %constant.83 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %reduce.89 = bf16[] reduce(bf16[8000,32]{1,0} %multiply.82, bf16[] %constant.83), dimensions={0,1}, to_apply=%AddComputation.85, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %sqrt.90 = bf16[] sqrt(bf16[] %reduce.89), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/kahfi/pytorch/torch/functional.py" source_line=1624}
  %multiply.92 = bf16[] multiply(bf16[] %sqrt.90, bf16[] %sqrt.90), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=40}
  %reshape.17 = bf16[1]{0} reshape(bf16[] %multiply.92), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %add.457 = bf16[1]{0} add(bf16[1]{0} %add.455, bf16[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=133}
  %all-reduce.466 = (bf16[1]{0}, bf16[]) all-reduce(bf16[1]{0} %add.457, bf16[] %get-tuple-element.461), replica_groups={}, to_apply=%AddComputation.462, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.467 = bf16[1]{0} get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.466), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %constant.1 = bf16[1]{0} constant({0.5})
  %power.486 = bf16[1]{0} power(bf16[1]{0} %get-tuple-element.467, bf16[1]{0} %constant.1), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=136}
  %p21.481 = bf16[] parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %reshape.19 = bf16[1]{0} reshape(bf16[] %p21.481), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %add.488 = bf16[1]{0} add(bf16[1]{0} %power.486, bf16[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=187}
  %divide.491 = bf16[1]{0} divide(bf16[1]{0} %constant, bf16[1]{0} %add.488), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/kahfi/pytorch/torch/_tensor.py" source_line=913}
  %constant.43 = bf16[1]{0} constant({1})
  %compare.498 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.43), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.44 = bf16[1]{0} constant({1})
  %select.500 = bf16[1]{0} select(pred[1]{0} %compare.498, bf16[1]{0} %divide.491, bf16[1]{0} %constant.44), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.502 = bf16[] reshape(bf16[1]{0} %select.500), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.504 = bf16[24,32]{1,0} broadcast(bf16[] %reshape.502), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.505 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %get-tuple-element.287, bf16[24,32]{1,0} %broadcast.504), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %p24.520 = bf16[] parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.524 = bf16[24,32]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.525 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.505, bf16[24,32]{1,0} %broadcast.524), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.530 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %multiply.529, bf16[24,32]{1,0} %multiply.525), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p23.507 = bf16[24,32]{1,0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p22.506 = bf16[] parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.508 = bf16[24,32]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.509 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p23.507, bf16[24,32]{1,0} %broadcast.508), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.511 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.505, bf16[24,32]{1,0} %multiply.505), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p20.475 = f32[] parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.510 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.512 = bf16[24,32]{1,0} broadcast(bf16[] %convert.510), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.513 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.511, bf16[24,32]{1,0} %broadcast.512), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.514 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %multiply.509, bf16[24,32]{1,0} %multiply.513), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.515 = bf16[24,32]{1,0} sqrt(bf16[24,32]{1,0} %add.514), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p19.474 = bf16[] parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.516 = bf16[24,32]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.517 = bf16[24,32]{1,0} divide(bf16[24,32]{1,0} %sqrt.515, bf16[24,32]{1,0} %broadcast.516), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p18.472 = bf16[] parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.518 = bf16[24,32]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.519 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %divide.517, bf16[24,32]{1,0} %broadcast.518), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.546 = bf16[24,32]{1,0} divide(bf16[24,32]{1,0} %add.530, bf16[24,32]{1,0} %add.519), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p17.470 = f32[] parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.545 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.547 = bf16[24,32]{1,0} broadcast(bf16[] %convert.545), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.548 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %divide.546, bf16[24,32]{1,0} %broadcast.547), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.549 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %subtract.544, bf16[24,32]{1,0} %multiply.548), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.553 = bf16[] get-tuple-element((bf16[1]{0}, bf16[]) %all-reduce.466), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=484}
  %all-gather.554 = (bf16[24,32]{1,0}, bf16[]) all-gather(bf16[24,32]{1,0} %add.549, bf16[] %get-tuple-element.553), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.555 = bf16[24,32]{1,0} get-tuple-element((bf16[24,32]{1,0}, bf16[]) %all-gather.554), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p32.603 = bf16[32,8]{1,0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.604 = bf16[32,8]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.605 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p32.603, bf16[32,8]{1,0} %broadcast.604), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.606 = bf16[32,8]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.608 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.605, bf16[32,8]{1,0} %broadcast.606), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.609 = bf16[32,8]{1,0} subtract(bf16[32,8]{1,0} %p32.603, bf16[32,8]{1,0} %multiply.608), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p31.594 = bf16[32,8]{1,0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.595 = bf16[32,8]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.596 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p31.594, bf16[32,8]{1,0} %broadcast.595), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.40 = bf16[1]{0} constant({1})
  %compare.568 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.40), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.41 = bf16[1]{0} constant({1})
  %select.570 = bf16[1]{0} select(pred[1]{0} %compare.568, bf16[1]{0} %divide.491, bf16[1]{0} %constant.41), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.572 = bf16[] reshape(bf16[1]{0} %select.570), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.574 = bf16[32,8]{1,0} broadcast(bf16[] %reshape.572), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.575 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.261, bf16[32,8]{1,0} %broadcast.574), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.592 = bf16[32,8]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.593 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.575, bf16[32,8]{1,0} %broadcast.592), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.597 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.596, bf16[32,8]{1,0} %multiply.593), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p30.576 = bf16[32,8]{1,0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.577 = bf16[32,8]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.578 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p30.576, bf16[32,8]{1,0} %broadcast.577), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.580 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.575, bf16[32,8]{1,0} %multiply.575), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.579 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.581 = bf16[32,8]{1,0} broadcast(bf16[] %convert.579), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.582 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.580, bf16[32,8]{1,0} %broadcast.581), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.583 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.578, bf16[32,8]{1,0} %multiply.582), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.584 = bf16[32,8]{1,0} sqrt(bf16[32,8]{1,0} %add.583), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.585 = bf16[32,8]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.586 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %sqrt.584, bf16[32,8]{1,0} %broadcast.585), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.587 = bf16[32,8]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.588 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %divide.586, bf16[32,8]{1,0} %broadcast.587), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.611 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %add.597, bf16[32,8]{1,0} %add.588), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.610 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.612 = bf16[32,8]{1,0} broadcast(bf16[] %convert.610), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.613 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %divide.611, bf16[32,8]{1,0} %broadcast.612), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.614 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %subtract.609, bf16[32,8]{1,0} %multiply.613), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.618 = bf16[] get-tuple-element((bf16[24,32]{1,0}, bf16[]) %all-gather.554), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.619 = (bf16[32,8]{1,0}, bf16[]) all-gather(bf16[32,8]{1,0} %add.614, bf16[] %get-tuple-element.618), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.620 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.619), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p35.668 = bf16[16,32]{1,0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.669 = bf16[16,32]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.670 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p35.668, bf16[16,32]{1,0} %broadcast.669), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.671 = bf16[16,32]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.673 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.670, bf16[16,32]{1,0} %broadcast.671), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.674 = bf16[16,32]{1,0} subtract(bf16[16,32]{1,0} %p35.668, bf16[16,32]{1,0} %multiply.673), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p34.659 = bf16[16,32]{1,0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.660 = bf16[16,32]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.661 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p34.659, bf16[16,32]{1,0} %broadcast.660), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.37 = bf16[1]{0} constant({1})
  %compare.633 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.38 = bf16[1]{0} constant({1})
  %select.635 = bf16[1]{0} select(pred[1]{0} %compare.633, bf16[1]{0} %divide.491, bf16[1]{0} %constant.38), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.637 = bf16[] reshape(bf16[1]{0} %select.635), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.639 = bf16[16,32]{1,0} broadcast(bf16[] %reshape.637), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.640 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %get-tuple-element.235, bf16[16,32]{1,0} %broadcast.639), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.657 = bf16[16,32]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.658 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.640, bf16[16,32]{1,0} %broadcast.657), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.662 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %multiply.661, bf16[16,32]{1,0} %multiply.658), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p33.641 = bf16[16,32]{1,0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.642 = bf16[16,32]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.643 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p33.641, bf16[16,32]{1,0} %broadcast.642), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.645 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.640, bf16[16,32]{1,0} %multiply.640), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.644 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.646 = bf16[16,32]{1,0} broadcast(bf16[] %convert.644), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.647 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.645, bf16[16,32]{1,0} %broadcast.646), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.648 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %multiply.643, bf16[16,32]{1,0} %multiply.647), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.649 = bf16[16,32]{1,0} sqrt(bf16[16,32]{1,0} %add.648), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.650 = bf16[16,32]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.651 = bf16[16,32]{1,0} divide(bf16[16,32]{1,0} %sqrt.649, bf16[16,32]{1,0} %broadcast.650), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.652 = bf16[16,32]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.653 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %divide.651, bf16[16,32]{1,0} %broadcast.652), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.676 = bf16[16,32]{1,0} divide(bf16[16,32]{1,0} %add.662, bf16[16,32]{1,0} %add.653), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.675 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.677 = bf16[16,32]{1,0} broadcast(bf16[] %convert.675), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.678 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %divide.676, bf16[16,32]{1,0} %broadcast.677), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.679 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %subtract.674, bf16[16,32]{1,0} %multiply.678), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.683 = bf16[] get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.619), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.684 = (bf16[16,32]{1,0}, bf16[]) all-gather(bf16[16,32]{1,0} %add.679, bf16[] %get-tuple-element.683), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.685 = bf16[16,32]{1,0} get-tuple-element((bf16[16,32]{1,0}, bf16[]) %all-gather.684), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p38.733 = bf16[32,8]{1,0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.734 = bf16[32,8]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.735 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p38.733, bf16[32,8]{1,0} %broadcast.734), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.736 = bf16[32,8]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.738 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.735, bf16[32,8]{1,0} %broadcast.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.739 = bf16[32,8]{1,0} subtract(bf16[32,8]{1,0} %p38.733, bf16[32,8]{1,0} %multiply.738), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p37.724 = bf16[32,8]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.725 = bf16[32,8]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.726 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p37.724, bf16[32,8]{1,0} %broadcast.725), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.34 = bf16[1]{0} constant({1})
  %compare.698 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.34), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.35 = bf16[1]{0} constant({1})
  %select.700 = bf16[1]{0} select(pred[1]{0} %compare.698, bf16[1]{0} %divide.491, bf16[1]{0} %constant.35), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.702 = bf16[] reshape(bf16[1]{0} %select.700), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.704 = bf16[32,8]{1,0} broadcast(bf16[] %reshape.702), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.705 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.209, bf16[32,8]{1,0} %broadcast.704), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.722 = bf16[32,8]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.723 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.705, bf16[32,8]{1,0} %broadcast.722), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.727 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.726, bf16[32,8]{1,0} %multiply.723), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p36.706 = bf16[32,8]{1,0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.707 = bf16[32,8]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.708 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p36.706, bf16[32,8]{1,0} %broadcast.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.710 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.705, bf16[32,8]{1,0} %multiply.705), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.709 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.711 = bf16[32,8]{1,0} broadcast(bf16[] %convert.709), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.712 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.710, bf16[32,8]{1,0} %broadcast.711), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.713 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.708, bf16[32,8]{1,0} %multiply.712), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.714 = bf16[32,8]{1,0} sqrt(bf16[32,8]{1,0} %add.713), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.715 = bf16[32,8]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.716 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %sqrt.714, bf16[32,8]{1,0} %broadcast.715), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.717 = bf16[32,8]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.718 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %divide.716, bf16[32,8]{1,0} %broadcast.717), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.741 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %add.727, bf16[32,8]{1,0} %add.718), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.740 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.742 = bf16[32,8]{1,0} broadcast(bf16[] %convert.740), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.743 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %divide.741, bf16[32,8]{1,0} %broadcast.742), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.744 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %subtract.739, bf16[32,8]{1,0} %multiply.743), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.748 = bf16[] get-tuple-element((bf16[16,32]{1,0}, bf16[]) %all-gather.684), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.749 = (bf16[32,8]{1,0}, bf16[]) all-gather(bf16[32,8]{1,0} %add.744, bf16[] %get-tuple-element.748), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.750 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.749), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p41.797 = bf16[32]{0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.798 = bf16[32]{0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.799 = bf16[32]{0} multiply(bf16[32]{0} %p41.797, bf16[32]{0} %broadcast.798), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.800 = bf16[32]{0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.802 = bf16[32]{0} multiply(bf16[32]{0} %multiply.799, bf16[32]{0} %broadcast.800), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.803 = bf16[32]{0} subtract(bf16[32]{0} %p41.797, bf16[32]{0} %multiply.802), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p40.788 = bf16[32]{0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.789 = bf16[32]{0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.790 = bf16[32]{0} multiply(bf16[32]{0} %p40.788, bf16[32]{0} %broadcast.789), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.31 = bf16[1]{0} constant({1})
  %compare.763 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.31), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.32 = bf16[1]{0} constant({1})
  %select.765 = bf16[1]{0} select(pred[1]{0} %compare.763, bf16[1]{0} %divide.491, bf16[1]{0} %constant.32), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.767 = bf16[] reshape(bf16[1]{0} %select.765), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.768 = bf16[32]{0} broadcast(bf16[] %reshape.767), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.769 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.413, bf16[32]{0} %broadcast.768), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.786 = bf16[32]{0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.787 = bf16[32]{0} multiply(bf16[32]{0} %multiply.769, bf16[32]{0} %broadcast.786), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.791 = bf16[32]{0} add(bf16[32]{0} %multiply.790, bf16[32]{0} %multiply.787), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p39.770 = bf16[32]{0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.771 = bf16[32]{0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.772 = bf16[32]{0} multiply(bf16[32]{0} %p39.770, bf16[32]{0} %broadcast.771), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.774 = bf16[32]{0} multiply(bf16[32]{0} %multiply.769, bf16[32]{0} %multiply.769), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.773 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.775 = bf16[32]{0} broadcast(bf16[] %convert.773), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.776 = bf16[32]{0} multiply(bf16[32]{0} %multiply.774, bf16[32]{0} %broadcast.775), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.777 = bf16[32]{0} add(bf16[32]{0} %multiply.772, bf16[32]{0} %multiply.776), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.778 = bf16[32]{0} sqrt(bf16[32]{0} %add.777), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.779 = bf16[32]{0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.780 = bf16[32]{0} divide(bf16[32]{0} %sqrt.778, bf16[32]{0} %broadcast.779), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.781 = bf16[32]{0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.782 = bf16[32]{0} add(bf16[32]{0} %divide.780, bf16[32]{0} %broadcast.781), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.805 = bf16[32]{0} divide(bf16[32]{0} %add.791, bf16[32]{0} %add.782), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.804 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.806 = bf16[32]{0} broadcast(bf16[] %convert.804), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.807 = bf16[32]{0} multiply(bf16[32]{0} %divide.805, bf16[32]{0} %broadcast.806), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.808 = bf16[32]{0} add(bf16[32]{0} %subtract.803, bf16[32]{0} %multiply.807), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.812 = bf16[] get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.749), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.813 = (bf16[32]{0}, bf16[]) all-gather(bf16[32]{0} %add.808, bf16[] %get-tuple-element.812), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.814 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.813), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p44.861 = bf16[32]{0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.862 = bf16[32]{0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.863 = bf16[32]{0} multiply(bf16[32]{0} %p44.861, bf16[32]{0} %broadcast.862), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.864 = bf16[32]{0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.866 = bf16[32]{0} multiply(bf16[32]{0} %multiply.863, bf16[32]{0} %broadcast.864), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.867 = bf16[32]{0} subtract(bf16[32]{0} %p44.861, bf16[32]{0} %multiply.866), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p43.852 = bf16[32]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.853 = bf16[32]{0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.854 = bf16[32]{0} multiply(bf16[32]{0} %p43.852, bf16[32]{0} %broadcast.853), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.28 = bf16[1]{0} constant({1})
  %compare.827 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.28), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.29 = bf16[1]{0} constant({1})
  %select.829 = bf16[1]{0} select(pred[1]{0} %compare.827, bf16[1]{0} %divide.491, bf16[1]{0} %constant.29), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.831 = bf16[] reshape(bf16[1]{0} %select.829), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.832 = bf16[32]{0} broadcast(bf16[] %reshape.831), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.833 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.388, bf16[32]{0} %broadcast.832), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.850 = bf16[32]{0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.851 = bf16[32]{0} multiply(bf16[32]{0} %multiply.833, bf16[32]{0} %broadcast.850), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.855 = bf16[32]{0} add(bf16[32]{0} %multiply.854, bf16[32]{0} %multiply.851), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p42.834 = bf16[32]{0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.835 = bf16[32]{0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.836 = bf16[32]{0} multiply(bf16[32]{0} %p42.834, bf16[32]{0} %broadcast.835), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.838 = bf16[32]{0} multiply(bf16[32]{0} %multiply.833, bf16[32]{0} %multiply.833), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.837 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.839 = bf16[32]{0} broadcast(bf16[] %convert.837), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.840 = bf16[32]{0} multiply(bf16[32]{0} %multiply.838, bf16[32]{0} %broadcast.839), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.841 = bf16[32]{0} add(bf16[32]{0} %multiply.836, bf16[32]{0} %multiply.840), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.842 = bf16[32]{0} sqrt(bf16[32]{0} %add.841), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.843 = bf16[32]{0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.844 = bf16[32]{0} divide(bf16[32]{0} %sqrt.842, bf16[32]{0} %broadcast.843), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.845 = bf16[32]{0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.846 = bf16[32]{0} add(bf16[32]{0} %divide.844, bf16[32]{0} %broadcast.845), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.869 = bf16[32]{0} divide(bf16[32]{0} %add.855, bf16[32]{0} %add.846), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.868 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.870 = bf16[32]{0} broadcast(bf16[] %convert.868), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.871 = bf16[32]{0} multiply(bf16[32]{0} %divide.869, bf16[32]{0} %broadcast.870), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.872 = bf16[32]{0} add(bf16[32]{0} %subtract.867, bf16[32]{0} %multiply.871), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.876 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.813), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.877 = (bf16[32]{0}, bf16[]) all-gather(bf16[32]{0} %add.872, bf16[] %get-tuple-element.876), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.878 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.877), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p47.926 = bf16[24,32]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.927 = bf16[24,32]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.928 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p47.926, bf16[24,32]{1,0} %broadcast.927), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.929 = bf16[24,32]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.931 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.928, bf16[24,32]{1,0} %broadcast.929), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.932 = bf16[24,32]{1,0} subtract(bf16[24,32]{1,0} %p47.926, bf16[24,32]{1,0} %multiply.931), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p46.917 = bf16[24,32]{1,0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.918 = bf16[24,32]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.919 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p46.917, bf16[24,32]{1,0} %broadcast.918), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.25 = bf16[1]{0} constant({1})
  %compare.891 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.26 = bf16[1]{0} constant({1})
  %select.893 = bf16[1]{0} select(pred[1]{0} %compare.891, bf16[1]{0} %divide.491, bf16[1]{0} %constant.26), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.895 = bf16[] reshape(bf16[1]{0} %select.893), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.897 = bf16[24,32]{1,0} broadcast(bf16[] %reshape.895), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.898 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %get-tuple-element.183, bf16[24,32]{1,0} %broadcast.897), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.915 = bf16[24,32]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.916 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.898, bf16[24,32]{1,0} %broadcast.915), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.920 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %multiply.919, bf16[24,32]{1,0} %multiply.916), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p45.899 = bf16[24,32]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.900 = bf16[24,32]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.901 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %p45.899, bf16[24,32]{1,0} %broadcast.900), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.903 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.898, bf16[24,32]{1,0} %multiply.898), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.902 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.904 = bf16[24,32]{1,0} broadcast(bf16[] %convert.902), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.905 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %multiply.903, bf16[24,32]{1,0} %broadcast.904), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.906 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %multiply.901, bf16[24,32]{1,0} %multiply.905), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.907 = bf16[24,32]{1,0} sqrt(bf16[24,32]{1,0} %add.906), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.908 = bf16[24,32]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.909 = bf16[24,32]{1,0} divide(bf16[24,32]{1,0} %sqrt.907, bf16[24,32]{1,0} %broadcast.908), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.910 = bf16[24,32]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.911 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %divide.909, bf16[24,32]{1,0} %broadcast.910), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.934 = bf16[24,32]{1,0} divide(bf16[24,32]{1,0} %add.920, bf16[24,32]{1,0} %add.911), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.933 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.935 = bf16[24,32]{1,0} broadcast(bf16[] %convert.933), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.936 = bf16[24,32]{1,0} multiply(bf16[24,32]{1,0} %divide.934, bf16[24,32]{1,0} %broadcast.935), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.937 = bf16[24,32]{1,0} add(bf16[24,32]{1,0} %subtract.932, bf16[24,32]{1,0} %multiply.936), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.941 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.877), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.942 = (bf16[24,32]{1,0}, bf16[]) all-gather(bf16[24,32]{1,0} %add.937, bf16[] %get-tuple-element.941), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.943 = bf16[24,32]{1,0} get-tuple-element((bf16[24,32]{1,0}, bf16[]) %all-gather.942), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p50.991 = bf16[32,8]{1,0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.992 = bf16[32,8]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.993 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p50.991, bf16[32,8]{1,0} %broadcast.992), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.994 = bf16[32,8]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.996 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.993, bf16[32,8]{1,0} %broadcast.994), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.997 = bf16[32,8]{1,0} subtract(bf16[32,8]{1,0} %p50.991, bf16[32,8]{1,0} %multiply.996), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p49.982 = bf16[32,8]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.983 = bf16[32,8]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.984 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p49.982, bf16[32,8]{1,0} %broadcast.983), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.22 = bf16[1]{0} constant({1})
  %compare.956 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.22), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.23 = bf16[1]{0} constant({1})
  %select.958 = bf16[1]{0} select(pred[1]{0} %compare.956, bf16[1]{0} %divide.491, bf16[1]{0} %constant.23), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.960 = bf16[] reshape(bf16[1]{0} %select.958), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.962 = bf16[32,8]{1,0} broadcast(bf16[] %reshape.960), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.963 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.157, bf16[32,8]{1,0} %broadcast.962), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.980 = bf16[32,8]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.981 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.963, bf16[32,8]{1,0} %broadcast.980), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.985 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.984, bf16[32,8]{1,0} %multiply.981), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p48.964 = bf16[32,8]{1,0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.965 = bf16[32,8]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.966 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p48.964, bf16[32,8]{1,0} %broadcast.965), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.968 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.963, bf16[32,8]{1,0} %multiply.963), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.967 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.969 = bf16[32,8]{1,0} broadcast(bf16[] %convert.967), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.970 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.968, bf16[32,8]{1,0} %broadcast.969), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.971 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.966, bf16[32,8]{1,0} %multiply.970), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.972 = bf16[32,8]{1,0} sqrt(bf16[32,8]{1,0} %add.971), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.973 = bf16[32,8]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.974 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %sqrt.972, bf16[32,8]{1,0} %broadcast.973), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.975 = bf16[32,8]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.976 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %divide.974, bf16[32,8]{1,0} %broadcast.975), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.999 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %add.985, bf16[32,8]{1,0} %add.976), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.998 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1000 = bf16[32,8]{1,0} broadcast(bf16[] %convert.998), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1001 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %divide.999, bf16[32,8]{1,0} %broadcast.1000), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1002 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %subtract.997, bf16[32,8]{1,0} %multiply.1001), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1006 = bf16[] get-tuple-element((bf16[24,32]{1,0}, bf16[]) %all-gather.942), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1007 = (bf16[32,8]{1,0}, bf16[]) all-gather(bf16[32,8]{1,0} %add.1002, bf16[] %get-tuple-element.1006), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1008 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.1007), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p53.1056 = bf16[16,32]{1,0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1057 = bf16[16,32]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1058 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p53.1056, bf16[16,32]{1,0} %broadcast.1057), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1059 = bf16[16,32]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1061 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.1058, bf16[16,32]{1,0} %broadcast.1059), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1062 = bf16[16,32]{1,0} subtract(bf16[16,32]{1,0} %p53.1056, bf16[16,32]{1,0} %multiply.1061), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p52.1047 = bf16[16,32]{1,0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1048 = bf16[16,32]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1049 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p52.1047, bf16[16,32]{1,0} %broadcast.1048), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.19 = bf16[1]{0} constant({1})
  %compare.1021 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.19), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.20 = bf16[1]{0} constant({1})
  %select.1023 = bf16[1]{0} select(pred[1]{0} %compare.1021, bf16[1]{0} %divide.491, bf16[1]{0} %constant.20), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1025 = bf16[] reshape(bf16[1]{0} %select.1023), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1027 = bf16[16,32]{1,0} broadcast(bf16[] %reshape.1025), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1028 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %get-tuple-element.131, bf16[16,32]{1,0} %broadcast.1027), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1045 = bf16[16,32]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1046 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.1028, bf16[16,32]{1,0} %broadcast.1045), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1050 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %multiply.1049, bf16[16,32]{1,0} %multiply.1046), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p51.1029 = bf16[16,32]{1,0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1030 = bf16[16,32]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1031 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %p51.1029, bf16[16,32]{1,0} %broadcast.1030), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1033 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.1028, bf16[16,32]{1,0} %multiply.1028), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1032 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1034 = bf16[16,32]{1,0} broadcast(bf16[] %convert.1032), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1035 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %multiply.1033, bf16[16,32]{1,0} %broadcast.1034), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1036 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %multiply.1031, bf16[16,32]{1,0} %multiply.1035), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1037 = bf16[16,32]{1,0} sqrt(bf16[16,32]{1,0} %add.1036), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1038 = bf16[16,32]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1039 = bf16[16,32]{1,0} divide(bf16[16,32]{1,0} %sqrt.1037, bf16[16,32]{1,0} %broadcast.1038), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1040 = bf16[16,32]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1041 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %divide.1039, bf16[16,32]{1,0} %broadcast.1040), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1064 = bf16[16,32]{1,0} divide(bf16[16,32]{1,0} %add.1050, bf16[16,32]{1,0} %add.1041), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1063 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1065 = bf16[16,32]{1,0} broadcast(bf16[] %convert.1063), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1066 = bf16[16,32]{1,0} multiply(bf16[16,32]{1,0} %divide.1064, bf16[16,32]{1,0} %broadcast.1065), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1067 = bf16[16,32]{1,0} add(bf16[16,32]{1,0} %subtract.1062, bf16[16,32]{1,0} %multiply.1066), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1071 = bf16[] get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.1007), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1072 = (bf16[16,32]{1,0}, bf16[]) all-gather(bf16[16,32]{1,0} %add.1067, bf16[] %get-tuple-element.1071), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1073 = bf16[16,32]{1,0} get-tuple-element((bf16[16,32]{1,0}, bf16[]) %all-gather.1072), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p56.1121 = bf16[32,8]{1,0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1122 = bf16[32,8]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1123 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p56.1121, bf16[32,8]{1,0} %broadcast.1122), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1124 = bf16[32,8]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1126 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.1123, bf16[32,8]{1,0} %broadcast.1124), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1127 = bf16[32,8]{1,0} subtract(bf16[32,8]{1,0} %p56.1121, bf16[32,8]{1,0} %multiply.1126), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p55.1112 = bf16[32,8]{1,0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1113 = bf16[32,8]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1114 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p55.1112, bf16[32,8]{1,0} %broadcast.1113), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.16 = bf16[1]{0} constant({1})
  %compare.1086 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.16), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.17 = bf16[1]{0} constant({1})
  %select.1088 = bf16[1]{0} select(pred[1]{0} %compare.1086, bf16[1]{0} %divide.491, bf16[1]{0} %constant.17), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1090 = bf16[] reshape(bf16[1]{0} %select.1088), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1092 = bf16[32,8]{1,0} broadcast(bf16[] %reshape.1090), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1093 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %get-tuple-element.105, bf16[32,8]{1,0} %broadcast.1092), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1110 = bf16[32,8]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1111 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.1093, bf16[32,8]{1,0} %broadcast.1110), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1115 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.1114, bf16[32,8]{1,0} %multiply.1111), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p54.1094 = bf16[32,8]{1,0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1095 = bf16[32,8]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1096 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %p54.1094, bf16[32,8]{1,0} %broadcast.1095), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1098 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.1093, bf16[32,8]{1,0} %multiply.1093), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1097 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1099 = bf16[32,8]{1,0} broadcast(bf16[] %convert.1097), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1100 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %multiply.1098, bf16[32,8]{1,0} %broadcast.1099), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1101 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %multiply.1096, bf16[32,8]{1,0} %multiply.1100), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1102 = bf16[32,8]{1,0} sqrt(bf16[32,8]{1,0} %add.1101), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1103 = bf16[32,8]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1104 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %sqrt.1102, bf16[32,8]{1,0} %broadcast.1103), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1105 = bf16[32,8]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1106 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %divide.1104, bf16[32,8]{1,0} %broadcast.1105), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1129 = bf16[32,8]{1,0} divide(bf16[32,8]{1,0} %add.1115, bf16[32,8]{1,0} %add.1106), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1128 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1130 = bf16[32,8]{1,0} broadcast(bf16[] %convert.1128), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1131 = bf16[32,8]{1,0} multiply(bf16[32,8]{1,0} %divide.1129, bf16[32,8]{1,0} %broadcast.1130), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1132 = bf16[32,8]{1,0} add(bf16[32,8]{1,0} %subtract.1127, bf16[32,8]{1,0} %multiply.1131), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1136 = bf16[] get-tuple-element((bf16[16,32]{1,0}, bf16[]) %all-gather.1072), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1137 = (bf16[32,8]{1,0}, bf16[]) all-gather(bf16[32,8]{1,0} %add.1132, bf16[] %get-tuple-element.1136), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1138 = bf16[32,8]{1,0} get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.1137), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p59.1185 = bf16[32]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1186 = bf16[32]{0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1187 = bf16[32]{0} multiply(bf16[32]{0} %p59.1185, bf16[32]{0} %broadcast.1186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1188 = bf16[32]{0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1190 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1187, bf16[32]{0} %broadcast.1188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1191 = bf16[32]{0} subtract(bf16[32]{0} %p59.1185, bf16[32]{0} %multiply.1190), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p58.1176 = bf16[32]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1177 = bf16[32]{0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1178 = bf16[32]{0} multiply(bf16[32]{0} %p58.1176, bf16[32]{0} %broadcast.1177), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.13 = bf16[1]{0} constant({1})
  %compare.1151 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.13), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.14 = bf16[1]{0} constant({1})
  %select.1153 = bf16[1]{0} select(pred[1]{0} %compare.1151, bf16[1]{0} %divide.491, bf16[1]{0} %constant.14), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1155 = bf16[] reshape(bf16[1]{0} %select.1153), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1156 = bf16[32]{0} broadcast(bf16[] %reshape.1155), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1157 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.363, bf16[32]{0} %broadcast.1156), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1174 = bf16[32]{0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1175 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1157, bf16[32]{0} %broadcast.1174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1179 = bf16[32]{0} add(bf16[32]{0} %multiply.1178, bf16[32]{0} %multiply.1175), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p57.1158 = bf16[32]{0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1159 = bf16[32]{0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1160 = bf16[32]{0} multiply(bf16[32]{0} %p57.1158, bf16[32]{0} %broadcast.1159), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1162 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1157, bf16[32]{0} %multiply.1157), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1161 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1163 = bf16[32]{0} broadcast(bf16[] %convert.1161), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1164 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1162, bf16[32]{0} %broadcast.1163), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1165 = bf16[32]{0} add(bf16[32]{0} %multiply.1160, bf16[32]{0} %multiply.1164), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1166 = bf16[32]{0} sqrt(bf16[32]{0} %add.1165), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1167 = bf16[32]{0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1168 = bf16[32]{0} divide(bf16[32]{0} %sqrt.1166, bf16[32]{0} %broadcast.1167), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1169 = bf16[32]{0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1170 = bf16[32]{0} add(bf16[32]{0} %divide.1168, bf16[32]{0} %broadcast.1169), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1193 = bf16[32]{0} divide(bf16[32]{0} %add.1179, bf16[32]{0} %add.1170), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1192 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1194 = bf16[32]{0} broadcast(bf16[] %convert.1192), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1195 = bf16[32]{0} multiply(bf16[32]{0} %divide.1193, bf16[32]{0} %broadcast.1194), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1196 = bf16[32]{0} add(bf16[32]{0} %subtract.1191, bf16[32]{0} %multiply.1195), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1200 = bf16[] get-tuple-element((bf16[32,8]{1,0}, bf16[]) %all-gather.1137), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1201 = (bf16[32]{0}, bf16[]) all-gather(bf16[32]{0} %add.1196, bf16[] %get-tuple-element.1200), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1202 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1201), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p62.1249 = bf16[32]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1250 = bf16[32]{0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1251 = bf16[32]{0} multiply(bf16[32]{0} %p62.1249, bf16[32]{0} %broadcast.1250), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1252 = bf16[32]{0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1254 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1251, bf16[32]{0} %broadcast.1252), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1255 = bf16[32]{0} subtract(bf16[32]{0} %p62.1249, bf16[32]{0} %multiply.1254), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p61.1240 = bf16[32]{0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1241 = bf16[32]{0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1242 = bf16[32]{0} multiply(bf16[32]{0} %p61.1240, bf16[32]{0} %broadcast.1241), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.10 = bf16[1]{0} constant({1})
  %compare.1215 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.10), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.11 = bf16[1]{0} constant({1})
  %select.1217 = bf16[1]{0} select(pred[1]{0} %compare.1215, bf16[1]{0} %divide.491, bf16[1]{0} %constant.11), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1219 = bf16[] reshape(bf16[1]{0} %select.1217), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1220 = bf16[32]{0} broadcast(bf16[] %reshape.1219), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1221 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.338, bf16[32]{0} %broadcast.1220), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1238 = bf16[32]{0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1239 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1221, bf16[32]{0} %broadcast.1238), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1243 = bf16[32]{0} add(bf16[32]{0} %multiply.1242, bf16[32]{0} %multiply.1239), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p60.1222 = bf16[32]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1223 = bf16[32]{0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1224 = bf16[32]{0} multiply(bf16[32]{0} %p60.1222, bf16[32]{0} %broadcast.1223), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1226 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1221, bf16[32]{0} %multiply.1221), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1225 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1227 = bf16[32]{0} broadcast(bf16[] %convert.1225), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1228 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1226, bf16[32]{0} %broadcast.1227), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1229 = bf16[32]{0} add(bf16[32]{0} %multiply.1224, bf16[32]{0} %multiply.1228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1230 = bf16[32]{0} sqrt(bf16[32]{0} %add.1229), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1231 = bf16[32]{0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1232 = bf16[32]{0} divide(bf16[32]{0} %sqrt.1230, bf16[32]{0} %broadcast.1231), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1233 = bf16[32]{0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1234 = bf16[32]{0} add(bf16[32]{0} %divide.1232, bf16[32]{0} %broadcast.1233), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1257 = bf16[32]{0} divide(bf16[32]{0} %add.1243, bf16[32]{0} %add.1234), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1256 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1258 = bf16[32]{0} broadcast(bf16[] %convert.1256), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1259 = bf16[32]{0} multiply(bf16[32]{0} %divide.1257, bf16[32]{0} %broadcast.1258), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1260 = bf16[32]{0} add(bf16[32]{0} %subtract.1255, bf16[32]{0} %multiply.1259), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1264 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1201), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1265 = (bf16[32]{0}, bf16[]) all-gather(bf16[32]{0} %add.1260, bf16[] %get-tuple-element.1264), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1266 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1265), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p65.1313 = bf16[32]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1314 = bf16[32]{0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1315 = bf16[32]{0} multiply(bf16[32]{0} %p65.1313, bf16[32]{0} %broadcast.1314), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1316 = bf16[32]{0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1318 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1315, bf16[32]{0} %broadcast.1316), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1319 = bf16[32]{0} subtract(bf16[32]{0} %p65.1313, bf16[32]{0} %multiply.1318), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p64.1304 = bf16[32]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1305 = bf16[32]{0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1306 = bf16[32]{0} multiply(bf16[32]{0} %p64.1304, bf16[32]{0} %broadcast.1305), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.7 = bf16[1]{0} constant({1})
  %compare.1279 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.7), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.8 = bf16[1]{0} constant({1})
  %select.1281 = bf16[1]{0} select(pred[1]{0} %compare.1279, bf16[1]{0} %divide.491, bf16[1]{0} %constant.8), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1283 = bf16[] reshape(bf16[1]{0} %select.1281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1284 = bf16[32]{0} broadcast(bf16[] %reshape.1283), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1285 = bf16[32]{0} multiply(bf16[32]{0} %get-tuple-element.313, bf16[32]{0} %broadcast.1284), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1302 = bf16[32]{0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1303 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1285, bf16[32]{0} %broadcast.1302), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1307 = bf16[32]{0} add(bf16[32]{0} %multiply.1306, bf16[32]{0} %multiply.1303), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p63.1286 = bf16[32]{0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1287 = bf16[32]{0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1288 = bf16[32]{0} multiply(bf16[32]{0} %p63.1286, bf16[32]{0} %broadcast.1287), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1290 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1285, bf16[32]{0} %multiply.1285), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1289 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1291 = bf16[32]{0} broadcast(bf16[] %convert.1289), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1292 = bf16[32]{0} multiply(bf16[32]{0} %multiply.1290, bf16[32]{0} %broadcast.1291), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1293 = bf16[32]{0} add(bf16[32]{0} %multiply.1288, bf16[32]{0} %multiply.1292), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1294 = bf16[32]{0} sqrt(bf16[32]{0} %add.1293), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1295 = bf16[32]{0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1296 = bf16[32]{0} divide(bf16[32]{0} %sqrt.1294, bf16[32]{0} %broadcast.1295), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1297 = bf16[32]{0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1298 = bf16[32]{0} add(bf16[32]{0} %divide.1296, bf16[32]{0} %broadcast.1297), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1321 = bf16[32]{0} divide(bf16[32]{0} %add.1307, bf16[32]{0} %add.1298), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1320 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1322 = bf16[32]{0} broadcast(bf16[] %convert.1320), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1323 = bf16[32]{0} multiply(bf16[32]{0} %divide.1321, bf16[32]{0} %broadcast.1322), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1324 = bf16[32]{0} add(bf16[32]{0} %subtract.1319, bf16[32]{0} %multiply.1323), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1328 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1265), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1329 = (bf16[32]{0}, bf16[]) all-gather(bf16[32]{0} %add.1324, bf16[] %get-tuple-element.1328), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1330 = bf16[32]{0} get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1329), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %p68.1378 = bf16[8000,32]{1,0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1379 = bf16[8000,32]{1,0} broadcast(bf16[] %p28.537), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1380 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %p68.1378, bf16[8000,32]{1,0} %broadcast.1379), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.1381 = bf16[8000,32]{1,0} broadcast(bf16[] %p27.536), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.1383 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %multiply.1380, bf16[8000,32]{1,0} %broadcast.1381), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.1384 = bf16[8000,32]{1,0} subtract(bf16[8000,32]{1,0} %p68.1378, bf16[8000,32]{1,0} %multiply.1383), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p67.1369 = bf16[8000,32]{1,0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.1370 = bf16[8000,32]{1,0} broadcast(bf16[] %p25.526), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1371 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %p67.1369, bf16[8000,32]{1,0} %broadcast.1370), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.4 = bf16[1]{0} constant({1})
  %compare.1343 = pred[1]{0} compare(bf16[1]{0} %divide.491, bf16[1]{0} %constant.4), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %constant.5 = bf16[1]{0} constant({1})
  %select.1345 = bf16[1]{0} select(pred[1]{0} %compare.1343, bf16[1]{0} %divide.491, bf16[1]{0} %constant.5), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %reshape.1347 = bf16[] reshape(bf16[1]{0} %select.1345), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1349 = bf16[8000,32]{1,0} broadcast(bf16[] %reshape.1347), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %multiply.1350 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %get-tuple-element.79, bf16[8000,32]{1,0} %broadcast.1349), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=189}
  %broadcast.1367 = bf16[8000,32]{1,0} broadcast(bf16[] %p24.520), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.1368 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %multiply.1350, bf16[8000,32]{1,0} %broadcast.1367), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.1372 = bf16[8000,32]{1,0} add(bf16[8000,32]{1,0} %multiply.1371, bf16[8000,32]{1,0} %multiply.1368), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %p66.1351 = bf16[8000,32]{1,0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1352 = bf16[8000,32]{1,0} broadcast(bf16[] %p22.506), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1353 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %p66.1351, bf16[8000,32]{1,0} %broadcast.1352), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1355 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %multiply.1350, bf16[8000,32]{1,0} %multiply.1350), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %convert.1354 = bf16[] convert(f32[] %p20.475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.1356 = bf16[8000,32]{1,0} broadcast(bf16[] %convert.1354), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1357 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %multiply.1355, bf16[8000,32]{1,0} %broadcast.1356), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.1358 = bf16[8000,32]{1,0} add(bf16[8000,32]{1,0} %multiply.1353, bf16[8000,32]{1,0} %multiply.1357), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.1359 = bf16[8000,32]{1,0} sqrt(bf16[8000,32]{1,0} %add.1358), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1360 = bf16[8000,32]{1,0} broadcast(bf16[] %p19.474), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1361 = bf16[8000,32]{1,0} divide(bf16[8000,32]{1,0} %sqrt.1359, bf16[8000,32]{1,0} %broadcast.1360), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.1362 = bf16[8000,32]{1,0} broadcast(bf16[] %p18.472), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.1363 = bf16[8000,32]{1,0} add(bf16[8000,32]{1,0} %divide.1361, bf16[8000,32]{1,0} %broadcast.1362), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.1386 = bf16[8000,32]{1,0} divide(bf16[8000,32]{1,0} %add.1372, bf16[8000,32]{1,0} %add.1363), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %convert.1385 = bf16[] convert(f32[] %p17.470), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.1387 = bf16[8000,32]{1,0} broadcast(bf16[] %convert.1385), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.1388 = bf16[8000,32]{1,0} multiply(bf16[8000,32]{1,0} %divide.1386, bf16[8000,32]{1,0} %broadcast.1387), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.1389 = bf16[8000,32]{1,0} add(bf16[8000,32]{1,0} %subtract.1384, bf16[8000,32]{1,0} %multiply.1388), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/kahfi/xla-explore-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %get-tuple-element.1393 = bf16[] get-tuple-element((bf16[32]{0}, bf16[]) %all-gather.1329), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %all-gather.1394 = (bf16[8000,32]{1,0}, bf16[]) all-gather(bf16[8000,32]{1,0} %add.1389, bf16[] %get-tuple-element.1393), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %get-tuple-element.1395 = bf16[8000,32]{1,0} get-tuple-element((bf16[8000,32]{1,0}, bf16[]) %all-gather.1394), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/kahfi/xla_modified/pytorch/xla/torch_xla/core/xla_model.py" source_line=585}
  %constant.1399 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1403 = bf16[8000,32]{1,0} broadcast(bf16[] %constant.1399), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1404 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1408 = bf16[32]{0} broadcast(bf16[] %constant.1404), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1409 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1413 = bf16[32,8]{1,0} broadcast(bf16[] %constant.1409), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1414 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1418 = bf16[16,32]{1,0} broadcast(bf16[] %constant.1414), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1419 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1423 = bf16[32]{0} broadcast(bf16[] %constant.1419), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1424 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1428 = bf16[32,8]{1,0} broadcast(bf16[] %constant.1424), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1429 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1433 = bf16[24,32]{1,0} broadcast(bf16[] %constant.1429), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1434 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1438 = bf16[32]{0} broadcast(bf16[] %constant.1434), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1439 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1443 = bf16[32,8]{1,0} broadcast(bf16[] %constant.1439), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1444 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1448 = bf16[16,32]{1,0} broadcast(bf16[] %constant.1444), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1449 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1453 = bf16[32]{0} broadcast(bf16[] %constant.1449), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1454 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1458 = bf16[32,8]{1,0} broadcast(bf16[] %constant.1454), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1459 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1463 = bf16[24,32]{1,0} broadcast(bf16[] %constant.1459), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %constant.1464 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  %broadcast.1468 = bf16[32]{0} broadcast(bf16[] %constant.1464), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/kahfi/pytorch/torch/optim/optimizer.py" source_line=815}
  ROOT %tuple.1469 = (bf16[24,32]{1,0}, bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32,8]{1,0}, bf16[32]{0}, /*index=5*/bf16[32]{0}, bf16[24,32]{1,0}, bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32,8]{1,0}, /*index=10*/bf16[32]{0}, bf16[32]{0}, bf16[32]{0}, bf16[8000,32]{1,0}, bf16[24,32]{1,0}, /*index=15*/bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32,8]{1,0}, bf16[32]{0}, bf16[32]{0}, /*index=20*/bf16[24,32]{1,0}, bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32,8]{1,0}, bf16[32]{0}, /*index=25*/bf16[32]{0}, bf16[32]{0}, bf16[8000,32]{1,0}, bf16[8000,32]{1,0}, bf16[32]{0}, /*index=30*/bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32]{0}, bf16[32,8]{1,0}, bf16[24,32]{1,0}, /*index=35*/bf16[32]{0}, bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[32]{0}, bf16[32,8]{1,0}, /*index=40*/bf16[24,32]{1,0}, bf16[32]{0}, bf16[24,32]{1,0}, bf16[24,32]{1,0}, bf16[32,8]{1,0}, /*index=45*/bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[16,32]{1,0}, bf16[32,8]{1,0}, bf16[32,8]{1,0}, /*index=50*/bf16[32]{0}, bf16[32]{0}, bf16[32]{0}, bf16[32]{0}, bf16[24,32]{1,0}, /*index=55*/bf16[24,32]{1,0}, bf16[32,8]{1,0}, bf16[32,8]{1,0}, bf16[16,32]{1,0}, bf16[16,32]{1,0}, /*index=60*/bf16[32,8]{1,0}, bf16[32,8]{1,0}, bf16[32]{0}, bf16[32]{0}, bf16[32]{0}, /*index=65*/bf16[32]{0}, bf16[32]{0}, bf16[32]{0}, bf16[8000,32]{1,0}, bf16[8000,32]{1,0}, /*index=70*/bf16[1]{0}) tuple(bf16[24,32]{1,0} %get-tuple-element.555, bf16[32,8]{1,0} %get-tuple-element.620, bf16[16,32]{1,0} %get-tuple-element.685, bf16[32,8]{1,0} %get-tuple-element.750, bf16[32]{0} %get-tuple-element.814, /*index=5*/bf16[32]{0} %get-tuple-element.878, bf16[24,32]{1,0} %get-tuple-element.943, bf16[32,8]{1,0} %get-tuple-element.1008, bf16[16,32]{1,0} %get-tuple-element.1073, bf16[32,8]{1,0} %get-tuple-element.1138, /*index=10*/bf16[32]{0} %get-tuple-element.1202, bf16[32]{0} %get-tuple-element.1266, bf16[32]{0} %get-tuple-element.1330, bf16[8000,32]{1,0} %get-tuple-element.1395, bf16[24,32]{1,0} %add.549, /*index=15*/bf16[32,8]{1,0} %add.614, bf16[16,32]{1,0} %add.679, bf16[32,8]{1,0} %add.744, bf16[32]{0} %add.808, bf16[32]{0} %add.872, /*index=20*/bf16[24,32]{1,0} %add.937, bf16[32,8]{1,0} %add.1002, bf16[16,32]{1,0} %add.1067, bf16[32,8]{1,0} %add.1132, bf16[32]{0} %add.1196, /*index=25*/bf16[32]{0} %add.1260, bf16[32]{0} %add.1324, bf16[8000,32]{1,0} %add.1389, bf16[8000,32]{1,0} %broadcast.1403, bf16[32]{0} %broadcast.1408, /*index=30*/bf16[32,8]{1,0} %broadcast.1413, bf16[16,32]{1,0} %broadcast.1418, bf16[32]{0} %broadcast.1423, bf16[32,8]{1,0} %broadcast.1428, bf16[24,32]{1,0} %broadcast.1433, /*index=35*/bf16[32]{0} %broadcast.1438, bf16[32,8]{1,0} %broadcast.1443, bf16[16,32]{1,0} %broadcast.1448, bf16[32]{0} %broadcast.1453, bf16[32,8]{1,0} %broadcast.1458, /*index=40*/bf16[24,32]{1,0} %broadcast.1463, bf16[32]{0} %broadcast.1468, bf16[24,32]{1,0} %add.530, bf16[24,32]{1,0} %add.514, bf16[32,8]{1,0} %add.597, /*index=45*/bf16[32,8]{1,0} %add.583, bf16[16,32]{1,0} %add.662, bf16[16,32]{1,0} %add.648, bf16[32,8]{1,0} %add.727, bf16[32,8]{1,0} %add.713, /*index=50*/bf16[32]{0} %add.791, bf16[32]{0} %add.777, bf16[32]{0} %add.855, bf16[32]{0} %add.841, bf16[24,32]{1,0} %add.920, /*index=55*/bf16[24,32]{1,0} %add.906, bf16[32,8]{1,0} %add.985, bf16[32,8]{1,0} %add.971, bf16[16,32]{1,0} %add.1050, bf16[16,32]{1,0} %add.1036, /*index=60*/bf16[32,8]{1,0} %add.1115, bf16[32,8]{1,0} %add.1101, bf16[32]{0} %add.1179, bf16[32]{0} %add.1165, bf16[32]{0} %add.1243, /*index=65*/bf16[32]{0} %add.1229, bf16[32]{0} %add.1307, bf16[32]{0} %add.1293, bf16[8000,32]{1,0} %add.1372, bf16[8000,32]{1,0} %add.1358, /*index=70*/bf16[1]{0} %power.486), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70"}
}

`

export default text;
